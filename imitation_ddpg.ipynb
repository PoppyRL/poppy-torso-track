{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7c47c1b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import gym\n",
    "import numpy as np\n",
    "from gym import spaces\n",
    "from tqdm import tqdm\n",
    "import pandas as pd\n",
    "\n",
    "import numpy as np\n",
    "from utils.skeleton import *\n",
    "from utils.quaternion import *\n",
    "from utils.blazepose import blazepose_skeletons\n",
    "import os\n",
    "from pypot.creatures import PoppyTorso\n",
    "os.environ[\"KMP_DUPLICATE_LIB_OK\"]=\"TRUE\"\n",
    "#from pypot.creatures.ik import IKChain\n",
    "from pypot.primitive.move import Move\n",
    "from pypot.primitive.move import MovePlayer\n",
    "\n",
    "import sys\n",
    "sys.path.append('E:\\Anaconda\\envs\\gym-examples')\n",
    "import gym_examples\n",
    "from gym.wrappers import FlattenObservation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b0372c23",
   "metadata": {},
   "outputs": [],
   "source": [
    "from stable_baselines3 import DDPG\n",
    "from stable_baselines3.common.noise import NormalActionNoise, OrnsteinUhlenbeckActionNoise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "238796fd",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hello, I am Poppy!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "E:\\Anaconda\\lib\\site-packages\\gym\\spaces\\box.py:73: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "  logger.warn(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([ 0.1087558 , -0.17607144,  0.07120024, -0.10220377, -0.18020962,\n",
       "        0.07149935], dtype=float32)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "env = gym.make('gym_examples/Poppy-v0')\n",
    "env.reset()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "bd8c2cc6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from stable_baselines3.common.env_checker import check_env\n",
    "# check_env(env)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1f61b4a",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using cpu device\n",
      "Wrapping the env with a `Monitor` wrapper\n",
      "Wrapping the env in a DummyVecEnv.\n",
      "reward :  0\n",
      "current step :  5\n",
      "episode :  0\n",
      "reward :  0\n",
      "current step :  10\n",
      "episode :  0\n",
      "reward :  0.3422028856737369\n",
      "current step :  15\n",
      "episode :  0\n",
      "reward :  0.379022864041348\n",
      "current step :  20\n",
      "episode :  0\n",
      "reward :  0.3283921954623704\n",
      "current step :  25\n",
      "episode :  0\n",
      "reward :  0\n",
      "current step :  30\n",
      "episode :  0\n",
      "reward :  0\n",
      "current step :  35\n",
      "episode :  0\n",
      "reward :  0.3107943591540679\n",
      "current step :  40\n",
      "episode :  0\n",
      "reward :  0\n",
      "current step :  45\n",
      "episode :  0\n",
      "reward :  0\n",
      "current step :  50\n",
      "episode :  0\n",
      "reward :  0.3084668602649885\n",
      "current step :  55\n",
      "episode :  0\n",
      "reward :  0\n",
      "current step :  60\n",
      "episode :  0\n",
      "reward :  0\n",
      "current step :  65\n",
      "episode :  0\n",
      "reward :  0\n",
      "current step :  70\n",
      "episode :  0\n",
      "reward :  0\n",
      "current step :  75\n",
      "episode :  0\n",
      "reward :  0\n",
      "current step :  80\n",
      "episode :  0\n",
      "reward :  0\n",
      "current step :  85\n",
      "episode :  0\n",
      "reward :  0.35728403031129513\n",
      "current step :  90\n",
      "episode :  0\n",
      "reward :  0\n",
      "current step :  95\n",
      "episode :  0\n",
      "reward :  0.42301066841657387\n",
      "current step :  100\n",
      "episode :  0\n",
      "reward :  0.3198004158319875\n",
      "current step :  105\n",
      "episode :  0\n",
      "reward :  0\n",
      "current step :  110\n",
      "episode :  0\n",
      "reward :  0.3640223838551742\n",
      "current step :  115\n",
      "episode :  0\n",
      "reward :  0\n",
      "current step :  120\n",
      "episode :  0\n",
      "reward :  0\n",
      "current step :  125\n",
      "episode :  0\n",
      "reward :  0\n",
      "current step :  130\n",
      "episode :  0\n",
      "reward :  0\n",
      "current step :  135\n",
      "episode :  0\n",
      "reward :  0\n",
      "current step :  140\n",
      "episode :  0\n",
      "reward :  0.501241376218085\n",
      "current step :  145\n",
      "episode :  0\n",
      "reward :  0.3654908472452527\n",
      "current step :  150\n",
      "episode :  0\n",
      "reward :  0\n",
      "current step :  155\n",
      "episode :  0\n",
      "reward :  0\n",
      "current step :  160\n",
      "episode :  0\n",
      "reward :  0.27219375181395644\n",
      "current step :  165\n",
      "episode :  0\n",
      "reward :  0\n",
      "current step :  170\n",
      "episode :  0\n",
      "reward :  0.4663852972932718\n",
      "current step :  175\n",
      "episode :  0\n",
      "reward :  0\n",
      "current step :  180\n",
      "episode :  0\n",
      "reward :  0\n",
      "current step :  185\n",
      "episode :  0\n",
      "reward :  0.3388720479085546\n",
      "current step :  190\n",
      "episode :  0\n",
      "reward :  0.7421115017438606\n",
      "current step :  195\n",
      "episode :  0\n",
      "reward :  0\n",
      "current step :  200\n",
      "episode :  0\n",
      "reward :  0\n",
      "current step :  205\n",
      "episode :  0\n",
      "reward :  0.4223148443983379\n",
      "current step :  210\n",
      "episode :  0\n"
     ]
    }
   ],
   "source": [
    "from stable_baselines3 import DDPG\n",
    "from stable_baselines3.common.noise import NormalActionNoise, OrnsteinUhlenbeckActionNoise\n",
    "\n",
    "# The noise objects for DDPG\n",
    "n_actions = env.action_space.shape[-1]\n",
    "action_noise = NormalActionNoise(mean=np.zeros(n_actions), sigma=0.15 * np.ones(n_actions))\n",
    "\n",
    "model = DDPG(\"MlpPolicy\", env, action_noise=action_noise, verbose=1,batch_size = 57 )\n",
    "model.learn(total_timesteps= 57*10)\n",
    "\n",
    "info = pd.DataFrame(env.infos)\n",
    "info.to_pickle('info.pkl')\n",
    "# info = pd.read_pickle('info.pkl')\n",
    "\n",
    "model.save(\"ddpg_imitation\")\n",
    "vec_env = model.get_env()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11064308",
   "metadata": {},
   "source": [
    "For training, we can stop here. We can begin the test."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2949ac5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# model = DDPG.load(\"ddpg_imitation\")\n",
    "\n",
    "# obs = env.reset()\n",
    "\n",
    "# while True:\n",
    "#     action, _states = model.predict(obs)\n",
    "#     obs, rewards, dones, info = env.step(action)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67225732",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = DDPG.load(\"ddpg_imitation\")\n",
    "\n",
    "obs = vec_env.reset()\n",
    "while True:\n",
    "    action, _states = model.predict(obs)\n",
    "    obs, rewards, dones, info = vec_env.step(action)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21c93538",
   "metadata": {},
   "source": [
    "The below is just some other tials, you can ignore it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "800f0e03",
   "metadata": {},
   "outputs": [],
   "source": [
    "# obs = vec_env.reset()\n",
    "# # while True:\n",
    "# #     action, _states = model.predict(obs)\n",
    "# #     obs, rewards, dones, info = vec_env.step(action)\n",
    "\n",
    "# for t in env.targets:\n",
    "#     action, _states = model.predict(np.array(t.flatten()).reshape(1,-1))\n",
    "#     obs, rewards, dones, info = vec_env.step(action)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ba77d3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from stable_baselines3 import DDPG\n",
    "# from stable_baselines3.common.noise import NormalActionNoise, OrnsteinUhlenbeckActionNoise\n",
    "\n",
    "# #env = gym.make(\"Pendulum-v1\")\n",
    "\n",
    "# # The noise objects for DDPG\n",
    "# n_actions = env.action_space.shape[-1]\n",
    "# action_noise = NormalActionNoise(mean=np.zeros(n_actions), sigma=0.1 * np.ones(n_actions))\n",
    "\n",
    "# model = DDPG(\"MlpPolicy\", env, action_noise=action_noise, verbose=1)\n",
    "\n",
    "# model = DDPG.load(\"ddpg_imitation\")\n",
    "# model.get_env()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8d3088d",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "\n",
    "# for t in env.targets:\n",
    "#     action, _states = model.predict(np.array(t.flatten()).reshape(1,-1))\n",
    "#     obs, rewards, dones, info = env.step(action.flatten())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c314bfa5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12c688d0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9be1a0ae",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "479c4861",
   "metadata": {},
   "outputs": [],
   "source": [
    "info = pd.DataFrame(env.infos)\n",
    "info.to_pickle('info.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46c8828a",
   "metadata": {},
   "outputs": [],
   "source": [
    "info = pd.read_pickle('info.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "080a6f1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3042912",
   "metadata": {},
   "outputs": [],
   "source": [
    "t=[]\n",
    "for ep in info['episode'].unique():\n",
    "      t.append(info[info['episode']==ep]['reward'].mean())\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7a33923",
   "metadata": {},
   "outputs": [],
   "source": [
    "info['episode'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d669ece3",
   "metadata": {},
   "outputs": [],
   "source": [
    "t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c4d0e35",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22bea98a",
   "metadata": {},
   "outputs": [],
   "source": [
    "env.get_obs()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80057415",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.linalg.norm([1,1],1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e9eb6cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "env.reset()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5e17413",
   "metadata": {},
   "outputs": [],
   "source": [
    "env.reset()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01f414b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "env.poppy.l_shoulder_y.goto_position(-0,3,wait=True)\n",
    "env.poppy.l_shoulder_x.goto_position(0,3,wait=True)\n",
    "env.poppy.abs_z.goto_position(-0,3,wait=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "339415d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "env.poppy.r_shoulder_y.goto_position(-0,3,wait=True)\n",
    "env.poppy.r_shoulder_x.goto_position(0,3,wait=True)\n",
    "env.poppy.abs_z.goto_position(-0,3,wait=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf1d2073",
   "metadata": {},
   "outputs": [],
   "source": [
    "joint_pos = { 'l_elbow_y':0.0,\n",
    "                     'head_y': 0.0,\n",
    "                     'r_arm_z': 0.0, \n",
    "                     'head_z': 0.0,\n",
    "                     'r_shoulder_x': 0.0, \n",
    "                     'r_shoulder_y': 0.0,\n",
    "                     'r_elbow_y': 0.0, \n",
    "                     'l_arm_z': 0.0,\n",
    "                     'abs_z': 0.0,\n",
    "                     'bust_y': 0.0, \n",
    "                     'bust_x':0.0,\n",
    "                     'l_shoulder_x': 0.0,\n",
    "                     'l_shoulder_y': 0.0\n",
    "                    }\n",
    "        \n",
    "for m in env.poppy.motors:\n",
    "               m.goto_position(joint_pos[m.name], 3, wait= True)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56e9eb70",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
