{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7c47c1b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import gym\n",
    "import numpy as np\n",
    "from gym import spaces\n",
    "from tqdm import tqdm\n",
    "\n",
    "import numpy as np\n",
    "from utils.skeleton import *\n",
    "from utils.quaternion import *\n",
    "from utils.blazepose import blazepose_skeletons\n",
    "import os\n",
    "from pypot.creatures import PoppyTorso\n",
    "os.environ[\"KMP_DUPLICATE_LIB_OK\"]=\"TRUE\"\n",
    "#from pypot.creatures.ik import IKChain\n",
    "from pypot.primitive.move import Move\n",
    "from pypot.primitive.move import MovePlayer\n",
    "\n",
    "import sys\n",
    "sys.path.append('gym-examples')\n",
    "import gym_examples\n",
    "from gym.wrappers import FlattenObservation\n",
    "\n",
    "from stable_baselines3 import SAC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "238796fd",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hello, I am Poppy!\n"
     ]
    }
   ],
   "source": [
    "env = gym.make('gym_examples/Poppy-v0') "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "a464c7fb",
   "metadata": {},
   "source": [
    "Check your CoppeliaSim, there is now a Poppy Torso on a table. \n",
    "\n",
    "Remove that table !\n",
    "\n",
    "Simply click on it and press the delete key."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9be88176",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.11493445, -0.15424101,  0.04693055, -0.10223083, -0.1787379 ,\n",
       "        0.0697045 ], dtype=float32)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "env.reset()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "bd8c2cc6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using cpu device\n",
      "Wrapping the env with a `Monitor` wrapper\n",
      "Wrapping the env in a DummyVecEnv.\n",
      "current step :  0\n",
      "reward :  -0.07757134918077349\n",
      "episode :  0\n",
      "current step :  1\n",
      "reward :  -0.0800618584331275\n",
      "episode :  0\n",
      "current step :  2\n",
      "reward :  -0.08291754301845267\n",
      "episode :  0\n",
      "current step :  3\n",
      "reward :  -0.08622130391123459\n",
      "episode :  0\n",
      "current step :  4\n",
      "reward :  -0.088930856662969\n",
      "episode :  0\n",
      "current step :  5\n",
      "reward :  -0.09142787466407476\n",
      "episode :  0\n",
      "current step :  6\n",
      "reward :  -0.0937691635044613\n",
      "episode :  0\n",
      "current step :  7\n",
      "reward :  -0.09685797213779038\n",
      "episode :  0\n",
      "current step :  8\n",
      "reward :  -0.10029836346781602\n",
      "episode :  0\n",
      "current step :  9\n",
      "reward :  -0.10113829489054582\n",
      "episode :  0\n",
      "current step :  10\n",
      "reward :  -0.10355167713007554\n",
      "episode :  0\n",
      "current step :  11\n",
      "reward :  -0.1074066946938677\n",
      "episode :  0\n",
      "current step :  12\n",
      "reward :  -0.11279500148448685\n",
      "episode :  0\n",
      "current step :  13\n",
      "reward :  -0.11993650541888257\n",
      "episode :  0\n",
      "current step :  14\n",
      "reward :  -0.12892356640193453\n",
      "episode :  0\n",
      "current step :  15\n",
      "reward :  -0.1395331983470622\n",
      "episode :  0\n",
      "current step :  16\n",
      "reward :  -0.15156864229665468\n",
      "episode :  0\n",
      "current step :  17\n",
      "reward :  -0.16488591549346315\n",
      "episode :  0\n",
      "current step :  18\n",
      "reward :  -0.17944710832495528\n",
      "episode :  0\n",
      "current step :  19\n",
      "reward :  -0.19603363873482765\n",
      "episode :  0\n",
      "current step :  20\n",
      "reward :  -0.2336783880456219\n",
      "episode :  0\n",
      "current step :  21\n",
      "reward :  -0.25159897621259897\n",
      "episode :  0\n",
      "current step :  22\n",
      "reward :  -0.2703489952873673\n",
      "episode :  0\n",
      "current step :  23\n",
      "reward :  -0.2894010239606254\n",
      "episode :  0\n",
      "current step :  24\n",
      "reward :  -0.3094759041238392\n",
      "episode :  0\n",
      "current step :  25\n",
      "reward :  -0.3284853550252054\n",
      "episode :  0\n",
      "current step :  26\n",
      "reward :  -0.34718161294246785\n",
      "episode :  0\n",
      "current step :  27\n",
      "reward :  -0.3646887800135828\n",
      "episode :  0\n",
      "current step :  28\n",
      "reward :  -0.4213824768637253\n",
      "episode :  0\n",
      "current step :  29\n",
      "reward :  -0.4325208611301619\n",
      "episode :  0\n",
      "current step :  30\n",
      "reward :  -0.4516608287857284\n",
      "episode :  0\n",
      "current step :  31\n",
      "reward :  -0.4661745844282712\n",
      "episode :  0\n",
      "current step :  32\n",
      "reward :  -0.4790941097062174\n",
      "episode :  0\n",
      "current step :  33\n",
      "reward :  -0.49020137193490326\n",
      "episode :  0\n",
      "current step :  34\n",
      "reward :  -0.5001362662939748\n",
      "episode :  0\n",
      "current step :  35\n",
      "reward :  -0.5090550835294902\n",
      "episode :  0\n",
      "current step :  36\n",
      "reward :  -0.5111687515496939\n",
      "episode :  0\n",
      "current step :  37\n",
      "reward :  -0.5112085331997862\n",
      "episode :  0\n",
      "current step :  38\n",
      "reward :  -0.5087447446001223\n",
      "episode :  0\n",
      "current step :  39\n",
      "reward :  -0.5044159837386661\n",
      "episode :  0\n",
      "current step :  40\n",
      "reward :  -0.49874273425869997\n",
      "episode :  0\n",
      "current step :  41\n",
      "reward :  -0.49477734248746413\n",
      "episode :  0\n",
      "current step :  42\n",
      "reward :  -0.4927421844534174\n",
      "episode :  0\n",
      "current step :  43\n",
      "reward :  -0.4909256002634271\n",
      "episode :  0\n",
      "current step :  44\n",
      "reward :  -0.4875462810080871\n",
      "episode :  0\n",
      "current step :  45\n",
      "reward :  -0.4862294018291616\n",
      "episode :  0\n",
      "current step :  46\n",
      "reward :  -0.4587527362276293\n",
      "episode :  0\n",
      "current step :  47\n",
      "reward :  -0.4572957014845934\n",
      "episode :  0\n",
      "current step :  48\n",
      "reward :  -0.4557827083431641\n",
      "episode :  0\n",
      "current step :  49\n",
      "reward :  -0.4549865174874619\n",
      "episode :  0\n",
      "current step :  50\n",
      "reward :  -0.45048270505465626\n",
      "episode :  0\n",
      "current step :  51\n",
      "reward :  -0.4511787037963086\n",
      "episode :  0\n",
      "current step :  52\n",
      "reward :  -0.45287073928294225\n",
      "episode :  0\n",
      "current step :  53\n",
      "reward :  -0.47777247690864505\n",
      "episode :  0\n",
      "current step :  54\n",
      "reward :  -0.4819271695578154\n",
      "episode :  0\n",
      "current step :  55\n",
      "reward :  -0.48611169213234234\n",
      "episode :  0\n",
      "current step :  56\n",
      "reward :  -0.4885327498381096\n",
      "episode :  0\n",
      "current step :  57\n",
      "reward :  -0.4893276109719842\n",
      "episode :  0\n",
      "current step :  58\n",
      "reward :  -0.4900632781453039\n",
      "episode :  0\n",
      "current step :  59\n",
      "reward :  -0.49082414475315816\n",
      "episode :  0\n",
      "current step :  60\n",
      "reward :  -0.4921735695038564\n",
      "episode :  0\n",
      "current step :  61\n",
      "reward :  -0.5690680209127307\n",
      "episode :  0\n",
      "current step :  62\n",
      "reward :  -0.6360686787606766\n",
      "episode :  0\n",
      "current step :  63\n",
      "reward :  -0.6375405684985533\n",
      "episode :  0\n",
      "current step :  64\n",
      "reward :  -0.6373281794372075\n",
      "episode :  0\n",
      "current step :  65\n",
      "reward :  -0.6371471857439499\n",
      "episode :  0\n",
      "current step :  66\n",
      "reward :  -0.6369377733606106\n",
      "episode :  0\n",
      "current step :  67\n",
      "reward :  -0.6367800967647681\n",
      "episode :  0\n",
      "current step :  68\n",
      "reward :  -0.6365670799963467\n",
      "episode :  0\n",
      "current step :  69\n",
      "reward :  -0.6360632199707733\n",
      "episode :  0\n",
      "current step :  70\n",
      "reward :  -0.6358461534411085\n",
      "episode :  0\n",
      "current step :  71\n",
      "reward :  -0.6343615332219222\n",
      "episode :  0\n",
      "current step :  72\n",
      "reward :  -0.6327834243431681\n",
      "episode :  0\n",
      "current step :  73\n",
      "reward :  -0.6310754344073047\n",
      "episode :  0\n",
      "current step :  74\n",
      "reward :  -0.6307476067841459\n",
      "episode :  0\n",
      "current step :  75\n",
      "reward :  -0.6296924414378022\n",
      "episode :  0\n",
      "current step :  76\n",
      "reward :  -0.6301806082402334\n",
      "episode :  0\n",
      "current step :  77\n",
      "reward :  -0.6276313706373063\n",
      "episode :  0\n",
      "current step :  78\n",
      "reward :  -0.6245428623262939\n",
      "episode :  0\n",
      "current step :  79\n",
      "reward :  -0.6212890385587461\n",
      "episode :  0\n",
      "current step :  80\n",
      "reward :  -0.6260813710045596\n",
      "episode :  0\n",
      "current step :  81\n",
      "reward :  -0.6127340843190588\n",
      "episode :  0\n",
      "current step :  82\n",
      "reward :  -0.6008266282784115\n",
      "episode :  0\n",
      "current step :  83\n",
      "reward :  -0.5885097145097776\n",
      "episode :  0\n",
      "current step :  84\n",
      "reward :  -0.5767185529850172\n",
      "episode :  0\n",
      "current step :  85\n",
      "reward :  -0.5646284268513675\n",
      "episode :  0\n",
      "current step :  86\n",
      "reward :  -0.5523660423160451\n",
      "episode :  0\n",
      "current step :  87\n",
      "reward :  -0.5370915413167199\n",
      "episode :  0\n",
      "current step :  88\n",
      "reward :  -0.5240992102356182\n",
      "episode :  0\n",
      "current step :  89\n",
      "reward :  -0.5115451942393848\n",
      "episode :  0\n",
      "current step :  90\n",
      "reward :  -0.49909477290389437\n",
      "episode :  0\n",
      "current step :  91\n",
      "reward :  -0.4879868171260756\n",
      "episode :  0\n",
      "current step :  92\n",
      "reward :  -0.47662970485860995\n",
      "episode :  0\n",
      "current step :  93\n",
      "reward :  -0.36711289753402426\n",
      "episode :  0\n",
      "current step :  94\n",
      "reward :  -0.35287488009575607\n",
      "episode :  0\n",
      "current step :  95\n",
      "reward :  -0.34168488054374474\n",
      "episode :  0\n",
      "current step :  96\n",
      "reward :  -0.3333930076910311\n",
      "episode :  0\n",
      "current step :  97\n",
      "reward :  -0.2553833686309701\n",
      "episode :  0\n",
      "current step :  98\n",
      "reward :  -0.26886835483902494\n",
      "episode :  0\n",
      "current step :  99\n",
      "reward :  -0.2597086967517952\n",
      "episode :  0\n",
      "current step :  100\n",
      "reward :  -0.2583806260080349\n",
      "episode :  0\n",
      "current step :  101\n",
      "reward :  -0.33580045071301473\n",
      "episode :  0\n",
      "current step :  102\n",
      "reward :  -0.27848397566730243\n",
      "episode :  0\n",
      "current step :  103\n",
      "reward :  -0.2592795947990482\n",
      "episode :  0\n",
      "current step :  104\n",
      "reward :  -0.2805503872685887\n",
      "episode :  0\n",
      "current step :  105\n",
      "reward :  -0.32076233831089346\n",
      "episode :  0\n",
      "current step :  106\n",
      "reward :  -0.3232030606942239\n",
      "episode :  0\n",
      "current step :  107\n",
      "reward :  -0.3895725292222829\n",
      "episode :  0\n",
      "current step :  108\n",
      "reward :  -0.32586631201569005\n",
      "episode :  0\n",
      "current step :  109\n",
      "reward :  -0.3773960266271828\n",
      "episode :  0\n",
      "current step :  110\n",
      "reward :  -0.4249922791461292\n",
      "episode :  0\n",
      "current step :  111\n",
      "reward :  -0.4051363445567366\n",
      "episode :  0\n",
      "current step :  112\n",
      "reward :  -0.3264413219606586\n",
      "episode :  0\n",
      "current step :  113\n",
      "reward :  -0.2642270156624069\n",
      "episode :  0\n",
      "current step :  114\n",
      "reward :  -0.3378988007066131\n",
      "episode :  0\n",
      "current step :  115\n",
      "reward :  -0.2957187737315912\n",
      "episode :  0\n",
      "current step :  116\n",
      "reward :  -0.29717648220955034\n",
      "episode :  0\n",
      "current step :  117\n",
      "reward :  -0.3080478433741005\n",
      "episode :  0\n",
      "current step :  118\n",
      "reward :  -0.3631354461556402\n",
      "episode :  0\n",
      "current step :  119\n",
      "reward :  -0.36743930006162406\n",
      "episode :  0\n",
      "current step :  120\n",
      "reward :  -0.4121775441601676\n",
      "episode :  0\n",
      "current step :  121\n",
      "reward :  -0.4457654699037088\n",
      "episode :  0\n",
      "current step :  122\n",
      "reward :  -0.5035758665660136\n",
      "episode :  0\n",
      "current step :  123\n",
      "reward :  -0.37571381675599835\n",
      "episode :  0\n",
      "current step :  124\n",
      "reward :  -0.2507387880324146\n",
      "episode :  0\n",
      "current step :  125\n",
      "reward :  -0.18855152153959384\n",
      "episode :  0\n",
      "current step :  126\n",
      "reward :  -0.35340335984096055\n",
      "episode :  0\n",
      "current step :  127\n",
      "reward :  -0.4709009384196028\n",
      "episode :  0\n",
      "current step :  128\n",
      "reward :  -0.4138999557779764\n",
      "episode :  0\n",
      "current step :  129\n",
      "reward :  -0.2795768448732522\n",
      "episode :  0\n",
      "current step :  130\n",
      "reward :  -0.3128219518839423\n",
      "episode :  0\n",
      "current step :  131\n",
      "reward :  -0.47975698051283494\n",
      "episode :  0\n",
      "current step :  132\n",
      "reward :  -0.4461819822058275\n",
      "episode :  0\n",
      "current step :  133\n",
      "reward :  -0.3600137399160173\n",
      "episode :  0\n",
      "current step :  134\n",
      "reward :  -0.2775467546614644\n",
      "episode :  0\n",
      "current step :  135\n",
      "reward :  -0.334753607404028\n",
      "episode :  0\n",
      "current step :  136\n",
      "reward :  -0.22362786285949815\n",
      "episode :  0\n",
      "current step :  137\n",
      "reward :  -0.24718817276762492\n",
      "episode :  0\n",
      "current step :  138\n",
      "reward :  -0.304304732411301\n",
      "episode :  0\n",
      "current step :  139\n",
      "reward :  -0.35333745874923483\n",
      "episode :  0\n",
      "current step :  140\n",
      "reward :  -0.19898525659172722\n",
      "episode :  0\n",
      "current step :  141\n",
      "reward :  -0.24245614067366827\n",
      "episode :  0\n",
      "current step :  142\n",
      "reward :  -0.289390218723609\n",
      "episode :  0\n",
      "current step :  143\n",
      "reward :  -0.16824624524807605\n",
      "episode :  0\n",
      "current step :  144\n",
      "reward :  -0.23580340121943766\n",
      "episode :  0\n",
      "current step :  145\n",
      "reward :  -0.3163316873003709\n",
      "episode :  0\n",
      "current step :  146\n",
      "reward :  -0.3382509258118611\n",
      "episode :  0\n",
      "current step :  147\n",
      "reward :  -0.39877249340069965\n",
      "episode :  0\n",
      "current step :  148\n",
      "reward :  -0.4190221415329914\n",
      "episode :  0\n",
      "current step :  149\n",
      "reward :  -0.427111548818071\n",
      "episode :  0\n",
      "current step :  150\n",
      "reward :  -0.42963175561789163\n",
      "episode :  0\n",
      "current step :  151\n",
      "reward :  -0.4572584043607097\n",
      "episode :  0\n",
      "current step :  152\n",
      "reward :  -0.42564138434777055\n",
      "episode :  0\n",
      "current step :  153\n",
      "reward :  -0.5078942180598607\n",
      "episode :  0\n",
      "current step :  154\n",
      "reward :  -0.4788399696023362\n",
      "episode :  0\n",
      "current step :  155\n",
      "reward :  -0.5005500912441208\n",
      "episode :  0\n",
      "current step :  156\n",
      "reward :  -0.6064328416649942\n",
      "episode :  0\n",
      "current step :  157\n",
      "reward :  -0.5769261942298489\n",
      "episode :  0\n",
      "current step :  158\n",
      "reward :  -0.5460577903525387\n",
      "episode :  0\n",
      "current step :  159\n",
      "reward :  -0.5570616950798216\n",
      "episode :  0\n",
      "current step :  160\n",
      "reward :  -0.5283105793339485\n",
      "episode :  0\n",
      "current step :  161\n",
      "reward :  -0.5675116952770886\n",
      "episode :  0\n",
      "current step :  162\n",
      "reward :  -0.5551325005765217\n",
      "episode :  0\n",
      "current step :  163\n",
      "reward :  -0.6071717456315985\n",
      "episode :  0\n",
      "current step :  164\n",
      "reward :  -0.6425518415304434\n",
      "episode :  0\n",
      "current step :  165\n",
      "reward :  -0.510328681539075\n",
      "episode :  0\n",
      "current step :  166\n",
      "reward :  -0.47962756035544546\n",
      "episode :  0\n",
      "current step :  167\n",
      "reward :  -0.48493069039391906\n",
      "episode :  0\n",
      "current step :  168\n",
      "reward :  -0.49954423888976524\n",
      "episode :  0\n",
      "current step :  169\n",
      "reward :  -0.4393520559511472\n",
      "episode :  0\n",
      "current step :  170\n",
      "reward :  -0.4550972228699694\n",
      "episode :  0\n",
      "current step :  171\n",
      "reward :  -0.5346142886348907\n",
      "episode :  0\n",
      "current step :  172\n",
      "reward :  -0.43190397609663256\n",
      "episode :  0\n",
      "current step :  173\n",
      "reward :  -0.5633225580366208\n",
      "episode :  0\n",
      "current step :  174\n",
      "reward :  -0.5472300706850819\n",
      "episode :  0\n",
      "current step :  175\n",
      "reward :  -0.5569032694568171\n",
      "episode :  0\n",
      "current step :  176\n",
      "reward :  -0.507079309423512\n",
      "episode :  0\n",
      "current step :  177\n",
      "reward :  -0.4433749494689916\n",
      "episode :  0\n",
      "current step :  178\n",
      "reward :  -0.38301029624923416\n",
      "episode :  0\n",
      "current step :  179\n",
      "reward :  -0.36185898977074016\n",
      "episode :  0\n",
      "current step :  180\n",
      "reward :  -0.35559874591710305\n",
      "episode :  0\n",
      "current step :  181\n",
      "reward :  -0.5276070670470286\n",
      "episode :  0\n",
      "current step :  182\n",
      "reward :  -0.34582785515498315\n",
      "episode :  0\n",
      "current step :  183\n",
      "reward :  -0.3955298640299726\n",
      "episode :  0\n",
      "current step :  184\n",
      "reward :  -0.30876737577103697\n",
      "episode :  0\n",
      "current step :  185\n",
      "reward :  -0.5436536390382136\n",
      "episode :  0\n",
      "current step :  186\n",
      "reward :  -0.600109567267529\n",
      "episode :  0\n",
      "current step :  187\n",
      "reward :  -0.522224059984857\n",
      "episode :  0\n",
      "current step :  188\n",
      "reward :  -0.6374741158262367\n",
      "episode :  0\n",
      "current step :  189\n",
      "reward :  -0.5883446810258355\n",
      "episode :  0\n",
      "current step :  190\n",
      "reward :  -0.5423250443872516\n",
      "episode :  0\n",
      "current step :  191\n",
      "reward :  -0.4298062627485093\n",
      "episode :  0\n",
      "current step :  192\n",
      "reward :  -0.5098699888360846\n",
      "episode :  0\n",
      "current step :  193\n",
      "reward :  -0.4892615028752718\n",
      "episode :  0\n",
      "current step :  194\n",
      "reward :  -0.5516453546970845\n",
      "episode :  0\n",
      "current step :  195\n",
      "reward :  -0.471898508966594\n",
      "episode :  0\n",
      "current step :  196\n",
      "reward :  -0.4720201308198683\n",
      "episode :  0\n",
      "current step :  197\n",
      "reward :  -0.4653608874948564\n",
      "episode :  0\n",
      "current step :  198\n",
      "reward :  -0.4758567308587659\n",
      "episode :  0\n",
      "current step :  199\n",
      "reward :  -0.45288689707930196\n",
      "episode :  0\n",
      "current step :  200\n",
      "reward :  -0.5189416199185118\n",
      "episode :  0\n",
      "current step :  201\n",
      "reward :  -0.5400729136703685\n",
      "episode :  0\n",
      "current step :  202\n",
      "reward :  -0.47367549962414957\n",
      "episode :  0\n",
      "current step :  203\n",
      "reward :  -0.4140083948101791\n",
      "episode :  0\n",
      "current step :  204\n",
      "reward :  -0.47429577625026975\n",
      "episode :  0\n",
      "current step :  205\n",
      "reward :  -0.5640154634816699\n",
      "episode :  0\n",
      "current step :  206\n",
      "reward :  -0.6307244872245633\n",
      "episode :  0\n",
      "current step :  207\n",
      "reward :  -0.6539156974703355\n",
      "episode :  0\n",
      "current step :  208\n",
      "reward :  -0.6640061219209343\n",
      "episode :  0\n",
      "current step :  209\n",
      "reward :  -0.6918898346942607\n",
      "episode :  0\n",
      "current step :  210\n",
      "reward :  -0.6923856072860332\n",
      "episode :  0\n",
      "current step :  211\n",
      "reward :  -0.6406013288483338\n",
      "episode :  0\n",
      "current step :  212\n",
      "reward :  -0.6003429290847314\n",
      "episode :  0\n",
      "current step :  213\n",
      "reward :  -0.5687889340217309\n",
      "episode :  0\n",
      "current step :  214\n",
      "reward :  -0.5389118816982182\n",
      "episode :  0\n",
      "current step :  215\n",
      "reward :  -0.5664123489286322\n",
      "episode :  0\n",
      "current step :  216\n",
      "reward :  -0.5207105700252718\n",
      "episode :  0\n",
      "current step :  217\n",
      "reward :  -0.5998957100536768\n",
      "episode :  0\n",
      "current step :  218\n",
      "reward :  -0.6077218136092988\n",
      "episode :  0\n",
      "current step :  219\n",
      "reward :  -0.5540968308303579\n",
      "episode :  0\n",
      "current step :  220\n",
      "reward :  -0.5884446321614595\n",
      "episode :  0\n",
      "current step :  221\n",
      "reward :  -0.5165711032892178\n",
      "episode :  0\n",
      "current step :  222\n",
      "reward :  -0.4227697403199134\n",
      "episode :  0\n",
      "current step :  223\n",
      "reward :  -0.46610845089339703\n",
      "episode :  0\n",
      "current step :  224\n",
      "reward :  -0.4941892095886514\n",
      "episode :  0\n",
      "current step :  225\n",
      "reward :  -0.6669159676409541\n",
      "episode :  0\n",
      "current step :  226\n",
      "reward :  -0.6361960886521622\n",
      "episode :  0\n",
      "current step :  227\n",
      "reward :  -0.4695846898422201\n",
      "episode :  0\n",
      "current step :  228\n",
      "reward :  -0.4605520723895749\n",
      "episode :  0\n",
      "current step :  229\n",
      "reward :  -0.5521756775729211\n",
      "episode :  0\n",
      "current step :  230\n",
      "reward :  -0.5232072389924719\n",
      "episode :  0\n",
      "current step :  231\n",
      "reward :  -0.575333116990622\n",
      "episode :  0\n",
      "current step :  232\n",
      "reward :  -0.5083890131707607\n",
      "episode :  0\n",
      "current step :  233\n",
      "reward :  -0.4846987722806984\n",
      "episode :  0\n",
      "current step :  234\n",
      "reward :  -0.45881501646335815\n",
      "episode :  0\n",
      "current step :  235\n",
      "reward :  -0.4098968412077305\n",
      "episode :  0\n",
      "current step :  236\n",
      "reward :  -0.4025295322706981\n",
      "episode :  0\n",
      "current step :  237\n",
      "reward :  -0.4295380848932443\n",
      "episode :  0\n",
      "current step :  238\n",
      "reward :  -0.4368549130502771\n",
      "episode :  0\n",
      "current step :  239\n",
      "reward :  -0.4312264268062891\n",
      "episode :  0\n",
      "current step :  240\n",
      "reward :  -0.4227701576658792\n",
      "episode :  0\n",
      "current step :  241\n",
      "reward :  -0.3923690321963912\n",
      "episode :  0\n",
      "current step :  242\n",
      "reward :  -0.41605709298991206\n",
      "episode :  0\n",
      "current step :  243\n",
      "reward :  -0.38077569904347636\n",
      "episode :  0\n",
      "current step :  244\n",
      "reward :  -0.34399705963668964\n",
      "episode :  0\n",
      "current step :  245\n",
      "reward :  -0.3573605588331821\n",
      "episode :  0\n",
      "current step :  246\n",
      "reward :  -0.3918555784775875\n",
      "episode :  0\n",
      "current step :  247\n",
      "reward :  -0.3571164098024547\n",
      "episode :  0\n",
      "current step :  248\n",
      "reward :  -0.3520129795009832\n",
      "episode :  0\n",
      "current step :  249\n",
      "reward :  -0.41168947831868086\n",
      "episode :  0\n",
      "current step :  250\n",
      "reward :  -0.4831360491131096\n",
      "episode :  0\n",
      "current step :  251\n",
      "reward :  -0.46244244432072745\n",
      "episode :  0\n",
      "current step :  252\n",
      "reward :  -0.42252574202296156\n",
      "episode :  0\n",
      "current step :  253\n",
      "reward :  -0.37767681810363896\n",
      "episode :  0\n",
      "current step :  254\n",
      "reward :  -0.4398499894032496\n",
      "episode :  0\n",
      "current step :  255\n",
      "reward :  -0.43711202233849034\n",
      "episode :  0\n",
      "current step :  256\n",
      "reward :  -0.3938703102198382\n",
      "episode :  0\n",
      "current step :  257\n",
      "reward :  -0.3360088123957198\n",
      "episode :  0\n",
      "current step :  258\n",
      "reward :  -0.3547682068933985\n",
      "episode :  0\n",
      "current step :  259\n",
      "reward :  -0.4452220938753885\n",
      "episode :  0\n",
      "current step :  260\n",
      "reward :  -0.35596144028529797\n",
      "episode :  0\n",
      "current step :  261\n",
      "reward :  -0.35244724550602663\n",
      "episode :  0\n",
      "current step :  262\n",
      "reward :  -0.35513477096954565\n",
      "episode :  0\n",
      "current step :  263\n",
      "reward :  -0.19557057510480136\n",
      "episode :  0\n",
      "current step :  264\n",
      "reward :  -0.26860004125645626\n",
      "episode :  0\n",
      "current step :  265\n",
      "reward :  -0.30780117562191067\n",
      "episode :  0\n",
      "current step :  266\n",
      "reward :  -0.25975489485528086\n",
      "episode :  0\n",
      "current step :  267\n",
      "reward :  -0.2712721514884398\n",
      "episode :  0\n",
      "current step :  268\n",
      "reward :  -0.3191273699004863\n",
      "episode :  0\n",
      "current step :  269\n",
      "reward :  -0.3869893848745923\n",
      "episode :  0\n",
      "current step :  270\n",
      "reward :  -0.2479967291890611\n",
      "episode :  0\n",
      "current step :  271\n",
      "reward :  -0.4141173161173777\n",
      "episode :  0\n",
      "current step :  272\n",
      "reward :  -0.31481575059445593\n",
      "episode :  0\n",
      "current step :  273\n",
      "reward :  -0.28095017797243654\n",
      "episode :  0\n",
      "current step :  274\n",
      "reward :  -0.21690305485143946\n",
      "episode :  0\n",
      "current step :  275\n",
      "reward :  -0.2834416647423925\n",
      "episode :  0\n",
      "current step :  276\n",
      "reward :  -0.26570479070750364\n",
      "episode :  0\n",
      "current step :  277\n",
      "reward :  -0.32989551494192504\n",
      "episode :  0\n",
      "current step :  278\n",
      "reward :  -0.42853631204505105\n",
      "episode :  0\n",
      "current step :  279\n",
      "reward :  -0.45877661270958975\n",
      "episode :  0\n",
      "current step :  280\n",
      "reward :  -0.4921583966460859\n",
      "episode :  0\n",
      "current step :  281\n",
      "reward :  -0.32708219580529324\n",
      "episode :  0\n",
      "current step :  282\n",
      "reward :  -0.2540041691005292\n",
      "episode :  0\n",
      "current step :  283\n",
      "reward :  -0.22576653115151937\n",
      "episode :  0\n",
      "current step :  284\n",
      "reward :  -0.3781235637758915\n",
      "episode :  0\n",
      "current step :  285\n",
      "reward :  -0.34856694137557825\n",
      "episode :  1\n",
      "current step :  0\n",
      "reward :  -0.3281172026890389\n",
      "episode :  1\n",
      "current step :  1\n",
      "reward :  -0.34611874775979834\n",
      "episode :  1\n",
      "current step :  2\n",
      "reward :  -0.4436649085334533\n",
      "episode :  1\n",
      "current step :  3\n",
      "reward :  -0.3851682909663019\n",
      "episode :  1\n",
      "current step :  4\n",
      "reward :  -0.18305018498622425\n",
      "episode :  1\n",
      "current step :  5\n",
      "reward :  -0.321906135827204\n",
      "episode :  1\n",
      "current step :  6\n",
      "reward :  -0.3409873576223156\n",
      "episode :  1\n",
      "current step :  7\n",
      "reward :  -0.25873436325912746\n",
      "episode :  1\n",
      "current step :  8\n",
      "reward :  -0.33576735344596315\n",
      "episode :  1\n",
      "current step :  9\n",
      "reward :  -0.34267431480102484\n",
      "episode :  1\n",
      "current step :  10\n",
      "reward :  -0.343609854625993\n",
      "episode :  1\n",
      "current step :  11\n",
      "reward :  -0.37234388803195145\n",
      "episode :  1\n",
      "current step :  12\n",
      "reward :  -0.35704692906608027\n",
      "episode :  1\n",
      "current step :  13\n",
      "reward :  -0.258769056350789\n",
      "episode :  1\n",
      "current step :  14\n",
      "reward :  -0.41330858534136483\n",
      "episode :  1\n",
      "current step :  15\n",
      "reward :  -0.25937094418508044\n",
      "episode :  1\n",
      "current step :  16\n",
      "reward :  -0.2408512582262771\n",
      "episode :  1\n",
      "current step :  17\n",
      "reward :  -0.29303085415232233\n",
      "episode :  1\n",
      "current step :  18\n",
      "reward :  -0.3134218970911965\n",
      "episode :  1\n",
      "current step :  19\n",
      "reward :  -0.3029192241703884\n",
      "episode :  1\n",
      "current step :  20\n",
      "reward :  -0.366209330808835\n",
      "episode :  1\n",
      "current step :  21\n",
      "reward :  -0.28322398326765114\n",
      "episode :  1\n",
      "current step :  22\n",
      "reward :  -0.21937400171542498\n",
      "episode :  1\n",
      "current step :  23\n",
      "reward :  -0.2803641362252254\n",
      "episode :  1\n",
      "current step :  24\n",
      "reward :  -0.23236722619203587\n",
      "episode :  1\n",
      "current step :  25\n",
      "reward :  -0.33511370366942367\n",
      "episode :  1\n",
      "current step :  26\n",
      "reward :  -0.2936466447229031\n",
      "episode :  1\n",
      "current step :  27\n",
      "reward :  -0.2931877492941775\n",
      "episode :  1\n",
      "current step :  28\n",
      "reward :  -0.3631417569997718\n",
      "episode :  1\n",
      "current step :  29\n",
      "reward :  -0.3118521020789775\n",
      "episode :  1\n",
      "current step :  30\n",
      "reward :  -0.3509222851517578\n",
      "episode :  1\n",
      "current step :  31\n",
      "reward :  -0.33053243366400775\n",
      "episode :  1\n",
      "current step :  32\n",
      "reward :  -0.3714653082735143\n",
      "episode :  1\n",
      "current step :  33\n",
      "reward :  -0.45940205648593757\n",
      "episode :  1\n",
      "current step :  34\n",
      "reward :  -0.38635110456962746\n",
      "episode :  1\n",
      "current step :  35\n",
      "reward :  -0.4232268870824821\n",
      "episode :  1\n",
      "current step :  36\n",
      "reward :  -0.44120516627287587\n",
      "episode :  1\n",
      "current step :  37\n",
      "reward :  -0.34678797297862596\n",
      "episode :  1\n",
      "current step :  38\n",
      "reward :  -0.3036267042614697\n",
      "episode :  1\n",
      "current step :  39\n",
      "reward :  -0.44934318938423157\n",
      "episode :  1\n",
      "current step :  40\n",
      "reward :  -0.5147268581089183\n",
      "episode :  1\n",
      "current step :  41\n",
      "reward :  -0.47253972312409764\n",
      "episode :  1\n",
      "current step :  42\n",
      "reward :  -0.5050706744097684\n",
      "episode :  1\n",
      "current step :  43\n",
      "reward :  -0.5090790894886906\n",
      "episode :  1\n",
      "current step :  44\n",
      "reward :  -0.3859031780993756\n",
      "episode :  1\n",
      "current step :  45\n",
      "reward :  -0.38068528031130483\n",
      "episode :  1\n",
      "current step :  46\n",
      "reward :  -0.4910372421617825\n",
      "episode :  1\n",
      "current step :  47\n",
      "reward :  -0.3833915260276053\n",
      "episode :  1\n",
      "current step :  48\n",
      "reward :  -0.270448724341319\n",
      "episode :  1\n",
      "current step :  49\n",
      "reward :  -0.4582774340722673\n",
      "episode :  1\n",
      "current step :  50\n",
      "reward :  -0.3864879530766117\n",
      "episode :  1\n",
      "current step :  51\n",
      "reward :  -0.3372523392646025\n",
      "episode :  1\n",
      "current step :  52\n",
      "reward :  -0.41703908917642607\n",
      "episode :  1\n",
      "current step :  53\n",
      "reward :  -0.43690256380779663\n",
      "episode :  1\n",
      "current step :  54\n",
      "reward :  -0.46581292295719334\n",
      "episode :  1\n",
      "current step :  55\n",
      "reward :  -0.5194889389910156\n",
      "episode :  1\n",
      "current step :  56\n",
      "reward :  -0.553842097914681\n",
      "episode :  1\n",
      "current step :  57\n",
      "reward :  -0.5181585519466374\n",
      "episode :  1\n",
      "current step :  58\n",
      "reward :  -0.49060444398905295\n",
      "episode :  1\n",
      "current step :  59\n",
      "reward :  -0.4355477214585056\n",
      "episode :  1\n",
      "current step :  60\n",
      "reward :  -0.5589995918246073\n",
      "episode :  1\n",
      "current step :  61\n",
      "reward :  -0.5385367741083792\n",
      "episode :  1\n",
      "current step :  62\n",
      "reward :  -0.35836845195211975\n",
      "episode :  1\n",
      "current step :  63\n",
      "reward :  -0.33674324274190964\n",
      "episode :  1\n",
      "current step :  64\n",
      "reward :  -0.32396087998076756\n",
      "episode :  1\n",
      "current step :  65\n",
      "reward :  -0.3414605719877921\n",
      "episode :  1\n",
      "current step :  66\n",
      "reward :  -0.4240245139938136\n",
      "episode :  1\n",
      "current step :  67\n",
      "reward :  -0.32136409325707394\n",
      "episode :  1\n",
      "current step :  68\n",
      "reward :  -0.2982672185887546\n",
      "episode :  1\n",
      "current step :  69\n",
      "reward :  -0.3615762320371441\n",
      "episode :  1\n",
      "current step :  70\n",
      "reward :  -0.3854567584887642\n",
      "episode :  1\n",
      "current step :  71\n",
      "reward :  -0.33979202635712175\n",
      "episode :  1\n",
      "current step :  72\n",
      "reward :  -0.3449055882551344\n",
      "episode :  1\n",
      "current step :  73\n",
      "reward :  -0.40215263817396685\n",
      "episode :  1\n",
      "current step :  74\n",
      "reward :  -0.44967579291300197\n",
      "episode :  1\n",
      "current step :  75\n",
      "reward :  -0.5558415773093588\n",
      "episode :  1\n",
      "current step :  76\n",
      "reward :  -0.3773092526816345\n",
      "episode :  1\n",
      "current step :  77\n",
      "reward :  -0.27307534280333506\n",
      "episode :  1\n",
      "current step :  78\n",
      "reward :  -0.19949691925904312\n",
      "episode :  1\n",
      "current step :  79\n",
      "reward :  -0.24635813037074136\n",
      "episode :  1\n",
      "current step :  80\n",
      "reward :  -0.345202893782484\n",
      "episode :  1\n",
      "current step :  81\n",
      "reward :  -0.2936063581495623\n",
      "episode :  1\n",
      "current step :  82\n",
      "reward :  -0.3474608450278488\n",
      "episode :  1\n",
      "current step :  83\n",
      "reward :  -0.35805676546883375\n",
      "episode :  1\n",
      "current step :  84\n",
      "reward :  -0.3532275289619206\n",
      "episode :  1\n",
      "current step :  85\n",
      "reward :  -0.28909475562907455\n",
      "episode :  1\n",
      "current step :  86\n",
      "reward :  -0.31073486455050453\n",
      "episode :  1\n",
      "current step :  87\n",
      "reward :  -0.3977144800565806\n",
      "episode :  1\n",
      "current step :  88\n",
      "reward :  -0.46325082336064954\n",
      "episode :  1\n",
      "current step :  89\n",
      "reward :  -0.3710323723183275\n",
      "episode :  1\n",
      "current step :  90\n",
      "reward :  -0.3140032859468442\n",
      "episode :  1\n",
      "current step :  91\n",
      "reward :  -0.4132126912098313\n",
      "episode :  1\n",
      "current step :  92\n",
      "reward :  -0.39501091736715327\n",
      "episode :  1\n",
      "current step :  93\n",
      "reward :  -0.4020862832139207\n",
      "episode :  1\n",
      "current step :  94\n",
      "reward :  -0.30201091303520583\n",
      "episode :  1\n",
      "current step :  95\n",
      "reward :  -0.1989523222219808\n",
      "episode :  1\n",
      "current step :  96\n",
      "reward :  -0.3608605554057326\n",
      "episode :  1\n",
      "current step :  97\n",
      "reward :  -0.21169290354978168\n",
      "episode :  1\n",
      "current step :  98\n",
      "reward :  -0.2348364498753164\n",
      "episode :  1\n",
      "current step :  99\n",
      "reward :  -0.3290489293912469\n",
      "episode :  1\n",
      "current step :  100\n",
      "reward :  -0.2906292424695108\n",
      "episode :  1\n",
      "current step :  101\n",
      "reward :  -0.23257163494711627\n",
      "episode :  1\n",
      "current step :  102\n",
      "reward :  -0.2674930064186706\n",
      "episode :  1\n",
      "current step :  103\n",
      "reward :  -0.2318546460395792\n",
      "episode :  1\n",
      "current step :  104\n",
      "reward :  -0.1915768054273426\n",
      "episode :  1\n",
      "current step :  105\n",
      "reward :  -0.19538925519078792\n",
      "episode :  1\n",
      "current step :  106\n",
      "reward :  -0.20895099190115896\n",
      "episode :  1\n",
      "current step :  107\n",
      "reward :  -0.2130360451698146\n",
      "episode :  1\n",
      "current step :  108\n",
      "reward :  -0.39341115840596175\n",
      "episode :  1\n",
      "current step :  109\n",
      "reward :  -0.5129558115023676\n",
      "episode :  1\n",
      "current step :  110\n",
      "reward :  -0.4374802900617753\n",
      "episode :  1\n",
      "current step :  111\n",
      "reward :  -0.3859337894195446\n",
      "episode :  1\n",
      "current step :  112\n",
      "reward :  -0.3228561381748366\n",
      "episode :  1\n",
      "current step :  113\n",
      "reward :  -0.2596283936690633\n",
      "episode :  1\n",
      "current step :  114\n",
      "reward :  -0.32152941059705953\n",
      "episode :  1\n",
      "current step :  115\n",
      "reward :  -0.41195089788743\n",
      "episode :  1\n",
      "current step :  116\n",
      "reward :  -0.42071081055338566\n",
      "episode :  1\n",
      "current step :  117\n",
      "reward :  -0.2552079103521381\n",
      "episode :  1\n",
      "current step :  118\n",
      "reward :  -0.2505066985723396\n",
      "episode :  1\n",
      "current step :  119\n",
      "reward :  -0.3086845771672786\n",
      "episode :  1\n",
      "current step :  120\n",
      "reward :  -0.3156406950778476\n",
      "episode :  1\n",
      "current step :  121\n",
      "reward :  -0.2708434671305207\n",
      "episode :  1\n",
      "current step :  122\n",
      "reward :  -0.17804349127243108\n",
      "episode :  1\n",
      "current step :  123\n",
      "reward :  -0.1308288217311252\n",
      "episode :  1\n",
      "current step :  124\n",
      "reward :  -0.16066134044081412\n",
      "episode :  1\n",
      "current step :  125\n",
      "reward :  -0.3047142800607873\n",
      "episode :  1\n",
      "current step :  126\n",
      "reward :  -0.39454075837957986\n",
      "episode :  1\n",
      "current step :  127\n",
      "reward :  -0.37447268587273363\n",
      "episode :  1\n",
      "current step :  128\n",
      "reward :  -0.36796778623699944\n",
      "episode :  1\n",
      "current step :  129\n",
      "reward :  -0.17554026551357543\n",
      "episode :  1\n",
      "current step :  130\n",
      "reward :  -0.2741856995624033\n",
      "episode :  1\n",
      "current step :  131\n",
      "reward :  -0.2814878247225723\n",
      "episode :  1\n",
      "current step :  132\n",
      "reward :  -0.33969335750625557\n",
      "episode :  1\n",
      "current step :  133\n",
      "reward :  -0.2721697558518037\n",
      "episode :  1\n",
      "current step :  134\n",
      "reward :  -0.24908484410943418\n",
      "episode :  1\n",
      "current step :  135\n",
      "reward :  -0.11374600512830396\n",
      "episode :  1\n",
      "current step :  136\n",
      "reward :  -0.21492789020837297\n",
      "episode :  1\n",
      "current step :  137\n",
      "reward :  -0.3284575496972762\n",
      "episode :  1\n",
      "current step :  138\n",
      "reward :  -0.3286964527754422\n",
      "episode :  1\n",
      "current step :  139\n",
      "reward :  -0.17893610164580254\n",
      "episode :  1\n",
      "current step :  140\n",
      "reward :  -0.13376674040675923\n",
      "episode :  1\n",
      "current step :  141\n",
      "reward :  -0.32114121237217375\n",
      "episode :  1\n",
      "current step :  142\n",
      "reward :  -0.3910933166544912\n",
      "episode :  1\n",
      "current step :  143\n",
      "reward :  -0.4402307391545161\n",
      "episode :  1\n",
      "current step :  144\n",
      "reward :  -0.48668243485518115\n",
      "episode :  1\n",
      "current step :  145\n",
      "reward :  -0.5084673259618772\n",
      "episode :  1\n",
      "current step :  146\n",
      "reward :  -0.44840436682399387\n",
      "episode :  1\n",
      "current step :  147\n",
      "reward :  -0.3545669394865232\n",
      "episode :  1\n",
      "current step :  148\n",
      "reward :  -0.41137030341023134\n",
      "episode :  1\n",
      "current step :  149\n",
      "reward :  -0.46375044395682447\n",
      "episode :  1\n",
      "current step :  150\n",
      "reward :  -0.47487934290996253\n",
      "episode :  1\n",
      "current step :  151\n",
      "reward :  -0.4044525905169781\n",
      "episode :  1\n",
      "current step :  152\n",
      "reward :  -0.3388361903455113\n",
      "episode :  1\n",
      "current step :  153\n",
      "reward :  -0.3692549351372627\n",
      "episode :  1\n",
      "current step :  154\n",
      "reward :  -0.3945766860387802\n",
      "episode :  1\n",
      "current step :  155\n",
      "reward :  -0.4071597912018547\n",
      "episode :  1\n",
      "current step :  156\n",
      "reward :  -0.38583682440147404\n",
      "episode :  1\n",
      "current step :  157\n",
      "reward :  -0.4012346019346283\n",
      "episode :  1\n",
      "current step :  158\n",
      "reward :  -0.30842410821448313\n",
      "episode :  1\n",
      "current step :  159\n",
      "reward :  -0.40234729381077733\n",
      "episode :  1\n",
      "current step :  160\n",
      "reward :  -0.4178028029848135\n",
      "episode :  1\n",
      "current step :  161\n",
      "reward :  -0.4653932420679844\n",
      "episode :  1\n",
      "current step :  162\n",
      "reward :  -0.4966016472903529\n",
      "episode :  1\n",
      "current step :  163\n",
      "reward :  -0.559630367292627\n",
      "episode :  1\n",
      "current step :  164\n",
      "reward :  -0.5738704227432807\n",
      "episode :  1\n",
      "current step :  165\n",
      "reward :  -0.6358754939252579\n",
      "episode :  1\n",
      "current step :  166\n",
      "reward :  -0.6722192771555255\n",
      "episode :  1\n",
      "current step :  167\n",
      "reward :  -0.5558978947931766\n",
      "episode :  1\n",
      "current step :  168\n",
      "reward :  -0.5089619542923152\n",
      "episode :  1\n",
      "current step :  169\n",
      "reward :  -0.4929640512891062\n",
      "episode :  1\n",
      "current step :  170\n",
      "reward :  -0.6341389265872778\n",
      "episode :  1\n",
      "current step :  171\n",
      "reward :  -0.6157561771003647\n",
      "episode :  1\n",
      "current step :  172\n",
      "reward :  -0.6501199968094911\n",
      "episode :  1\n",
      "current step :  173\n",
      "reward :  -0.6513584026838872\n",
      "episode :  1\n",
      "current step :  174\n",
      "reward :  -0.5726710970560926\n",
      "episode :  1\n",
      "current step :  175\n",
      "reward :  -0.507351668993833\n",
      "episode :  1\n",
      "current step :  176\n",
      "reward :  -0.5679624968216912\n",
      "episode :  1\n",
      "current step :  177\n",
      "reward :  -0.43187549727908986\n",
      "episode :  1\n",
      "current step :  178\n",
      "reward :  -0.478517378980375\n",
      "episode :  1\n",
      "current step :  179\n",
      "reward :  -0.5425095238247438\n",
      "episode :  1\n",
      "current step :  180\n",
      "reward :  -0.6315048255133905\n",
      "episode :  1\n",
      "current step :  181\n",
      "reward :  -0.5576411194432016\n",
      "episode :  1\n",
      "current step :  182\n",
      "reward :  -0.49290037598690295\n",
      "episode :  1\n",
      "current step :  183\n",
      "reward :  -0.4502873966328091\n",
      "episode :  1\n",
      "current step :  184\n",
      "reward :  -0.5590097254643555\n",
      "episode :  1\n",
      "current step :  185\n",
      "reward :  -0.6180027278683135\n",
      "episode :  1\n",
      "current step :  186\n",
      "reward :  -0.5019896545098693\n",
      "episode :  1\n",
      "current step :  187\n",
      "reward :  -0.50260074250447\n",
      "episode :  1\n",
      "current step :  188\n",
      "reward :  -0.644073823189706\n",
      "episode :  1\n",
      "current step :  189\n",
      "reward :  -0.6277715878288292\n",
      "episode :  1\n",
      "current step :  190\n",
      "reward :  -0.6482152716320149\n",
      "episode :  1\n",
      "current step :  191\n",
      "reward :  -0.6200963321152926\n",
      "episode :  1\n",
      "current step :  192\n",
      "reward :  -0.5914960332439688\n",
      "episode :  1\n",
      "current step :  193\n",
      "reward :  -0.5650463287426656\n",
      "episode :  1\n",
      "current step :  194\n",
      "reward :  -0.5715458821907281\n",
      "episode :  1\n",
      "current step :  195\n",
      "reward :  -0.6690832430379121\n",
      "episode :  1\n",
      "current step :  196\n",
      "reward :  -0.7057749522396427\n",
      "episode :  1\n",
      "current step :  197\n",
      "reward :  -0.6501198370304837\n",
      "episode :  1\n",
      "current step :  198\n",
      "reward :  -0.6552467143487707\n",
      "episode :  1\n",
      "current step :  199\n",
      "reward :  -0.6830777811417441\n",
      "episode :  1\n",
      "current step :  200\n",
      "reward :  -0.699753262636925\n",
      "episode :  1\n",
      "current step :  201\n",
      "reward :  -0.6988432334560025\n",
      "episode :  1\n",
      "current step :  202\n",
      "reward :  -0.6363533274704494\n",
      "episode :  1\n",
      "current step :  203\n",
      "reward :  -0.6106871274987782\n",
      "episode :  1\n",
      "current step :  204\n",
      "reward :  -0.6530166201130766\n",
      "episode :  1\n",
      "current step :  205\n",
      "reward :  -0.6443674179138063\n",
      "episode :  1\n",
      "current step :  206\n",
      "reward :  -0.6038488990962256\n",
      "episode :  1\n",
      "current step :  207\n",
      "reward :  -0.5742698170558922\n",
      "episode :  1\n",
      "current step :  208\n",
      "reward :  -0.6146517783290023\n",
      "episode :  1\n",
      "current step :  209\n",
      "reward :  -0.4071427311545393\n",
      "episode :  1\n",
      "current step :  210\n",
      "reward :  -0.36159234228870496\n",
      "episode :  1\n",
      "current step :  211\n",
      "reward :  -0.35331289339384664\n",
      "episode :  1\n",
      "current step :  212\n",
      "reward :  -0.366296672496593\n",
      "episode :  1\n",
      "current step :  213\n",
      "reward :  -0.48131598231674205\n",
      "episode :  1\n",
      "current step :  214\n",
      "reward :  -0.4540533756753125\n",
      "episode :  1\n",
      "current step :  215\n",
      "reward :  -0.599485772170717\n",
      "episode :  1\n",
      "current step :  216\n",
      "reward :  -0.621368024478163\n",
      "episode :  1\n",
      "current step :  217\n",
      "reward :  -0.6363516388894943\n",
      "episode :  1\n",
      "current step :  218\n",
      "reward :  -0.6275464277815804\n",
      "episode :  1\n",
      "current step :  219\n",
      "reward :  -0.625464696627171\n",
      "episode :  1\n",
      "current step :  220\n",
      "reward :  -0.5258900444989693\n",
      "episode :  1\n",
      "current step :  221\n",
      "reward :  -0.4478511989190139\n",
      "episode :  1\n",
      "current step :  222\n",
      "reward :  -0.48029603478340205\n",
      "episode :  1\n",
      "current step :  223\n",
      "reward :  -0.5110765944783916\n",
      "episode :  1\n",
      "current step :  224\n",
      "reward :  -0.44310611749932366\n",
      "episode :  1\n",
      "current step :  225\n",
      "reward :  -0.44095910801764565\n",
      "episode :  1\n",
      "current step :  226\n",
      "reward :  -0.5030203592250053\n",
      "episode :  1\n",
      "current step :  227\n",
      "reward :  -0.6316454196029258\n",
      "episode :  1\n",
      "current step :  228\n",
      "reward :  -0.5411931624343488\n",
      "episode :  1\n",
      "current step :  229\n",
      "reward :  -0.5165677880191858\n",
      "episode :  1\n",
      "current step :  230\n",
      "reward :  -0.4528320626113991\n",
      "episode :  1\n",
      "current step :  231\n",
      "reward :  -0.4179372403884303\n",
      "episode :  1\n",
      "current step :  232\n",
      "reward :  -0.3986159055771287\n",
      "episode :  1\n",
      "current step :  233\n",
      "reward :  -0.47247118028904994\n",
      "episode :  1\n",
      "current step :  234\n",
      "reward :  -0.54874949782002\n",
      "episode :  1\n",
      "current step :  235\n",
      "reward :  -0.440304181663145\n",
      "episode :  1\n",
      "current step :  236\n",
      "reward :  -0.3951309819418227\n",
      "episode :  1\n",
      "current step :  237\n",
      "reward :  -0.3038399816976961\n",
      "episode :  1\n",
      "current step :  238\n",
      "reward :  -0.27007669935469697\n",
      "episode :  1\n",
      "current step :  239\n",
      "reward :  -0.3590435266326524\n",
      "episode :  1\n",
      "current step :  240\n",
      "reward :  -0.3445160611267537\n",
      "episode :  1\n",
      "current step :  241\n",
      "reward :  -0.3816685228170106\n",
      "episode :  1\n",
      "current step :  242\n",
      "reward :  -0.4456360192536702\n",
      "episode :  1\n",
      "current step :  243\n",
      "reward :  -0.42974611114856104\n",
      "episode :  1\n",
      "current step :  244\n",
      "reward :  -0.3632155033975284\n",
      "episode :  1\n",
      "current step :  245\n",
      "reward :  -0.3555175926698305\n",
      "episode :  1\n",
      "current step :  246\n",
      "reward :  -0.36105076301397365\n",
      "episode :  1\n",
      "current step :  247\n",
      "reward :  -0.31315772537697817\n",
      "episode :  1\n",
      "current step :  248\n",
      "reward :  -0.21546114890656712\n",
      "episode :  1\n",
      "current step :  249\n",
      "reward :  -0.28979107668070236\n",
      "episode :  1\n",
      "current step :  250\n",
      "reward :  -0.4591805734891223\n",
      "episode :  1\n",
      "current step :  251\n",
      "reward :  -0.5983731016525319\n",
      "episode :  1\n",
      "current step :  252\n",
      "reward :  -0.5802893063285299\n",
      "episode :  1\n",
      "current step :  253\n",
      "reward :  -0.4527910310785789\n",
      "episode :  1\n",
      "current step :  254\n",
      "reward :  -0.33314429014616515\n",
      "episode :  1\n",
      "current step :  255\n",
      "reward :  -0.39074860135054584\n",
      "episode :  1\n",
      "current step :  256\n",
      "reward :  -0.29555200685431043\n",
      "episode :  1\n",
      "current step :  257\n",
      "reward :  -0.2414479535976208\n",
      "episode :  1\n",
      "current step :  258\n",
      "reward :  -0.23757873826294892\n",
      "episode :  1\n",
      "current step :  259\n",
      "reward :  -0.3316347045144376\n",
      "episode :  1\n",
      "current step :  260\n",
      "reward :  -0.32433233712867326\n",
      "episode :  1\n",
      "current step :  261\n",
      "reward :  -0.3102897733768114\n",
      "episode :  1\n",
      "current step :  262\n",
      "reward :  -0.3369426193816958\n",
      "episode :  1\n",
      "current step :  263\n",
      "reward :  -0.3508386041616579\n",
      "episode :  1\n",
      "current step :  264\n",
      "reward :  -0.30374697064591943\n",
      "episode :  1\n",
      "current step :  265\n",
      "reward :  -0.16098785652500536\n",
      "episode :  1\n",
      "current step :  266\n",
      "reward :  -0.2360116185749729\n",
      "episode :  1\n",
      "current step :  267\n",
      "reward :  -0.31434440625785415\n",
      "episode :  1\n",
      "current step :  268\n",
      "reward :  -0.3379124508157491\n",
      "episode :  1\n",
      "current step :  269\n",
      "reward :  -0.2549983938016834\n",
      "episode :  1\n",
      "current step :  270\n",
      "reward :  -0.22806467870352976\n",
      "episode :  1\n",
      "current step :  271\n",
      "reward :  -0.24170911558244187\n",
      "episode :  1\n",
      "current step :  272\n",
      "reward :  -0.22161806405818862\n",
      "episode :  1\n",
      "current step :  273\n",
      "reward :  -0.2818333989003976\n",
      "episode :  1\n",
      "current step :  274\n",
      "reward :  -0.381581936991025\n",
      "episode :  1\n",
      "current step :  275\n",
      "reward :  -0.3120284333321633\n",
      "episode :  1\n",
      "current step :  276\n",
      "reward :  -0.30480442111042555\n",
      "episode :  1\n",
      "current step :  277\n",
      "reward :  -0.3986780076011576\n",
      "episode :  1\n",
      "current step :  278\n",
      "reward :  -0.4264866131480448\n",
      "episode :  1\n",
      "current step :  279\n",
      "reward :  -0.3066434187229594\n",
      "episode :  1\n",
      "current step :  280\n",
      "reward :  -0.43795210358403197\n",
      "episode :  1\n",
      "current step :  281\n",
      "reward :  -0.37603936405830596\n",
      "episode :  1\n",
      "current step :  282\n",
      "reward :  -0.29550265587829944\n",
      "episode :  1\n",
      "current step :  283\n",
      "reward :  -0.40706155386294235\n",
      "episode :  1\n",
      "current step :  284\n",
      "reward :  -0.4582561150839424\n",
      "episode :  1\n",
      "current step :  285\n",
      "reward :  -0.44585328250539924\n",
      "episode :  2\n",
      "current step :  0\n",
      "reward :  -0.40142886571788255\n",
      "episode :  2\n",
      "current step :  1\n",
      "reward :  -0.3504266442989867\n",
      "episode :  2\n",
      "current step :  2\n",
      "reward :  -0.2966081001368536\n",
      "episode :  2\n",
      "current step :  3\n",
      "reward :  -0.3220720275308914\n",
      "episode :  2\n",
      "current step :  4\n",
      "reward :  -0.374313986646529\n",
      "episode :  2\n",
      "current step :  5\n",
      "reward :  -0.38920616747131714\n",
      "episode :  2\n",
      "current step :  6\n",
      "reward :  -0.4447369731615547\n",
      "episode :  2\n",
      "current step :  7\n",
      "reward :  -0.32515793170113083\n",
      "episode :  2\n",
      "current step :  8\n",
      "reward :  -0.407000167891251\n",
      "episode :  2\n",
      "current step :  9\n",
      "reward :  -0.4743870898870461\n",
      "episode :  2\n",
      "current step :  10\n",
      "reward :  -0.42565644406489184\n",
      "episode :  2\n",
      "current step :  11\n",
      "reward :  -0.3431394715701672\n",
      "episode :  2\n",
      "current step :  12\n",
      "reward :  -0.32814046032790006\n",
      "episode :  2\n",
      "current step :  13\n",
      "reward :  -0.35645834008117805\n",
      "episode :  2\n",
      "current step :  14\n",
      "reward :  -0.4401883674645121\n",
      "episode :  2\n",
      "current step :  15\n",
      "reward :  -0.4230123934716417\n",
      "episode :  2\n",
      "current step :  16\n",
      "reward :  -0.2431464069537077\n",
      "episode :  2\n",
      "current step :  17\n",
      "reward :  -0.2453655689236991\n",
      "episode :  2\n",
      "current step :  18\n",
      "reward :  -0.3039705978405662\n",
      "episode :  2\n",
      "current step :  19\n",
      "reward :  -0.4480323303818217\n",
      "episode :  2\n",
      "current step :  20\n",
      "reward :  -0.38236388256940096\n",
      "episode :  2\n",
      "current step :  21\n",
      "reward :  -0.3775472668762149\n",
      "episode :  2\n",
      "current step :  22\n",
      "reward :  -0.43500495097221825\n",
      "episode :  2\n",
      "current step :  23\n",
      "reward :  -0.4911432249628493\n",
      "episode :  2\n",
      "current step :  24\n",
      "reward :  -0.4894599884364505\n",
      "episode :  2\n",
      "current step :  25\n",
      "reward :  -0.37549967184614624\n",
      "episode :  2\n",
      "current step :  26\n",
      "reward :  -0.33697616119236723\n",
      "episode :  2\n",
      "current step :  27\n",
      "reward :  -0.307216413909422\n",
      "episode :  2\n",
      "current step :  28\n",
      "reward :  -0.39968386522483673\n",
      "episode :  2\n",
      "current step :  29\n",
      "reward :  -0.35997281061682984\n",
      "episode :  2\n",
      "current step :  30\n",
      "reward :  -0.252297828389617\n",
      "episode :  2\n",
      "current step :  31\n",
      "reward :  -0.2158724675001205\n",
      "episode :  2\n",
      "current step :  32\n",
      "reward :  -0.304044755323603\n",
      "episode :  2\n",
      "current step :  33\n",
      "reward :  -0.3599237558706117\n",
      "episode :  2\n",
      "current step :  34\n",
      "reward :  -0.4509769700821064\n",
      "episode :  2\n",
      "current step :  35\n",
      "reward :  -0.42330060862856833\n",
      "episode :  2\n",
      "current step :  36\n",
      "reward :  -0.43961210544073365\n",
      "episode :  2\n",
      "current step :  37\n",
      "reward :  -0.29730204134654314\n",
      "episode :  2\n",
      "current step :  38\n",
      "reward :  -0.20446292468586716\n",
      "episode :  2\n",
      "current step :  39\n",
      "reward :  -0.51645191100696\n",
      "episode :  2\n",
      "current step :  40\n",
      "reward :  -0.49469623412405644\n",
      "episode :  2\n",
      "current step :  41\n",
      "reward :  -0.5133967846027683\n",
      "episode :  2\n",
      "current step :  42\n",
      "reward :  -0.475468292581983\n",
      "episode :  2\n",
      "current step :  43\n",
      "reward :  -0.2990944799324143\n",
      "episode :  2\n",
      "current step :  44\n",
      "reward :  -0.2353402471500807\n",
      "episode :  2\n",
      "current step :  45\n",
      "reward :  -0.22661679587877792\n",
      "episode :  2\n",
      "current step :  46\n",
      "reward :  -0.22395489870794397\n",
      "episode :  2\n",
      "current step :  47\n",
      "reward :  -0.4129711039210877\n",
      "episode :  2\n",
      "current step :  48\n",
      "reward :  -0.574191419873597\n",
      "episode :  2\n",
      "current step :  49\n",
      "reward :  -0.5039671693867169\n",
      "episode :  2\n",
      "current step :  50\n",
      "reward :  -0.5140858124009227\n",
      "episode :  2\n",
      "current step :  51\n",
      "reward :  -0.37735072206582426\n",
      "episode :  2\n",
      "current step :  52\n",
      "reward :  -0.5540404164898619\n",
      "episode :  2\n",
      "current step :  53\n",
      "reward :  -0.5106862617674905\n",
      "episode :  2\n",
      "current step :  54\n",
      "reward :  -0.4918109074140351\n",
      "episode :  2\n",
      "current step :  55\n",
      "reward :  -0.5295187573664982\n",
      "episode :  2\n",
      "current step :  56\n",
      "reward :  -0.4948024392279478\n",
      "episode :  2\n",
      "current step :  57\n",
      "reward :  -0.43429184472946814\n",
      "episode :  2\n",
      "current step :  58\n",
      "reward :  -0.4660589576002454\n",
      "episode :  2\n",
      "current step :  59\n",
      "reward :  -0.5861292821272392\n",
      "episode :  2\n",
      "current step :  60\n",
      "reward :  -0.6460543310971271\n",
      "episode :  2\n",
      "current step :  61\n",
      "reward :  -0.6258217181515586\n",
      "episode :  2\n",
      "current step :  62\n",
      "reward :  -0.6437629143673766\n",
      "episode :  2\n",
      "current step :  63\n",
      "reward :  -0.6212705150606644\n",
      "episode :  2\n",
      "current step :  64\n",
      "reward :  -0.6597230862001241\n",
      "episode :  2\n",
      "current step :  65\n",
      "reward :  -0.5807027314441706\n",
      "episode :  2\n",
      "current step :  66\n",
      "reward :  -0.5658774277428457\n",
      "episode :  2\n",
      "current step :  67\n",
      "reward :  -0.6241155345024841\n",
      "episode :  2\n",
      "current step :  68\n",
      "reward :  -0.6730946198542702\n",
      "episode :  2\n",
      "current step :  69\n",
      "reward :  -0.6609016765485236\n",
      "episode :  2\n",
      "current step :  70\n",
      "reward :  -0.5494831250943184\n",
      "episode :  2\n",
      "current step :  71\n",
      "reward :  -0.47582349279578184\n",
      "episode :  2\n",
      "current step :  72\n",
      "reward :  -0.457025218222728\n",
      "episode :  2\n",
      "current step :  73\n",
      "reward :  -0.4751617499514848\n",
      "episode :  2\n",
      "current step :  74\n",
      "reward :  -0.512626398505764\n",
      "episode :  2\n",
      "current step :  75\n",
      "reward :  -0.5223988520847954\n",
      "episode :  2\n",
      "current step :  76\n",
      "reward :  -0.47228744617301094\n",
      "episode :  2\n",
      "current step :  77\n",
      "reward :  -0.3737720003861697\n",
      "episode :  2\n",
      "current step :  78\n",
      "reward :  -0.4372689255572733\n",
      "episode :  2\n",
      "current step :  79\n",
      "reward :  -0.43216245782667523\n",
      "episode :  2\n",
      "current step :  80\n",
      "reward :  -0.3217202172868826\n",
      "episode :  2\n",
      "current step :  81\n",
      "reward :  -0.41791329342164\n",
      "episode :  2\n",
      "current step :  82\n",
      "reward :  -0.44763534556535883\n",
      "episode :  2\n",
      "current step :  83\n",
      "reward :  -0.44918514967799233\n",
      "episode :  2\n",
      "current step :  84\n",
      "reward :  -0.5411984783544957\n",
      "episode :  2\n",
      "current step :  85\n",
      "reward :  -0.506837608503899\n",
      "episode :  2\n",
      "current step :  86\n",
      "reward :  -0.47366203204616786\n",
      "episode :  2\n",
      "current step :  87\n",
      "reward :  -0.4904396169806397\n",
      "episode :  2\n",
      "current step :  88\n",
      "reward :  -0.49678882219524056\n",
      "episode :  2\n",
      "current step :  89\n",
      "reward :  -0.36019863097296895\n",
      "episode :  2\n",
      "current step :  90\n",
      "reward :  -0.26873658568419806\n",
      "episode :  2\n",
      "current step :  91\n",
      "reward :  -0.23575525652489693\n",
      "episode :  2\n",
      "current step :  92\n",
      "reward :  -0.3362772814335429\n",
      "episode :  2\n",
      "current step :  93\n",
      "reward :  -0.2979469536970513\n",
      "episode :  2\n",
      "current step :  94\n",
      "reward :  -0.3721546582057481\n",
      "episode :  2\n",
      "current step :  95\n",
      "reward :  -0.3076617362189674\n",
      "episode :  2\n",
      "current step :  96\n",
      "reward :  -0.30292530853674376\n",
      "episode :  2\n",
      "current step :  97\n",
      "reward :  -0.3385327530604531\n",
      "episode :  2\n",
      "current step :  98\n",
      "reward :  -0.3366882168148258\n",
      "episode :  2\n",
      "current step :  99\n",
      "reward :  -0.49201070215821135\n",
      "episode :  2\n",
      "current step :  100\n",
      "reward :  -0.34371924404800147\n",
      "episode :  2\n",
      "current step :  101\n",
      "reward :  -0.2839256372002185\n",
      "episode :  2\n",
      "current step :  102\n",
      "reward :  -0.24802441058633942\n",
      "episode :  2\n",
      "current step :  103\n",
      "reward :  -0.32131952832788124\n",
      "episode :  2\n",
      "current step :  104\n",
      "reward :  -0.30269867603354716\n",
      "episode :  2\n",
      "current step :  105\n",
      "reward :  -0.32108978870807287\n",
      "episode :  2\n",
      "current step :  106\n",
      "reward :  -0.42907021762203906\n",
      "episode :  2\n",
      "current step :  107\n",
      "reward :  -0.2772332227523298\n",
      "episode :  2\n",
      "current step :  108\n",
      "reward :  -0.36676687561432186\n",
      "episode :  2\n",
      "current step :  109\n",
      "reward :  -0.23198314439979212\n",
      "episode :  2\n",
      "current step :  110\n",
      "reward :  -0.2322353009447878\n",
      "episode :  2\n",
      "current step :  111\n",
      "reward :  -0.30719196185788095\n",
      "episode :  2\n",
      "current step :  112\n",
      "reward :  -0.28569745457184964\n",
      "episode :  2\n",
      "current step :  113\n",
      "reward :  -0.19506441374976147\n",
      "episode :  2\n",
      "current step :  114\n",
      "reward :  -0.17109577966086156\n",
      "episode :  2\n",
      "current step :  115\n",
      "reward :  -0.19536172341125266\n",
      "episode :  2\n",
      "current step :  116\n",
      "reward :  -0.22304584563298002\n",
      "episode :  2\n",
      "current step :  117\n",
      "reward :  -0.31800358808954593\n",
      "episode :  2\n",
      "current step :  118\n",
      "reward :  -0.21326080888040583\n",
      "episode :  2\n",
      "current step :  119\n",
      "reward :  -0.28141880732658253\n",
      "episode :  2\n",
      "current step :  120\n",
      "reward :  -0.2657010628874626\n",
      "episode :  2\n",
      "current step :  121\n",
      "reward :  -0.23632574642263043\n",
      "episode :  2\n",
      "current step :  122\n",
      "reward :  -0.2701114864439916\n",
      "episode :  2\n",
      "current step :  123\n",
      "reward :  -0.2937081527088547\n",
      "episode :  2\n",
      "current step :  124\n",
      "reward :  -0.3239800279430808\n",
      "episode :  2\n",
      "current step :  125\n",
      "reward :  -0.23038956820018347\n",
      "episode :  2\n",
      "current step :  126\n",
      "reward :  -0.26460187070383223\n",
      "episode :  2\n",
      "current step :  127\n",
      "reward :  -0.2522305279823231\n",
      "episode :  2\n",
      "current step :  128\n",
      "reward :  -0.2965404389686913\n",
      "episode :  2\n",
      "current step :  129\n",
      "reward :  -0.39156911645557396\n",
      "episode :  2\n",
      "current step :  130\n",
      "reward :  -0.3773195889768411\n",
      "episode :  2\n",
      "current step :  131\n",
      "reward :  -0.3447583586882704\n",
      "episode :  2\n",
      "current step :  132\n",
      "reward :  -0.23379069664710084\n",
      "episode :  2\n",
      "current step :  133\n",
      "reward :  -0.3917008773067913\n",
      "episode :  2\n",
      "current step :  134\n",
      "reward :  -0.37275049345647976\n",
      "episode :  2\n",
      "current step :  135\n",
      "reward :  -0.16452437124289654\n",
      "episode :  2\n",
      "current step :  136\n",
      "reward :  -0.22926366838445605\n",
      "episode :  2\n",
      "current step :  137\n",
      "reward :  -0.17476582238581292\n",
      "episode :  2\n",
      "current step :  138\n",
      "reward :  -0.1516711316807578\n",
      "episode :  2\n",
      "current step :  139\n",
      "reward :  -0.3072352428118704\n",
      "episode :  2\n",
      "current step :  140\n",
      "reward :  -0.41841161802957116\n",
      "episode :  2\n",
      "current step :  141\n",
      "reward :  -0.29984908421859474\n",
      "episode :  2\n",
      "current step :  142\n",
      "reward :  -0.3221600735532259\n",
      "episode :  2\n",
      "current step :  143\n",
      "reward :  -0.33315858322729713\n",
      "episode :  2\n",
      "current step :  144\n",
      "reward :  -0.26888803942880807\n",
      "episode :  2\n",
      "current step :  145\n",
      "reward :  -0.3065344483289522\n",
      "episode :  2\n",
      "current step :  146\n",
      "reward :  -0.34334608605319594\n",
      "episode :  2\n",
      "current step :  147\n",
      "reward :  -0.401426971046564\n",
      "episode :  2\n",
      "current step :  148\n",
      "reward :  -0.542767682805414\n",
      "episode :  2\n",
      "current step :  149\n",
      "reward :  -0.5656804939836758\n",
      "episode :  2\n",
      "current step :  150\n",
      "reward :  -0.45556472437863216\n",
      "episode :  2\n",
      "current step :  151\n",
      "reward :  -0.4105250805888119\n",
      "episode :  2\n",
      "current step :  152\n",
      "reward :  -0.4961805710153102\n",
      "episode :  2\n",
      "current step :  153\n",
      "reward :  -0.5424652024890749\n",
      "episode :  2\n",
      "current step :  154\n",
      "reward :  -0.32966682659249386\n",
      "episode :  2\n",
      "current step :  155\n",
      "reward :  -0.2964274930622295\n",
      "episode :  2\n",
      "current step :  156\n",
      "reward :  -0.3860510086315517\n",
      "episode :  2\n",
      "current step :  157\n",
      "reward :  -0.5266764304013551\n",
      "episode :  2\n",
      "current step :  158\n",
      "reward :  -0.4345645141332139\n",
      "episode :  2\n",
      "current step :  159\n",
      "reward :  -0.5120165332578102\n",
      "episode :  2\n",
      "current step :  160\n",
      "reward :  -0.5278449037303643\n",
      "episode :  2\n",
      "current step :  161\n",
      "reward :  -0.38035218584053737\n",
      "episode :  2\n",
      "current step :  162\n",
      "reward :  -0.36994696743999345\n",
      "episode :  2\n",
      "current step :  163\n",
      "reward :  -0.39037215855984536\n",
      "episode :  2\n",
      "current step :  164\n",
      "reward :  -0.40502786450910205\n",
      "episode :  2\n",
      "current step :  165\n",
      "reward :  -0.42710792942037623\n",
      "episode :  2\n",
      "current step :  166\n",
      "reward :  -0.43751961432041553\n",
      "episode :  2\n",
      "current step :  167\n",
      "reward :  -0.5158982661533631\n",
      "episode :  2\n",
      "current step :  168\n",
      "reward :  -0.6618409360284847\n",
      "episode :  2\n",
      "current step :  169\n",
      "reward :  -0.6280592376133661\n",
      "episode :  2\n",
      "current step :  170\n",
      "reward :  -0.5910809560382246\n",
      "episode :  2\n",
      "current step :  171\n",
      "reward :  -0.572993120192536\n",
      "episode :  2\n",
      "current step :  172\n",
      "reward :  -0.6110301703657122\n",
      "episode :  2\n",
      "current step :  173\n",
      "reward :  -0.6482394571601334\n",
      "episode :  2\n",
      "current step :  174\n",
      "reward :  -0.6446065373381289\n",
      "episode :  2\n",
      "current step :  175\n",
      "reward :  -0.5855955076527044\n",
      "episode :  2\n",
      "current step :  176\n",
      "reward :  -0.5256292497092652\n",
      "episode :  2\n",
      "current step :  177\n",
      "reward :  -0.5040766606793838\n",
      "episode :  2\n",
      "current step :  178\n",
      "reward :  -0.5216157200823917\n",
      "episode :  2\n",
      "current step :  179\n",
      "reward :  -0.5703858944175395\n",
      "episode :  2\n",
      "current step :  180\n",
      "reward :  -0.6206730898633869\n",
      "episode :  2\n",
      "current step :  181\n",
      "reward :  -0.5641495860918688\n",
      "episode :  2\n",
      "current step :  182\n",
      "reward :  -0.6367930317063913\n",
      "episode :  2\n",
      "current step :  183\n",
      "reward :  -0.6262728146677569\n",
      "episode :  2\n",
      "current step :  184\n",
      "reward :  -0.4731482999645466\n",
      "episode :  2\n",
      "current step :  185\n",
      "reward :  -0.21686339657821785\n",
      "episode :  2\n",
      "current step :  186\n",
      "reward :  -0.23935659566221995\n",
      "episode :  2\n",
      "current step :  187\n",
      "reward :  -0.43348859478589225\n",
      "episode :  2\n",
      "current step :  188\n",
      "reward :  -0.540547833874559\n",
      "episode :  2\n",
      "current step :  189\n",
      "reward :  -0.47376849194669196\n",
      "episode :  2\n",
      "current step :  190\n",
      "reward :  -0.5561636878040598\n",
      "episode :  2\n",
      "current step :  191\n",
      "reward :  -0.4450015505239697\n",
      "episode :  2\n",
      "current step :  192\n",
      "reward :  -0.3819057178559786\n",
      "episode :  2\n",
      "current step :  193\n",
      "reward :  -0.44151579820130366\n",
      "episode :  2\n",
      "current step :  194\n",
      "reward :  -0.5428489327412502\n",
      "episode :  2\n",
      "current step :  195\n",
      "reward :  -0.6114734572802322\n",
      "episode :  2\n",
      "current step :  196\n",
      "reward :  -0.649687703071627\n",
      "episode :  2\n",
      "current step :  197\n",
      "reward :  -0.5749132597127584\n",
      "episode :  2\n",
      "current step :  198\n",
      "reward :  -0.5573063564651222\n",
      "episode :  2\n",
      "current step :  199\n",
      "reward :  -0.5335851678376267\n",
      "episode :  2\n",
      "current step :  200\n",
      "reward :  -0.5151494484925851\n",
      "episode :  2\n",
      "current step :  201\n",
      "reward :  -0.5247244525437998\n",
      "episode :  2\n",
      "current step :  202\n",
      "reward :  -0.4190064599275867\n",
      "episode :  2\n",
      "current step :  203\n",
      "reward :  -0.4900823124485836\n",
      "episode :  2\n",
      "current step :  204\n",
      "reward :  -0.5344284599802754\n",
      "episode :  2\n",
      "current step :  205\n",
      "reward :  -0.5705437917656665\n",
      "episode :  2\n",
      "current step :  206\n",
      "reward :  -0.6158426786158097\n",
      "episode :  2\n",
      "current step :  207\n",
      "reward :  -0.5632433471987871\n",
      "episode :  2\n",
      "current step :  208\n",
      "reward :  -0.5613038759938269\n",
      "episode :  2\n",
      "current step :  209\n",
      "reward :  -0.5641879622137946\n",
      "episode :  2\n",
      "current step :  210\n",
      "reward :  -0.5007870366073349\n",
      "episode :  2\n",
      "current step :  211\n",
      "reward :  -0.45666040904912053\n",
      "episode :  2\n",
      "current step :  212\n",
      "reward :  -0.3923947999184768\n",
      "episode :  2\n",
      "current step :  213\n",
      "reward :  -0.4355937695175276\n",
      "episode :  2\n",
      "current step :  214\n",
      "reward :  -0.4263271671294152\n",
      "episode :  2\n",
      "current step :  215\n",
      "reward :  -0.411800072087244\n",
      "episode :  2\n",
      "current step :  216\n",
      "reward :  -0.44730071324092285\n",
      "episode :  2\n",
      "current step :  217\n",
      "reward :  -0.42876035281357233\n",
      "episode :  2\n",
      "current step :  218\n",
      "reward :  -0.5333528744386618\n",
      "episode :  2\n",
      "current step :  219\n",
      "reward :  -0.43423186970414224\n",
      "episode :  2\n",
      "current step :  220\n",
      "reward :  -0.40570381509337367\n",
      "episode :  2\n",
      "current step :  221\n",
      "reward :  -0.41304282334540665\n",
      "episode :  2\n",
      "current step :  222\n",
      "reward :  -0.5148659954548472\n",
      "episode :  2\n",
      "current step :  223\n",
      "reward :  -0.41711920279176695\n",
      "episode :  2\n",
      "current step :  224\n",
      "reward :  -0.3728741273384593\n",
      "episode :  2\n",
      "current step :  225\n",
      "reward :  -0.47294609737878984\n",
      "episode :  2\n",
      "current step :  226\n",
      "reward :  -0.5175670014196542\n",
      "episode :  2\n",
      "current step :  227\n",
      "reward :  -0.4226425685673505\n",
      "episode :  2\n",
      "current step :  228\n",
      "reward :  -0.5317189320334312\n",
      "episode :  2\n",
      "current step :  229\n",
      "reward :  -0.39171586150521687\n",
      "episode :  2\n",
      "current step :  230\n",
      "reward :  -0.25722008833689886\n",
      "episode :  2\n",
      "current step :  231\n",
      "reward :  -0.2868649979055603\n",
      "episode :  2\n",
      "current step :  232\n",
      "reward :  -0.35044183146698543\n",
      "episode :  2\n",
      "current step :  233\n",
      "reward :  -0.4418975760540883\n",
      "episode :  2\n",
      "current step :  234\n",
      "reward :  -0.4346440719144063\n",
      "episode :  2\n",
      "current step :  235\n",
      "reward :  -0.44568113547691945\n",
      "episode :  2\n",
      "current step :  236\n",
      "reward :  -0.44417683219349047\n",
      "episode :  2\n",
      "current step :  237\n",
      "reward :  -0.3771926026494396\n",
      "episode :  2\n",
      "current step :  238\n",
      "reward :  -0.33228530479870405\n",
      "episode :  2\n",
      "current step :  239\n",
      "reward :  -0.3029944559073678\n",
      "episode :  2\n",
      "current step :  240\n",
      "reward :  -0.28268426955965426\n",
      "episode :  2\n",
      "current step :  241\n",
      "reward :  -0.23238713006350423\n",
      "episode :  2\n",
      "current step :  242\n",
      "reward :  -0.2950937114996668\n",
      "episode :  2\n",
      "current step :  243\n",
      "reward :  -0.19840970548876807\n",
      "episode :  2\n",
      "current step :  244\n",
      "reward :  -0.18733304805977274\n",
      "episode :  2\n",
      "current step :  245\n",
      "reward :  -0.24700009113169308\n",
      "episode :  2\n",
      "current step :  246\n",
      "reward :  -0.2760647079234496\n",
      "episode :  2\n",
      "current step :  247\n",
      "reward :  -0.16857724133763963\n",
      "episode :  2\n",
      "current step :  248\n",
      "reward :  -0.394248057733194\n",
      "episode :  2\n",
      "current step :  249\n",
      "reward :  -0.4968764649005965\n",
      "episode :  2\n",
      "current step :  250\n",
      "reward :  -0.4749499328314611\n",
      "episode :  2\n",
      "current step :  251\n",
      "reward :  -0.47010395251314774\n",
      "episode :  2\n",
      "current step :  252\n",
      "reward :  -0.32265938648067194\n",
      "episode :  2\n",
      "current step :  253\n",
      "reward :  -0.281219369910968\n",
      "episode :  2\n",
      "current step :  254\n",
      "reward :  -0.23470362600407252\n",
      "episode :  2\n",
      "current step :  255\n",
      "reward :  -0.34174276105128476\n",
      "episode :  2\n",
      "current step :  256\n",
      "reward :  -0.41031037875749143\n",
      "episode :  2\n",
      "current step :  257\n",
      "reward :  -0.31584845173413606\n",
      "episode :  2\n",
      "current step :  258\n",
      "reward :  -0.34931538614981894\n",
      "episode :  2\n",
      "current step :  259\n",
      "reward :  -0.4259959538523374\n",
      "episode :  2\n",
      "current step :  260\n",
      "reward :  -0.3898959366268184\n",
      "episode :  2\n",
      "current step :  261\n",
      "reward :  -0.3017502916623266\n",
      "episode :  2\n",
      "current step :  262\n",
      "reward :  -0.35516508394817\n",
      "episode :  2\n",
      "current step :  263\n",
      "reward :  -0.37024598835823985\n",
      "episode :  2\n",
      "current step :  264\n",
      "reward :  -0.3017104571405178\n",
      "episode :  2\n",
      "current step :  265\n",
      "reward :  -0.29180574298553236\n",
      "episode :  2\n",
      "current step :  266\n",
      "reward :  -0.25002247693987695\n",
      "episode :  2\n",
      "current step :  267\n",
      "reward :  -0.2532396098080393\n",
      "episode :  2\n",
      "current step :  268\n",
      "reward :  -0.37343151965249727\n",
      "episode :  2\n",
      "current step :  269\n",
      "reward :  -0.4069748369351499\n",
      "episode :  2\n",
      "current step :  270\n",
      "reward :  -0.3775784158619117\n",
      "episode :  2\n",
      "current step :  271\n",
      "reward :  -0.3852871451992664\n",
      "episode :  2\n",
      "current step :  272\n",
      "reward :  -0.43927544701991383\n",
      "episode :  2\n",
      "current step :  273\n",
      "reward :  -0.42005646619786974\n",
      "episode :  2\n",
      "current step :  274\n",
      "reward :  -0.44058040325116415\n",
      "episode :  2\n",
      "current step :  275\n",
      "reward :  -0.3258436747013632\n",
      "episode :  2\n",
      "current step :  276\n",
      "reward :  -0.29853854286261405\n",
      "episode :  2\n",
      "current step :  277\n",
      "reward :  -0.20351585635236025\n",
      "episode :  2\n",
      "current step :  278\n",
      "reward :  -0.19747445504292585\n",
      "episode :  2\n",
      "current step :  279\n",
      "reward :  -0.30506128632197593\n",
      "episode :  2\n",
      "current step :  280\n",
      "reward :  -0.42885267509022135\n",
      "episode :  2\n",
      "current step :  281\n",
      "reward :  -0.4143904123273011\n",
      "episode :  2\n",
      "current step :  282\n",
      "reward :  -0.34896768523699717\n",
      "episode :  2\n",
      "current step :  283\n",
      "reward :  -0.30645588745818897\n",
      "episode :  2\n",
      "current step :  284\n",
      "reward :  -0.179133865939549\n",
      "episode :  2\n",
      "current step :  285\n",
      "reward :  -0.22588732989950525\n",
      "episode :  3\n",
      "current step :  0\n",
      "reward :  -0.35613641752474373\n",
      "episode :  3\n",
      "current step :  1\n",
      "reward :  -0.3083962264177898\n",
      "episode :  3\n",
      "current step :  2\n",
      "reward :  -0.3508257259822825\n",
      "episode :  3\n",
      "current step :  3\n",
      "reward :  -0.39395273686156035\n",
      "episode :  3\n",
      "current step :  4\n",
      "reward :  -0.39477459019621663\n",
      "episode :  3\n",
      "current step :  5\n",
      "reward :  -0.40985326368671937\n",
      "episode :  3\n",
      "current step :  6\n",
      "reward :  -0.44029411586612893\n",
      "episode :  3\n",
      "current step :  7\n",
      "reward :  -0.26246080227701946\n",
      "episode :  3\n",
      "current step :  8\n",
      "reward :  -0.3530151478682164\n",
      "episode :  3\n",
      "current step :  9\n",
      "reward :  -0.3593165976791658\n",
      "episode :  3\n",
      "current step :  10\n",
      "reward :  -0.24875949789371754\n",
      "episode :  3\n",
      "current step :  11\n",
      "reward :  -0.29708014729220794\n",
      "episode :  3\n",
      "current step :  12\n",
      "reward :  -0.35256187289491836\n",
      "episode :  3\n",
      "current step :  13\n",
      "reward :  -0.4399412150959937\n",
      "episode :  3\n",
      "current step :  14\n",
      "reward :  -0.41071569309117884\n",
      "episode :  3\n",
      "current step :  15\n",
      "reward :  -0.3432407411829377\n",
      "episode :  3\n",
      "current step :  16\n",
      "reward :  -0.31328712368571854\n",
      "episode :  3\n",
      "current step :  17\n",
      "reward :  -0.4249515750176914\n",
      "episode :  3\n",
      "current step :  18\n",
      "reward :  -0.5137546755487256\n",
      "episode :  3\n",
      "current step :  19\n",
      "reward :  -0.46563657562705013\n",
      "episode :  3\n",
      "current step :  20\n",
      "reward :  -0.3545905610795296\n",
      "episode :  3\n",
      "current step :  21\n",
      "reward :  -0.3719761991636918\n",
      "episode :  3\n",
      "current step :  22\n",
      "reward :  -0.4129238206227588\n",
      "episode :  3\n",
      "current step :  23\n",
      "reward :  -0.405186534520177\n",
      "episode :  3\n",
      "current step :  24\n",
      "reward :  -0.4139420785911522\n",
      "episode :  3\n",
      "current step :  25\n",
      "reward :  -0.48055732888208547\n",
      "episode :  3\n",
      "current step :  26\n",
      "reward :  -0.3794192968169632\n",
      "episode :  3\n",
      "current step :  27\n",
      "reward :  -0.29453762889340385\n",
      "episode :  3\n",
      "current step :  28\n",
      "reward :  -0.2735687784305377\n",
      "episode :  3\n",
      "current step :  29\n",
      "reward :  -0.3600945478400545\n",
      "episode :  3\n",
      "current step :  30\n",
      "reward :  -0.41677143143146667\n",
      "episode :  3\n",
      "current step :  31\n",
      "reward :  -0.3828335865919729\n",
      "episode :  3\n",
      "current step :  32\n",
      "reward :  -0.33838285166132376\n",
      "episode :  3\n",
      "current step :  33\n",
      "reward :  -0.19242540472386377\n",
      "episode :  3\n",
      "current step :  34\n",
      "reward :  -0.39714045750733795\n",
      "episode :  3\n",
      "current step :  35\n",
      "reward :  -0.29675756756536525\n",
      "episode :  3\n",
      "current step :  36\n",
      "reward :  -0.3541047579043071\n",
      "episode :  3\n",
      "current step :  37\n",
      "reward :  -0.5091325349736585\n",
      "episode :  3\n",
      "current step :  38\n",
      "reward :  -0.5335587616555216\n",
      "episode :  3\n",
      "current step :  39\n",
      "reward :  -0.4798622804426083\n",
      "episode :  3\n",
      "current step :  40\n",
      "reward :  -0.41285578567882386\n",
      "episode :  3\n",
      "current step :  41\n",
      "reward :  -0.39166300661420733\n",
      "episode :  3\n",
      "current step :  42\n",
      "reward :  -0.3262447780254847\n",
      "episode :  3\n",
      "current step :  43\n",
      "reward :  -0.2894397819835213\n",
      "episode :  3\n",
      "current step :  44\n",
      "reward :  -0.43940554914295626\n",
      "episode :  3\n",
      "current step :  45\n",
      "reward :  -0.5373745079050404\n",
      "episode :  3\n",
      "current step :  46\n",
      "reward :  -0.4854473550406587\n",
      "episode :  3\n",
      "current step :  47\n",
      "reward :  -0.49725194249178734\n",
      "episode :  3\n",
      "current step :  48\n",
      "reward :  -0.4694425367906641\n",
      "episode :  3\n",
      "current step :  49\n",
      "reward :  -0.3411297417406419\n",
      "episode :  3\n",
      "current step :  50\n",
      "reward :  -0.5883969528342246\n",
      "episode :  3\n",
      "current step :  51\n",
      "reward :  -0.5941632819099796\n",
      "episode :  3\n",
      "current step :  52\n",
      "reward :  -0.6423119358941572\n",
      "episode :  3\n",
      "current step :  53\n",
      "reward :  -0.7303566826119515\n",
      "episode :  3\n",
      "current step :  54\n",
      "reward :  -0.6728449768674684\n",
      "episode :  3\n",
      "current step :  55\n",
      "reward :  -0.6129560678563593\n",
      "episode :  3\n",
      "current step :  56\n",
      "reward :  -0.5576032888305948\n",
      "episode :  3\n",
      "current step :  57\n",
      "reward :  -0.5869586351034339\n",
      "episode :  3\n",
      "current step :  58\n",
      "reward :  -0.5036189978953167\n",
      "episode :  3\n",
      "current step :  59\n",
      "reward :  -0.5194670560366883\n",
      "episode :  3\n",
      "current step :  60\n",
      "reward :  -0.5450977493082465\n",
      "episode :  3\n",
      "current step :  61\n",
      "reward :  -0.5542436661902629\n",
      "episode :  3\n",
      "current step :  62\n",
      "reward :  -0.622989684129114\n",
      "episode :  3\n",
      "current step :  63\n",
      "reward :  -0.6434018912855894\n",
      "episode :  3\n",
      "current step :  64\n",
      "reward :  -0.5623720208352164\n",
      "episode :  3\n",
      "current step :  65\n",
      "reward :  -0.5081739471928651\n",
      "episode :  3\n",
      "current step :  66\n",
      "reward :  -0.4157142553759466\n",
      "episode :  3\n",
      "current step :  67\n",
      "reward :  -0.3931663557378537\n",
      "episode :  3\n",
      "current step :  68\n",
      "reward :  -0.5722965367035414\n",
      "episode :  3\n",
      "current step :  69\n",
      "reward :  -0.6796450776474766\n",
      "episode :  3\n",
      "current step :  70\n",
      "reward :  -0.6322079090617595\n",
      "episode :  3\n",
      "current step :  71\n",
      "reward :  -0.7128255298475971\n",
      "episode :  3\n",
      "current step :  72\n",
      "reward :  -0.6326508066849381\n",
      "episode :  3\n",
      "current step :  73\n",
      "reward :  -0.3419457269781056\n",
      "episode :  3\n",
      "current step :  74\n",
      "reward :  -0.26965785933095643\n",
      "episode :  3\n",
      "current step :  75\n",
      "reward :  -0.38471075764545354\n",
      "episode :  3\n",
      "current step :  76\n",
      "reward :  -0.458588692991876\n",
      "episode :  3\n",
      "current step :  77\n",
      "reward :  -0.2503836710988603\n",
      "episode :  3\n",
      "current step :  78\n",
      "reward :  -0.3718097711610013\n",
      "episode :  3\n",
      "current step :  79\n",
      "reward :  -0.25085822005447905\n",
      "episode :  3\n",
      "current step :  80\n",
      "reward :  -0.22098418092963582\n",
      "episode :  3\n",
      "current step :  81\n",
      "reward :  -0.41713876265741395\n",
      "episode :  3\n",
      "current step :  82\n",
      "reward :  -0.3875772709403284\n",
      "episode :  3\n",
      "current step :  83\n",
      "reward :  -0.33190922894128916\n",
      "episode :  3\n",
      "current step :  84\n",
      "reward :  -0.26403132069693863\n",
      "episode :  3\n",
      "current step :  85\n",
      "reward :  -0.29157081130780066\n",
      "episode :  3\n",
      "current step :  86\n",
      "reward :  -0.36198632303326106\n",
      "episode :  3\n",
      "current step :  87\n",
      "reward :  -0.3962980518867308\n",
      "episode :  3\n",
      "current step :  88\n",
      "reward :  -0.34439949886898513\n",
      "episode :  3\n",
      "current step :  89\n",
      "reward :  -0.3911605838475007\n",
      "episode :  3\n",
      "current step :  90\n",
      "reward :  -0.4668750005440824\n",
      "episode :  3\n",
      "current step :  91\n",
      "reward :  -0.4899869672805481\n",
      "episode :  3\n",
      "current step :  92\n",
      "reward :  -0.4544809827541707\n",
      "episode :  3\n",
      "current step :  93\n",
      "reward :  -0.4566538612228993\n",
      "episode :  3\n",
      "current step :  94\n",
      "reward :  -0.4560447794678287\n",
      "episode :  3\n",
      "current step :  95\n",
      "reward :  -0.3246897923402354\n",
      "episode :  3\n",
      "current step :  96\n",
      "reward :  -0.27733138528352635\n",
      "episode :  3\n",
      "current step :  97\n",
      "reward :  -0.3071556321200587\n",
      "episode :  3\n",
      "current step :  98\n",
      "reward :  -0.26026868951351256\n",
      "episode :  3\n",
      "current step :  99\n",
      "reward :  -0.2271460250437587\n",
      "episode :  3\n",
      "current step :  100\n",
      "reward :  -0.36904471424215785\n",
      "episode :  3\n",
      "current step :  101\n",
      "reward :  -0.39993211076782403\n",
      "episode :  3\n",
      "current step :  102\n",
      "reward :  -0.3269251477504237\n",
      "episode :  3\n",
      "current step :  103\n",
      "reward :  -0.30120203172845805\n",
      "episode :  3\n",
      "current step :  104\n",
      "reward :  -0.37339175910188344\n",
      "episode :  3\n",
      "current step :  105\n",
      "reward :  -0.3805432453695782\n",
      "episode :  3\n",
      "current step :  106\n",
      "reward :  -0.3172391082079382\n",
      "episode :  3\n",
      "current step :  107\n",
      "reward :  -0.3532872786971475\n",
      "episode :  3\n",
      "current step :  108\n",
      "reward :  -0.3964535601147901\n",
      "episode :  3\n",
      "current step :  109\n",
      "reward :  -0.3666927109746522\n",
      "episode :  3\n",
      "current step :  110\n",
      "reward :  -0.360492733050949\n",
      "episode :  3\n",
      "current step :  111\n",
      "reward :  -0.39584586760995\n",
      "episode :  3\n",
      "current step :  112\n",
      "reward :  -0.43289379354535396\n",
      "episode :  3\n",
      "current step :  113\n",
      "reward :  -0.47119702893584575\n",
      "episode :  3\n",
      "current step :  114\n",
      "reward :  -0.48623871793944756\n",
      "episode :  3\n",
      "current step :  115\n",
      "reward :  -0.4400931248531312\n",
      "episode :  3\n",
      "current step :  116\n",
      "reward :  -0.40597303683040187\n",
      "episode :  3\n",
      "current step :  117\n",
      "reward :  -0.3905534057123804\n",
      "episode :  3\n",
      "current step :  118\n",
      "reward :  -0.3627536578246414\n",
      "episode :  3\n",
      "current step :  119\n",
      "reward :  -0.3631281175488291\n",
      "episode :  3\n",
      "current step :  120\n",
      "reward :  -0.3916461442272027\n",
      "episode :  3\n",
      "current step :  121\n",
      "reward :  -0.2596894460395033\n",
      "episode :  3\n",
      "current step :  122\n",
      "reward :  -0.353398673522281\n",
      "episode :  3\n",
      "current step :  123\n",
      "reward :  -0.3444984420111849\n",
      "episode :  3\n",
      "current step :  124\n",
      "reward :  -0.3615142772028939\n",
      "episode :  3\n",
      "current step :  125\n",
      "reward :  -0.3095713500595117\n",
      "episode :  3\n",
      "current step :  126\n",
      "reward :  -0.391062488327537\n",
      "episode :  3\n",
      "current step :  127\n",
      "reward :  -0.3512292057946799\n",
      "episode :  3\n",
      "current step :  128\n",
      "reward :  -0.18222806128288016\n",
      "episode :  3\n",
      "current step :  129\n",
      "reward :  -0.21947622106216222\n",
      "episode :  3\n",
      "current step :  130\n",
      "reward :  -0.2778398417515224\n",
      "episode :  3\n",
      "current step :  131\n",
      "reward :  -0.30733399938843275\n",
      "episode :  3\n",
      "current step :  132\n",
      "reward :  -0.3353745296991252\n",
      "episode :  3\n",
      "current step :  133\n",
      "reward :  -0.3064251601867507\n",
      "episode :  3\n",
      "current step :  134\n",
      "reward :  -0.313477199971432\n",
      "episode :  3\n",
      "current step :  135\n",
      "reward :  -0.343676882872973\n",
      "episode :  3\n",
      "current step :  136\n",
      "reward :  -0.39040645575620264\n",
      "episode :  3\n",
      "current step :  137\n",
      "reward :  -0.37071944587084443\n",
      "episode :  3\n",
      "current step :  138\n",
      "reward :  -0.281677784373608\n",
      "episode :  3\n",
      "current step :  139\n",
      "reward :  -0.16457031865867006\n",
      "episode :  3\n",
      "current step :  140\n",
      "reward :  -0.26153630661337646\n",
      "episode :  3\n",
      "current step :  141\n",
      "reward :  -0.3045689794389183\n",
      "episode :  3\n",
      "current step :  142\n",
      "reward :  -0.35416260609383265\n",
      "episode :  3\n",
      "current step :  143\n",
      "reward :  -0.39413184900556153\n",
      "episode :  3\n",
      "current step :  144\n",
      "reward :  -0.33139479477305633\n",
      "episode :  3\n",
      "current step :  145\n",
      "reward :  -0.3103358935499864\n",
      "episode :  3\n",
      "current step :  146\n",
      "reward :  -0.31622452898196257\n",
      "episode :  3\n",
      "current step :  147\n",
      "reward :  -0.3217851925968797\n",
      "episode :  3\n",
      "current step :  148\n",
      "reward :  -0.3350876690250618\n",
      "episode :  3\n",
      "current step :  149\n",
      "reward :  -0.40775543433916145\n",
      "episode :  3\n",
      "current step :  150\n",
      "reward :  -0.5923771284192596\n",
      "episode :  3\n",
      "current step :  151\n",
      "reward :  -0.48853139385878264\n",
      "episode :  3\n",
      "current step :  152\n",
      "reward :  -0.40920154564627104\n",
      "episode :  3\n",
      "current step :  153\n",
      "reward :  -0.3376660845023147\n",
      "episode :  3\n",
      "current step :  154\n",
      "reward :  -0.47466099210257706\n",
      "episode :  3\n",
      "current step :  155\n",
      "reward :  -0.44445043473658624\n",
      "episode :  3\n",
      "current step :  156\n",
      "reward :  -0.4667081083670813\n",
      "episode :  3\n",
      "current step :  157\n",
      "reward :  -0.5441546806889456\n",
      "episode :  3\n",
      "current step :  158\n",
      "reward :  -0.4820775876993008\n",
      "episode :  3\n",
      "current step :  159\n",
      "reward :  -0.5455445266113209\n",
      "episode :  3\n",
      "current step :  160\n",
      "reward :  -0.5659097329047448\n",
      "episode :  3\n",
      "current step :  161\n",
      "reward :  -0.5263068383755867\n",
      "episode :  3\n",
      "current step :  162\n",
      "reward :  -0.40399951345314533\n",
      "episode :  3\n",
      "current step :  163\n",
      "reward :  -0.3727081910723922\n",
      "episode :  3\n",
      "current step :  164\n",
      "reward :  -0.33245272253645847\n",
      "episode :  3\n",
      "current step :  165\n",
      "reward :  -0.41598711978992714\n",
      "episode :  3\n",
      "current step :  166\n",
      "reward :  -0.49892688330721946\n",
      "episode :  3\n",
      "current step :  167\n",
      "reward :  -0.5424830172174417\n",
      "episode :  3\n",
      "current step :  168\n",
      "reward :  -0.40543618954360316\n",
      "episode :  3\n",
      "current step :  169\n",
      "reward :  -0.3808062953506187\n",
      "episode :  3\n",
      "current step :  170\n",
      "reward :  -0.3410866852545992\n",
      "episode :  3\n",
      "current step :  171\n",
      "reward :  -0.43934829625651145\n",
      "episode :  3\n",
      "current step :  172\n",
      "reward :  -0.5215502910064355\n",
      "episode :  3\n",
      "current step :  173\n",
      "reward :  -0.4952148448515234\n",
      "episode :  3\n",
      "current step :  174\n",
      "reward :  -0.44201569455152884\n",
      "episode :  3\n",
      "current step :  175\n",
      "reward :  -0.5361572593004393\n",
      "episode :  3\n",
      "current step :  176\n",
      "reward :  -0.5362377529060596\n",
      "episode :  3\n",
      "current step :  177\n",
      "reward :  -0.38826174656776563\n",
      "episode :  3\n",
      "current step :  178\n",
      "reward :  -0.45137016489162035\n",
      "episode :  3\n",
      "current step :  179\n",
      "reward :  -0.5497284828055796\n",
      "episode :  3\n",
      "current step :  180\n",
      "reward :  -0.593344989201581\n",
      "episode :  3\n",
      "current step :  181\n",
      "reward :  -0.6329902705909161\n",
      "episode :  3\n",
      "current step :  182\n",
      "reward :  -0.6288611778713825\n",
      "episode :  3\n",
      "current step :  183\n",
      "reward :  -0.622445927058752\n",
      "episode :  3\n",
      "current step :  184\n",
      "reward :  -0.5782183287028235\n",
      "episode :  3\n",
      "current step :  185\n",
      "reward :  -0.7170675569341066\n",
      "episode :  3\n",
      "current step :  186\n",
      "reward :  -0.67431046026329\n",
      "episode :  3\n",
      "current step :  187\n",
      "reward :  -0.6972036477470241\n",
      "episode :  3\n",
      "current step :  188\n",
      "reward :  -0.5135979797912046\n",
      "episode :  3\n",
      "current step :  189\n",
      "reward :  -0.5655861692313429\n",
      "episode :  3\n",
      "current step :  190\n",
      "reward :  -0.5541189139606854\n",
      "episode :  3\n",
      "current step :  191\n",
      "reward :  -0.5411353392537432\n",
      "episode :  3\n",
      "current step :  192\n",
      "reward :  -0.470864219224317\n",
      "episode :  3\n",
      "current step :  193\n",
      "reward :  -0.49710493700037695\n",
      "episode :  3\n",
      "current step :  194\n",
      "reward :  -0.6495367433432027\n",
      "episode :  3\n",
      "current step :  195\n",
      "reward :  -0.4890193895659923\n",
      "episode :  3\n",
      "current step :  196\n",
      "reward :  -0.31813693946460425\n",
      "episode :  3\n",
      "current step :  197\n",
      "reward :  -0.35240433116752096\n",
      "episode :  3\n",
      "current step :  198\n",
      "reward :  -0.45246857324199036\n",
      "episode :  3\n",
      "current step :  199\n",
      "reward :  -0.5417210410920229\n",
      "episode :  3\n",
      "current step :  200\n",
      "reward :  -0.5440465858623086\n",
      "episode :  3\n",
      "current step :  201\n",
      "reward :  -0.4478894571848399\n",
      "episode :  3\n",
      "current step :  202\n",
      "reward :  -0.4808060034107033\n",
      "episode :  3\n",
      "current step :  203\n",
      "reward :  -0.6197996865082743\n",
      "episode :  3\n",
      "current step :  204\n",
      "reward :  -0.6078821266672673\n",
      "episode :  3\n",
      "current step :  205\n",
      "reward :  -0.5523649794496943\n",
      "episode :  3\n",
      "current step :  206\n",
      "reward :  -0.5555850657792184\n",
      "episode :  3\n",
      "current step :  207\n",
      "reward :  -0.6072384470691023\n",
      "episode :  3\n",
      "current step :  208\n",
      "reward :  -0.4327207328544553\n",
      "episode :  3\n",
      "current step :  209\n",
      "reward :  -0.3963338553237744\n",
      "episode :  3\n",
      "current step :  210\n",
      "reward :  -0.47392547473944396\n",
      "episode :  3\n",
      "current step :  211\n",
      "reward :  -0.5523020987991081\n",
      "episode :  3\n",
      "current step :  212\n",
      "reward :  -0.5771798788038379\n",
      "episode :  3\n",
      "current step :  213\n",
      "reward :  -0.5346147659119583\n",
      "episode :  3\n",
      "current step :  214\n",
      "reward :  -0.5505552670725464\n",
      "episode :  3\n",
      "current step :  215\n",
      "reward :  -0.5582646299823115\n",
      "episode :  3\n",
      "current step :  216\n",
      "reward :  -0.5910703135754483\n",
      "episode :  3\n",
      "current step :  217\n",
      "reward :  -0.5340948183151775\n",
      "episode :  3\n",
      "current step :  218\n",
      "reward :  -0.543679919266998\n",
      "episode :  3\n",
      "current step :  219\n",
      "reward :  -0.5178671353342436\n",
      "episode :  3\n",
      "current step :  220\n",
      "reward :  -0.4961753635297776\n",
      "episode :  3\n",
      "current step :  221\n",
      "reward :  -0.49161340887995597\n",
      "episode :  3\n",
      "current step :  222\n",
      "reward :  -0.3826716854004012\n",
      "episode :  3\n",
      "current step :  223\n",
      "reward :  -0.3716684672936156\n",
      "episode :  3\n",
      "current step :  224\n",
      "reward :  -0.4619036170023859\n",
      "episode :  3\n",
      "current step :  225\n",
      "reward :  -0.4351319795524136\n",
      "episode :  3\n",
      "current step :  226\n",
      "reward :  -0.43056277557726147\n",
      "episode :  3\n",
      "current step :  227\n",
      "reward :  -0.5266266194387089\n",
      "episode :  3\n",
      "current step :  228\n",
      "reward :  -0.5744653573225044\n",
      "episode :  3\n",
      "current step :  229\n",
      "reward :  -0.48902282830240074\n",
      "episode :  3\n",
      "current step :  230\n",
      "reward :  -0.4655868966084435\n",
      "episode :  3\n",
      "current step :  231\n",
      "reward :  -0.4915671806891993\n",
      "episode :  3\n",
      "current step :  232\n",
      "reward :  -0.4447056927560366\n",
      "episode :  3\n",
      "current step :  233\n",
      "reward :  -0.3824298902125104\n",
      "episode :  3\n",
      "current step :  234\n",
      "reward :  -0.37682895403292466\n",
      "episode :  3\n",
      "current step :  235\n",
      "reward :  -0.38563496080806675\n",
      "episode :  3\n",
      "current step :  236\n",
      "reward :  -0.4092051234584627\n",
      "episode :  3\n",
      "current step :  237\n",
      "reward :  -0.37781196333517664\n",
      "episode :  3\n",
      "current step :  238\n",
      "reward :  -0.3889223552451394\n",
      "episode :  3\n",
      "current step :  239\n",
      "reward :  -0.34240451773516484\n",
      "episode :  3\n",
      "current step :  240\n",
      "reward :  -0.35511584117330686\n",
      "episode :  3\n",
      "current step :  241\n",
      "reward :  -0.43700944626310645\n",
      "episode :  3\n",
      "current step :  242\n",
      "reward :  -0.6069901078410664\n",
      "episode :  3\n",
      "current step :  243\n",
      "reward :  -0.5774073959596737\n",
      "episode :  3\n",
      "current step :  244\n",
      "reward :  -0.47422953458750294\n",
      "episode :  3\n",
      "current step :  245\n",
      "reward :  -0.42925295808823555\n",
      "episode :  3\n",
      "current step :  246\n",
      "reward :  -0.48528844581070624\n",
      "episode :  3\n",
      "current step :  247\n",
      "reward :  -0.41179443089080164\n",
      "episode :  3\n",
      "current step :  248\n",
      "reward :  -0.4132675117768518\n",
      "episode :  3\n",
      "current step :  249\n",
      "reward :  -0.4455545832589088\n",
      "episode :  3\n",
      "current step :  250\n",
      "reward :  -0.31291191758404124\n",
      "episode :  3\n",
      "current step :  251\n",
      "reward :  -0.3112044123387733\n",
      "episode :  3\n",
      "current step :  252\n",
      "reward :  -0.24441875649742092\n",
      "episode :  3\n",
      "current step :  253\n",
      "reward :  -0.25374518924657424\n",
      "episode :  3\n",
      "current step :  254\n",
      "reward :  -0.3196463436744023\n",
      "episode :  3\n",
      "current step :  255\n",
      "reward :  -0.341625331288669\n",
      "episode :  3\n",
      "current step :  256\n",
      "reward :  -0.3423309022627016\n",
      "episode :  3\n",
      "current step :  257\n",
      "reward :  -0.29291760487876484\n",
      "episode :  3\n",
      "current step :  258\n",
      "reward :  -0.3106288953659001\n",
      "episode :  3\n",
      "current step :  259\n",
      "reward :  -0.3963792388197685\n",
      "episode :  3\n",
      "current step :  260\n",
      "reward :  -0.305032039412658\n",
      "episode :  3\n",
      "current step :  261\n",
      "reward :  -0.2382824689923499\n",
      "episode :  3\n",
      "current step :  262\n",
      "reward :  -0.16656843973053365\n",
      "episode :  3\n",
      "current step :  263\n",
      "reward :  -0.24331224766942428\n",
      "episode :  3\n",
      "current step :  264\n",
      "reward :  -0.25860788876650637\n",
      "episode :  3\n",
      "current step :  265\n",
      "reward :  -0.2113029740923859\n",
      "episode :  3\n",
      "current step :  266\n",
      "reward :  -0.21124691779343924\n",
      "episode :  3\n",
      "current step :  267\n",
      "reward :  -0.3319030954006502\n",
      "episode :  3\n",
      "current step :  268\n",
      "reward :  -0.12664323950041761\n",
      "episode :  3\n",
      "current step :  269\n",
      "reward :  -0.23490014870784892\n",
      "episode :  3\n",
      "current step :  270\n",
      "reward :  -0.3084140317087983\n",
      "episode :  3\n",
      "current step :  271\n",
      "reward :  -0.3710110343485987\n",
      "episode :  3\n",
      "current step :  272\n",
      "reward :  -0.30139509866886105\n",
      "episode :  3\n",
      "current step :  273\n",
      "reward :  -0.30732405814706676\n",
      "episode :  3\n",
      "current step :  274\n",
      "reward :  -0.3290128397049278\n",
      "episode :  3\n",
      "current step :  275\n",
      "reward :  -0.3455412856683666\n",
      "episode :  3\n",
      "current step :  276\n",
      "reward :  -0.2782703123854153\n",
      "episode :  3\n",
      "current step :  277\n",
      "reward :  -0.25012245044609743\n",
      "episode :  3\n",
      "current step :  278\n",
      "reward :  -0.2719268237077393\n",
      "episode :  3\n",
      "current step :  279\n",
      "reward :  -0.2654647486293884\n",
      "episode :  3\n",
      "current step :  280\n",
      "reward :  -0.3027327368845258\n",
      "episode :  3\n",
      "current step :  281\n",
      "reward :  -0.29888245147546233\n",
      "episode :  3\n",
      "current step :  282\n",
      "reward :  -0.22464356731092763\n",
      "episode :  3\n",
      "current step :  283\n",
      "reward :  -0.21203024232861795\n",
      "episode :  3\n",
      "current step :  284\n",
      "reward :  -0.2681580337763448\n",
      "episode :  3\n",
      "current step :  285\n",
      "reward :  -0.22753478915376327\n",
      "episode :  4\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 286      |\n",
      "|    ep_rew_mean     | -117     |\n",
      "| time/              |          |\n",
      "|    episodes        | 4        |\n",
      "|    fps             | 12       |\n",
      "|    time_elapsed    | 88       |\n",
      "|    total_timesteps | 1144     |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -40.8    |\n",
      "|    critic_loss     | 8.48     |\n",
      "|    ent_coef        | 0.734    |\n",
      "|    ent_coef_loss   | -7.06    |\n",
      "|    learning_rate   | 0.0003   |\n",
      "|    n_updates       | 1043     |\n",
      "---------------------------------\n",
      "current step :  0\n",
      "reward :  -0.17763272623422657\n",
      "episode :  4\n",
      "current step :  1\n",
      "reward :  -0.17978509176789365\n",
      "episode :  4\n",
      "current step :  2\n",
      "reward :  -0.27264330637365114\n",
      "episode :  4\n",
      "current step :  3\n",
      "reward :  -0.23050034677770975\n",
      "episode :  4\n",
      "current step :  4\n",
      "reward :  -0.21789585860864905\n",
      "episode :  4\n",
      "current step :  5\n",
      "reward :  -0.20150762735029482\n",
      "episode :  4\n",
      "current step :  6\n",
      "reward :  -0.19602092267057855\n",
      "episode :  4\n",
      "current step :  7\n",
      "reward :  -0.16469880451539468\n",
      "episode :  4\n",
      "current step :  8\n",
      "reward :  -0.21060809190688204\n",
      "episode :  4\n",
      "current step :  9\n",
      "reward :  -0.27139422096568827\n",
      "episode :  4\n",
      "current step :  10\n",
      "reward :  -0.3098851333472102\n",
      "episode :  4\n",
      "current step :  11\n",
      "reward :  -0.3079957336417227\n",
      "episode :  4\n",
      "current step :  12\n",
      "reward :  -0.28033844381567996\n",
      "episode :  4\n",
      "current step :  13\n",
      "reward :  -0.2355339767381623\n",
      "episode :  4\n",
      "current step :  14\n",
      "reward :  -0.20930981119103784\n",
      "episode :  4\n",
      "current step :  15\n",
      "reward :  -0.364656995283874\n",
      "episode :  4\n",
      "current step :  16\n",
      "reward :  -0.19411143229848793\n",
      "episode :  4\n",
      "current step :  17\n",
      "reward :  -0.24431291066157554\n",
      "episode :  4\n",
      "current step :  18\n",
      "reward :  -0.24537563863504883\n",
      "episode :  4\n",
      "current step :  19\n",
      "reward :  -0.30313089729175235\n",
      "episode :  4\n",
      "current step :  20\n",
      "reward :  -0.35710200060840924\n",
      "episode :  4\n",
      "current step :  21\n",
      "reward :  -0.4809117661826447\n",
      "episode :  4\n",
      "current step :  22\n",
      "reward :  -0.5814267000703685\n",
      "episode :  4\n",
      "current step :  23\n",
      "reward :  -0.5567195914251658\n",
      "episode :  4\n",
      "current step :  24\n",
      "reward :  -0.5896538114038448\n",
      "episode :  4\n",
      "current step :  25\n",
      "reward :  -0.5619161575248585\n",
      "episode :  4\n",
      "current step :  26\n",
      "reward :  -0.40530691706255595\n",
      "episode :  4\n",
      "current step :  27\n",
      "reward :  -0.45656937267601017\n",
      "episode :  4\n",
      "current step :  28\n",
      "reward :  -0.47494573147927144\n",
      "episode :  4\n",
      "current step :  29\n",
      "reward :  -0.504005360771617\n",
      "episode :  4\n",
      "current step :  30\n",
      "reward :  -0.5118162807385889\n",
      "episode :  4\n",
      "current step :  31\n",
      "reward :  -0.552410353275765\n",
      "episode :  4\n",
      "current step :  32\n",
      "reward :  -0.5097266703234369\n",
      "episode :  4\n",
      "current step :  33\n",
      "reward :  -0.4857256933519459\n",
      "episode :  4\n",
      "current step :  34\n",
      "reward :  -0.4312304188436181\n",
      "episode :  4\n",
      "current step :  35\n",
      "reward :  -0.3711826630806703\n",
      "episode :  4\n",
      "current step :  36\n",
      "reward :  -0.2876932153404614\n",
      "episode :  4\n",
      "current step :  37\n",
      "reward :  -0.3269027044904166\n",
      "episode :  4\n",
      "current step :  38\n",
      "reward :  -0.48777464807262183\n",
      "episode :  4\n",
      "current step :  39\n",
      "reward :  -0.5353469088475458\n",
      "episode :  4\n",
      "current step :  40\n",
      "reward :  -0.589957120633899\n",
      "episode :  4\n",
      "current step :  41\n",
      "reward :  -0.5581647241243657\n",
      "episode :  4\n",
      "current step :  42\n",
      "reward :  -0.633713006772369\n",
      "episode :  4\n",
      "current step :  43\n",
      "reward :  -0.6226011409433166\n",
      "episode :  4\n",
      "current step :  44\n",
      "reward :  -0.5434640660997552\n",
      "episode :  4\n",
      "current step :  45\n",
      "reward :  -0.6382745369642496\n",
      "episode :  4\n",
      "current step :  46\n",
      "reward :  -0.7017943599850004\n",
      "episode :  4\n",
      "current step :  47\n",
      "reward :  -0.6329541204273417\n",
      "episode :  4\n",
      "current step :  48\n",
      "reward :  -0.5863866179535475\n",
      "episode :  4\n",
      "current step :  49\n",
      "reward :  -0.4479029819139397\n",
      "episode :  4\n",
      "current step :  50\n",
      "reward :  -0.48576387587123043\n",
      "episode :  4\n",
      "current step :  51\n",
      "reward :  -0.5024810531653622\n",
      "episode :  4\n",
      "current step :  52\n",
      "reward :  -0.4048522405725839\n",
      "episode :  4\n",
      "current step :  53\n",
      "reward :  -0.5658779522037177\n",
      "episode :  4\n",
      "current step :  54\n",
      "reward :  -0.6289750233560943\n",
      "episode :  4\n",
      "current step :  55\n",
      "reward :  -0.548358396630278\n",
      "episode :  4\n",
      "current step :  56\n",
      "reward :  -0.4370580259929808\n",
      "episode :  4\n",
      "current step :  57\n",
      "reward :  -0.28080554978173\n",
      "episode :  4\n",
      "current step :  58\n",
      "reward :  -0.3449115557485992\n",
      "episode :  4\n",
      "current step :  59\n",
      "reward :  -0.38872291295051103\n",
      "episode :  4\n",
      "current step :  60\n",
      "reward :  -0.4734382502217222\n",
      "episode :  4\n",
      "current step :  61\n",
      "reward :  -0.4953853523534088\n",
      "episode :  4\n",
      "current step :  62\n",
      "reward :  -0.6217986768423232\n",
      "episode :  4\n",
      "current step :  63\n",
      "reward :  -0.5775415057618284\n",
      "episode :  4\n",
      "current step :  64\n",
      "reward :  -0.6641395900542164\n",
      "episode :  4\n",
      "current step :  65\n",
      "reward :  -0.5713597853867574\n",
      "episode :  4\n",
      "current step :  66\n",
      "reward :  -0.5155859655953785\n",
      "episode :  4\n",
      "current step :  67\n",
      "reward :  -0.5750487310206057\n",
      "episode :  4\n",
      "current step :  68\n",
      "reward :  -0.5496897911452253\n",
      "episode :  4\n",
      "current step :  69\n",
      "reward :  -0.6603184756393448\n",
      "episode :  4\n",
      "current step :  70\n",
      "reward :  -0.6607299078351752\n",
      "episode :  4\n",
      "current step :  71\n",
      "reward :  -0.6317778828102817\n",
      "episode :  4\n",
      "current step :  72\n",
      "reward :  -0.5903928437778897\n",
      "episode :  4\n",
      "current step :  73\n",
      "reward :  -0.5604806681652201\n",
      "episode :  4\n",
      "current step :  74\n",
      "reward :  -0.4996642400310637\n",
      "episode :  4\n",
      "current step :  75\n",
      "reward :  -0.4030925686357775\n",
      "episode :  4\n",
      "current step :  76\n",
      "reward :  -0.3105441010578526\n",
      "episode :  4\n",
      "current step :  77\n",
      "reward :  -0.35827286223694516\n",
      "episode :  4\n",
      "current step :  78\n",
      "reward :  -0.4208220512173949\n",
      "episode :  4\n",
      "current step :  79\n",
      "reward :  -0.38329313169710383\n",
      "episode :  4\n",
      "current step :  80\n",
      "reward :  -0.36723576040074835\n",
      "episode :  4\n",
      "current step :  81\n",
      "reward :  -0.4028756557597925\n",
      "episode :  4\n",
      "current step :  82\n",
      "reward :  -0.45584177982796104\n",
      "episode :  4\n",
      "current step :  83\n",
      "reward :  -0.4444218140844756\n",
      "episode :  4\n",
      "current step :  84\n",
      "reward :  -0.4742034578058657\n",
      "episode :  4\n",
      "current step :  85\n",
      "reward :  -0.3717116992699571\n",
      "episode :  4\n",
      "current step :  86\n",
      "reward :  -0.38148410495140955\n",
      "episode :  4\n",
      "current step :  87\n",
      "reward :  -0.3746024045062541\n",
      "episode :  4\n",
      "current step :  88\n",
      "reward :  -0.3505234025614449\n",
      "episode :  4\n",
      "current step :  89\n",
      "reward :  -0.3045842607234096\n",
      "episode :  4\n",
      "current step :  90\n",
      "reward :  -0.2802971430797324\n",
      "episode :  4\n",
      "current step :  91\n",
      "reward :  -0.3984017807566289\n",
      "episode :  4\n",
      "current step :  92\n",
      "reward :  -0.3986640678122793\n",
      "episode :  4\n",
      "current step :  93\n",
      "reward :  -0.42770070681931704\n",
      "episode :  4\n",
      "current step :  94\n",
      "reward :  -0.4359277445591379\n",
      "episode :  4\n",
      "current step :  95\n",
      "reward :  -0.36991939060925033\n",
      "episode :  4\n",
      "current step :  96\n",
      "reward :  -0.40459307080222373\n",
      "episode :  4\n",
      "current step :  97\n",
      "reward :  -0.42771939289221306\n",
      "episode :  4\n",
      "current step :  98\n",
      "reward :  -0.41970014743189\n",
      "episode :  4\n",
      "current step :  99\n",
      "reward :  -0.42861320043905415\n",
      "episode :  4\n",
      "current step :  100\n",
      "reward :  -0.3424954286641387\n",
      "episode :  4\n",
      "current step :  101\n",
      "reward :  -0.2552955751620087\n",
      "episode :  4\n",
      "current step :  102\n",
      "reward :  -0.3527464206989008\n",
      "episode :  4\n",
      "current step :  103\n",
      "reward :  -0.26771882777322237\n",
      "episode :  4\n",
      "current step :  104\n",
      "reward :  -0.24020448612178094\n",
      "episode :  4\n",
      "current step :  105\n",
      "reward :  -0.24089581171667138\n",
      "episode :  4\n",
      "current step :  106\n",
      "reward :  -0.24685767737257433\n",
      "episode :  4\n",
      "current step :  107\n",
      "reward :  -0.15451888648387235\n",
      "episode :  4\n",
      "current step :  108\n",
      "reward :  -0.3191504581979556\n",
      "episode :  4\n",
      "current step :  109\n",
      "reward :  -0.38077319612773397\n",
      "episode :  4\n",
      "current step :  110\n",
      "reward :  -0.4497162400428365\n",
      "episode :  4\n",
      "current step :  111\n",
      "reward :  -0.46420257437750784\n",
      "episode :  4\n",
      "current step :  112\n",
      "reward :  -0.36884955834983324\n",
      "episode :  4\n",
      "current step :  113\n",
      "reward :  -0.2204949028043569\n",
      "episode :  4\n",
      "current step :  114\n",
      "reward :  -0.23916384695557402\n",
      "episode :  4\n",
      "current step :  115\n",
      "reward :  -0.15645268497252476\n",
      "episode :  4\n",
      "current step :  116\n",
      "reward :  -0.20650616375745834\n",
      "episode :  4\n",
      "current step :  117\n",
      "reward :  -0.22227187163612505\n",
      "episode :  4\n",
      "current step :  118\n",
      "reward :  -0.24353071995904765\n",
      "episode :  4\n",
      "current step :  119\n",
      "reward :  -0.25239778623986525\n",
      "episode :  4\n",
      "current step :  120\n",
      "reward :  -0.19470058495175727\n",
      "episode :  4\n",
      "current step :  121\n",
      "reward :  -0.19201069875775215\n",
      "episode :  4\n",
      "current step :  122\n",
      "reward :  -0.2628947166182761\n",
      "episode :  4\n",
      "current step :  123\n",
      "reward :  -0.3956646928252519\n",
      "episode :  4\n",
      "current step :  124\n",
      "reward :  -0.34785284961573204\n",
      "episode :  4\n",
      "current step :  125\n",
      "reward :  -0.34210803727039313\n",
      "episode :  4\n",
      "current step :  126\n",
      "reward :  -0.17092228178734092\n",
      "episode :  4\n",
      "current step :  127\n",
      "reward :  -0.3638121701654692\n",
      "episode :  4\n",
      "current step :  128\n",
      "reward :  -0.33063413124389673\n",
      "episode :  4\n",
      "current step :  129\n",
      "reward :  -0.28634328744165927\n",
      "episode :  4\n",
      "current step :  130\n",
      "reward :  -0.35689420985334697\n",
      "episode :  4\n",
      "current step :  131\n",
      "reward :  -0.34718243908438023\n",
      "episode :  4\n",
      "current step :  132\n",
      "reward :  -0.48009531983607906\n",
      "episode :  4\n",
      "current step :  133\n",
      "reward :  -0.4459669812659114\n",
      "episode :  4\n",
      "current step :  134\n",
      "reward :  -0.4587034045971258\n",
      "episode :  4\n",
      "current step :  135\n",
      "reward :  -0.42218235758935974\n",
      "episode :  4\n",
      "current step :  136\n",
      "reward :  -0.37221812657129644\n",
      "episode :  4\n",
      "current step :  137\n",
      "reward :  -0.44286823849111784\n",
      "episode :  4\n",
      "current step :  138\n",
      "reward :  -0.3890581583640872\n",
      "episode :  4\n",
      "current step :  139\n",
      "reward :  -0.32815857777842244\n",
      "episode :  4\n",
      "current step :  140\n",
      "reward :  -0.37816205083466525\n",
      "episode :  4\n",
      "current step :  141\n",
      "reward :  -0.29635024014450867\n",
      "episode :  4\n",
      "current step :  142\n",
      "reward :  -0.22890413913566252\n",
      "episode :  4\n",
      "current step :  143\n",
      "reward :  -0.20236562225383461\n",
      "episode :  4\n",
      "current step :  144\n",
      "reward :  -0.22986127397621775\n",
      "episode :  4\n",
      "current step :  145\n",
      "reward :  -0.2822021544850482\n",
      "episode :  4\n",
      "current step :  146\n",
      "reward :  -0.3329994357836091\n",
      "episode :  4\n",
      "current step :  147\n",
      "reward :  -0.3617891136374531\n",
      "episode :  4\n",
      "current step :  148\n",
      "reward :  -0.39150676540321316\n",
      "episode :  4\n",
      "current step :  149\n",
      "reward :  -0.36565874834693324\n",
      "episode :  4\n",
      "current step :  150\n",
      "reward :  -0.3378053612340841\n",
      "episode :  4\n",
      "current step :  151\n",
      "reward :  -0.38978045574640335\n",
      "episode :  4\n",
      "current step :  152\n",
      "reward :  -0.4460745638882849\n",
      "episode :  4\n",
      "current step :  153\n",
      "reward :  -0.4664392935040408\n",
      "episode :  4\n",
      "current step :  154\n",
      "reward :  -0.3673296962628606\n",
      "episode :  4\n",
      "current step :  155\n",
      "reward :  -0.28577464848278067\n",
      "episode :  4\n",
      "current step :  156\n",
      "reward :  -0.26538251279387426\n",
      "episode :  4\n",
      "current step :  157\n",
      "reward :  -0.5451174960143614\n",
      "episode :  4\n",
      "current step :  158\n",
      "reward :  -0.5422392603580584\n",
      "episode :  4\n",
      "current step :  159\n",
      "reward :  -0.5195700492834467\n",
      "episode :  4\n",
      "current step :  160\n",
      "reward :  -0.4862863369650758\n",
      "episode :  4\n",
      "current step :  161\n",
      "reward :  -0.47194402003963354\n",
      "episode :  4\n",
      "current step :  162\n",
      "reward :  -0.4750643805407453\n",
      "episode :  4\n",
      "current step :  163\n",
      "reward :  -0.4842769952331261\n",
      "episode :  4\n",
      "current step :  164\n",
      "reward :  -0.5574148170750207\n",
      "episode :  4\n",
      "current step :  165\n",
      "reward :  -0.4157308516132464\n",
      "episode :  4\n",
      "current step :  166\n",
      "reward :  -0.4235269195677395\n",
      "episode :  4\n",
      "current step :  167\n",
      "reward :  -0.4977125001576796\n",
      "episode :  4\n",
      "current step :  168\n",
      "reward :  -0.4057714883881979\n",
      "episode :  4\n",
      "current step :  169\n",
      "reward :  -0.5073893126216421\n",
      "episode :  4\n",
      "current step :  170\n",
      "reward :  -0.5608266430437244\n",
      "episode :  4\n",
      "current step :  171\n",
      "reward :  -0.5642329389340467\n",
      "episode :  4\n",
      "current step :  172\n",
      "reward :  -0.6003386135239324\n",
      "episode :  4\n",
      "current step :  173\n",
      "reward :  -0.6547714277300178\n",
      "episode :  4\n",
      "current step :  174\n",
      "reward :  -0.5721959311657715\n",
      "episode :  4\n",
      "current step :  175\n",
      "reward :  -0.5879388128090747\n",
      "episode :  4\n",
      "current step :  176\n",
      "reward :  -0.7045089223189579\n",
      "episode :  4\n",
      "current step :  177\n",
      "reward :  -0.6396963876551442\n",
      "episode :  4\n",
      "current step :  178\n",
      "reward :  -0.5871809331487219\n",
      "episode :  4\n",
      "current step :  179\n",
      "reward :  -0.5963226124446971\n",
      "episode :  4\n",
      "current step :  180\n",
      "reward :  -0.6143361861795192\n",
      "episode :  4\n",
      "current step :  181\n",
      "reward :  -0.6122163020202995\n",
      "episode :  4\n",
      "current step :  182\n",
      "reward :  -0.566276619114051\n",
      "episode :  4\n",
      "current step :  183\n",
      "reward :  -0.480200581127579\n",
      "episode :  4\n",
      "current step :  184\n",
      "reward :  -0.45529732737592443\n",
      "episode :  4\n",
      "current step :  185\n",
      "reward :  -0.4039638214216205\n",
      "episode :  4\n",
      "current step :  186\n",
      "reward :  -0.3829694631240599\n",
      "episode :  4\n",
      "current step :  187\n",
      "reward :  -0.3704119141018411\n",
      "episode :  4\n",
      "current step :  188\n",
      "reward :  -0.3638095684725203\n",
      "episode :  4\n",
      "current step :  189\n",
      "reward :  -0.46356028206337074\n",
      "episode :  4\n",
      "current step :  190\n",
      "reward :  -0.5894669570809044\n",
      "episode :  4\n",
      "current step :  191\n",
      "reward :  -0.4143649528872868\n",
      "episode :  4\n",
      "current step :  192\n",
      "reward :  -0.35621111078766277\n",
      "episode :  4\n",
      "current step :  193\n",
      "reward :  -0.4491544847979883\n",
      "episode :  4\n",
      "current step :  194\n",
      "reward :  -0.5334515791735241\n",
      "episode :  4\n",
      "current step :  195\n",
      "reward :  -0.4492539284828531\n",
      "episode :  4\n",
      "current step :  196\n",
      "reward :  -0.3838565692377725\n",
      "episode :  4\n",
      "current step :  197\n",
      "reward :  -0.40466287508072585\n",
      "episode :  4\n",
      "current step :  198\n",
      "reward :  -0.48299044144986575\n",
      "episode :  4\n",
      "current step :  199\n",
      "reward :  -0.5320684204854454\n",
      "episode :  4\n",
      "current step :  200\n",
      "reward :  -0.5233766907728012\n",
      "episode :  4\n",
      "current step :  201\n",
      "reward :  -0.564564986959276\n",
      "episode :  4\n",
      "current step :  202\n",
      "reward :  -0.4802783569670038\n",
      "episode :  4\n",
      "current step :  203\n",
      "reward :  -0.4398665098575754\n",
      "episode :  4\n",
      "current step :  204\n",
      "reward :  -0.42881818859703696\n",
      "episode :  4\n",
      "current step :  205\n",
      "reward :  -0.461907748033742\n",
      "episode :  4\n",
      "current step :  206\n",
      "reward :  -0.3987417796584959\n",
      "episode :  4\n",
      "current step :  207\n",
      "reward :  -0.4233126354168476\n",
      "episode :  4\n",
      "current step :  208\n",
      "reward :  -0.4210150714371738\n",
      "episode :  4\n",
      "current step :  209\n",
      "reward :  -0.44479887623508974\n",
      "episode :  4\n",
      "current step :  210\n",
      "reward :  -0.5523921053428719\n",
      "episode :  4\n",
      "current step :  211\n",
      "reward :  -0.6094835603766473\n",
      "episode :  4\n",
      "current step :  212\n",
      "reward :  -0.611392417033617\n",
      "episode :  4\n",
      "current step :  213\n",
      "reward :  -0.512964359426321\n",
      "episode :  4\n",
      "current step :  214\n",
      "reward :  -0.42801100926215613\n",
      "episode :  4\n",
      "current step :  215\n",
      "reward :  -0.43598725992766246\n",
      "episode :  4\n",
      "current step :  216\n",
      "reward :  -0.5366568316587457\n",
      "episode :  4\n",
      "current step :  217\n",
      "reward :  -0.48425635287028396\n",
      "episode :  4\n",
      "current step :  218\n",
      "reward :  -0.3968414997023424\n",
      "episode :  4\n",
      "current step :  219\n",
      "reward :  -0.45910901973758794\n",
      "episode :  4\n",
      "current step :  220\n",
      "reward :  -0.5249791586493057\n",
      "episode :  4\n",
      "current step :  221\n",
      "reward :  -0.4111457209623744\n",
      "episode :  4\n",
      "current step :  222\n",
      "reward :  -0.38322077364332724\n",
      "episode :  4\n",
      "current step :  223\n",
      "reward :  -0.490108607017698\n",
      "episode :  4\n",
      "current step :  224\n",
      "reward :  -0.57005073104006\n",
      "episode :  4\n",
      "current step :  225\n",
      "reward :  -0.5734913001076398\n",
      "episode :  4\n",
      "current step :  226\n",
      "reward :  -0.45265066659752035\n",
      "episode :  4\n",
      "current step :  227\n",
      "reward :  -0.3724343393594282\n",
      "episode :  4\n",
      "current step :  228\n",
      "reward :  -0.44546731529758915\n",
      "episode :  4\n",
      "current step :  229\n",
      "reward :  -0.31244826508951035\n",
      "episode :  4\n",
      "current step :  230\n",
      "reward :  -0.4415344796986587\n",
      "episode :  4\n",
      "current step :  231\n",
      "reward :  -0.5398521794327698\n",
      "episode :  4\n",
      "current step :  232\n",
      "reward :  -0.4454750539470123\n",
      "episode :  4\n",
      "current step :  233\n",
      "reward :  -0.469095212143082\n",
      "episode :  4\n",
      "current step :  234\n",
      "reward :  -0.5017614168438806\n",
      "episode :  4\n",
      "current step :  235\n",
      "reward :  -0.5446801055766394\n",
      "episode :  4\n",
      "current step :  236\n",
      "reward :  -0.43108895514166873\n",
      "episode :  4\n",
      "current step :  237\n",
      "reward :  -0.43951848337057725\n",
      "episode :  4\n",
      "current step :  238\n",
      "reward :  -0.48274422546012313\n",
      "episode :  4\n",
      "current step :  239\n",
      "reward :  -0.3849686317092224\n",
      "episode :  4\n",
      "current step :  240\n",
      "reward :  -0.34352684643371173\n",
      "episode :  4\n",
      "current step :  241\n",
      "reward :  -0.40617230344425687\n",
      "episode :  4\n",
      "current step :  242\n",
      "reward :  -0.39927368469598074\n",
      "episode :  4\n",
      "current step :  243\n",
      "reward :  -0.4123245935983311\n",
      "episode :  4\n",
      "current step :  244\n",
      "reward :  -0.37735252740953273\n",
      "episode :  4\n",
      "current step :  245\n",
      "reward :  -0.36896664943628277\n",
      "episode :  4\n",
      "current step :  246\n",
      "reward :  -0.38959339481108457\n",
      "episode :  4\n",
      "current step :  247\n",
      "reward :  -0.3890724935061803\n",
      "episode :  4\n",
      "current step :  248\n",
      "reward :  -0.39978454417438575\n",
      "episode :  4\n",
      "current step :  249\n",
      "reward :  -0.39110012073554123\n",
      "episode :  4\n",
      "current step :  250\n",
      "reward :  -0.5345506031234482\n",
      "episode :  4\n",
      "current step :  251\n",
      "reward :  -0.49765218967211045\n",
      "episode :  4\n",
      "current step :  252\n",
      "reward :  -0.49251372719597064\n",
      "episode :  4\n",
      "current step :  253\n",
      "reward :  -0.45174589134064785\n",
      "episode :  4\n",
      "current step :  254\n",
      "reward :  -0.4224149706839948\n",
      "episode :  4\n",
      "current step :  255\n",
      "reward :  -0.365063755637002\n",
      "episode :  4\n",
      "current step :  256\n",
      "reward :  -0.3411606630787766\n",
      "episode :  4\n",
      "current step :  257\n",
      "reward :  -0.28488729255835127\n",
      "episode :  4\n",
      "current step :  258\n",
      "reward :  -0.24373718829504518\n",
      "episode :  4\n",
      "current step :  259\n",
      "reward :  -0.2882276909199377\n",
      "episode :  4\n",
      "current step :  260\n",
      "reward :  -0.1969471916442275\n",
      "episode :  4\n",
      "current step :  261\n",
      "reward :  -0.21225342080472767\n",
      "episode :  4\n",
      "current step :  262\n",
      "reward :  -0.2860148627728763\n",
      "episode :  4\n",
      "current step :  263\n",
      "reward :  -0.2751583147116945\n",
      "episode :  4\n",
      "current step :  264\n",
      "reward :  -0.13765652900767128\n",
      "episode :  4\n",
      "current step :  265\n",
      "reward :  -0.2784972405507412\n",
      "episode :  4\n",
      "current step :  266\n",
      "reward :  -0.2837979982183514\n",
      "episode :  4\n",
      "current step :  267\n",
      "reward :  -0.3774275546514855\n",
      "episode :  4\n",
      "current step :  268\n",
      "reward :  -0.38300996945913046\n",
      "episode :  4\n",
      "current step :  269\n",
      "reward :  -0.31101319784747783\n",
      "episode :  4\n",
      "current step :  270\n",
      "reward :  -0.3463956871287449\n",
      "episode :  4\n",
      "current step :  271\n",
      "reward :  -0.38271771390526\n",
      "episode :  4\n",
      "current step :  272\n",
      "reward :  -0.3619337984991727\n",
      "episode :  4\n",
      "current step :  273\n",
      "reward :  -0.34408308695692014\n",
      "episode :  4\n",
      "current step :  274\n",
      "reward :  -0.37289220096251935\n",
      "episode :  4\n",
      "current step :  275\n",
      "reward :  -0.3278512680795829\n",
      "episode :  4\n",
      "current step :  276\n",
      "reward :  -0.2656594160013571\n",
      "episode :  4\n",
      "current step :  277\n",
      "reward :  -0.2218719069199706\n",
      "episode :  4\n",
      "current step :  278\n",
      "reward :  -0.26701993317621214\n",
      "episode :  4\n",
      "current step :  279\n",
      "reward :  -0.24962068005994165\n",
      "episode :  4\n",
      "current step :  280\n",
      "reward :  -0.2897452317591299\n",
      "episode :  4\n",
      "current step :  281\n",
      "reward :  -0.24956350704221109\n",
      "episode :  4\n",
      "current step :  282\n",
      "reward :  -0.273381911613995\n",
      "episode :  4\n",
      "current step :  283\n",
      "reward :  -0.1625199207154598\n",
      "episode :  4\n",
      "current step :  284\n",
      "reward :  -0.1920522098681675\n",
      "episode :  4\n",
      "current step :  285\n",
      "reward :  -0.3445448895660137\n",
      "episode :  5\n",
      "current step :  0\n",
      "reward :  -0.21454053420305336\n",
      "episode :  5\n",
      "current step :  1\n",
      "reward :  -0.12602781885792516\n",
      "episode :  5\n",
      "current step :  2\n",
      "reward :  -0.25881303817551704\n",
      "episode :  5\n",
      "current step :  3\n",
      "reward :  -0.22749115648297707\n",
      "episode :  5\n",
      "current step :  4\n",
      "reward :  -0.3098389193680265\n",
      "episode :  5\n",
      "current step :  5\n",
      "reward :  -0.2830762629583552\n",
      "episode :  5\n",
      "current step :  6\n",
      "reward :  -0.29038906253522456\n",
      "episode :  5\n",
      "current step :  7\n",
      "reward :  -0.2735522681335537\n",
      "episode :  5\n",
      "current step :  8\n",
      "reward :  -0.2857409523845332\n",
      "episode :  5\n",
      "current step :  9\n",
      "reward :  -0.2799552675677295\n",
      "episode :  5\n",
      "current step :  10\n",
      "reward :  -0.3152457208747003\n",
      "episode :  5\n",
      "current step :  11\n",
      "reward :  -0.1345226904014117\n",
      "episode :  5\n",
      "current step :  12\n",
      "reward :  -0.09430308585629993\n",
      "episode :  5\n",
      "current step :  13\n",
      "reward :  -0.150271208154686\n",
      "episode :  5\n",
      "current step :  14\n",
      "reward :  -0.11229683731865962\n",
      "episode :  5\n",
      "current step :  15\n",
      "reward :  -0.286582488226103\n",
      "episode :  5\n",
      "current step :  16\n",
      "reward :  -0.24167307153955433\n",
      "episode :  5\n",
      "current step :  17\n",
      "reward :  -0.31085338198445694\n",
      "episode :  5\n",
      "current step :  18\n",
      "reward :  -0.21030121149762382\n",
      "episode :  5\n",
      "current step :  19\n",
      "reward :  -0.21084484170229892\n",
      "episode :  5\n",
      "current step :  20\n",
      "reward :  -0.14799814269162456\n",
      "episode :  5\n",
      "current step :  21\n",
      "reward :  -0.306019783346787\n",
      "episode :  5\n",
      "current step :  22\n",
      "reward :  -0.2473292564801994\n",
      "episode :  5\n",
      "current step :  23\n",
      "reward :  -0.28283266789133255\n",
      "episode :  5\n",
      "current step :  24\n",
      "reward :  -0.24597079661398755\n",
      "episode :  5\n",
      "current step :  25\n",
      "reward :  -0.31779257937781363\n",
      "episode :  5\n",
      "current step :  26\n",
      "reward :  -0.26971591976665593\n",
      "episode :  5\n",
      "current step :  27\n",
      "reward :  -0.2620023882503456\n",
      "episode :  5\n",
      "current step :  28\n",
      "reward :  -0.3023485049485431\n",
      "episode :  5\n",
      "current step :  29\n",
      "reward :  -0.3997113046236989\n",
      "episode :  5\n",
      "current step :  30\n",
      "reward :  -0.486656571847518\n",
      "episode :  5\n",
      "current step :  31\n",
      "reward :  -0.5007113382923285\n",
      "episode :  5\n",
      "current step :  32\n",
      "reward :  -0.4929705363912392\n",
      "episode :  5\n",
      "current step :  33\n",
      "reward :  -0.5076222722221497\n",
      "episode :  5\n",
      "current step :  34\n",
      "reward :  -0.5219675903328913\n",
      "episode :  5\n",
      "current step :  35\n",
      "reward :  -0.5595064324092016\n",
      "episode :  5\n",
      "current step :  36\n",
      "reward :  -0.5369898513629824\n",
      "episode :  5\n",
      "current step :  37\n",
      "reward :  -0.4916700021184123\n",
      "episode :  5\n",
      "current step :  38\n",
      "reward :  -0.5019155580150684\n",
      "episode :  5\n",
      "current step :  39\n",
      "reward :  -0.5032988616201086\n",
      "episode :  5\n",
      "current step :  40\n",
      "reward :  -0.5131950110267314\n",
      "episode :  5\n",
      "current step :  41\n",
      "reward :  -0.3487847701963308\n",
      "episode :  5\n",
      "current step :  42\n",
      "reward :  -0.3311094558302746\n",
      "episode :  5\n",
      "current step :  43\n",
      "reward :  -0.32697614361919053\n",
      "episode :  5\n",
      "current step :  44\n",
      "reward :  -0.3493263322791373\n",
      "episode :  5\n",
      "current step :  45\n",
      "reward :  -0.43058759401687263\n",
      "episode :  5\n",
      "current step :  46\n",
      "reward :  -0.4574309093081478\n",
      "episode :  5\n",
      "current step :  47\n",
      "reward :  -0.43369651139907095\n",
      "episode :  5\n",
      "current step :  48\n",
      "reward :  -0.5024147747078392\n",
      "episode :  5\n",
      "current step :  49\n",
      "reward :  -0.45582342291310424\n",
      "episode :  5\n",
      "current step :  50\n",
      "reward :  -0.48795010925225396\n",
      "episode :  5\n",
      "current step :  51\n",
      "reward :  -0.6036539979285546\n",
      "episode :  5\n",
      "current step :  52\n",
      "reward :  -0.5680252784302323\n",
      "episode :  5\n",
      "current step :  53\n",
      "reward :  -0.5594892413590454\n",
      "episode :  5\n",
      "current step :  54\n",
      "reward :  -0.5481679111858532\n",
      "episode :  5\n",
      "current step :  55\n",
      "reward :  -0.4844991952375232\n",
      "episode :  5\n",
      "current step :  56\n",
      "reward :  -0.427651100879547\n",
      "episode :  5\n",
      "current step :  57\n",
      "reward :  -0.4220083861736598\n",
      "episode :  5\n",
      "current step :  58\n",
      "reward :  -0.5113112506268886\n",
      "episode :  5\n",
      "current step :  59\n",
      "reward :  -0.5220714921980102\n",
      "episode :  5\n",
      "current step :  60\n",
      "reward :  -0.5405422556474192\n",
      "episode :  5\n",
      "current step :  61\n",
      "reward :  -0.6020327535058408\n",
      "episode :  5\n",
      "current step :  62\n",
      "reward :  -0.6156374584111\n",
      "episode :  5\n",
      "current step :  63\n",
      "reward :  -0.6271600835203172\n",
      "episode :  5\n",
      "current step :  64\n",
      "reward :  -0.6224363664570741\n",
      "episode :  5\n",
      "current step :  65\n",
      "reward :  -0.6152746517807993\n",
      "episode :  5\n",
      "current step :  66\n",
      "reward :  -0.6170738023434525\n",
      "episode :  5\n",
      "current step :  67\n",
      "reward :  -0.597399234986278\n",
      "episode :  5\n",
      "current step :  68\n",
      "reward :  -0.5425590160497554\n",
      "episode :  5\n",
      "current step :  69\n",
      "reward :  -0.5515046697581321\n",
      "episode :  5\n",
      "current step :  70\n",
      "reward :  -0.5471021475549269\n",
      "episode :  5\n",
      "current step :  71\n",
      "reward :  -0.56973901937391\n",
      "episode :  5\n",
      "current step :  72\n",
      "reward :  -0.565244733144124\n",
      "episode :  5\n",
      "current step :  73\n",
      "reward :  -0.522482757519987\n",
      "episode :  5\n",
      "current step :  74\n",
      "reward :  -0.5871412111623862\n",
      "episode :  5\n",
      "current step :  75\n",
      "reward :  -0.5269622713093144\n",
      "episode :  5\n",
      "current step :  76\n",
      "reward :  -0.6256841401171851\n",
      "episode :  5\n",
      "current step :  77\n",
      "reward :  -0.5699537925059166\n",
      "episode :  5\n",
      "current step :  78\n",
      "reward :  -0.5894257218367912\n",
      "episode :  5\n",
      "current step :  79\n",
      "reward :  -0.6249595032563765\n",
      "episode :  5\n",
      "current step :  80\n",
      "reward :  -0.6184728792057469\n",
      "episode :  5\n",
      "current step :  81\n",
      "reward :  -0.5971169764359884\n",
      "episode :  5\n",
      "current step :  82\n",
      "reward :  -0.6261174512318357\n",
      "episode :  5\n",
      "current step :  83\n",
      "reward :  -0.516872815988823\n",
      "episode :  5\n",
      "current step :  84\n",
      "reward :  -0.5784812566473317\n",
      "episode :  5\n",
      "current step :  85\n",
      "reward :  -0.6201259214403432\n",
      "episode :  5\n",
      "current step :  86\n",
      "reward :  -0.6060185441931379\n",
      "episode :  5\n",
      "current step :  87\n",
      "reward :  -0.4967847429114511\n",
      "episode :  5\n",
      "current step :  88\n",
      "reward :  -0.4691013186744072\n",
      "episode :  5\n",
      "current step :  89\n",
      "reward :  -0.4959075632690468\n",
      "episode :  5\n",
      "current step :  90\n",
      "reward :  -0.457200784784107\n",
      "episode :  5\n",
      "current step :  91\n",
      "reward :  -0.47834383633797944\n",
      "episode :  5\n",
      "current step :  92\n",
      "reward :  -0.4779957663052031\n",
      "episode :  5\n",
      "current step :  93\n",
      "reward :  -0.5690998858177003\n",
      "episode :  5\n",
      "current step :  94\n",
      "reward :  -0.5540859911878109\n",
      "episode :  5\n",
      "current step :  95\n",
      "reward :  -0.3983761216835247\n",
      "episode :  5\n",
      "current step :  96\n",
      "reward :  -0.4367259685079658\n",
      "episode :  5\n",
      "current step :  97\n",
      "reward :  -0.4430850730997476\n",
      "episode :  5\n",
      "current step :  98\n",
      "reward :  -0.45227481624802957\n",
      "episode :  5\n",
      "current step :  99\n",
      "reward :  -0.40563398180380766\n",
      "episode :  5\n",
      "current step :  100\n",
      "reward :  -0.35243253440917943\n",
      "episode :  5\n",
      "current step :  101\n",
      "reward :  -0.24335461422272422\n",
      "episode :  5\n",
      "current step :  102\n",
      "reward :  -0.20149531363939624\n",
      "episode :  5\n",
      "current step :  103\n",
      "reward :  -0.2794445217383463\n",
      "episode :  5\n",
      "current step :  104\n",
      "reward :  -0.21147471042548657\n",
      "episode :  5\n",
      "current step :  105\n",
      "reward :  -0.21157615333893337\n",
      "episode :  5\n",
      "current step :  106\n",
      "reward :  -0.2565232994049096\n",
      "episode :  5\n",
      "current step :  107\n",
      "reward :  -0.20023353971374797\n",
      "episode :  5\n",
      "current step :  108\n",
      "reward :  -0.2065496943309892\n",
      "episode :  5\n",
      "current step :  109\n",
      "reward :  -0.09628736965731582\n",
      "episode :  5\n",
      "current step :  110\n",
      "reward :  -0.3037683113627192\n",
      "episode :  5\n",
      "current step :  111\n",
      "reward :  -0.42368413549661826\n",
      "episode :  5\n",
      "current step :  112\n",
      "reward :  -0.37302035432045016\n",
      "episode :  5\n",
      "current step :  113\n",
      "reward :  -0.3886538408257531\n",
      "episode :  5\n",
      "current step :  114\n",
      "reward :  -0.4215445619422535\n",
      "episode :  5\n",
      "current step :  115\n",
      "reward :  -0.4424436643289739\n",
      "episode :  5\n",
      "current step :  116\n",
      "reward :  -0.3572703196390972\n",
      "episode :  5\n",
      "current step :  117\n",
      "reward :  -0.3761404274037262\n",
      "episode :  5\n",
      "current step :  118\n",
      "reward :  -0.4722953516859718\n",
      "episode :  5\n",
      "current step :  119\n",
      "reward :  -0.32712320158564107\n",
      "episode :  5\n",
      "current step :  120\n",
      "reward :  -0.4334678940734298\n",
      "episode :  5\n",
      "current step :  121\n",
      "reward :  -0.37881673179581743\n",
      "episode :  5\n",
      "current step :  122\n",
      "reward :  -0.49708836110715987\n",
      "episode :  5\n",
      "current step :  123\n",
      "reward :  -0.4079033289325609\n",
      "episode :  5\n",
      "current step :  124\n",
      "reward :  -0.3558883183812454\n",
      "episode :  5\n",
      "current step :  125\n",
      "reward :  -0.31353163217995556\n",
      "episode :  5\n",
      "current step :  126\n",
      "reward :  -0.2702723710545333\n",
      "episode :  5\n",
      "current step :  127\n",
      "reward :  -0.2937035302021251\n",
      "episode :  5\n",
      "current step :  128\n",
      "reward :  -0.39826415673556587\n",
      "episode :  5\n",
      "current step :  129\n",
      "reward :  -0.29698243625645077\n",
      "episode :  5\n",
      "current step :  130\n",
      "reward :  -0.27305236565046964\n",
      "episode :  5\n",
      "current step :  131\n",
      "reward :  -0.3044484070326092\n",
      "episode :  5\n",
      "current step :  132\n",
      "reward :  -0.3523526769267496\n",
      "episode :  5\n",
      "current step :  133\n",
      "reward :  -0.39080968076672645\n",
      "episode :  5\n",
      "current step :  134\n",
      "reward :  -0.3602087758113419\n",
      "episode :  5\n",
      "current step :  135\n",
      "reward :  -0.4254982467291296\n",
      "episode :  5\n",
      "current step :  136\n",
      "reward :  -0.25356430888619896\n",
      "episode :  5\n",
      "current step :  137\n",
      "reward :  -0.28483984307908766\n",
      "episode :  5\n",
      "current step :  138\n",
      "reward :  -0.30823192957247425\n",
      "episode :  5\n",
      "current step :  139\n",
      "reward :  -0.3110008994360293\n",
      "episode :  5\n",
      "current step :  140\n",
      "reward :  -0.3764378438644791\n",
      "episode :  5\n",
      "current step :  141\n",
      "reward :  -0.3898924307506473\n",
      "episode :  5\n",
      "current step :  142\n",
      "reward :  -0.40254712706952267\n",
      "episode :  5\n",
      "current step :  143\n",
      "reward :  -0.45567431993239355\n",
      "episode :  5\n",
      "current step :  144\n",
      "reward :  -0.4309953893055281\n",
      "episode :  5\n",
      "current step :  145\n",
      "reward :  -0.47350484502994056\n",
      "episode :  5\n",
      "current step :  146\n",
      "reward :  -0.40140094514734764\n",
      "episode :  5\n",
      "current step :  147\n",
      "reward :  -0.4330441350566582\n",
      "episode :  5\n",
      "current step :  148\n",
      "reward :  -0.43177061778385734\n",
      "episode :  5\n",
      "current step :  149\n",
      "reward :  -0.45482286854863463\n",
      "episode :  5\n",
      "current step :  150\n",
      "reward :  -0.5102667353183528\n",
      "episode :  5\n",
      "current step :  151\n",
      "reward :  -0.46056977199789834\n",
      "episode :  5\n",
      "current step :  152\n",
      "reward :  -0.4314907982200653\n",
      "episode :  5\n",
      "current step :  153\n",
      "reward :  -0.44710427107422146\n",
      "episode :  5\n",
      "current step :  154\n",
      "reward :  -0.3557755411893354\n",
      "episode :  5\n",
      "current step :  155\n",
      "reward :  -0.3695820996104226\n",
      "episode :  5\n",
      "current step :  156\n",
      "reward :  -0.39902489499943283\n",
      "episode :  5\n",
      "current step :  157\n",
      "reward :  -0.5256404227996808\n",
      "episode :  5\n",
      "current step :  158\n",
      "reward :  -0.5135135061194099\n",
      "episode :  5\n",
      "current step :  159\n",
      "reward :  -0.45212686701037763\n",
      "episode :  5\n",
      "current step :  160\n",
      "reward :  -0.4968823198781702\n",
      "episode :  5\n",
      "current step :  161\n",
      "reward :  -0.36998776138961026\n",
      "episode :  5\n",
      "current step :  162\n",
      "reward :  -0.4520769652606093\n",
      "episode :  5\n",
      "current step :  163\n",
      "reward :  -0.4438515351943412\n",
      "episode :  5\n",
      "current step :  164\n",
      "reward :  -0.34341718417204037\n",
      "episode :  5\n",
      "current step :  165\n",
      "reward :  -0.5228468654676558\n",
      "episode :  5\n",
      "current step :  166\n",
      "reward :  -0.5029075569575727\n",
      "episode :  5\n",
      "current step :  167\n",
      "reward :  -0.49294361752404003\n",
      "episode :  5\n",
      "current step :  168\n",
      "reward :  -0.5296440150429302\n",
      "episode :  5\n",
      "current step :  169\n",
      "reward :  -0.5332336340045939\n",
      "episode :  5\n",
      "current step :  170\n",
      "reward :  -0.48503192166848325\n",
      "episode :  5\n",
      "current step :  171\n",
      "reward :  -0.42698015501683073\n",
      "episode :  5\n",
      "current step :  172\n",
      "reward :  -0.5034761528667415\n",
      "episode :  5\n",
      "current step :  173\n",
      "reward :  -0.4106953631893514\n",
      "episode :  5\n",
      "current step :  174\n",
      "reward :  -0.36811349274436317\n",
      "episode :  5\n",
      "current step :  175\n",
      "reward :  -0.5825073000096392\n",
      "episode :  5\n",
      "current step :  176\n",
      "reward :  -0.603859350383994\n",
      "episode :  5\n",
      "current step :  177\n",
      "reward :  -0.6349677780688896\n",
      "episode :  5\n",
      "current step :  178\n",
      "reward :  -0.65334549384593\n",
      "episode :  5\n",
      "current step :  179\n",
      "reward :  -0.5616591483744366\n",
      "episode :  5\n",
      "current step :  180\n",
      "reward :  -0.4422602780178364\n",
      "episode :  5\n",
      "current step :  181\n",
      "reward :  -0.508174807332239\n",
      "episode :  5\n",
      "current step :  182\n",
      "reward :  -0.46569103905822584\n",
      "episode :  5\n",
      "current step :  183\n",
      "reward :  -0.4947202301620737\n",
      "episode :  5\n",
      "current step :  184\n",
      "reward :  -0.507143701809004\n",
      "episode :  5\n",
      "current step :  185\n",
      "reward :  -0.5264712465735568\n",
      "episode :  5\n",
      "current step :  186\n",
      "reward :  -0.6066871460884091\n",
      "episode :  5\n",
      "current step :  187\n",
      "reward :  -0.5318830976463303\n",
      "episode :  5\n",
      "current step :  188\n",
      "reward :  -0.39646665777971146\n",
      "episode :  5\n",
      "current step :  189\n",
      "reward :  -0.3970012864082023\n",
      "episode :  5\n",
      "current step :  190\n",
      "reward :  -0.3738766989094439\n",
      "episode :  5\n",
      "current step :  191\n",
      "reward :  -0.37459124731094806\n",
      "episode :  5\n",
      "current step :  192\n",
      "reward :  -0.3539273087127787\n",
      "episode :  5\n",
      "current step :  193\n",
      "reward :  -0.4069209675731416\n",
      "episode :  5\n",
      "current step :  194\n",
      "reward :  -0.4439796035070881\n",
      "episode :  5\n",
      "current step :  195\n",
      "reward :  -0.41440426377830475\n",
      "episode :  5\n",
      "current step :  196\n",
      "reward :  -0.4602098913180683\n",
      "episode :  5\n",
      "current step :  197\n",
      "reward :  -0.43199732728783913\n",
      "episode :  5\n",
      "current step :  198\n",
      "reward :  -0.5460464444459582\n",
      "episode :  5\n",
      "current step :  199\n",
      "reward :  -0.6089664847058078\n",
      "episode :  5\n",
      "current step :  200\n",
      "reward :  -0.4668813859525245\n",
      "episode :  5\n",
      "current step :  201\n",
      "reward :  -0.5290633608070947\n",
      "episode :  5\n",
      "current step :  202\n",
      "reward :  -0.5175069605685524\n",
      "episode :  5\n",
      "current step :  203\n",
      "reward :  -0.6669613479404057\n",
      "episode :  5\n",
      "current step :  204\n",
      "reward :  -0.5993795352242307\n",
      "episode :  5\n",
      "current step :  205\n",
      "reward :  -0.5530450492712551\n",
      "episode :  5\n",
      "current step :  206\n",
      "reward :  -0.49673998772988287\n",
      "episode :  5\n",
      "current step :  207\n",
      "reward :  -0.47418306213735134\n",
      "episode :  5\n",
      "current step :  208\n",
      "reward :  -0.49402569432879095\n",
      "episode :  5\n",
      "current step :  209\n",
      "reward :  -0.4109966001622204\n",
      "episode :  5\n",
      "current step :  210\n",
      "reward :  -0.3923918563059797\n",
      "episode :  5\n",
      "current step :  211\n",
      "reward :  -0.42617632171167474\n",
      "episode :  5\n",
      "current step :  212\n",
      "reward :  -0.5037721673609601\n",
      "episode :  5\n",
      "current step :  213\n",
      "reward :  -0.6040538603446756\n",
      "episode :  5\n",
      "current step :  214\n",
      "reward :  -0.603947465976918\n",
      "episode :  5\n",
      "current step :  215\n",
      "reward :  -0.6211415996496573\n",
      "episode :  5\n",
      "current step :  216\n",
      "reward :  -0.6015732563314001\n",
      "episode :  5\n",
      "current step :  217\n",
      "reward :  -0.5916720624705344\n",
      "episode :  5\n",
      "current step :  218\n",
      "reward :  -0.5805089570643472\n",
      "episode :  5\n",
      "current step :  219\n",
      "reward :  -0.5338769246124124\n",
      "episode :  5\n",
      "current step :  220\n",
      "reward :  -0.4822445350494791\n",
      "episode :  5\n",
      "current step :  221\n",
      "reward :  -0.41331786298109596\n",
      "episode :  5\n",
      "current step :  222\n",
      "reward :  -0.42124579794814576\n",
      "episode :  5\n",
      "current step :  223\n",
      "reward :  -0.4410213235779952\n",
      "episode :  5\n",
      "current step :  224\n",
      "reward :  -0.45258480721195765\n",
      "episode :  5\n",
      "current step :  225\n",
      "reward :  -0.4483975709402701\n",
      "episode :  5\n",
      "current step :  226\n",
      "reward :  -0.39904675252095956\n",
      "episode :  5\n",
      "current step :  227\n",
      "reward :  -0.3813729789620575\n",
      "episode :  5\n",
      "current step :  228\n",
      "reward :  -0.4188990355778303\n",
      "episode :  5\n",
      "current step :  229\n",
      "reward :  -0.3404667375362272\n",
      "episode :  5\n",
      "current step :  230\n",
      "reward :  -0.3613810277881548\n",
      "episode :  5\n",
      "current step :  231\n",
      "reward :  -0.5079712233622441\n",
      "episode :  5\n",
      "current step :  232\n",
      "reward :  -0.5429197376342411\n",
      "episode :  5\n",
      "current step :  233\n",
      "reward :  -0.5118751487269604\n",
      "episode :  5\n",
      "current step :  234\n",
      "reward :  -0.4711065034989503\n",
      "episode :  5\n",
      "current step :  235\n",
      "reward :  -0.5630928611053123\n",
      "episode :  5\n",
      "current step :  236\n",
      "reward :  -0.6002801778789665\n",
      "episode :  5\n",
      "current step :  237\n",
      "reward :  -0.5966288158271609\n",
      "episode :  5\n",
      "current step :  238\n",
      "reward :  -0.571585834171794\n",
      "episode :  5\n",
      "current step :  239\n",
      "reward :  -0.48768901818851335\n",
      "episode :  5\n",
      "current step :  240\n",
      "reward :  -0.5091631000460113\n",
      "episode :  5\n",
      "current step :  241\n",
      "reward :  -0.45682162019980865\n",
      "episode :  5\n",
      "current step :  242\n",
      "reward :  -0.41230197368916544\n",
      "episode :  5\n",
      "current step :  243\n",
      "reward :  -0.32672101900586076\n",
      "episode :  5\n",
      "current step :  244\n",
      "reward :  -0.3024565685327542\n",
      "episode :  5\n",
      "current step :  245\n",
      "reward :  -0.3261814643989385\n",
      "episode :  5\n",
      "current step :  246\n",
      "reward :  -0.3596096043472951\n",
      "episode :  5\n",
      "current step :  247\n",
      "reward :  -0.38262592443546783\n",
      "episode :  5\n",
      "current step :  248\n",
      "reward :  -0.4107021496080534\n",
      "episode :  5\n",
      "current step :  249\n",
      "reward :  -0.3701224689721058\n",
      "episode :  5\n",
      "current step :  250\n",
      "reward :  -0.28965179885528064\n",
      "episode :  5\n",
      "current step :  251\n",
      "reward :  -0.25333001908810776\n",
      "episode :  5\n",
      "current step :  252\n",
      "reward :  -0.2561850474879954\n",
      "episode :  5\n",
      "current step :  253\n",
      "reward :  -0.18561414409275223\n",
      "episode :  5\n",
      "current step :  254\n",
      "reward :  -0.21591967311752536\n",
      "episode :  5\n",
      "current step :  255\n",
      "reward :  -0.2450644183054116\n",
      "episode :  5\n",
      "current step :  256\n",
      "reward :  -0.30327073032986923\n",
      "episode :  5\n",
      "current step :  257\n",
      "reward :  -0.28710444470902585\n",
      "episode :  5\n",
      "current step :  258\n",
      "reward :  -0.2759607130526273\n",
      "episode :  5\n",
      "current step :  259\n",
      "reward :  -0.2664525976073765\n",
      "episode :  5\n",
      "current step :  260\n",
      "reward :  -0.28136573792022057\n",
      "episode :  5\n",
      "current step :  261\n",
      "reward :  -0.25732733925417534\n",
      "episode :  5\n",
      "current step :  262\n",
      "reward :  -0.23934107528849483\n",
      "episode :  5\n",
      "current step :  263\n",
      "reward :  -0.3075150644124877\n",
      "episode :  5\n",
      "current step :  264\n",
      "reward :  -0.26279138817917513\n",
      "episode :  5\n",
      "current step :  265\n",
      "reward :  -0.33533813707246984\n",
      "episode :  5\n",
      "current step :  266\n",
      "reward :  -0.3377495969146669\n",
      "episode :  5\n",
      "current step :  267\n",
      "reward :  -0.3625587552457591\n",
      "episode :  5\n",
      "current step :  268\n",
      "reward :  -0.35355472660918924\n",
      "episode :  5\n",
      "current step :  269\n",
      "reward :  -0.3533942787398624\n",
      "episode :  5\n",
      "current step :  270\n",
      "reward :  -0.32183652727671364\n",
      "episode :  5\n",
      "current step :  271\n",
      "reward :  -0.31394663406357354\n",
      "episode :  5\n",
      "current step :  272\n",
      "reward :  -0.2547087600484747\n",
      "episode :  5\n",
      "current step :  273\n",
      "reward :  -0.2090931278727559\n",
      "episode :  5\n",
      "current step :  274\n",
      "reward :  -0.2226967293910184\n",
      "episode :  5\n",
      "current step :  275\n",
      "reward :  -0.2864570694335163\n",
      "episode :  5\n",
      "current step :  276\n",
      "reward :  -0.3131045101231359\n",
      "episode :  5\n",
      "current step :  277\n",
      "reward :  -0.3196140594031124\n",
      "episode :  5\n",
      "current step :  278\n",
      "reward :  -0.34696105393130083\n",
      "episode :  5\n",
      "current step :  279\n",
      "reward :  -0.30426811490490524\n",
      "episode :  5\n",
      "current step :  280\n",
      "reward :  -0.3363286557062378\n",
      "episode :  5\n",
      "current step :  281\n",
      "reward :  -0.3210451741821109\n",
      "episode :  5\n",
      "current step :  282\n",
      "reward :  -0.36946003022671536\n",
      "episode :  5\n",
      "current step :  283\n",
      "reward :  -0.2919405433892588\n",
      "episode :  5\n",
      "current step :  284\n",
      "reward :  -0.3139144763819633\n",
      "episode :  5\n",
      "current step :  285\n",
      "reward :  -0.2968297916916306\n",
      "episode :  6\n",
      "current step :  0\n",
      "reward :  -0.16585038032652033\n",
      "episode :  6\n",
      "current step :  1\n",
      "reward :  -0.16855562906962762\n",
      "episode :  6\n",
      "current step :  2\n",
      "reward :  -0.2642193482865396\n",
      "episode :  6\n",
      "current step :  3\n",
      "reward :  -0.31894335238717075\n",
      "episode :  6\n",
      "current step :  4\n",
      "reward :  -0.34061346632227374\n",
      "episode :  6\n",
      "current step :  5\n",
      "reward :  -0.3522226286752519\n",
      "episode :  6\n",
      "current step :  6\n",
      "reward :  -0.3306318295109351\n",
      "episode :  6\n",
      "current step :  7\n",
      "reward :  -0.3261881546534851\n",
      "episode :  6\n",
      "current step :  8\n",
      "reward :  -0.30927257568588284\n",
      "episode :  6\n",
      "current step :  9\n",
      "reward :  -0.3178480596613651\n",
      "episode :  6\n",
      "current step :  10\n",
      "reward :  -0.35259885879918157\n",
      "episode :  6\n",
      "current step :  11\n",
      "reward :  -0.30535333347494586\n",
      "episode :  6\n",
      "current step :  12\n",
      "reward :  -0.2971869996441494\n",
      "episode :  6\n",
      "current step :  13\n",
      "reward :  -0.29114847396431814\n",
      "episode :  6\n",
      "current step :  14\n",
      "reward :  -0.18863136816678192\n",
      "episode :  6\n",
      "current step :  15\n",
      "reward :  -0.19990535442812973\n",
      "episode :  6\n",
      "current step :  16\n",
      "reward :  -0.3088088311201002\n",
      "episode :  6\n",
      "current step :  17\n",
      "reward :  -0.2979622588294558\n",
      "episode :  6\n",
      "current step :  18\n",
      "reward :  -0.28699484483852\n",
      "episode :  6\n",
      "current step :  19\n",
      "reward :  -0.21312695373707416\n",
      "episode :  6\n",
      "current step :  20\n",
      "reward :  -0.12402225827711891\n",
      "episode :  6\n",
      "current step :  21\n",
      "reward :  -0.18255922037388053\n",
      "episode :  6\n",
      "current step :  22\n",
      "reward :  -0.28285725411716267\n",
      "episode :  6\n",
      "current step :  23\n",
      "reward :  -0.19112930658187635\n",
      "episode :  6\n",
      "current step :  24\n",
      "reward :  -0.2696163935555024\n",
      "episode :  6\n",
      "current step :  25\n",
      "reward :  -0.2669753607453702\n",
      "episode :  6\n",
      "current step :  26\n",
      "reward :  -0.37499818464086504\n",
      "episode :  6\n",
      "current step :  27\n",
      "reward :  -0.4684622156021468\n",
      "episode :  6\n",
      "current step :  28\n",
      "reward :  -0.5181950715877377\n",
      "episode :  6\n",
      "current step :  29\n",
      "reward :  -0.5315364699551259\n",
      "episode :  6\n",
      "current step :  30\n",
      "reward :  -0.5141516421646618\n",
      "episode :  6\n",
      "current step :  31\n",
      "reward :  -0.585774504303592\n",
      "episode :  6\n",
      "current step :  32\n",
      "reward :  -0.48246614999635806\n",
      "episode :  6\n",
      "current step :  33\n",
      "reward :  -0.45178323375404056\n",
      "episode :  6\n",
      "current step :  34\n",
      "reward :  -0.49736639626865353\n",
      "episode :  6\n",
      "current step :  35\n",
      "reward :  -0.4921080821512569\n",
      "episode :  6\n",
      "current step :  36\n",
      "reward :  -0.4870981424965399\n",
      "episode :  6\n",
      "current step :  37\n",
      "reward :  -0.5404744696470655\n",
      "episode :  6\n",
      "current step :  38\n",
      "reward :  -0.5418558944821255\n",
      "episode :  6\n",
      "current step :  39\n",
      "reward :  -0.5843407301679129\n",
      "episode :  6\n",
      "current step :  40\n",
      "reward :  -0.4841763310778099\n",
      "episode :  6\n",
      "current step :  41\n",
      "reward :  -0.49215486066284464\n",
      "episode :  6\n",
      "current step :  42\n",
      "reward :  -0.411456687346633\n",
      "episode :  6\n",
      "current step :  43\n",
      "reward :  -0.3096972221571199\n",
      "episode :  6\n",
      "current step :  44\n",
      "reward :  -0.319745261155004\n",
      "episode :  6\n",
      "current step :  45\n",
      "reward :  -0.38538294354862956\n",
      "episode :  6\n",
      "current step :  46\n",
      "reward :  -0.4660867680481066\n",
      "episode :  6\n",
      "current step :  47\n",
      "reward :  -0.4718699143421299\n",
      "episode :  6\n",
      "current step :  48\n",
      "reward :  -0.3235863005491339\n",
      "episode :  6\n",
      "current step :  49\n",
      "reward :  -0.3831452893872811\n",
      "episode :  6\n",
      "current step :  50\n",
      "reward :  -0.5050103710387642\n",
      "episode :  6\n",
      "current step :  51\n",
      "reward :  -0.5831087701307835\n",
      "episode :  6\n",
      "current step :  52\n",
      "reward :  -0.41551340404517123\n",
      "episode :  6\n",
      "current step :  53\n",
      "reward :  -0.3589611045459069\n",
      "episode :  6\n",
      "current step :  54\n",
      "reward :  -0.350404719062892\n",
      "episode :  6\n",
      "current step :  55\n",
      "reward :  -0.4150715426234087\n",
      "episode :  6\n",
      "current step :  56\n",
      "reward :  -0.3668401693656211\n",
      "episode :  6\n",
      "current step :  57\n",
      "reward :  -0.3209798544195882\n",
      "episode :  6\n",
      "current step :  58\n",
      "reward :  -0.4035194988619165\n",
      "episode :  6\n",
      "current step :  59\n",
      "reward :  -0.31473673228197424\n",
      "episode :  6\n",
      "current step :  60\n",
      "reward :  -0.4183629274156369\n",
      "episode :  6\n",
      "current step :  61\n",
      "reward :  -0.4514939288057056\n",
      "episode :  6\n",
      "current step :  62\n",
      "reward :  -0.3418757584161109\n",
      "episode :  6\n",
      "current step :  63\n",
      "reward :  -0.39439874197622665\n",
      "episode :  6\n",
      "current step :  64\n",
      "reward :  -0.5101875627108609\n",
      "episode :  6\n",
      "current step :  65\n",
      "reward :  -0.5967480110180299\n",
      "episode :  6\n",
      "current step :  66\n",
      "reward :  -0.55146339360063\n",
      "episode :  6\n",
      "current step :  67\n",
      "reward :  -0.4740894356629731\n",
      "episode :  6\n",
      "current step :  68\n",
      "reward :  -0.4994654497437105\n",
      "episode :  6\n",
      "current step :  69\n",
      "reward :  -0.5376788114414697\n",
      "episode :  6\n",
      "current step :  70\n",
      "reward :  -0.42982419593098387\n",
      "episode :  6\n",
      "current step :  71\n",
      "reward :  -0.36325629970100065\n",
      "episode :  6\n",
      "current step :  72\n",
      "reward :  -0.33070046922607654\n",
      "episode :  6\n",
      "current step :  73\n",
      "reward :  -0.39210102793964796\n",
      "episode :  6\n",
      "current step :  74\n",
      "reward :  -0.3298172852337122\n",
      "episode :  6\n",
      "current step :  75\n",
      "reward :  -0.3766790573857363\n",
      "episode :  6\n",
      "current step :  76\n",
      "reward :  -0.3573641703520056\n",
      "episode :  6\n",
      "current step :  77\n",
      "reward :  -0.5776877867450358\n",
      "episode :  6\n",
      "current step :  78\n",
      "reward :  -0.5755578382819451\n",
      "episode :  6\n",
      "current step :  79\n",
      "reward :  -0.6074459220110794\n",
      "episode :  6\n",
      "current step :  80\n",
      "reward :  -0.5353605175455622\n",
      "episode :  6\n",
      "current step :  81\n",
      "reward :  -0.5447674082184739\n",
      "episode :  6\n",
      "current step :  82\n",
      "reward :  -0.5712980374622255\n",
      "episode :  6\n",
      "current step :  83\n",
      "reward :  -0.5547101316764255\n",
      "episode :  6\n",
      "current step :  84\n",
      "reward :  -0.5254616225706426\n",
      "episode :  6\n",
      "current step :  85\n",
      "reward :  -0.5184436489780302\n",
      "episode :  6\n",
      "current step :  86\n",
      "reward :  -0.5110774715682713\n",
      "episode :  6\n",
      "current step :  87\n",
      "reward :  -0.36369913477742466\n",
      "episode :  6\n",
      "current step :  88\n",
      "reward :  -0.3593641401432556\n",
      "episode :  6\n",
      "current step :  89\n",
      "reward :  -0.3465620882137328\n",
      "episode :  6\n",
      "current step :  90\n",
      "reward :  -0.30595600181243915\n",
      "episode :  6\n",
      "current step :  91\n",
      "reward :  -0.2920256071354778\n",
      "episode :  6\n",
      "current step :  92\n",
      "reward :  -0.2356549107068114\n",
      "episode :  6\n",
      "current step :  93\n",
      "reward :  -0.23337819136697247\n",
      "episode :  6\n",
      "current step :  94\n",
      "reward :  -0.30972048115467943\n",
      "episode :  6\n",
      "current step :  95\n",
      "reward :  -0.3794455577857448\n",
      "episode :  6\n",
      "current step :  96\n",
      "reward :  -0.3152573570022582\n",
      "episode :  6\n",
      "current step :  97\n",
      "reward :  -0.3386157635931438\n",
      "episode :  6\n",
      "current step :  98\n",
      "reward :  -0.4184387182798659\n",
      "episode :  6\n",
      "current step :  99\n",
      "reward :  -0.3686462975592138\n",
      "episode :  6\n",
      "current step :  100\n",
      "reward :  -0.2603069404731342\n",
      "episode :  6\n",
      "current step :  101\n",
      "reward :  -0.24483402668004817\n",
      "episode :  6\n",
      "current step :  102\n",
      "reward :  -0.22966401872281642\n",
      "episode :  6\n",
      "current step :  103\n",
      "reward :  -0.2492059864325352\n",
      "episode :  6\n",
      "current step :  104\n",
      "reward :  -0.3697972215889876\n",
      "episode :  6\n",
      "current step :  105\n",
      "reward :  -0.39065622540942974\n",
      "episode :  6\n",
      "current step :  106\n",
      "reward :  -0.3480440750632862\n",
      "episode :  6\n",
      "current step :  107\n",
      "reward :  -0.19965591424571155\n",
      "episode :  6\n",
      "current step :  108\n",
      "reward :  -0.27970952132192506\n",
      "episode :  6\n",
      "current step :  109\n",
      "reward :  -0.24848700640584853\n",
      "episode :  6\n",
      "current step :  110\n",
      "reward :  -0.2382220628221716\n",
      "episode :  6\n",
      "current step :  111\n",
      "reward :  -0.25747999984444814\n",
      "episode :  6\n",
      "current step :  112\n",
      "reward :  -0.28408278518932595\n",
      "episode :  6\n",
      "current step :  113\n",
      "reward :  -0.36060043956137705\n",
      "episode :  6\n",
      "current step :  114\n",
      "reward :  -0.2670994469085036\n",
      "episode :  6\n",
      "current step :  115\n",
      "reward :  -0.3253328996659982\n",
      "episode :  6\n",
      "current step :  116\n",
      "reward :  -0.29111289164629056\n",
      "episode :  6\n",
      "current step :  117\n",
      "reward :  -0.3139122841141906\n",
      "episode :  6\n",
      "current step :  118\n",
      "reward :  -0.31081211400796055\n",
      "episode :  6\n",
      "current step :  119\n",
      "reward :  -0.236376864828638\n",
      "episode :  6\n",
      "current step :  120\n",
      "reward :  -0.19281578753434053\n",
      "episode :  6\n",
      "current step :  121\n",
      "reward :  -0.20687011017150586\n",
      "episode :  6\n",
      "current step :  122\n",
      "reward :  -0.18310831492006152\n",
      "episode :  6\n",
      "current step :  123\n",
      "reward :  -0.2424117397671076\n",
      "episode :  6\n",
      "current step :  124\n",
      "reward :  -0.3025006789591833\n",
      "episode :  6\n",
      "current step :  125\n",
      "reward :  -0.32522248977130186\n",
      "episode :  6\n",
      "current step :  126\n",
      "reward :  -0.394533109247229\n",
      "episode :  6\n",
      "current step :  127\n",
      "reward :  -0.36914079657293725\n",
      "episode :  6\n",
      "current step :  128\n",
      "reward :  -0.2691048846458761\n",
      "episode :  6\n",
      "current step :  129\n",
      "reward :  -0.3289572012558384\n",
      "episode :  6\n",
      "current step :  130\n",
      "reward :  -0.25174771334874574\n",
      "episode :  6\n",
      "current step :  131\n",
      "reward :  -0.24752420068548422\n",
      "episode :  6\n",
      "current step :  132\n",
      "reward :  -0.23430687479791354\n",
      "episode :  6\n",
      "current step :  133\n",
      "reward :  -0.3916470748380493\n",
      "episode :  6\n",
      "current step :  134\n",
      "reward :  -0.386672651573237\n",
      "episode :  6\n",
      "current step :  135\n",
      "reward :  -0.4121517842750498\n",
      "episode :  6\n",
      "current step :  136\n",
      "reward :  -0.29077382786363426\n",
      "episode :  6\n",
      "current step :  137\n",
      "reward :  -0.38538634245195674\n",
      "episode :  6\n",
      "current step :  138\n",
      "reward :  -0.3266482296684592\n",
      "episode :  6\n",
      "current step :  139\n",
      "reward :  -0.2568802893907128\n",
      "episode :  6\n",
      "current step :  140\n",
      "reward :  -0.3209451550830713\n",
      "episode :  6\n",
      "current step :  141\n",
      "reward :  -0.2740991907586821\n",
      "episode :  6\n",
      "current step :  142\n",
      "reward :  -0.26760039638837047\n",
      "episode :  6\n",
      "current step :  143\n",
      "reward :  -0.2709833708628041\n",
      "episode :  6\n",
      "current step :  144\n",
      "reward :  -0.2775180384412427\n",
      "episode :  6\n",
      "current step :  145\n",
      "reward :  -0.37380691727510407\n",
      "episode :  6\n",
      "current step :  146\n",
      "reward :  -0.20195404028075398\n",
      "episode :  6\n",
      "current step :  147\n",
      "reward :  -0.3479925558071683\n",
      "episode :  6\n",
      "current step :  148\n",
      "reward :  -0.3445308386017481\n",
      "episode :  6\n",
      "current step :  149\n",
      "reward :  -0.30620571231614174\n",
      "episode :  6\n",
      "current step :  150\n",
      "reward :  -0.28977809287197437\n",
      "episode :  6\n",
      "current step :  151\n",
      "reward :  -0.23611196831188114\n",
      "episode :  6\n",
      "current step :  152\n",
      "reward :  -0.34152201083651834\n",
      "episode :  6\n",
      "current step :  153\n",
      "reward :  -0.3843650869476944\n",
      "episode :  6\n",
      "current step :  154\n",
      "reward :  -0.5276747338686856\n",
      "episode :  6\n",
      "current step :  155\n",
      "reward :  -0.5969176592326001\n",
      "episode :  6\n",
      "current step :  156\n",
      "reward :  -0.4973396923455055\n",
      "episode :  6\n",
      "current step :  157\n",
      "reward :  -0.4438139691438852\n",
      "episode :  6\n",
      "current step :  158\n",
      "reward :  -0.38903362890364007\n",
      "episode :  6\n",
      "current step :  159\n",
      "reward :  -0.5084506231793826\n",
      "episode :  6\n",
      "current step :  160\n",
      "reward :  -0.3984606725891971\n",
      "episode :  6\n",
      "current step :  161\n",
      "reward :  -0.3363243395957312\n",
      "episode :  6\n",
      "current step :  162\n",
      "reward :  -0.3487760504249832\n",
      "episode :  6\n",
      "current step :  163\n",
      "reward :  -0.3403087014385973\n",
      "episode :  6\n",
      "current step :  164\n",
      "reward :  -0.5212939043476956\n",
      "episode :  6\n",
      "current step :  165\n",
      "reward :  -0.4696733994490205\n",
      "episode :  6\n",
      "current step :  166\n",
      "reward :  -0.45487356796918743\n",
      "episode :  6\n",
      "current step :  167\n",
      "reward :  -0.5162303433933539\n",
      "episode :  6\n",
      "current step :  168\n",
      "reward :  -0.486822744945296\n",
      "episode :  6\n",
      "current step :  169\n",
      "reward :  -0.3827700453776752\n",
      "episode :  6\n",
      "current step :  170\n",
      "reward :  -0.3726536570142114\n",
      "episode :  6\n",
      "current step :  171\n",
      "reward :  -0.3425714296192759\n",
      "episode :  6\n",
      "current step :  172\n",
      "reward :  -0.34528600784049474\n",
      "episode :  6\n",
      "current step :  173\n",
      "reward :  -0.36988991624648704\n",
      "episode :  6\n",
      "current step :  174\n",
      "reward :  -0.40613136157835694\n",
      "episode :  6\n",
      "current step :  175\n",
      "reward :  -0.46788917424404075\n",
      "episode :  6\n",
      "current step :  176\n",
      "reward :  -0.4022679199884031\n",
      "episode :  6\n",
      "current step :  177\n",
      "reward :  -0.4266304954022221\n",
      "episode :  6\n",
      "current step :  178\n",
      "reward :  -0.42079911017499855\n",
      "episode :  6\n",
      "current step :  179\n",
      "reward :  -0.5219633586398178\n",
      "episode :  6\n",
      "current step :  180\n",
      "reward :  -0.6575459711467461\n",
      "episode :  6\n",
      "current step :  181\n",
      "reward :  -0.6793152935386694\n",
      "episode :  6\n",
      "current step :  182\n",
      "reward :  -0.5550431473613137\n",
      "episode :  6\n",
      "current step :  183\n",
      "reward :  -0.5310116372457493\n",
      "episode :  6\n",
      "current step :  184\n",
      "reward :  -0.5061690727324535\n",
      "episode :  6\n",
      "current step :  185\n",
      "reward :  -0.3869324339239836\n",
      "episode :  6\n",
      "current step :  186\n",
      "reward :  -0.3971302986768073\n",
      "episode :  6\n",
      "current step :  187\n",
      "reward :  -0.4312882420322837\n",
      "episode :  6\n",
      "current step :  188\n",
      "reward :  -0.4683913744728489\n",
      "episode :  6\n",
      "current step :  189\n",
      "reward :  -0.5067012813623429\n",
      "episode :  6\n",
      "current step :  190\n",
      "reward :  -0.5580395973659715\n",
      "episode :  6\n",
      "current step :  191\n",
      "reward :  -0.5802903182056511\n",
      "episode :  6\n",
      "current step :  192\n",
      "reward :  -0.5297243625691507\n",
      "episode :  6\n",
      "current step :  193\n",
      "reward :  -0.5014656591297654\n",
      "episode :  6\n",
      "current step :  194\n",
      "reward :  -0.5069751648964901\n",
      "episode :  6\n",
      "current step :  195\n",
      "reward :  -0.5793812678955096\n",
      "episode :  6\n",
      "current step :  196\n",
      "reward :  -0.39211598646635487\n",
      "episode :  6\n",
      "current step :  197\n",
      "reward :  -0.3180373741780018\n",
      "episode :  6\n",
      "current step :  198\n",
      "reward :  -0.36414800871585734\n",
      "episode :  6\n",
      "current step :  199\n",
      "reward :  -0.47136054616907896\n",
      "episode :  6\n",
      "current step :  200\n",
      "reward :  -0.39432502107491124\n",
      "episode :  6\n",
      "current step :  201\n",
      "reward :  -0.4615209633506973\n",
      "episode :  6\n",
      "current step :  202\n",
      "reward :  -0.552032235039213\n",
      "episode :  6\n",
      "current step :  203\n",
      "reward :  -0.529624071404911\n",
      "episode :  6\n",
      "current step :  204\n",
      "reward :  -0.5300985859437191\n",
      "episode :  6\n",
      "current step :  205\n",
      "reward :  -0.42717180016351686\n",
      "episode :  6\n",
      "current step :  206\n",
      "reward :  -0.4554533864232331\n",
      "episode :  6\n",
      "current step :  207\n",
      "reward :  -0.48956407942324415\n",
      "episode :  6\n",
      "current step :  208\n",
      "reward :  -0.5542213475462108\n",
      "episode :  6\n",
      "current step :  209\n",
      "reward :  -0.547095203597246\n",
      "episode :  6\n",
      "current step :  210\n",
      "reward :  -0.4338932875034677\n",
      "episode :  6\n",
      "current step :  211\n",
      "reward :  -0.3718315277434853\n",
      "episode :  6\n",
      "current step :  212\n",
      "reward :  -0.33000320871848626\n",
      "episode :  6\n",
      "current step :  213\n",
      "reward :  -0.3183068692660849\n",
      "episode :  6\n",
      "current step :  214\n",
      "reward :  -0.551089333458401\n",
      "episode :  6\n",
      "current step :  215\n",
      "reward :  -0.5551064355082055\n",
      "episode :  6\n",
      "current step :  216\n",
      "reward :  -0.5083399917201802\n",
      "episode :  6\n",
      "current step :  217\n",
      "reward :  -0.524222534619721\n",
      "episode :  6\n",
      "current step :  218\n",
      "reward :  -0.57970911818513\n",
      "episode :  6\n",
      "current step :  219\n",
      "reward :  -0.6597033500949417\n",
      "episode :  6\n",
      "current step :  220\n",
      "reward :  -0.6615270769352619\n",
      "episode :  6\n",
      "current step :  221\n",
      "reward :  -0.6214686234500698\n",
      "episode :  6\n",
      "current step :  222\n",
      "reward :  -0.5520051954158611\n",
      "episode :  6\n",
      "current step :  223\n",
      "reward :  -0.48606203629023964\n",
      "episode :  6\n",
      "current step :  224\n",
      "reward :  -0.44806276524297334\n",
      "episode :  6\n",
      "current step :  225\n",
      "reward :  -0.28439985472025026\n",
      "episode :  6\n",
      "current step :  226\n",
      "reward :  -0.3744841536468477\n",
      "episode :  6\n",
      "current step :  227\n",
      "reward :  -0.4023191561680655\n",
      "episode :  6\n",
      "current step :  228\n",
      "reward :  -0.4103979772320443\n",
      "episode :  6\n",
      "current step :  229\n",
      "reward :  -0.3531055161372824\n",
      "episode :  6\n",
      "current step :  230\n",
      "reward :  -0.39587092968729504\n",
      "episode :  6\n",
      "current step :  231\n",
      "reward :  -0.37201771113262905\n",
      "episode :  6\n",
      "current step :  232\n",
      "reward :  -0.4113755471646758\n",
      "episode :  6\n",
      "current step :  233\n",
      "reward :  -0.3385705250273907\n",
      "episode :  6\n",
      "current step :  234\n",
      "reward :  -0.41872836127888213\n",
      "episode :  6\n",
      "current step :  235\n",
      "reward :  -0.4532571099049504\n",
      "episode :  6\n",
      "current step :  236\n",
      "reward :  -0.48058327348235874\n",
      "episode :  6\n",
      "current step :  237\n",
      "reward :  -0.5104055818490035\n",
      "episode :  6\n",
      "current step :  238\n",
      "reward :  -0.5023028713046103\n",
      "episode :  6\n",
      "current step :  239\n",
      "reward :  -0.5519360879255609\n",
      "episode :  6\n",
      "current step :  240\n",
      "reward :  -0.442641895472452\n",
      "episode :  6\n",
      "current step :  241\n",
      "reward :  -0.459958925565164\n",
      "episode :  6\n",
      "current step :  242\n",
      "reward :  -0.4746384909671003\n",
      "episode :  6\n",
      "current step :  243\n",
      "reward :  -0.40984001063340253\n",
      "episode :  6\n",
      "current step :  244\n",
      "reward :  -0.3373542793680494\n",
      "episode :  6\n",
      "current step :  245\n",
      "reward :  -0.3905443093813147\n",
      "episode :  6\n",
      "current step :  246\n",
      "reward :  -0.4148772104340226\n",
      "episode :  6\n",
      "current step :  247\n",
      "reward :  -0.33836275610016664\n",
      "episode :  6\n",
      "current step :  248\n",
      "reward :  -0.3709815884768069\n",
      "episode :  6\n",
      "current step :  249\n",
      "reward :  -0.2900091644159909\n",
      "episode :  6\n",
      "current step :  250\n",
      "reward :  -0.3481500368966969\n",
      "episode :  6\n",
      "current step :  251\n",
      "reward :  -0.29655207823657265\n",
      "episode :  6\n",
      "current step :  252\n",
      "reward :  -0.2971265826578954\n",
      "episode :  6\n",
      "current step :  253\n",
      "reward :  -0.41369774316631713\n",
      "episode :  6\n",
      "current step :  254\n",
      "reward :  -0.30016279217500513\n",
      "episode :  6\n",
      "current step :  255\n",
      "reward :  -0.2635495751575931\n",
      "episode :  6\n",
      "current step :  256\n",
      "reward :  -0.32906581709966526\n",
      "episode :  6\n",
      "current step :  257\n",
      "reward :  -0.228067147097068\n",
      "episode :  6\n",
      "current step :  258\n",
      "reward :  -0.2242202800547702\n",
      "episode :  6\n",
      "current step :  259\n",
      "reward :  -0.35092626470025357\n",
      "episode :  6\n",
      "current step :  260\n",
      "reward :  -0.3546694070061671\n",
      "episode :  6\n",
      "current step :  261\n",
      "reward :  -0.3253712284790706\n",
      "episode :  6\n",
      "current step :  262\n",
      "reward :  -0.3105310069987274\n",
      "episode :  6\n",
      "current step :  263\n",
      "reward :  -0.34122434111993316\n",
      "episode :  6\n",
      "current step :  264\n",
      "reward :  -0.46927317135544655\n",
      "episode :  6\n",
      "current step :  265\n",
      "reward :  -0.42851022869238414\n",
      "episode :  6\n",
      "current step :  266\n",
      "reward :  -0.2947850297135567\n",
      "episode :  6\n",
      "current step :  267\n",
      "reward :  -0.18711927938650486\n",
      "episode :  6\n",
      "current step :  268\n",
      "reward :  -0.39681600429116654\n",
      "episode :  6\n",
      "current step :  269\n",
      "reward :  -0.43290959408677576\n",
      "episode :  6\n",
      "current step :  270\n",
      "reward :  -0.3608018241763645\n",
      "episode :  6\n",
      "current step :  271\n",
      "reward :  -0.2873397679805075\n",
      "episode :  6\n",
      "current step :  272\n",
      "reward :  -0.2536839114945553\n",
      "episode :  6\n",
      "current step :  273\n",
      "reward :  -0.23781208035520016\n",
      "episode :  6\n",
      "current step :  274\n",
      "reward :  -0.21444865668337923\n",
      "episode :  6\n",
      "current step :  275\n",
      "reward :  -0.2654881291285585\n",
      "episode :  6\n",
      "current step :  276\n",
      "reward :  -0.3454441024940413\n",
      "episode :  6\n",
      "current step :  277\n",
      "reward :  -0.37276517909541873\n",
      "episode :  6\n",
      "current step :  278\n",
      "reward :  -0.34108609717751576\n",
      "episode :  6\n",
      "current step :  279\n",
      "reward :  -0.3440950123638761\n",
      "episode :  6\n",
      "current step :  280\n",
      "reward :  -0.39462568639155804\n",
      "episode :  6\n",
      "current step :  281\n",
      "reward :  -0.16706316408182317\n",
      "episode :  6\n",
      "current step :  282\n",
      "reward :  -0.2693387588964937\n",
      "episode :  6\n",
      "current step :  283\n",
      "reward :  -0.3737676413400944\n",
      "episode :  6\n",
      "current step :  284\n",
      "reward :  -0.42259206880442907\n",
      "episode :  6\n",
      "current step :  285\n",
      "reward :  -0.353201578310843\n",
      "episode :  7\n",
      "current step :  0\n",
      "reward :  -0.2090509822051492\n",
      "episode :  7\n",
      "current step :  1\n",
      "reward :  -0.15348135329544055\n",
      "episode :  7\n",
      "current step :  2\n",
      "reward :  -0.26947055862699787\n",
      "episode :  7\n",
      "current step :  3\n",
      "reward :  -0.2443624481432776\n",
      "episode :  7\n",
      "current step :  4\n",
      "reward :  -0.2371631895168308\n",
      "episode :  7\n",
      "current step :  5\n",
      "reward :  -0.24360038085753674\n",
      "episode :  7\n",
      "current step :  6\n",
      "reward :  -0.17584769079123452\n",
      "episode :  7\n",
      "current step :  7\n",
      "reward :  -0.2744480105208827\n",
      "episode :  7\n",
      "current step :  8\n",
      "reward :  -0.22057258287992515\n",
      "episode :  7\n",
      "current step :  9\n",
      "reward :  -0.16937141632151237\n",
      "episode :  7\n",
      "current step :  10\n",
      "reward :  -0.26936896705096725\n",
      "episode :  7\n",
      "current step :  11\n",
      "reward :  -0.2944220293382442\n",
      "episode :  7\n",
      "current step :  12\n",
      "reward :  -0.17192000915501662\n",
      "episode :  7\n",
      "current step :  13\n",
      "reward :  -0.2626992425480196\n",
      "episode :  7\n",
      "current step :  14\n",
      "reward :  -0.39657550130092833\n",
      "episode :  7\n",
      "current step :  15\n",
      "reward :  -0.4106893322088518\n",
      "episode :  7\n",
      "current step :  16\n",
      "reward :  -0.33433928106519695\n",
      "episode :  7\n",
      "current step :  17\n",
      "reward :  -0.21097136596139407\n",
      "episode :  7\n",
      "current step :  18\n",
      "reward :  -0.2582631746281725\n",
      "episode :  7\n",
      "current step :  19\n",
      "reward :  -0.28047449751317816\n",
      "episode :  7\n",
      "current step :  20\n",
      "reward :  -0.37451982020932967\n",
      "episode :  7\n",
      "current step :  21\n",
      "reward :  -0.31873481194629705\n",
      "episode :  7\n",
      "current step :  22\n",
      "reward :  -0.46019552702123945\n",
      "episode :  7\n",
      "current step :  23\n",
      "reward :  -0.45057030983167967\n",
      "episode :  7\n",
      "current step :  24\n",
      "reward :  -0.4127080373349269\n",
      "episode :  7\n",
      "current step :  25\n",
      "reward :  -0.39856045354388014\n",
      "episode :  7\n",
      "current step :  26\n",
      "reward :  -0.33949051459331026\n",
      "episode :  7\n",
      "current step :  27\n",
      "reward :  -0.343271463123253\n",
      "episode :  7\n",
      "current step :  28\n",
      "reward :  -0.38216863556473796\n",
      "episode :  7\n",
      "current step :  29\n",
      "reward :  -0.3210306023458084\n",
      "episode :  7\n",
      "current step :  30\n",
      "reward :  -0.4096766264045318\n",
      "episode :  7\n",
      "current step :  31\n",
      "reward :  -0.34061490737772554\n",
      "episode :  7\n",
      "current step :  32\n",
      "reward :  -0.34912227823863906\n",
      "episode :  7\n",
      "current step :  33\n",
      "reward :  -0.32925196562160286\n",
      "episode :  7\n",
      "current step :  34\n",
      "reward :  -0.3553881170569513\n",
      "episode :  7\n",
      "current step :  35\n",
      "reward :  -0.4674706827674175\n",
      "episode :  7\n",
      "current step :  36\n",
      "reward :  -0.5460947334236035\n",
      "episode :  7\n",
      "current step :  37\n",
      "reward :  -0.6133126688660898\n",
      "episode :  7\n",
      "current step :  38\n",
      "reward :  -0.5410213993374969\n",
      "episode :  7\n",
      "current step :  39\n",
      "reward :  -0.6181786629996235\n",
      "episode :  7\n",
      "current step :  40\n",
      "reward :  -0.5999671614963382\n",
      "episode :  7\n",
      "current step :  41\n",
      "reward :  -0.47544558597187697\n",
      "episode :  7\n",
      "current step :  42\n",
      "reward :  -0.5109249195782755\n",
      "episode :  7\n",
      "current step :  43\n",
      "reward :  -0.6147318525679011\n",
      "episode :  7\n",
      "current step :  44\n",
      "reward :  -0.4023109027850312\n",
      "episode :  7\n",
      "current step :  45\n",
      "reward :  -0.4686213546888902\n",
      "episode :  7\n",
      "current step :  46\n",
      "reward :  -0.4213559484340872\n",
      "episode :  7\n",
      "current step :  47\n",
      "reward :  -0.39878126544901\n",
      "episode :  7\n",
      "current step :  48\n",
      "reward :  -0.31512986445384983\n",
      "episode :  7\n",
      "current step :  49\n",
      "reward :  -0.3607835835670745\n",
      "episode :  7\n",
      "current step :  50\n",
      "reward :  -0.41616060772496694\n",
      "episode :  7\n",
      "current step :  51\n",
      "reward :  -0.48863047757222045\n",
      "episode :  7\n",
      "current step :  52\n",
      "reward :  -0.520808528610897\n",
      "episode :  7\n",
      "current step :  53\n",
      "reward :  -0.5392317594517285\n",
      "episode :  7\n",
      "current step :  54\n",
      "reward :  -0.5752249908351693\n",
      "episode :  7\n",
      "current step :  55\n",
      "reward :  -0.5437587712827708\n",
      "episode :  7\n",
      "current step :  56\n",
      "reward :  -0.6351382743341484\n",
      "episode :  7\n",
      "current step :  57\n",
      "reward :  -0.6299071776863228\n",
      "episode :  7\n",
      "current step :  58\n",
      "reward :  -0.508708932491458\n",
      "episode :  7\n",
      "current step :  59\n",
      "reward :  -0.483239462507702\n",
      "episode :  7\n",
      "current step :  60\n",
      "reward :  -0.6265021284942647\n",
      "episode :  7\n",
      "current step :  61\n",
      "reward :  -0.46139118207934776\n",
      "episode :  7\n",
      "current step :  62\n",
      "reward :  -0.6363755102709469\n",
      "episode :  7\n",
      "current step :  63\n",
      "reward :  -0.6187132387075336\n",
      "episode :  7\n",
      "current step :  64\n",
      "reward :  -0.5367351521979289\n",
      "episode :  7\n",
      "current step :  65\n",
      "reward :  -0.55895875826371\n",
      "episode :  7\n",
      "current step :  66\n",
      "reward :  -0.5240447446738552\n",
      "episode :  7\n",
      "current step :  67\n",
      "reward :  -0.5185988425935907\n",
      "episode :  7\n",
      "current step :  68\n",
      "reward :  -0.5993436964245359\n",
      "episode :  7\n",
      "current step :  69\n",
      "reward :  -0.6468690395567528\n",
      "episode :  7\n",
      "current step :  70\n",
      "reward :  -0.5658524794775213\n",
      "episode :  7\n",
      "current step :  71\n",
      "reward :  -0.42019234424047675\n",
      "episode :  7\n",
      "current step :  72\n",
      "reward :  -0.3533264722670016\n",
      "episode :  7\n",
      "current step :  73\n",
      "reward :  -0.5507593847946843\n",
      "episode :  7\n",
      "current step :  74\n",
      "reward :  -0.48305308280568154\n",
      "episode :  7\n",
      "current step :  75\n",
      "reward :  -0.36547817646651537\n",
      "episode :  7\n",
      "current step :  76\n",
      "reward :  -0.5082296216948188\n",
      "episode :  7\n",
      "current step :  77\n",
      "reward :  -0.4128690433342277\n",
      "episode :  7\n",
      "current step :  78\n",
      "reward :  -0.3775594221577491\n",
      "episode :  7\n",
      "current step :  79\n",
      "reward :  -0.3655189827774871\n",
      "episode :  7\n",
      "current step :  80\n",
      "reward :  -0.49034492803920593\n",
      "episode :  7\n",
      "current step :  81\n",
      "reward :  -0.5595397048613979\n",
      "episode :  7\n",
      "current step :  82\n",
      "reward :  -0.5761984641225764\n",
      "episode :  7\n",
      "current step :  83\n",
      "reward :  -0.5829352605082567\n",
      "episode :  7\n",
      "current step :  84\n",
      "reward :  -0.5846570144140516\n",
      "episode :  7\n",
      "current step :  85\n",
      "reward :  -0.5255555860039706\n",
      "episode :  7\n",
      "current step :  86\n",
      "reward :  -0.5197865050623991\n",
      "episode :  7\n",
      "current step :  87\n",
      "reward :  -0.49709561898395543\n",
      "episode :  7\n",
      "current step :  88\n",
      "reward :  -0.447020491480253\n",
      "episode :  7\n",
      "current step :  89\n",
      "reward :  -0.5234691249190858\n",
      "episode :  7\n",
      "current step :  90\n",
      "reward :  -0.44429219352369986\n",
      "episode :  7\n",
      "current step :  91\n",
      "reward :  -0.3691420368230648\n",
      "episode :  7\n",
      "current step :  92\n",
      "reward :  -0.3983223104508997\n",
      "episode :  7\n",
      "current step :  93\n",
      "reward :  -0.4491088674208161\n",
      "episode :  7\n",
      "current step :  94\n",
      "reward :  -0.3662937919795203\n",
      "episode :  7\n",
      "current step :  95\n",
      "reward :  -0.30133087271701936\n",
      "episode :  7\n",
      "current step :  96\n",
      "reward :  -0.30204412405406017\n",
      "episode :  7\n",
      "current step :  97\n",
      "reward :  -0.228140447465729\n",
      "episode :  7\n",
      "current step :  98\n",
      "reward :  -0.23975401612213224\n",
      "episode :  7\n",
      "current step :  99\n",
      "reward :  -0.24650157357300329\n",
      "episode :  7\n",
      "current step :  100\n",
      "reward :  -0.3831577534834344\n",
      "episode :  7\n",
      "current step :  101\n",
      "reward :  -0.36997588704051293\n",
      "episode :  7\n",
      "current step :  102\n",
      "reward :  -0.42353648779006975\n",
      "episode :  7\n",
      "current step :  103\n",
      "reward :  -0.4311919829292901\n",
      "episode :  7\n",
      "current step :  104\n",
      "reward :  -0.4494187544109719\n",
      "episode :  7\n",
      "current step :  105\n",
      "reward :  -0.39141223259390767\n",
      "episode :  7\n",
      "current step :  106\n",
      "reward :  -0.2893464884771337\n",
      "episode :  7\n",
      "current step :  107\n",
      "reward :  -0.31641097134403634\n",
      "episode :  7\n",
      "current step :  108\n",
      "reward :  -0.4422556079628415\n",
      "episode :  7\n",
      "current step :  109\n",
      "reward :  -0.347833688292305\n",
      "episode :  7\n",
      "current step :  110\n",
      "reward :  -0.31390459119297676\n",
      "episode :  7\n",
      "current step :  111\n",
      "reward :  -0.32638391626456903\n",
      "episode :  7\n",
      "current step :  112\n",
      "reward :  -0.3547286025802168\n",
      "episode :  7\n",
      "current step :  113\n",
      "reward :  -0.3738157466947814\n",
      "episode :  7\n",
      "current step :  114\n",
      "reward :  -0.37584674351448427\n",
      "episode :  7\n",
      "current step :  115\n",
      "reward :  -0.46985372835161526\n",
      "episode :  7\n",
      "current step :  116\n",
      "reward :  -0.4936230126414934\n",
      "episode :  7\n",
      "current step :  117\n",
      "reward :  -0.47270458758428685\n",
      "episode :  7\n",
      "current step :  118\n",
      "reward :  -0.29045936155622515\n",
      "episode :  7\n",
      "current step :  119\n",
      "reward :  -0.32384422277326197\n",
      "episode :  7\n",
      "current step :  120\n",
      "reward :  -0.40116445489872604\n",
      "episode :  7\n",
      "current step :  121\n",
      "reward :  -0.33844386040797764\n",
      "episode :  7\n",
      "current step :  122\n",
      "reward :  -0.2402368722536593\n",
      "episode :  7\n",
      "current step :  123\n",
      "reward :  -0.2699980334181078\n",
      "episode :  7\n",
      "current step :  124\n",
      "reward :  -0.2349735410378346\n",
      "episode :  7\n",
      "current step :  125\n",
      "reward :  -0.27726012272193296\n",
      "episode :  7\n",
      "current step :  126\n",
      "reward :  -0.25836083361854\n",
      "episode :  7\n",
      "current step :  127\n",
      "reward :  -0.23351697688077314\n",
      "episode :  7\n",
      "current step :  128\n",
      "reward :  -0.22906486789015082\n",
      "episode :  7\n",
      "current step :  129\n",
      "reward :  -0.3068390617570118\n",
      "episode :  7\n",
      "current step :  130\n",
      "reward :  -0.21445428316276902\n",
      "episode :  7\n",
      "current step :  131\n",
      "reward :  -0.1766916503386002\n",
      "episode :  7\n",
      "current step :  132\n",
      "reward :  -0.3772556517537807\n",
      "episode :  7\n",
      "current step :  133\n",
      "reward :  -0.37811315672290924\n",
      "episode :  7\n",
      "current step :  134\n",
      "reward :  -0.3139139051283503\n",
      "episode :  7\n",
      "current step :  135\n",
      "reward :  -0.33126772597255194\n",
      "episode :  7\n",
      "current step :  136\n",
      "reward :  -0.45142053587174513\n",
      "episode :  7\n",
      "current step :  137\n",
      "reward :  -0.3297252782611464\n",
      "episode :  7\n",
      "current step :  138\n",
      "reward :  -0.29592025727409615\n",
      "episode :  7\n",
      "current step :  139\n",
      "reward :  -0.3474261031924551\n",
      "episode :  7\n",
      "current step :  140\n",
      "reward :  -0.39607324314061604\n",
      "episode :  7\n",
      "current step :  141\n",
      "reward :  -0.29465676819491793\n",
      "episode :  7\n",
      "current step :  142\n",
      "reward :  -0.353103343769875\n",
      "episode :  7\n",
      "current step :  143\n",
      "reward :  -0.3252075960267987\n",
      "episode :  7\n",
      "current step :  144\n",
      "reward :  -0.3382842048589813\n",
      "episode :  7\n",
      "current step :  145\n",
      "reward :  -0.2576708585302265\n",
      "episode :  7\n",
      "current step :  146\n",
      "reward :  -0.23842894052894378\n",
      "episode :  7\n",
      "current step :  147\n",
      "reward :  -0.2967736217319819\n",
      "episode :  7\n",
      "current step :  148\n",
      "reward :  -0.3252093861499145\n",
      "episode :  7\n",
      "current step :  149\n",
      "reward :  -0.3026187147813594\n",
      "episode :  7\n",
      "current step :  150\n",
      "reward :  -0.4086838063445362\n",
      "episode :  7\n",
      "current step :  151\n",
      "reward :  -0.4547040569563009\n",
      "episode :  7\n",
      "current step :  152\n",
      "reward :  -0.5111130108742167\n",
      "episode :  7\n",
      "current step :  153\n",
      "reward :  -0.4613734076155965\n",
      "episode :  7\n",
      "current step :  154\n",
      "reward :  -0.40851896460461873\n",
      "episode :  7\n",
      "current step :  155\n",
      "reward :  -0.3715324796750925\n",
      "episode :  7\n",
      "current step :  156\n",
      "reward :  -0.3494485066284281\n",
      "episode :  7\n",
      "current step :  157\n",
      "reward :  -0.3965588813745858\n",
      "episode :  7\n",
      "current step :  158\n",
      "reward :  -0.49675849025407204\n",
      "episode :  7\n",
      "current step :  159\n",
      "reward :  -0.5196371872909349\n",
      "episode :  7\n",
      "current step :  160\n",
      "reward :  -0.5751355544091185\n",
      "episode :  7\n",
      "current step :  161\n",
      "reward :  -0.5407413788978138\n",
      "episode :  7\n",
      "current step :  162\n",
      "reward :  -0.5123752013383776\n",
      "episode :  7\n",
      "current step :  163\n",
      "reward :  -0.5955003663547344\n",
      "episode :  7\n",
      "current step :  164\n",
      "reward :  -0.6594382943420555\n",
      "episode :  7\n",
      "current step :  165\n",
      "reward :  -0.7498397607236862\n",
      "episode :  7\n",
      "current step :  166\n",
      "reward :  -0.7139817775019193\n",
      "episode :  7\n",
      "current step :  167\n",
      "reward :  -0.6971349102971459\n",
      "episode :  7\n",
      "current step :  168\n",
      "reward :  -0.6734744468516645\n",
      "episode :  7\n",
      "current step :  169\n",
      "reward :  -0.5738081694900364\n",
      "episode :  7\n",
      "current step :  170\n",
      "reward :  -0.604573405712801\n",
      "episode :  7\n",
      "current step :  171\n",
      "reward :  -0.6423877939794411\n",
      "episode :  7\n",
      "current step :  172\n",
      "reward :  -0.6482339074550983\n",
      "episode :  7\n",
      "current step :  173\n",
      "reward :  -0.5858776455591541\n",
      "episode :  7\n",
      "current step :  174\n",
      "reward :  -0.5182906142112871\n",
      "episode :  7\n",
      "current step :  175\n",
      "reward :  -0.5902781336351749\n",
      "episode :  7\n",
      "current step :  176\n",
      "reward :  -0.5392415992322953\n",
      "episode :  7\n",
      "current step :  177\n",
      "reward :  -0.43888042358985263\n",
      "episode :  7\n",
      "current step :  178\n",
      "reward :  -0.513125466484884\n",
      "episode :  7\n",
      "current step :  179\n",
      "reward :  -0.39305499787678116\n",
      "episode :  7\n",
      "current step :  180\n",
      "reward :  -0.4058069204831788\n",
      "episode :  7\n",
      "current step :  181\n",
      "reward :  -0.42778471093242126\n",
      "episode :  7\n",
      "current step :  182\n",
      "reward :  -0.4421461787206539\n",
      "episode :  7\n",
      "current step :  183\n",
      "reward :  -0.5082010877325106\n",
      "episode :  7\n",
      "current step :  184\n",
      "reward :  -0.44423175445432095\n",
      "episode :  7\n",
      "current step :  185\n",
      "reward :  -0.408206884984268\n",
      "episode :  7\n",
      "current step :  186\n",
      "reward :  -0.42139289598221985\n",
      "episode :  7\n",
      "current step :  187\n",
      "reward :  -0.47063662568726067\n",
      "episode :  7\n",
      "current step :  188\n",
      "reward :  -0.465162899417774\n",
      "episode :  7\n",
      "current step :  189\n",
      "reward :  -0.439846244089148\n",
      "episode :  7\n",
      "current step :  190\n",
      "reward :  -0.5513150212506858\n",
      "episode :  7\n",
      "current step :  191\n",
      "reward :  -0.5116367713728542\n",
      "episode :  7\n",
      "current step :  192\n",
      "reward :  -0.5661894022188777\n",
      "episode :  7\n",
      "current step :  193\n",
      "reward :  -0.6323007123374497\n",
      "episode :  7\n",
      "current step :  194\n",
      "reward :  -0.6153266779744402\n",
      "episode :  7\n",
      "current step :  195\n",
      "reward :  -0.56829747207353\n",
      "episode :  7\n",
      "current step :  196\n",
      "reward :  -0.5631153678773164\n",
      "episode :  7\n",
      "current step :  197\n",
      "reward :  -0.5455150554582016\n",
      "episode :  7\n",
      "current step :  198\n",
      "reward :  -0.637815363424722\n",
      "episode :  7\n",
      "current step :  199\n",
      "reward :  -0.682944683254995\n",
      "episode :  7\n",
      "current step :  200\n",
      "reward :  -0.6851584844264419\n",
      "episode :  7\n",
      "current step :  201\n",
      "reward :  -0.6292909588157652\n",
      "episode :  7\n",
      "current step :  202\n",
      "reward :  -0.5326785587997346\n",
      "episode :  7\n",
      "current step :  203\n",
      "reward :  -0.5785734414893217\n",
      "episode :  7\n",
      "current step :  204\n",
      "reward :  -0.5365177085417318\n",
      "episode :  7\n",
      "current step :  205\n",
      "reward :  -0.5433663173885241\n",
      "episode :  7\n",
      "current step :  206\n",
      "reward :  -0.6313787007389261\n",
      "episode :  7\n",
      "current step :  207\n",
      "reward :  -0.5299297249204226\n",
      "episode :  7\n",
      "current step :  208\n",
      "reward :  -0.5334511922655196\n",
      "episode :  7\n",
      "current step :  209\n",
      "reward :  -0.6007243939402643\n",
      "episode :  7\n",
      "current step :  210\n",
      "reward :  -0.5754819974966848\n",
      "episode :  7\n",
      "current step :  211\n",
      "reward :  -0.6598478133904699\n",
      "episode :  7\n",
      "current step :  212\n",
      "reward :  -0.722006021023054\n",
      "episode :  7\n",
      "current step :  213\n",
      "reward :  -0.6374874196381206\n",
      "episode :  7\n",
      "current step :  214\n",
      "reward :  -0.5738947818263885\n",
      "episode :  7\n",
      "current step :  215\n",
      "reward :  -0.4619545107791971\n",
      "episode :  7\n",
      "current step :  216\n",
      "reward :  -0.4511774706087438\n",
      "episode :  7\n",
      "current step :  217\n",
      "reward :  -0.5485541490828483\n",
      "episode :  7\n",
      "current step :  218\n",
      "reward :  -0.531294927730954\n",
      "episode :  7\n",
      "current step :  219\n",
      "reward :  -0.5612694439737682\n",
      "episode :  7\n",
      "current step :  220\n",
      "reward :  -0.5726714364249906\n",
      "episode :  7\n",
      "current step :  221\n",
      "reward :  -0.5581346572800796\n",
      "episode :  7\n",
      "current step :  222\n",
      "reward :  -0.5820077827295664\n",
      "episode :  7\n",
      "current step :  223\n",
      "reward :  -0.5793833829838028\n",
      "episode :  7\n",
      "current step :  224\n",
      "reward :  -0.48202161155008455\n",
      "episode :  7\n",
      "current step :  225\n",
      "reward :  -0.49069050031347294\n",
      "episode :  7\n",
      "current step :  226\n",
      "reward :  -0.4935657699831096\n",
      "episode :  7\n",
      "current step :  227\n",
      "reward :  -0.5570354066295616\n",
      "episode :  7\n",
      "current step :  228\n",
      "reward :  -0.5241799255753481\n",
      "episode :  7\n",
      "current step :  229\n",
      "reward :  -0.4919723065451017\n",
      "episode :  7\n",
      "current step :  230\n",
      "reward :  -0.4872581773775947\n",
      "episode :  7\n",
      "current step :  231\n",
      "reward :  -0.5775907179503238\n",
      "episode :  7\n",
      "current step :  232\n",
      "reward :  -0.5913585284484387\n",
      "episode :  7\n",
      "current step :  233\n",
      "reward :  -0.5398603953333049\n",
      "episode :  7\n",
      "current step :  234\n",
      "reward :  -0.47826829224143685\n",
      "episode :  7\n",
      "current step :  235\n",
      "reward :  -0.5084086948602289\n",
      "episode :  7\n",
      "current step :  236\n",
      "reward :  -0.47226684103038824\n",
      "episode :  7\n",
      "current step :  237\n",
      "reward :  -0.4799883810041634\n",
      "episode :  7\n",
      "current step :  238\n",
      "reward :  -0.47575063611910057\n",
      "episode :  7\n",
      "current step :  239\n",
      "reward :  -0.5287157539280465\n",
      "episode :  7\n",
      "current step :  240\n",
      "reward :  -0.55518328576245\n",
      "episode :  7\n",
      "current step :  241\n",
      "reward :  -0.5567365511179204\n",
      "episode :  7\n",
      "current step :  242\n",
      "reward :  -0.49278033494484624\n",
      "episode :  7\n",
      "current step :  243\n",
      "reward :  -0.4358014793882415\n",
      "episode :  7\n",
      "current step :  244\n",
      "reward :  -0.41917775170355875\n",
      "episode :  7\n",
      "current step :  245\n",
      "reward :  -0.35008946849061734\n",
      "episode :  7\n",
      "current step :  246\n",
      "reward :  -0.37044742861197805\n",
      "episode :  7\n",
      "current step :  247\n",
      "reward :  -0.33502287190065083\n",
      "episode :  7\n",
      "current step :  248\n",
      "reward :  -0.28980756173552513\n",
      "episode :  7\n",
      "current step :  249\n",
      "reward :  -0.32144932308793817\n",
      "episode :  7\n",
      "current step :  250\n",
      "reward :  -0.3851213692508841\n",
      "episode :  7\n",
      "current step :  251\n",
      "reward :  -0.43817397659193913\n",
      "episode :  7\n",
      "current step :  252\n",
      "reward :  -0.5408827286093082\n",
      "episode :  7\n",
      "current step :  253\n",
      "reward :  -0.5378135403254625\n",
      "episode :  7\n",
      "current step :  254\n",
      "reward :  -0.47299443928767665\n",
      "episode :  7\n",
      "current step :  255\n",
      "reward :  -0.44887943220568427\n",
      "episode :  7\n",
      "current step :  256\n",
      "reward :  -0.3680660346352968\n",
      "episode :  7\n",
      "current step :  257\n",
      "reward :  -0.42925842565829014\n",
      "episode :  7\n",
      "current step :  258\n",
      "reward :  -0.49615301025859293\n",
      "episode :  7\n",
      "current step :  259\n",
      "reward :  -0.5248822914171283\n",
      "episode :  7\n",
      "current step :  260\n",
      "reward :  -0.5661644608427339\n",
      "episode :  7\n",
      "current step :  261\n",
      "reward :  -0.43713203741828893\n",
      "episode :  7\n",
      "current step :  262\n",
      "reward :  -0.3702924277643361\n",
      "episode :  7\n",
      "current step :  263\n",
      "reward :  -0.40269254773389573\n",
      "episode :  7\n",
      "current step :  264\n",
      "reward :  -0.4049967284955406\n",
      "episode :  7\n",
      "current step :  265\n",
      "reward :  -0.40108760074071514\n",
      "episode :  7\n",
      "current step :  266\n",
      "reward :  -0.38894454428604813\n",
      "episode :  7\n",
      "current step :  267\n",
      "reward :  -0.37830314479384486\n",
      "episode :  7\n",
      "current step :  268\n",
      "reward :  -0.3772797777845924\n",
      "episode :  7\n",
      "current step :  269\n",
      "reward :  -0.3209547653489333\n",
      "episode :  7\n",
      "current step :  270\n",
      "reward :  -0.3211881273370526\n",
      "episode :  7\n",
      "current step :  271\n",
      "reward :  -0.3981057013044502\n",
      "episode :  7\n",
      "current step :  272\n",
      "reward :  -0.4734923725774033\n",
      "episode :  7\n",
      "current step :  273\n",
      "reward :  -0.4177715367191175\n",
      "episode :  7\n",
      "current step :  274\n",
      "reward :  -0.4566627832924883\n",
      "episode :  7\n",
      "current step :  275\n",
      "reward :  -0.4738359430443329\n",
      "episode :  7\n",
      "current step :  276\n",
      "reward :  -0.34933030334823756\n",
      "episode :  7\n",
      "current step :  277\n",
      "reward :  -0.3586999104695578\n",
      "episode :  7\n",
      "current step :  278\n",
      "reward :  -0.38366985073562865\n",
      "episode :  7\n",
      "current step :  279\n",
      "reward :  -0.38714241583362485\n",
      "episode :  7\n",
      "current step :  280\n",
      "reward :  -0.3503085473272801\n",
      "episode :  7\n",
      "current step :  281\n",
      "reward :  -0.3331957186524206\n",
      "episode :  7\n",
      "current step :  282\n",
      "reward :  -0.24487072661196296\n",
      "episode :  7\n",
      "current step :  283\n",
      "reward :  -0.2771975979440085\n",
      "episode :  7\n",
      "current step :  284\n",
      "reward :  -0.45288939060332944\n",
      "episode :  7\n",
      "current step :  285\n",
      "reward :  -0.38210656026301093\n",
      "episode :  8\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 286      |\n",
      "|    ep_rew_mean     | -118     |\n",
      "| time/              |          |\n",
      "|    episodes        | 8        |\n",
      "|    fps             | 13       |\n",
      "|    time_elapsed    | 171      |\n",
      "|    total_timesteps | 2288     |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -60.9    |\n",
      "|    critic_loss     | 2.01     |\n",
      "|    ent_coef        | 0.519    |\n",
      "|    ent_coef_loss   | -15.2    |\n",
      "|    learning_rate   | 0.0003   |\n",
      "|    n_updates       | 2187     |\n",
      "---------------------------------\n",
      "current step :  0\n",
      "reward :  -0.37821445731912534\n",
      "episode :  8\n",
      "current step :  1\n",
      "reward :  -0.3586485741782377\n",
      "episode :  8\n",
      "current step :  2\n",
      "reward :  -0.38623976902567114\n",
      "episode :  8\n",
      "current step :  3\n",
      "reward :  -0.38191504257586256\n",
      "episode :  8\n",
      "current step :  4\n",
      "reward :  -0.374856600515241\n",
      "episode :  8\n",
      "current step :  5\n",
      "reward :  -0.42227387624321233\n",
      "episode :  8\n",
      "current step :  6\n",
      "reward :  -0.4384504937301291\n",
      "episode :  8\n",
      "current step :  7\n",
      "reward :  -0.48176092936702325\n",
      "episode :  8\n",
      "current step :  8\n",
      "reward :  -0.41312010953288775\n",
      "episode :  8\n",
      "current step :  9\n",
      "reward :  -0.2845962167233813\n",
      "episode :  8\n",
      "current step :  10\n",
      "reward :  -0.3348226091393368\n",
      "episode :  8\n",
      "current step :  11\n",
      "reward :  -0.3491955896435665\n",
      "episode :  8\n",
      "current step :  12\n",
      "reward :  -0.27572235562041597\n",
      "episode :  8\n",
      "current step :  13\n",
      "reward :  -0.1980248238483176\n",
      "episode :  8\n",
      "current step :  14\n",
      "reward :  -0.3161444278785641\n",
      "episode :  8\n",
      "current step :  15\n",
      "reward :  -0.27106228009342465\n",
      "episode :  8\n",
      "current step :  16\n",
      "reward :  -0.2617524366784071\n",
      "episode :  8\n",
      "current step :  17\n",
      "reward :  -0.31724548388653867\n",
      "episode :  8\n",
      "current step :  18\n",
      "reward :  -0.3460917974115512\n",
      "episode :  8\n",
      "current step :  19\n",
      "reward :  -0.3712871923664993\n",
      "episode :  8\n",
      "current step :  20\n",
      "reward :  -0.35323710304343703\n",
      "episode :  8\n",
      "current step :  21\n",
      "reward :  -0.37993194528458585\n",
      "episode :  8\n",
      "current step :  22\n",
      "reward :  -0.5137302605493215\n",
      "episode :  8\n",
      "current step :  23\n",
      "reward :  -0.5226534500022187\n",
      "episode :  8\n",
      "current step :  24\n",
      "reward :  -0.49753561437225136\n",
      "episode :  8\n",
      "current step :  25\n",
      "reward :  -0.4862853457292596\n",
      "episode :  8\n",
      "current step :  26\n",
      "reward :  -0.43935633186780454\n",
      "episode :  8\n",
      "current step :  27\n",
      "reward :  -0.4792309872887344\n",
      "episode :  8\n",
      "current step :  28\n",
      "reward :  -0.5756260430066394\n",
      "episode :  8\n",
      "current step :  29\n",
      "reward :  -0.5156954675564704\n",
      "episode :  8\n",
      "current step :  30\n",
      "reward :  -0.49790605240544034\n",
      "episode :  8\n",
      "current step :  31\n",
      "reward :  -0.5377455137813434\n",
      "episode :  8\n",
      "current step :  32\n",
      "reward :  -0.5001371445952776\n",
      "episode :  8\n",
      "current step :  33\n",
      "reward :  -0.48253950211855245\n",
      "episode :  8\n",
      "current step :  34\n",
      "reward :  -0.4487718277565219\n",
      "episode :  8\n",
      "current step :  35\n",
      "reward :  -0.6227230261500916\n",
      "episode :  8\n",
      "current step :  36\n",
      "reward :  -0.6028988083124707\n",
      "episode :  8\n",
      "current step :  37\n",
      "reward :  -0.5617511724257134\n",
      "episode :  8\n",
      "current step :  38\n",
      "reward :  -0.6496184686262465\n",
      "episode :  8\n",
      "current step :  39\n",
      "reward :  -0.5372771289939555\n",
      "episode :  8\n",
      "current step :  40\n",
      "reward :  -0.5955770195590022\n",
      "episode :  8\n",
      "current step :  41\n",
      "reward :  -0.573053368892815\n",
      "episode :  8\n",
      "current step :  42\n",
      "reward :  -0.5064445720153341\n",
      "episode :  8\n",
      "current step :  43\n",
      "reward :  -0.45614934175202543\n",
      "episode :  8\n",
      "current step :  44\n",
      "reward :  -0.4266476823462152\n",
      "episode :  8\n",
      "current step :  45\n",
      "reward :  -0.31814532906751375\n",
      "episode :  8\n",
      "current step :  46\n",
      "reward :  -0.4717058239643227\n",
      "episode :  8\n",
      "current step :  47\n",
      "reward :  -0.4915725792187321\n",
      "episode :  8\n",
      "current step :  48\n",
      "reward :  -0.34477390767371613\n",
      "episode :  8\n",
      "current step :  49\n",
      "reward :  -0.40901806064348617\n",
      "episode :  8\n",
      "current step :  50\n",
      "reward :  -0.6937304592628883\n",
      "episode :  8\n",
      "current step :  51\n",
      "reward :  -0.674718033892698\n",
      "episode :  8\n",
      "current step :  52\n",
      "reward :  -0.6316285897103034\n",
      "episode :  8\n",
      "current step :  53\n",
      "reward :  -0.6466365220867609\n",
      "episode :  8\n",
      "current step :  54\n",
      "reward :  -0.5103525234791627\n",
      "episode :  8\n",
      "current step :  55\n",
      "reward :  -0.44791551218446196\n",
      "episode :  8\n",
      "current step :  56\n",
      "reward :  -0.44166637357822885\n",
      "episode :  8\n",
      "current step :  57\n",
      "reward :  -0.37602061182976126\n",
      "episode :  8\n",
      "current step :  58\n",
      "reward :  -0.32949843378255383\n",
      "episode :  8\n",
      "current step :  59\n",
      "reward :  -0.3709243643341122\n",
      "episode :  8\n",
      "current step :  60\n",
      "reward :  -0.44757027512670666\n",
      "episode :  8\n",
      "current step :  61\n",
      "reward :  -0.4031714510551167\n",
      "episode :  8\n",
      "current step :  62\n",
      "reward :  -0.4713330548464241\n",
      "episode :  8\n",
      "current step :  63\n",
      "reward :  -0.4395323460357878\n",
      "episode :  8\n",
      "current step :  64\n",
      "reward :  -0.35352447445734864\n",
      "episode :  8\n",
      "current step :  65\n",
      "reward :  -0.42644214078585924\n",
      "episode :  8\n",
      "current step :  66\n",
      "reward :  -0.4581722295570231\n",
      "episode :  8\n",
      "current step :  67\n",
      "reward :  -0.3987500003279748\n",
      "episode :  8\n",
      "current step :  68\n",
      "reward :  -0.2714248374320654\n",
      "episode :  8\n",
      "current step :  69\n",
      "reward :  -0.2343526401290105\n",
      "episode :  8\n",
      "current step :  70\n",
      "reward :  -0.39497464106862534\n",
      "episode :  8\n",
      "current step :  71\n",
      "reward :  -0.3693711430741992\n",
      "episode :  8\n",
      "current step :  72\n",
      "reward :  -0.5351635103676977\n",
      "episode :  8\n",
      "current step :  73\n",
      "reward :  -0.6262348515799832\n",
      "episode :  8\n",
      "current step :  74\n",
      "reward :  -0.5632958311630546\n",
      "episode :  8\n",
      "current step :  75\n",
      "reward :  -0.5555358819285368\n",
      "episode :  8\n",
      "current step :  76\n",
      "reward :  -0.6198871816259466\n",
      "episode :  8\n",
      "current step :  77\n",
      "reward :  -0.6476400582155482\n",
      "episode :  8\n",
      "current step :  78\n",
      "reward :  -0.7110282695451966\n",
      "episode :  8\n",
      "current step :  79\n",
      "reward :  -0.6840216427360555\n",
      "episode :  8\n",
      "current step :  80\n",
      "reward :  -0.5916899803722303\n",
      "episode :  8\n",
      "current step :  81\n",
      "reward :  -0.48482188002387594\n",
      "episode :  8\n",
      "current step :  82\n",
      "reward :  -0.5461020037592453\n",
      "episode :  8\n",
      "current step :  83\n",
      "reward :  -0.4207769415531447\n",
      "episode :  8\n",
      "current step :  84\n",
      "reward :  -0.34745386159435176\n",
      "episode :  8\n",
      "current step :  85\n",
      "reward :  -0.33503258227802973\n",
      "episode :  8\n",
      "current step :  86\n",
      "reward :  -0.45628508056603\n",
      "episode :  8\n",
      "current step :  87\n",
      "reward :  -0.5863748673847883\n",
      "episode :  8\n",
      "current step :  88\n",
      "reward :  -0.6305227948776373\n",
      "episode :  8\n",
      "current step :  89\n",
      "reward :  -0.6554631654518853\n",
      "episode :  8\n",
      "current step :  90\n",
      "reward :  -0.5794586546554163\n",
      "episode :  8\n",
      "current step :  91\n",
      "reward :  -0.5074643641002654\n",
      "episode :  8\n",
      "current step :  92\n",
      "reward :  -0.4167302525693671\n",
      "episode :  8\n",
      "current step :  93\n",
      "reward :  -0.3841788937020381\n",
      "episode :  8\n",
      "current step :  94\n",
      "reward :  -0.3212298018507799\n",
      "episode :  8\n",
      "current step :  95\n",
      "reward :  -0.35957284440686954\n",
      "episode :  8\n",
      "current step :  96\n",
      "reward :  -0.3533743107749145\n",
      "episode :  8\n",
      "current step :  97\n",
      "reward :  -0.33238649567254275\n",
      "episode :  8\n",
      "current step :  98\n",
      "reward :  -0.25824734950292705\n",
      "episode :  8\n",
      "current step :  99\n",
      "reward :  -0.2231498881494924\n",
      "episode :  8\n",
      "current step :  100\n",
      "reward :  -0.24892883448717823\n",
      "episode :  8\n",
      "current step :  101\n",
      "reward :  -0.27411766028955376\n",
      "episode :  8\n",
      "current step :  102\n",
      "reward :  -0.3321350127507049\n",
      "episode :  8\n",
      "current step :  103\n",
      "reward :  -0.26394392973673353\n",
      "episode :  8\n",
      "current step :  104\n",
      "reward :  -0.21982626922142967\n",
      "episode :  8\n",
      "current step :  105\n",
      "reward :  -0.15925630700031151\n",
      "episode :  8\n",
      "current step :  106\n",
      "reward :  -0.20497223526122033\n",
      "episode :  8\n",
      "current step :  107\n",
      "reward :  -0.32449609803497337\n",
      "episode :  8\n",
      "current step :  108\n",
      "reward :  -0.27084460100468316\n",
      "episode :  8\n",
      "current step :  109\n",
      "reward :  -0.18914336462341336\n",
      "episode :  8\n",
      "current step :  110\n",
      "reward :  -0.23120002263745795\n",
      "episode :  8\n",
      "current step :  111\n",
      "reward :  -0.09300668222522888\n",
      "episode :  8\n",
      "current step :  112\n",
      "reward :  -0.33408172047420603\n",
      "episode :  8\n",
      "current step :  113\n",
      "reward :  -0.26600378873387165\n",
      "episode :  8\n",
      "current step :  114\n",
      "reward :  -0.33692070713272254\n",
      "episode :  8\n",
      "current step :  115\n",
      "reward :  -0.33704669794151704\n",
      "episode :  8\n",
      "current step :  116\n",
      "reward :  -0.23312854081874554\n",
      "episode :  8\n",
      "current step :  117\n",
      "reward :  -0.2577375168295479\n",
      "episode :  8\n",
      "current step :  118\n",
      "reward :  -0.3012217028129281\n",
      "episode :  8\n",
      "current step :  119\n",
      "reward :  -0.23703813178560193\n",
      "episode :  8\n",
      "current step :  120\n",
      "reward :  -0.2619074522147179\n",
      "episode :  8\n",
      "current step :  121\n",
      "reward :  -0.3016018491693661\n",
      "episode :  8\n",
      "current step :  122\n",
      "reward :  -0.3149736068366828\n",
      "episode :  8\n",
      "current step :  123\n",
      "reward :  -0.24608141540884576\n",
      "episode :  8\n",
      "current step :  124\n",
      "reward :  -0.32707132651838045\n",
      "episode :  8\n",
      "current step :  125\n",
      "reward :  -0.214033612355093\n",
      "episode :  8\n",
      "current step :  126\n",
      "reward :  -0.2834357196682823\n",
      "episode :  8\n",
      "current step :  127\n",
      "reward :  -0.29457933660175284\n",
      "episode :  8\n",
      "current step :  128\n",
      "reward :  -0.31603801949440513\n",
      "episode :  8\n",
      "current step :  129\n",
      "reward :  -0.2419175894266715\n",
      "episode :  8\n",
      "current step :  130\n",
      "reward :  -0.2550905202545327\n",
      "episode :  8\n",
      "current step :  131\n",
      "reward :  -0.3147174374375656\n",
      "episode :  8\n",
      "current step :  132\n",
      "reward :  -0.32538839120605234\n",
      "episode :  8\n",
      "current step :  133\n",
      "reward :  -0.4009777191079681\n",
      "episode :  8\n",
      "current step :  134\n",
      "reward :  -0.42871080775278414\n",
      "episode :  8\n",
      "current step :  135\n",
      "reward :  -0.4082229991478633\n",
      "episode :  8\n",
      "current step :  136\n",
      "reward :  -0.32879732453432814\n",
      "episode :  8\n",
      "current step :  137\n",
      "reward :  -0.4399094719998944\n",
      "episode :  8\n",
      "current step :  138\n",
      "reward :  -0.40245973171939714\n",
      "episode :  8\n",
      "current step :  139\n",
      "reward :  -0.37156915255276646\n",
      "episode :  8\n",
      "current step :  140\n",
      "reward :  -0.25450267887105193\n",
      "episode :  8\n",
      "current step :  141\n",
      "reward :  -0.331571644603111\n",
      "episode :  8\n",
      "current step :  142\n",
      "reward :  -0.4505118807560386\n",
      "episode :  8\n",
      "current step :  143\n",
      "reward :  -0.42999228571968384\n",
      "episode :  8\n",
      "current step :  144\n",
      "reward :  -0.4260654267057761\n",
      "episode :  8\n",
      "current step :  145\n",
      "reward :  -0.45341516424712347\n",
      "episode :  8\n",
      "current step :  146\n",
      "reward :  -0.38180011653862195\n",
      "episode :  8\n",
      "current step :  147\n",
      "reward :  -0.40872301173001685\n",
      "episode :  8\n",
      "current step :  148\n",
      "reward :  -0.4011011611213098\n",
      "episode :  8\n",
      "current step :  149\n",
      "reward :  -0.4898146341059378\n",
      "episode :  8\n",
      "current step :  150\n",
      "reward :  -0.5289685821168122\n",
      "episode :  8\n",
      "current step :  151\n",
      "reward :  -0.4994581870440645\n",
      "episode :  8\n",
      "current step :  152\n",
      "reward :  -0.5524530463687813\n",
      "episode :  8\n",
      "current step :  153\n",
      "reward :  -0.5807533668872993\n",
      "episode :  8\n",
      "current step :  154\n",
      "reward :  -0.6615951819343514\n",
      "episode :  8\n",
      "current step :  155\n",
      "reward :  -0.6513576473868721\n",
      "episode :  8\n",
      "current step :  156\n",
      "reward :  -0.6300650424585544\n",
      "episode :  8\n",
      "current step :  157\n",
      "reward :  -0.6205295815799151\n",
      "episode :  8\n",
      "current step :  158\n",
      "reward :  -0.6115159497856952\n",
      "episode :  8\n",
      "current step :  159\n",
      "reward :  -0.6429188223389221\n",
      "episode :  8\n",
      "current step :  160\n",
      "reward :  -0.6240357113638072\n",
      "episode :  8\n",
      "current step :  161\n",
      "reward :  -0.6707272935055162\n",
      "episode :  8\n",
      "current step :  162\n",
      "reward :  -0.7159940255152449\n",
      "episode :  8\n",
      "current step :  163\n",
      "reward :  -0.7125602913470482\n",
      "episode :  8\n",
      "current step :  164\n",
      "reward :  -0.6146682592369286\n",
      "episode :  8\n",
      "current step :  165\n",
      "reward :  -0.5407640381423939\n",
      "episode :  8\n",
      "current step :  166\n",
      "reward :  -0.5095966006196959\n",
      "episode :  8\n",
      "current step :  167\n",
      "reward :  -0.509926723702682\n",
      "episode :  8\n",
      "current step :  168\n",
      "reward :  -0.4840890350955018\n",
      "episode :  8\n",
      "current step :  169\n",
      "reward :  -0.4655863130659481\n",
      "episode :  8\n",
      "current step :  170\n",
      "reward :  -0.419881895157872\n",
      "episode :  8\n",
      "current step :  171\n",
      "reward :  -0.4338976036455277\n",
      "episode :  8\n",
      "current step :  172\n",
      "reward :  -0.47930793104569425\n",
      "episode :  8\n",
      "current step :  173\n",
      "reward :  -0.3721732243990545\n",
      "episode :  8\n",
      "current step :  174\n",
      "reward :  -0.4583841918792821\n",
      "episode :  8\n",
      "current step :  175\n",
      "reward :  -0.44658554505551884\n",
      "episode :  8\n",
      "current step :  176\n",
      "reward :  -0.5701532682322034\n",
      "episode :  8\n",
      "current step :  177\n",
      "reward :  -0.5022526230630164\n",
      "episode :  8\n",
      "current step :  178\n",
      "reward :  -0.46654150093242497\n",
      "episode :  8\n",
      "current step :  179\n",
      "reward :  -0.37504517015501254\n",
      "episode :  8\n",
      "current step :  180\n",
      "reward :  -0.3825849077408052\n",
      "episode :  8\n",
      "current step :  181\n",
      "reward :  -0.4725508986964798\n",
      "episode :  8\n",
      "current step :  182\n",
      "reward :  -0.425137295639213\n",
      "episode :  8\n",
      "current step :  183\n",
      "reward :  -0.37488436260380265\n",
      "episode :  8\n",
      "current step :  184\n",
      "reward :  -0.41902054244210285\n",
      "episode :  8\n",
      "current step :  185\n",
      "reward :  -0.3845225711251625\n",
      "episode :  8\n",
      "current step :  186\n",
      "reward :  -0.3332724605390458\n",
      "episode :  8\n",
      "current step :  187\n",
      "reward :  -0.40545127897128563\n",
      "episode :  8\n",
      "current step :  188\n",
      "reward :  -0.4470434282080551\n",
      "episode :  8\n",
      "current step :  189\n",
      "reward :  -0.5451337114920178\n",
      "episode :  8\n",
      "current step :  190\n",
      "reward :  -0.31403882876559885\n",
      "episode :  8\n",
      "current step :  191\n",
      "reward :  -0.33050890101324126\n",
      "episode :  8\n",
      "current step :  192\n",
      "reward :  -0.3529688764233716\n",
      "episode :  8\n",
      "current step :  193\n",
      "reward :  -0.4092396874919721\n",
      "episode :  8\n",
      "current step :  194\n",
      "reward :  -0.44266113331212814\n",
      "episode :  8\n",
      "current step :  195\n",
      "reward :  -0.4368314535798867\n",
      "episode :  8\n",
      "current step :  196\n",
      "reward :  -0.2858236582797803\n",
      "episode :  8\n",
      "current step :  197\n",
      "reward :  -0.34942300169157614\n",
      "episode :  8\n",
      "current step :  198\n",
      "reward :  -0.5897178224152853\n",
      "episode :  8\n",
      "current step :  199\n",
      "reward :  -0.6666946949965357\n",
      "episode :  8\n",
      "current step :  200\n",
      "reward :  -0.4808947981997568\n",
      "episode :  8\n",
      "current step :  201\n",
      "reward :  -0.5396828440973102\n",
      "episode :  8\n",
      "current step :  202\n",
      "reward :  -0.5583856212672705\n",
      "episode :  8\n",
      "current step :  203\n",
      "reward :  -0.5425190521015313\n",
      "episode :  8\n",
      "current step :  204\n",
      "reward :  -0.43941452820207966\n",
      "episode :  8\n",
      "current step :  205\n",
      "reward :  -0.3917762840276684\n",
      "episode :  8\n",
      "current step :  206\n",
      "reward :  -0.3163473187115095\n",
      "episode :  8\n",
      "current step :  207\n",
      "reward :  -0.2561219732122874\n",
      "episode :  8\n",
      "current step :  208\n",
      "reward :  -0.29033962153754067\n",
      "episode :  8\n",
      "current step :  209\n",
      "reward :  -0.3881400456433606\n",
      "episode :  8\n",
      "current step :  210\n",
      "reward :  -0.4131874147182047\n",
      "episode :  8\n",
      "current step :  211\n",
      "reward :  -0.4274898050245914\n",
      "episode :  8\n",
      "current step :  212\n",
      "reward :  -0.465589006129732\n",
      "episode :  8\n",
      "current step :  213\n",
      "reward :  -0.5499117240729932\n",
      "episode :  8\n",
      "current step :  214\n",
      "reward :  -0.5872830104810641\n",
      "episode :  8\n",
      "current step :  215\n",
      "reward :  -0.5073772899032397\n",
      "episode :  8\n",
      "current step :  216\n",
      "reward :  -0.5915623193441478\n",
      "episode :  8\n",
      "current step :  217\n",
      "reward :  -0.46072739462516055\n",
      "episode :  8\n",
      "current step :  218\n",
      "reward :  -0.44519753889920166\n",
      "episode :  8\n",
      "current step :  219\n",
      "reward :  -0.4125344952825073\n",
      "episode :  8\n",
      "current step :  220\n",
      "reward :  -0.359424927182456\n",
      "episode :  8\n",
      "current step :  221\n",
      "reward :  -0.3484852991464113\n",
      "episode :  8\n",
      "current step :  222\n",
      "reward :  -0.47631444937786066\n",
      "episode :  8\n",
      "current step :  223\n",
      "reward :  -0.3853968949021684\n",
      "episode :  8\n",
      "current step :  224\n",
      "reward :  -0.381097191055286\n",
      "episode :  8\n",
      "current step :  225\n",
      "reward :  -0.41486208848203104\n",
      "episode :  8\n",
      "current step :  226\n",
      "reward :  -0.4077573267839075\n",
      "episode :  8\n",
      "current step :  227\n",
      "reward :  -0.4037015799233122\n",
      "episode :  8\n",
      "current step :  228\n",
      "reward :  -0.4009094432061012\n",
      "episode :  8\n",
      "current step :  229\n",
      "reward :  -0.47201279910962773\n",
      "episode :  8\n",
      "current step :  230\n",
      "reward :  -0.5237405695530754\n",
      "episode :  8\n",
      "current step :  231\n",
      "reward :  -0.6115530579828478\n",
      "episode :  8\n",
      "current step :  232\n",
      "reward :  -0.5676592878692441\n",
      "episode :  8\n",
      "current step :  233\n",
      "reward :  -0.49972227007343145\n",
      "episode :  8\n",
      "current step :  234\n",
      "reward :  -0.550371832154024\n",
      "episode :  8\n",
      "current step :  235\n",
      "reward :  -0.4748893054887253\n",
      "episode :  8\n",
      "current step :  236\n",
      "reward :  -0.4234821170379382\n",
      "episode :  8\n",
      "current step :  237\n",
      "reward :  -0.42326228892630774\n",
      "episode :  8\n",
      "current step :  238\n",
      "reward :  -0.4101942142988414\n",
      "episode :  8\n",
      "current step :  239\n",
      "reward :  -0.421795516125532\n",
      "episode :  8\n",
      "current step :  240\n",
      "reward :  -0.4386456486194754\n",
      "episode :  8\n",
      "current step :  241\n",
      "reward :  -0.3476199268796234\n",
      "episode :  8\n",
      "current step :  242\n",
      "reward :  -0.39457919006401015\n",
      "episode :  8\n",
      "current step :  243\n",
      "reward :  -0.4655135316419233\n",
      "episode :  8\n",
      "current step :  244\n",
      "reward :  -0.3961025115208459\n",
      "episode :  8\n",
      "current step :  245\n",
      "reward :  -0.3588464528294648\n",
      "episode :  8\n",
      "current step :  246\n",
      "reward :  -0.3548510057605048\n",
      "episode :  8\n",
      "current step :  247\n",
      "reward :  -0.2568355305317423\n",
      "episode :  8\n",
      "current step :  248\n",
      "reward :  -0.2729427124871158\n",
      "episode :  8\n",
      "current step :  249\n",
      "reward :  -0.34410884272020736\n",
      "episode :  8\n",
      "current step :  250\n",
      "reward :  -0.26778347085063287\n",
      "episode :  8\n",
      "current step :  251\n",
      "reward :  -0.2686896223668556\n",
      "episode :  8\n",
      "current step :  252\n",
      "reward :  -0.3778554879831246\n",
      "episode :  8\n",
      "current step :  253\n",
      "reward :  -0.3721940633380062\n",
      "episode :  8\n",
      "current step :  254\n",
      "reward :  -0.36742409556876804\n",
      "episode :  8\n",
      "current step :  255\n",
      "reward :  -0.3898506722324876\n",
      "episode :  8\n",
      "current step :  256\n",
      "reward :  -0.4192635292429542\n",
      "episode :  8\n",
      "current step :  257\n",
      "reward :  -0.4098042795802176\n",
      "episode :  8\n",
      "current step :  258\n",
      "reward :  -0.4223121134531501\n",
      "episode :  8\n",
      "current step :  259\n",
      "reward :  -0.4457149346520285\n",
      "episode :  8\n",
      "current step :  260\n",
      "reward :  -0.43344574985413553\n",
      "episode :  8\n",
      "current step :  261\n",
      "reward :  -0.4489236772648532\n",
      "episode :  8\n",
      "current step :  262\n",
      "reward :  -0.48778105854696496\n",
      "episode :  8\n",
      "current step :  263\n",
      "reward :  -0.5314993962554088\n",
      "episode :  8\n",
      "current step :  264\n",
      "reward :  -0.5709179415851147\n",
      "episode :  8\n",
      "current step :  265\n",
      "reward :  -0.5448732003411824\n",
      "episode :  8\n",
      "current step :  266\n",
      "reward :  -0.3964798289572233\n",
      "episode :  8\n",
      "current step :  267\n",
      "reward :  -0.26056832889253045\n",
      "episode :  8\n",
      "current step :  268\n",
      "reward :  -0.2523083388305369\n",
      "episode :  8\n",
      "current step :  269\n",
      "reward :  -0.1307638768190412\n",
      "episode :  8\n",
      "current step :  270\n",
      "reward :  -0.2905974716722114\n",
      "episode :  8\n",
      "current step :  271\n",
      "reward :  -0.30456076006744826\n",
      "episode :  8\n",
      "current step :  272\n",
      "reward :  -0.3569634553168882\n",
      "episode :  8\n",
      "current step :  273\n",
      "reward :  -0.3718642642503745\n",
      "episode :  8\n",
      "current step :  274\n",
      "reward :  -0.33314171086566136\n",
      "episode :  8\n",
      "current step :  275\n",
      "reward :  -0.38585527720773694\n",
      "episode :  8\n",
      "current step :  276\n",
      "reward :  -0.4420356959528702\n",
      "episode :  8\n",
      "current step :  277\n",
      "reward :  -0.5143672869848597\n",
      "episode :  8\n",
      "current step :  278\n",
      "reward :  -0.4548031759115168\n",
      "episode :  8\n",
      "current step :  279\n",
      "reward :  -0.39831088079488775\n",
      "episode :  8\n",
      "current step :  280\n",
      "reward :  -0.36562734273288167\n",
      "episode :  8\n",
      "current step :  281\n",
      "reward :  -0.31053871615194806\n",
      "episode :  8\n",
      "current step :  282\n",
      "reward :  -0.32938821011753683\n",
      "episode :  8\n",
      "current step :  283\n",
      "reward :  -0.36614320298843\n",
      "episode :  8\n",
      "current step :  284\n",
      "reward :  -0.30306606604444136\n",
      "episode :  8\n",
      "current step :  285\n",
      "reward :  -0.17780140605948327\n",
      "episode :  9\n",
      "current step :  0\n",
      "reward :  -0.19588521562882422\n",
      "episode :  9\n",
      "current step :  1\n",
      "reward :  -0.17648282860529385\n",
      "episode :  9\n",
      "current step :  2\n",
      "reward :  -0.253055470879205\n",
      "episode :  9\n",
      "current step :  3\n",
      "reward :  -0.30615619568188696\n",
      "episode :  9\n",
      "current step :  4\n",
      "reward :  -0.26610278844205615\n",
      "episode :  9\n",
      "current step :  5\n",
      "reward :  -0.329965098301215\n",
      "episode :  9\n",
      "current step :  6\n",
      "reward :  -0.3314318665192116\n",
      "episode :  9\n",
      "current step :  7\n",
      "reward :  -0.4000219295861811\n",
      "episode :  9\n",
      "current step :  8\n",
      "reward :  -0.4617987375289324\n",
      "episode :  9\n",
      "current step :  9\n",
      "reward :  -0.33119415537713315\n",
      "episode :  9\n",
      "current step :  10\n",
      "reward :  -0.2446400386643527\n",
      "episode :  9\n",
      "current step :  11\n",
      "reward :  -0.31880152715968374\n",
      "episode :  9\n",
      "current step :  12\n",
      "reward :  -0.3501467903558124\n",
      "episode :  9\n",
      "current step :  13\n",
      "reward :  -0.32004352025073923\n",
      "episode :  9\n",
      "current step :  14\n",
      "reward :  -0.34495611797140957\n",
      "episode :  9\n",
      "current step :  15\n",
      "reward :  -0.4457265405850841\n",
      "episode :  9\n",
      "current step :  16\n",
      "reward :  -0.37685139836233117\n",
      "episode :  9\n",
      "current step :  17\n",
      "reward :  -0.4280307333692748\n",
      "episode :  9\n",
      "current step :  18\n",
      "reward :  -0.4584267190809853\n",
      "episode :  9\n",
      "current step :  19\n",
      "reward :  -0.4981141227717555\n",
      "episode :  9\n",
      "current step :  20\n",
      "reward :  -0.4508145565902056\n",
      "episode :  9\n",
      "current step :  21\n",
      "reward :  -0.38359591741866816\n",
      "episode :  9\n",
      "current step :  22\n",
      "reward :  -0.34939932669806445\n",
      "episode :  9\n",
      "current step :  23\n",
      "reward :  -0.34684116860432734\n",
      "episode :  9\n",
      "current step :  24\n",
      "reward :  -0.3974674516645471\n",
      "episode :  9\n",
      "current step :  25\n",
      "reward :  -0.55142177739395\n",
      "episode :  9\n",
      "current step :  26\n",
      "reward :  -0.5352278415776237\n",
      "episode :  9\n",
      "current step :  27\n",
      "reward :  -0.52611222790207\n",
      "episode :  9\n",
      "current step :  28\n",
      "reward :  -0.31430827721101234\n",
      "episode :  9\n",
      "current step :  29\n",
      "reward :  -0.334322718597679\n",
      "episode :  9\n",
      "current step :  30\n",
      "reward :  -0.37104336176765557\n",
      "episode :  9\n",
      "current step :  31\n",
      "reward :  -0.4788882142529716\n",
      "episode :  9\n",
      "current step :  32\n",
      "reward :  -0.4704953642451375\n",
      "episode :  9\n",
      "current step :  33\n",
      "reward :  -0.534546770043911\n",
      "episode :  9\n",
      "current step :  34\n",
      "reward :  -0.5369992777663799\n",
      "episode :  9\n",
      "current step :  35\n",
      "reward :  -0.5244212061510647\n",
      "episode :  9\n",
      "current step :  36\n",
      "reward :  -0.4899273417471172\n",
      "episode :  9\n",
      "current step :  37\n",
      "reward :  -0.5774511829197749\n",
      "episode :  9\n",
      "current step :  38\n",
      "reward :  -0.6057372300363703\n",
      "episode :  9\n",
      "current step :  39\n",
      "reward :  -0.6003415160740181\n",
      "episode :  9\n",
      "current step :  40\n",
      "reward :  -0.6257507411742533\n",
      "episode :  9\n",
      "current step :  41\n",
      "reward :  -0.648855044568315\n",
      "episode :  9\n",
      "current step :  42\n",
      "reward :  -0.6021821253358466\n",
      "episode :  9\n",
      "current step :  43\n",
      "reward :  -0.5470491831709728\n",
      "episode :  9\n",
      "current step :  44\n",
      "reward :  -0.5033103189360559\n",
      "episode :  9\n",
      "current step :  45\n",
      "reward :  -0.40226374315859775\n",
      "episode :  9\n",
      "current step :  46\n",
      "reward :  -0.4630517822541949\n",
      "episode :  9\n",
      "current step :  47\n",
      "reward :  -0.5243442534599526\n",
      "episode :  9\n",
      "current step :  48\n",
      "reward :  -0.44848242401591987\n",
      "episode :  9\n",
      "current step :  49\n",
      "reward :  -0.502479706614596\n",
      "episode :  9\n",
      "current step :  50\n",
      "reward :  -0.496642562141934\n",
      "episode :  9\n",
      "current step :  51\n",
      "reward :  -0.4705050165082686\n",
      "episode :  9\n",
      "current step :  52\n",
      "reward :  -0.44125072501082546\n",
      "episode :  9\n",
      "current step :  53\n",
      "reward :  -0.4462352594586119\n",
      "episode :  9\n",
      "current step :  54\n",
      "reward :  -0.5328051082850007\n",
      "episode :  9\n",
      "current step :  55\n",
      "reward :  -0.46811157634133355\n",
      "episode :  9\n",
      "current step :  56\n",
      "reward :  -0.45364929850078883\n",
      "episode :  9\n",
      "current step :  57\n",
      "reward :  -0.4630264387296678\n",
      "episode :  9\n",
      "current step :  58\n",
      "reward :  -0.4589027872583049\n",
      "episode :  9\n",
      "current step :  59\n",
      "reward :  -0.5462206129241812\n",
      "episode :  9\n",
      "current step :  60\n",
      "reward :  -0.5691157446843262\n",
      "episode :  9\n",
      "current step :  61\n",
      "reward :  -0.3913153736789738\n",
      "episode :  9\n",
      "current step :  62\n",
      "reward :  -0.3412338701870436\n",
      "episode :  9\n",
      "current step :  63\n",
      "reward :  -0.31783501074645354\n",
      "episode :  9\n",
      "current step :  64\n",
      "reward :  -0.4215398709261153\n",
      "episode :  9\n",
      "current step :  65\n",
      "reward :  -0.463495836955566\n",
      "episode :  9\n",
      "current step :  66\n",
      "reward :  -0.4055632093208328\n",
      "episode :  9\n",
      "current step :  67\n",
      "reward :  -0.5387893305706373\n",
      "episode :  9\n",
      "current step :  68\n",
      "reward :  -0.6063505803766587\n",
      "episode :  9\n",
      "current step :  69\n",
      "reward :  -0.5369320252596352\n",
      "episode :  9\n",
      "current step :  70\n",
      "reward :  -0.6541172600053801\n",
      "episode :  9\n",
      "current step :  71\n",
      "reward :  -0.6561095593968509\n",
      "episode :  9\n",
      "current step :  72\n",
      "reward :  -0.64501162441003\n",
      "episode :  9\n",
      "current step :  73\n",
      "reward :  -0.6174822420395879\n",
      "episode :  9\n",
      "current step :  74\n",
      "reward :  -0.49323937171349785\n",
      "episode :  9\n",
      "current step :  75\n",
      "reward :  -0.44696151221103314\n",
      "episode :  9\n",
      "current step :  76\n",
      "reward :  -0.4366734066321747\n",
      "episode :  9\n",
      "current step :  77\n",
      "reward :  -0.418759785691174\n",
      "episode :  9\n",
      "current step :  78\n",
      "reward :  -0.4018166137113646\n",
      "episode :  9\n",
      "current step :  79\n",
      "reward :  -0.43405442793677285\n",
      "episode :  9\n",
      "current step :  80\n",
      "reward :  -0.35084259379324595\n",
      "episode :  9\n",
      "current step :  81\n",
      "reward :  -0.3674782853121695\n",
      "episode :  9\n",
      "current step :  82\n",
      "reward :  -0.3788611880781907\n",
      "episode :  9\n",
      "current step :  83\n",
      "reward :  -0.2943489553669224\n",
      "episode :  9\n",
      "current step :  84\n",
      "reward :  -0.350217875448591\n",
      "episode :  9\n",
      "current step :  85\n",
      "reward :  -0.4088274562917338\n",
      "episode :  9\n",
      "current step :  86\n",
      "reward :  -0.29404523395953686\n",
      "episode :  9\n",
      "current step :  87\n",
      "reward :  -0.36522831921306853\n",
      "episode :  9\n",
      "current step :  88\n",
      "reward :  -0.383768966763947\n",
      "episode :  9\n",
      "current step :  89\n",
      "reward :  -0.36358781582770106\n",
      "episode :  9\n",
      "current step :  90\n",
      "reward :  -0.40352391775762736\n",
      "episode :  9\n",
      "current step :  91\n",
      "reward :  -0.5690781117080747\n",
      "episode :  9\n",
      "current step :  92\n",
      "reward :  -0.49203468754046764\n",
      "episode :  9\n",
      "current step :  93\n",
      "reward :  -0.46177611375078975\n",
      "episode :  9\n",
      "current step :  94\n",
      "reward :  -0.32190389911779\n",
      "episode :  9\n",
      "current step :  95\n",
      "reward :  -0.3917359594590155\n",
      "episode :  9\n",
      "current step :  96\n",
      "reward :  -0.4578740468709638\n",
      "episode :  9\n",
      "current step :  97\n",
      "reward :  -0.4533855443796965\n",
      "episode :  9\n",
      "current step :  98\n",
      "reward :  -0.28776835923366406\n",
      "episode :  9\n",
      "current step :  99\n",
      "reward :  -0.2708642550790154\n",
      "episode :  9\n",
      "current step :  100\n",
      "reward :  -0.3177841080390774\n",
      "episode :  9\n",
      "current step :  101\n",
      "reward :  -0.3223313327862669\n",
      "episode :  9\n",
      "current step :  102\n",
      "reward :  -0.30015958604625814\n",
      "episode :  9\n",
      "current step :  103\n",
      "reward :  -0.14982136733572313\n",
      "episode :  9\n",
      "current step :  104\n",
      "reward :  -0.3600156768678401\n",
      "episode :  9\n",
      "current step :  105\n",
      "reward :  -0.38048874934442034\n",
      "episode :  9\n",
      "current step :  106\n",
      "reward :  -0.3270860730899053\n",
      "episode :  9\n",
      "current step :  107\n",
      "reward :  -0.3773474364209671\n",
      "episode :  9\n",
      "current step :  108\n",
      "reward :  -0.3823664124236639\n",
      "episode :  9\n",
      "current step :  109\n",
      "reward :  -0.30785921467154465\n",
      "episode :  9\n",
      "current step :  110\n",
      "reward :  -0.3103322598039198\n",
      "episode :  9\n",
      "current step :  111\n",
      "reward :  -0.3444774236917229\n",
      "episode :  9\n",
      "current step :  112\n",
      "reward :  -0.3583281114946827\n",
      "episode :  9\n",
      "current step :  113\n",
      "reward :  -0.4524592277921725\n",
      "episode :  9\n",
      "current step :  114\n",
      "reward :  -0.48185087436247587\n",
      "episode :  9\n",
      "current step :  115\n",
      "reward :  -0.3764914178421642\n",
      "episode :  9\n",
      "current step :  116\n",
      "reward :  -0.4172087273959343\n",
      "episode :  9\n",
      "current step :  117\n",
      "reward :  -0.48560017787768944\n",
      "episode :  9\n",
      "current step :  118\n",
      "reward :  -0.4859666707325026\n",
      "episode :  9\n",
      "current step :  119\n",
      "reward :  -0.4958695112495163\n",
      "episode :  9\n",
      "current step :  120\n",
      "reward :  -0.441238561103574\n",
      "episode :  9\n",
      "current step :  121\n",
      "reward :  -0.46667963950134006\n",
      "episode :  9\n",
      "current step :  122\n",
      "reward :  -0.43208815351693314\n",
      "episode :  9\n",
      "current step :  123\n",
      "reward :  -0.37202902745115707\n",
      "episode :  9\n",
      "current step :  124\n",
      "reward :  -0.4574475534163409\n",
      "episode :  9\n",
      "current step :  125\n",
      "reward :  -0.4725201847076526\n",
      "episode :  9\n",
      "current step :  126\n",
      "reward :  -0.5157793486332022\n",
      "episode :  9\n",
      "current step :  127\n",
      "reward :  -0.5127641514476694\n",
      "episode :  9\n",
      "current step :  128\n",
      "reward :  -0.5157718116622338\n",
      "episode :  9\n",
      "current step :  129\n",
      "reward :  -0.4171893107194873\n",
      "episode :  9\n",
      "current step :  130\n",
      "reward :  -0.40008449191511114\n",
      "episode :  9\n",
      "current step :  131\n",
      "reward :  -0.2103710506611819\n",
      "episode :  9\n",
      "current step :  132\n",
      "reward :  -0.37641128935926793\n",
      "episode :  9\n",
      "current step :  133\n",
      "reward :  -0.25744739620139495\n",
      "episode :  9\n",
      "current step :  134\n",
      "reward :  -0.1873831581941871\n",
      "episode :  9\n",
      "current step :  135\n",
      "reward :  -0.30529681657286784\n",
      "episode :  9\n",
      "current step :  136\n",
      "reward :  -0.3703452561529561\n",
      "episode :  9\n",
      "current step :  137\n",
      "reward :  -0.27621745664098757\n",
      "episode :  9\n",
      "current step :  138\n",
      "reward :  -0.41251967016738134\n",
      "episode :  9\n",
      "current step :  139\n",
      "reward :  -0.4252820604264785\n",
      "episode :  9\n",
      "current step :  140\n",
      "reward :  -0.4428840657491403\n",
      "episode :  9\n",
      "current step :  141\n",
      "reward :  -0.5255185587021535\n",
      "episode :  9\n",
      "current step :  142\n",
      "reward :  -0.5321676782614134\n",
      "episode :  9\n",
      "current step :  143\n",
      "reward :  -0.5128101844812966\n",
      "episode :  9\n",
      "current step :  144\n",
      "reward :  -0.384609358240373\n",
      "episode :  9\n",
      "current step :  145\n",
      "reward :  -0.43356317674054773\n",
      "episode :  9\n",
      "current step :  146\n",
      "reward :  -0.34117598010214517\n",
      "episode :  9\n",
      "current step :  147\n",
      "reward :  -0.33458253978121105\n",
      "episode :  9\n",
      "current step :  148\n",
      "reward :  -0.28324103850888366\n",
      "episode :  9\n",
      "current step :  149\n",
      "reward :  -0.23307269558796692\n",
      "episode :  9\n",
      "current step :  150\n",
      "reward :  -0.3054567094836697\n",
      "episode :  9\n",
      "current step :  151\n",
      "reward :  -0.31359766886715473\n",
      "episode :  9\n",
      "current step :  152\n",
      "reward :  -0.44840369894617726\n",
      "episode :  9\n",
      "current step :  153\n",
      "reward :  -0.4927799807606953\n",
      "episode :  9\n",
      "current step :  154\n",
      "reward :  -0.5596625643829702\n",
      "episode :  9\n",
      "current step :  155\n",
      "reward :  -0.5248422925128011\n",
      "episode :  9\n",
      "current step :  156\n",
      "reward :  -0.49944883272836454\n",
      "episode :  9\n",
      "current step :  157\n",
      "reward :  -0.5592967537846038\n",
      "episode :  9\n",
      "current step :  158\n",
      "reward :  -0.559715188145568\n",
      "episode :  9\n",
      "current step :  159\n",
      "reward :  -0.5365389534676352\n",
      "episode :  9\n",
      "current step :  160\n",
      "reward :  -0.48546834381306486\n",
      "episode :  9\n",
      "current step :  161\n",
      "reward :  -0.481459757026713\n",
      "episode :  9\n",
      "current step :  162\n",
      "reward :  -0.5015138280477244\n",
      "episode :  9\n",
      "current step :  163\n",
      "reward :  -0.4317763212174089\n",
      "episode :  9\n",
      "current step :  164\n",
      "reward :  -0.5016316918655587\n",
      "episode :  9\n",
      "current step :  165\n",
      "reward :  -0.4454382573896926\n",
      "episode :  9\n",
      "current step :  166\n",
      "reward :  -0.4120160040560341\n",
      "episode :  9\n",
      "current step :  167\n",
      "reward :  -0.3527857390364779\n",
      "episode :  9\n",
      "current step :  168\n",
      "reward :  -0.4091013440927821\n",
      "episode :  9\n",
      "current step :  169\n",
      "reward :  -0.4917826998855787\n",
      "episode :  9\n",
      "current step :  170\n",
      "reward :  -0.6196846066434083\n",
      "episode :  9\n",
      "current step :  171\n",
      "reward :  -0.6199477777776445\n",
      "episode :  9\n",
      "current step :  172\n",
      "reward :  -0.5456688545513043\n",
      "episode :  9\n",
      "current step :  173\n",
      "reward :  -0.5901886278179577\n",
      "episode :  9\n",
      "current step :  174\n",
      "reward :  -0.6276939477231267\n",
      "episode :  9\n",
      "current step :  175\n",
      "reward :  -0.5295963177519954\n",
      "episode :  9\n",
      "current step :  176\n",
      "reward :  -0.48628119626328153\n",
      "episode :  9\n",
      "current step :  177\n",
      "reward :  -0.42783963764635047\n",
      "episode :  9\n",
      "current step :  178\n",
      "reward :  -0.42328792191907416\n",
      "episode :  9\n",
      "current step :  179\n",
      "reward :  -0.48441873627640203\n",
      "episode :  9\n",
      "current step :  180\n",
      "reward :  -0.53034859269149\n",
      "episode :  9\n",
      "current step :  181\n",
      "reward :  -0.5553189925398883\n",
      "episode :  9\n",
      "current step :  182\n",
      "reward :  -0.4733341786000365\n",
      "episode :  9\n",
      "current step :  183\n",
      "reward :  -0.4962240374823174\n",
      "episode :  9\n",
      "current step :  184\n",
      "reward :  -0.4135389787540285\n",
      "episode :  9\n",
      "current step :  185\n",
      "reward :  -0.30437165427934815\n",
      "episode :  9\n",
      "current step :  186\n",
      "reward :  -0.5134681177395772\n",
      "episode :  9\n",
      "current step :  187\n",
      "reward :  -0.6121060673588112\n",
      "episode :  9\n",
      "current step :  188\n",
      "reward :  -0.6321066043314179\n",
      "episode :  9\n",
      "current step :  189\n",
      "reward :  -0.5829509826115906\n",
      "episode :  9\n",
      "current step :  190\n",
      "reward :  -0.5277092712106538\n",
      "episode :  9\n",
      "current step :  191\n",
      "reward :  -0.48819667382270426\n",
      "episode :  9\n",
      "current step :  192\n",
      "reward :  -0.35386656423991786\n",
      "episode :  9\n",
      "current step :  193\n",
      "reward :  -0.3189116594323143\n",
      "episode :  9\n",
      "current step :  194\n",
      "reward :  -0.34543466116364574\n",
      "episode :  9\n",
      "current step :  195\n",
      "reward :  -0.3953920515237714\n",
      "episode :  9\n",
      "current step :  196\n",
      "reward :  -0.505809766750611\n",
      "episode :  9\n",
      "current step :  197\n",
      "reward :  -0.6246678548253861\n",
      "episode :  9\n",
      "current step :  198\n",
      "reward :  -0.5887721557850636\n",
      "episode :  9\n",
      "current step :  199\n",
      "reward :  -0.6231063233206164\n",
      "episode :  9\n",
      "current step :  200\n",
      "reward :  -0.5489539126797115\n",
      "episode :  9\n",
      "current step :  201\n",
      "reward :  -0.4992594153935425\n",
      "episode :  9\n",
      "current step :  202\n",
      "reward :  -0.378297070254643\n",
      "episode :  9\n",
      "current step :  203\n",
      "reward :  -0.3208779987114035\n",
      "episode :  9\n",
      "current step :  204\n",
      "reward :  -0.39253063298903523\n",
      "episode :  9\n",
      "current step :  205\n",
      "reward :  -0.4129382163593573\n",
      "episode :  9\n",
      "current step :  206\n",
      "reward :  -0.3406160007781265\n",
      "episode :  9\n",
      "current step :  207\n",
      "reward :  -0.539590446427382\n",
      "episode :  9\n",
      "current step :  208\n",
      "reward :  -0.5321513247537462\n",
      "episode :  9\n",
      "current step :  209\n",
      "reward :  -0.5473883082901271\n",
      "episode :  9\n",
      "current step :  210\n",
      "reward :  -0.48088655153452925\n",
      "episode :  9\n",
      "current step :  211\n",
      "reward :  -0.2982155929300959\n",
      "episode :  9\n",
      "current step :  212\n",
      "reward :  -0.3357405409843636\n",
      "episode :  9\n",
      "current step :  213\n",
      "reward :  -0.34986118431631213\n",
      "episode :  9\n",
      "current step :  214\n",
      "reward :  -0.384553811748271\n",
      "episode :  9\n",
      "current step :  215\n",
      "reward :  -0.5031078301681811\n",
      "episode :  9\n",
      "current step :  216\n",
      "reward :  -0.40507246234463307\n",
      "episode :  9\n",
      "current step :  217\n",
      "reward :  -0.37901873524268936\n",
      "episode :  9\n",
      "current step :  218\n",
      "reward :  -0.5035170263538913\n",
      "episode :  9\n",
      "current step :  219\n",
      "reward :  -0.4481805404169004\n",
      "episode :  9\n",
      "current step :  220\n",
      "reward :  -0.36350486689849537\n",
      "episode :  9\n",
      "current step :  221\n",
      "reward :  -0.444176999694247\n",
      "episode :  9\n",
      "current step :  222\n",
      "reward :  -0.46840270964604513\n",
      "episode :  9\n",
      "current step :  223\n",
      "reward :  -0.3979185253082768\n",
      "episode :  9\n",
      "current step :  224\n",
      "reward :  -0.44107238329007137\n",
      "episode :  9\n",
      "current step :  225\n",
      "reward :  -0.4366458617283123\n",
      "episode :  9\n",
      "current step :  226\n",
      "reward :  -0.4447384950154407\n",
      "episode :  9\n",
      "current step :  227\n",
      "reward :  -0.46009182434778745\n",
      "episode :  9\n",
      "current step :  228\n",
      "reward :  -0.4288550600960955\n",
      "episode :  9\n",
      "current step :  229\n",
      "reward :  -0.39317758174303896\n",
      "episode :  9\n",
      "current step :  230\n",
      "reward :  -0.22585372454241426\n",
      "episode :  9\n",
      "current step :  231\n",
      "reward :  -0.26147563130500523\n",
      "episode :  9\n",
      "current step :  232\n",
      "reward :  -0.27747597626946074\n",
      "episode :  9\n",
      "current step :  233\n",
      "reward :  -0.43040119371677893\n",
      "episode :  9\n",
      "current step :  234\n",
      "reward :  -0.5359386167457951\n",
      "episode :  9\n",
      "current step :  235\n",
      "reward :  -0.5412361346853394\n",
      "episode :  9\n",
      "current step :  236\n",
      "reward :  -0.45002980150453864\n",
      "episode :  9\n",
      "current step :  237\n",
      "reward :  -0.2846282815378661\n",
      "episode :  9\n",
      "current step :  238\n",
      "reward :  -0.33915002599855254\n",
      "episode :  9\n",
      "current step :  239\n",
      "reward :  -0.34276340869880983\n",
      "episode :  9\n",
      "current step :  240\n",
      "reward :  -0.3085614003877116\n",
      "episode :  9\n",
      "current step :  241\n",
      "reward :  -0.3215712034807184\n",
      "episode :  9\n",
      "current step :  242\n",
      "reward :  -0.42798673945804216\n",
      "episode :  9\n",
      "current step :  243\n",
      "reward :  -0.4657289388564376\n",
      "episode :  9\n",
      "current step :  244\n",
      "reward :  -0.39283313623922383\n",
      "episode :  9\n",
      "current step :  245\n",
      "reward :  -0.3179756792741118\n",
      "episode :  9\n",
      "current step :  246\n",
      "reward :  -0.2713584500208729\n",
      "episode :  9\n",
      "current step :  247\n",
      "reward :  -0.2238011278108882\n",
      "episode :  9\n",
      "current step :  248\n",
      "reward :  -0.1890022108744215\n",
      "episode :  9\n",
      "current step :  249\n",
      "reward :  -0.22596015309512207\n",
      "episode :  9\n",
      "current step :  250\n",
      "reward :  -0.32409213943883586\n",
      "episode :  9\n",
      "current step :  251\n",
      "reward :  -0.32380056677900404\n",
      "episode :  9\n",
      "current step :  252\n",
      "reward :  -0.28789121384361877\n",
      "episode :  9\n",
      "current step :  253\n",
      "reward :  -0.34739238901288794\n",
      "episode :  9\n",
      "current step :  254\n",
      "reward :  -0.32900358628349136\n",
      "episode :  9\n",
      "current step :  255\n",
      "reward :  -0.3406541640700446\n",
      "episode :  9\n",
      "current step :  256\n",
      "reward :  -0.4207122860068955\n",
      "episode :  9\n",
      "current step :  257\n",
      "reward :  -0.4252907517350753\n",
      "episode :  9\n",
      "current step :  258\n",
      "reward :  -0.47789141430448767\n",
      "episode :  9\n",
      "current step :  259\n",
      "reward :  -0.5238214356383021\n",
      "episode :  9\n",
      "current step :  260\n",
      "reward :  -0.40276513765131305\n",
      "episode :  9\n",
      "current step :  261\n",
      "reward :  -0.4471329792800814\n",
      "episode :  9\n",
      "current step :  262\n",
      "reward :  -0.322251980408418\n",
      "episode :  9\n",
      "current step :  263\n",
      "reward :  -0.31745075919170673\n",
      "episode :  9\n",
      "current step :  264\n",
      "reward :  -0.40471786418231026\n",
      "episode :  9\n",
      "current step :  265\n",
      "reward :  -0.4494747339270482\n",
      "episode :  9\n",
      "current step :  266\n",
      "reward :  -0.4112251779470407\n",
      "episode :  9\n",
      "current step :  267\n",
      "reward :  -0.33578027198261284\n",
      "episode :  9\n",
      "current step :  268\n",
      "reward :  -0.4147842265989815\n",
      "episode :  9\n",
      "current step :  269\n",
      "reward :  -0.3676741124485912\n",
      "episode :  9\n",
      "current step :  270\n",
      "reward :  -0.2710077995080875\n",
      "episode :  9\n",
      "current step :  271\n",
      "reward :  -0.2696517425656838\n",
      "episode :  9\n",
      "current step :  272\n",
      "reward :  -0.33162392394682777\n",
      "episode :  9\n",
      "current step :  273\n",
      "reward :  -0.3437610084626568\n",
      "episode :  9\n",
      "current step :  274\n",
      "reward :  -0.3868572036091776\n",
      "episode :  9\n",
      "current step :  275\n",
      "reward :  -0.3387405250358726\n",
      "episode :  9\n",
      "current step :  276\n",
      "reward :  -0.27433780118067824\n",
      "episode :  9\n",
      "current step :  277\n",
      "reward :  -0.30527285478177346\n",
      "episode :  9\n",
      "current step :  278\n",
      "reward :  -0.3986923208612435\n",
      "episode :  9\n",
      "current step :  279\n",
      "reward :  -0.4661045112808558\n",
      "episode :  9\n",
      "current step :  280\n",
      "reward :  -0.3901303196451439\n",
      "episode :  9\n",
      "current step :  281\n",
      "reward :  -0.47493855326246465\n",
      "episode :  9\n",
      "current step :  282\n",
      "reward :  -0.4352594733348986\n",
      "episode :  9\n",
      "current step :  283\n",
      "reward :  -0.4077270638002237\n",
      "episode :  9\n",
      "current step :  284\n",
      "reward :  -0.2579831132644003\n",
      "episode :  9\n",
      "current step :  285\n",
      "reward :  -0.24631884229620135\n",
      "episode :  10\n",
      "current step :  0\n",
      "reward :  -0.17840106736412242\n",
      "episode :  10\n",
      "current step :  1\n",
      "reward :  -0.20167216961122197\n",
      "episode :  10\n",
      "current step :  2\n",
      "reward :  -0.2960766313693649\n",
      "episode :  10\n",
      "current step :  3\n",
      "reward :  -0.35425709792531185\n",
      "episode :  10\n",
      "current step :  4\n",
      "reward :  -0.2632568491518034\n",
      "episode :  10\n",
      "current step :  5\n",
      "reward :  -0.32547152567727117\n",
      "episode :  10\n",
      "current step :  6\n",
      "reward :  -0.3652187656817361\n",
      "episode :  10\n",
      "current step :  7\n",
      "reward :  -0.37417417882282716\n",
      "episode :  10\n",
      "current step :  8\n",
      "reward :  -0.2920399894417048\n",
      "episode :  10\n",
      "current step :  9\n",
      "reward :  -0.37658441053992225\n",
      "episode :  10\n",
      "current step :  10\n",
      "reward :  -0.3371459827493461\n",
      "episode :  10\n",
      "current step :  11\n",
      "reward :  -0.31248473986519126\n",
      "episode :  10\n",
      "current step :  12\n",
      "reward :  -0.35842687471353496\n",
      "episode :  10\n",
      "current step :  13\n",
      "reward :  -0.3792107913152909\n",
      "episode :  10\n",
      "current step :  14\n",
      "reward :  -0.2639458321640844\n",
      "episode :  10\n",
      "current step :  15\n",
      "reward :  -0.24451776897075453\n",
      "episode :  10\n",
      "current step :  16\n",
      "reward :  -0.28968266980372603\n",
      "episode :  10\n",
      "current step :  17\n",
      "reward :  -0.40807902349708297\n",
      "episode :  10\n",
      "current step :  18\n",
      "reward :  -0.49624477486249424\n",
      "episode :  10\n",
      "current step :  19\n",
      "reward :  -0.36124375307232043\n",
      "episode :  10\n",
      "current step :  20\n",
      "reward :  -0.42094360786950086\n",
      "episode :  10\n",
      "current step :  21\n",
      "reward :  -0.5143441956938244\n",
      "episode :  10\n",
      "current step :  22\n",
      "reward :  -0.5508714593714887\n",
      "episode :  10\n",
      "current step :  23\n",
      "reward :  -0.5176651162117373\n",
      "episode :  10\n",
      "current step :  24\n",
      "reward :  -0.4767706895724148\n",
      "episode :  10\n",
      "current step :  25\n",
      "reward :  -0.46516556223748107\n",
      "episode :  10\n",
      "current step :  26\n",
      "reward :  -0.4795348300159587\n",
      "episode :  10\n",
      "current step :  27\n",
      "reward :  -0.4221724315588036\n",
      "episode :  10\n",
      "current step :  28\n",
      "reward :  -0.5247298680419296\n",
      "episode :  10\n",
      "current step :  29\n",
      "reward :  -0.5492498879888377\n",
      "episode :  10\n",
      "current step :  30\n",
      "reward :  -0.5635759191184625\n",
      "episode :  10\n",
      "current step :  31\n",
      "reward :  -0.4528519921549197\n",
      "episode :  10\n",
      "current step :  32\n",
      "reward :  -0.3619200450202225\n",
      "episode :  10\n",
      "current step :  33\n",
      "reward :  -0.405606040332122\n",
      "episode :  10\n",
      "current step :  34\n",
      "reward :  -0.42951836442195457\n",
      "episode :  10\n",
      "current step :  35\n",
      "reward :  -0.4170456447613333\n",
      "episode :  10\n",
      "current step :  36\n",
      "reward :  -0.5472301534130828\n",
      "episode :  10\n",
      "current step :  37\n",
      "reward :  -0.5184173050903566\n",
      "episode :  10\n",
      "current step :  38\n",
      "reward :  -0.3839997104327541\n",
      "episode :  10\n",
      "current step :  39\n",
      "reward :  -0.603361506432549\n",
      "episode :  10\n",
      "current step :  40\n",
      "reward :  -0.5411694201380061\n",
      "episode :  10\n",
      "current step :  41\n",
      "reward :  -0.6277074750843937\n",
      "episode :  10\n",
      "current step :  42\n",
      "reward :  -0.6086274446819337\n",
      "episode :  10\n",
      "current step :  43\n",
      "reward :  -0.5600339869777807\n",
      "episode :  10\n",
      "current step :  44\n",
      "reward :  -0.5243650965377886\n",
      "episode :  10\n",
      "current step :  45\n",
      "reward :  -0.36122537593935294\n",
      "episode :  10\n",
      "current step :  46\n",
      "reward :  -0.44180943403986783\n",
      "episode :  10\n",
      "current step :  47\n",
      "reward :  -0.4521885241437257\n",
      "episode :  10\n",
      "current step :  48\n",
      "reward :  -0.48857849376616647\n",
      "episode :  10\n",
      "current step :  49\n",
      "reward :  -0.6262463130874615\n",
      "episode :  10\n",
      "current step :  50\n",
      "reward :  -0.644098184645722\n",
      "episode :  10\n",
      "current step :  51\n",
      "reward :  -0.6418874722300831\n",
      "episode :  10\n",
      "current step :  52\n",
      "reward :  -0.4557050531293842\n",
      "episode :  10\n",
      "current step :  53\n",
      "reward :  -0.36813717602780816\n",
      "episode :  10\n",
      "current step :  54\n",
      "reward :  -0.3720215740018547\n",
      "episode :  10\n",
      "current step :  55\n",
      "reward :  -0.504739526352869\n",
      "episode :  10\n",
      "current step :  56\n",
      "reward :  -0.6065509215719027\n",
      "episode :  10\n",
      "current step :  57\n",
      "reward :  -0.488778031872548\n",
      "episode :  10\n",
      "current step :  58\n",
      "reward :  -0.5379481626072516\n",
      "episode :  10\n",
      "current step :  59\n",
      "reward :  -0.6054145194081073\n",
      "episode :  10\n",
      "current step :  60\n",
      "reward :  -0.5883852079647038\n",
      "episode :  10\n",
      "current step :  61\n",
      "reward :  -0.5908929162592775\n",
      "episode :  10\n",
      "current step :  62\n",
      "reward :  -0.5682832436128658\n",
      "episode :  10\n",
      "current step :  63\n",
      "reward :  -0.5812114178030992\n",
      "episode :  10\n",
      "current step :  64\n",
      "reward :  -0.5082606192044758\n",
      "episode :  10\n",
      "current step :  65\n",
      "reward :  -0.4406018234459389\n",
      "episode :  10\n",
      "current step :  66\n",
      "reward :  -0.3173501952724023\n",
      "episode :  10\n",
      "current step :  67\n",
      "reward :  -0.39047338741036\n",
      "episode :  10\n",
      "current step :  68\n",
      "reward :  -0.33976143046157836\n",
      "episode :  10\n",
      "current step :  69\n",
      "reward :  -0.49091398884003196\n",
      "episode :  10\n",
      "current step :  70\n",
      "reward :  -0.46658086765449513\n",
      "episode :  10\n",
      "current step :  71\n",
      "reward :  -0.5362688570131265\n",
      "episode :  10\n",
      "current step :  72\n",
      "reward :  -0.5239990130073485\n",
      "episode :  10\n",
      "current step :  73\n",
      "reward :  -0.5654912758215971\n",
      "episode :  10\n",
      "current step :  74\n",
      "reward :  -0.6016103252025334\n",
      "episode :  10\n",
      "current step :  75\n",
      "reward :  -0.5540489799740688\n",
      "episode :  10\n",
      "current step :  76\n",
      "reward :  -0.5154601976443589\n",
      "episode :  10\n",
      "current step :  77\n",
      "reward :  -0.5247178152551649\n",
      "episode :  10\n",
      "current step :  78\n",
      "reward :  -0.5336811800965181\n",
      "episode :  10\n",
      "current step :  79\n",
      "reward :  -0.5278445070148668\n",
      "episode :  10\n",
      "current step :  80\n",
      "reward :  -0.46047464768877494\n",
      "episode :  10\n",
      "current step :  81\n",
      "reward :  -0.5241859634126692\n",
      "episode :  10\n",
      "current step :  82\n",
      "reward :  -0.5473304550692355\n",
      "episode :  10\n",
      "current step :  83\n",
      "reward :  -0.37361998643649647\n",
      "episode :  10\n",
      "current step :  84\n",
      "reward :  -0.33181933689991944\n",
      "episode :  10\n",
      "current step :  85\n",
      "reward :  -0.3156604274881894\n",
      "episode :  10\n",
      "current step :  86\n",
      "reward :  -0.4142699004409083\n",
      "episode :  10\n",
      "current step :  87\n",
      "reward :  -0.4840053490873731\n",
      "episode :  10\n",
      "current step :  88\n",
      "reward :  -0.5248404445150807\n",
      "episode :  10\n",
      "current step :  89\n",
      "reward :  -0.4699656488554438\n",
      "episode :  10\n",
      "current step :  90\n",
      "reward :  -0.494754514759735\n",
      "episode :  10\n",
      "current step :  91\n",
      "reward :  -0.4808412030105473\n",
      "episode :  10\n",
      "current step :  92\n",
      "reward :  -0.41510119746760055\n",
      "episode :  10\n",
      "current step :  93\n",
      "reward :  -0.3915108815039182\n",
      "episode :  10\n",
      "current step :  94\n",
      "reward :  -0.4037105931275568\n",
      "episode :  10\n",
      "current step :  95\n",
      "reward :  -0.45545645857965467\n",
      "episode :  10\n",
      "current step :  96\n",
      "reward :  -0.5118504238965601\n",
      "episode :  10\n",
      "current step :  97\n",
      "reward :  -0.4486338118318231\n",
      "episode :  10\n",
      "current step :  98\n",
      "reward :  -0.3190342084994446\n",
      "episode :  10\n",
      "current step :  99\n",
      "reward :  -0.30641730966286057\n",
      "episode :  10\n",
      "current step :  100\n",
      "reward :  -0.32038918555984\n",
      "episode :  10\n",
      "current step :  101\n",
      "reward :  -0.21400104066103817\n",
      "episode :  10\n",
      "current step :  102\n",
      "reward :  -0.4056952468605349\n",
      "episode :  10\n",
      "current step :  103\n",
      "reward :  -0.43017978296479603\n",
      "episode :  10\n",
      "current step :  104\n",
      "reward :  -0.38330778414063643\n",
      "episode :  10\n",
      "current step :  105\n",
      "reward :  -0.29694475725152714\n",
      "episode :  10\n",
      "current step :  106\n",
      "reward :  -0.24226907261257433\n",
      "episode :  10\n",
      "current step :  107\n",
      "reward :  -0.22475586280685603\n",
      "episode :  10\n",
      "current step :  108\n",
      "reward :  -0.24916998158346837\n",
      "episode :  10\n",
      "current step :  109\n",
      "reward :  -0.32712540586999955\n",
      "episode :  10\n",
      "current step :  110\n",
      "reward :  -0.28010501258384896\n",
      "episode :  10\n",
      "current step :  111\n",
      "reward :  -0.21355244635891188\n",
      "episode :  10\n",
      "current step :  112\n",
      "reward :  -0.19231162810528166\n",
      "episode :  10\n",
      "current step :  113\n",
      "reward :  -0.1568318189591415\n",
      "episode :  10\n",
      "current step :  114\n",
      "reward :  -0.15147441510533152\n",
      "episode :  10\n",
      "current step :  115\n",
      "reward :  -0.2005927884187154\n",
      "episode :  10\n",
      "current step :  116\n",
      "reward :  -0.2310919231659892\n",
      "episode :  10\n",
      "current step :  117\n",
      "reward :  -0.34606642999342135\n",
      "episode :  10\n",
      "current step :  118\n",
      "reward :  -0.25476798352575153\n",
      "episode :  10\n",
      "current step :  119\n",
      "reward :  -0.1938714073601123\n",
      "episode :  10\n",
      "current step :  120\n",
      "reward :  -0.4205508590323434\n",
      "episode :  10\n",
      "current step :  121\n",
      "reward :  -0.4331555685331999\n",
      "episode :  10\n",
      "current step :  122\n",
      "reward :  -0.49103335471731563\n",
      "episode :  10\n",
      "current step :  123\n",
      "reward :  -0.5122092513560867\n",
      "episode :  10\n",
      "current step :  124\n",
      "reward :  -0.44053663191805054\n",
      "episode :  10\n",
      "current step :  125\n",
      "reward :  -0.4025769086803981\n",
      "episode :  10\n",
      "current step :  126\n",
      "reward :  -0.3974731654216897\n",
      "episode :  10\n",
      "current step :  127\n",
      "reward :  -0.33797543673218433\n",
      "episode :  10\n",
      "current step :  128\n",
      "reward :  -0.36874253763681014\n",
      "episode :  10\n",
      "current step :  129\n",
      "reward :  -0.4255507653722154\n",
      "episode :  10\n",
      "current step :  130\n",
      "reward :  -0.47215779071299424\n",
      "episode :  10\n",
      "current step :  131\n",
      "reward :  -0.39877634026254266\n",
      "episode :  10\n",
      "current step :  132\n",
      "reward :  -0.36476198459458997\n",
      "episode :  10\n",
      "current step :  133\n",
      "reward :  -0.42516056294398274\n",
      "episode :  10\n",
      "current step :  134\n",
      "reward :  -0.40487744502035994\n",
      "episode :  10\n",
      "current step :  135\n",
      "reward :  -0.3678698298269321\n",
      "episode :  10\n",
      "current step :  136\n",
      "reward :  -0.27350948005903575\n",
      "episode :  10\n",
      "current step :  137\n",
      "reward :  -0.23487641578799204\n",
      "episode :  10\n",
      "current step :  138\n",
      "reward :  -0.3202494754288701\n",
      "episode :  10\n",
      "current step :  139\n",
      "reward :  -0.21226720949972683\n",
      "episode :  10\n",
      "current step :  140\n",
      "reward :  -0.20688288756718842\n",
      "episode :  10\n",
      "current step :  141\n",
      "reward :  -0.20421087779775435\n",
      "episode :  10\n",
      "current step :  142\n",
      "reward :  -0.22903993304923906\n",
      "episode :  10\n",
      "current step :  143\n",
      "reward :  -0.31156236372057683\n",
      "episode :  10\n",
      "current step :  144\n",
      "reward :  -0.337980402717627\n",
      "episode :  10\n",
      "current step :  145\n",
      "reward :  -0.39970499489721156\n",
      "episode :  10\n",
      "current step :  146\n",
      "reward :  -0.5539451188936707\n",
      "episode :  10\n",
      "current step :  147\n",
      "reward :  -0.4792257647210484\n",
      "episode :  10\n",
      "current step :  148\n",
      "reward :  -0.3953670852829416\n",
      "episode :  10\n",
      "current step :  149\n",
      "reward :  -0.4236608932468528\n",
      "episode :  10\n",
      "current step :  150\n",
      "reward :  -0.44291386484193956\n",
      "episode :  10\n",
      "current step :  151\n",
      "reward :  -0.4527336060425494\n",
      "episode :  10\n",
      "current step :  152\n",
      "reward :  -0.45312288140710055\n",
      "episode :  10\n",
      "current step :  153\n",
      "reward :  -0.36000700405789354\n",
      "episode :  10\n",
      "current step :  154\n",
      "reward :  -0.3387092348587091\n",
      "episode :  10\n",
      "current step :  155\n",
      "reward :  -0.4383852304911382\n",
      "episode :  10\n",
      "current step :  156\n",
      "reward :  -0.5365654919667864\n",
      "episode :  10\n",
      "current step :  157\n",
      "reward :  -0.5234242714771935\n",
      "episode :  10\n",
      "current step :  158\n",
      "reward :  -0.4636739515005772\n",
      "episode :  10\n",
      "current step :  159\n",
      "reward :  -0.5256716374626986\n",
      "episode :  10\n",
      "current step :  160\n",
      "reward :  -0.6380151401087729\n",
      "episode :  10\n",
      "current step :  161\n",
      "reward :  -0.6171692437422964\n",
      "episode :  10\n",
      "current step :  162\n",
      "reward :  -0.6389528890607463\n",
      "episode :  10\n",
      "current step :  163\n",
      "reward :  -0.5807577153646316\n",
      "episode :  10\n",
      "current step :  164\n",
      "reward :  -0.5660283345499758\n",
      "episode :  10\n",
      "current step :  165\n",
      "reward :  -0.4825372834413011\n",
      "episode :  10\n",
      "current step :  166\n",
      "reward :  -0.5122537697609115\n",
      "episode :  10\n",
      "current step :  167\n",
      "reward :  -0.5302781899084174\n",
      "episode :  10\n",
      "current step :  168\n",
      "reward :  -0.5331119703217776\n",
      "episode :  10\n",
      "current step :  169\n",
      "reward :  -0.548475936123359\n",
      "episode :  10\n",
      "current step :  170\n",
      "reward :  -0.4897386519589811\n",
      "episode :  10\n",
      "current step :  171\n",
      "reward :  -0.42260064505887723\n",
      "episode :  10\n",
      "current step :  172\n",
      "reward :  -0.48293279641679754\n",
      "episode :  10\n",
      "current step :  173\n",
      "reward :  -0.4766545492525467\n",
      "episode :  10\n",
      "current step :  174\n",
      "reward :  -0.4329300514449364\n",
      "episode :  10\n",
      "current step :  175\n",
      "reward :  -0.34830689826827343\n",
      "episode :  10\n",
      "current step :  176\n",
      "reward :  -0.4663473073538679\n",
      "episode :  10\n",
      "current step :  177\n",
      "reward :  -0.4010335584216144\n",
      "episode :  10\n",
      "current step :  178\n",
      "reward :  -0.3334527721927276\n",
      "episode :  10\n",
      "current step :  179\n",
      "reward :  -0.3563274615233479\n",
      "episode :  10\n",
      "current step :  180\n",
      "reward :  -0.295542108873179\n",
      "episode :  10\n",
      "current step :  181\n",
      "reward :  -0.284252187727154\n",
      "episode :  10\n",
      "current step :  182\n",
      "reward :  -0.5585519815682533\n",
      "episode :  10\n",
      "current step :  183\n",
      "reward :  -0.41122556273775396\n",
      "episode :  10\n",
      "current step :  184\n",
      "reward :  -0.3464836656795469\n",
      "episode :  10\n",
      "current step :  185\n",
      "reward :  -0.463742660707021\n",
      "episode :  10\n",
      "current step :  186\n",
      "reward :  -0.372165015912196\n",
      "episode :  10\n",
      "current step :  187\n",
      "reward :  -0.4776631427868947\n",
      "episode :  10\n",
      "current step :  188\n",
      "reward :  -0.49701434216152496\n",
      "episode :  10\n",
      "current step :  189\n",
      "reward :  -0.448925982002663\n",
      "episode :  10\n",
      "current step :  190\n",
      "reward :  -0.39651169401843467\n",
      "episode :  10\n",
      "current step :  191\n",
      "reward :  -0.43681028216566203\n",
      "episode :  10\n",
      "current step :  192\n",
      "reward :  -0.45627563488430684\n",
      "episode :  10\n",
      "current step :  193\n",
      "reward :  -0.5571754169710964\n",
      "episode :  10\n",
      "current step :  194\n",
      "reward :  -0.5768758735991786\n",
      "episode :  10\n",
      "current step :  195\n",
      "reward :  -0.5270231837163011\n",
      "episode :  10\n",
      "current step :  196\n",
      "reward :  -0.5651166658427381\n",
      "episode :  10\n",
      "current step :  197\n",
      "reward :  -0.445504218499583\n",
      "episode :  10\n",
      "current step :  198\n",
      "reward :  -0.37504213300380884\n",
      "episode :  10\n",
      "current step :  199\n",
      "reward :  -0.32291137301577216\n",
      "episode :  10\n",
      "current step :  200\n",
      "reward :  -0.5611444309775128\n",
      "episode :  10\n",
      "current step :  201\n",
      "reward :  -0.5289183481572864\n",
      "episode :  10\n",
      "current step :  202\n",
      "reward :  -0.5395237172831882\n",
      "episode :  10\n",
      "current step :  203\n",
      "reward :  -0.5029206736501359\n",
      "episode :  10\n",
      "current step :  204\n",
      "reward :  -0.5841607613803558\n",
      "episode :  10\n",
      "current step :  205\n",
      "reward :  -0.5790234377450371\n",
      "episode :  10\n",
      "current step :  206\n",
      "reward :  -0.5184650801134335\n",
      "episode :  10\n",
      "current step :  207\n",
      "reward :  -0.27742039041919747\n",
      "episode :  10\n",
      "current step :  208\n",
      "reward :  -0.36370763991754\n",
      "episode :  10\n",
      "current step :  209\n",
      "reward :  -0.40711898159855425\n",
      "episode :  10\n",
      "current step :  210\n",
      "reward :  -0.30045899468376763\n",
      "episode :  10\n",
      "current step :  211\n",
      "reward :  -0.47246736122794947\n",
      "episode :  10\n",
      "current step :  212\n",
      "reward :  -0.5798583514241868\n",
      "episode :  10\n",
      "current step :  213\n",
      "reward :  -0.6501653212265511\n",
      "episode :  10\n",
      "current step :  214\n",
      "reward :  -0.6380162694906132\n",
      "episode :  10\n",
      "current step :  215\n",
      "reward :  -0.504146676631959\n",
      "episode :  10\n",
      "current step :  216\n",
      "reward :  -0.4490435496861947\n",
      "episode :  10\n",
      "current step :  217\n",
      "reward :  -0.41345716308306035\n",
      "episode :  10\n",
      "current step :  218\n",
      "reward :  -0.44727317124155486\n",
      "episode :  10\n",
      "current step :  219\n",
      "reward :  -0.41785890030959977\n",
      "episode :  10\n",
      "current step :  220\n",
      "reward :  -0.3634466587161497\n",
      "episode :  10\n",
      "current step :  221\n",
      "reward :  -0.3263247454421499\n",
      "episode :  10\n",
      "current step :  222\n",
      "reward :  -0.3717289360597395\n",
      "episode :  10\n",
      "current step :  223\n",
      "reward :  -0.31187023983607265\n",
      "episode :  10\n",
      "current step :  224\n",
      "reward :  -0.4426109815490034\n",
      "episode :  10\n",
      "current step :  225\n",
      "reward :  -0.546149559586877\n",
      "episode :  10\n",
      "current step :  226\n",
      "reward :  -0.5173721685383482\n",
      "episode :  10\n",
      "current step :  227\n",
      "reward :  -0.39141773586901996\n",
      "episode :  10\n",
      "current step :  228\n",
      "reward :  -0.38696185164224334\n",
      "episode :  10\n",
      "current step :  229\n",
      "reward :  -0.43142337517853957\n",
      "episode :  10\n",
      "current step :  230\n",
      "reward :  -0.42530048519632174\n",
      "episode :  10\n",
      "current step :  231\n",
      "reward :  -0.38648572976247164\n",
      "episode :  10\n",
      "current step :  232\n",
      "reward :  -0.4992812783513705\n",
      "episode :  10\n",
      "current step :  233\n",
      "reward :  -0.5118155500153233\n",
      "episode :  10\n",
      "current step :  234\n",
      "reward :  -0.4681400473976528\n",
      "episode :  10\n",
      "current step :  235\n",
      "reward :  -0.31008085186195483\n",
      "episode :  10\n",
      "current step :  236\n",
      "reward :  -0.26879793653031914\n",
      "episode :  10\n",
      "current step :  237\n",
      "reward :  -0.32384079556816314\n",
      "episode :  10\n",
      "current step :  238\n",
      "reward :  -0.33484370747382786\n",
      "episode :  10\n",
      "current step :  239\n",
      "reward :  -0.28902641383165567\n",
      "episode :  10\n",
      "current step :  240\n",
      "reward :  -0.3747311386604697\n",
      "episode :  10\n",
      "current step :  241\n",
      "reward :  -0.4484196951975694\n",
      "episode :  10\n",
      "current step :  242\n",
      "reward :  -0.4795771744685744\n",
      "episode :  10\n",
      "current step :  243\n",
      "reward :  -0.4379232267496294\n",
      "episode :  10\n",
      "current step :  244\n",
      "reward :  -0.3707519595440224\n",
      "episode :  10\n",
      "current step :  245\n",
      "reward :  -0.3637550664172915\n",
      "episode :  10\n",
      "current step :  246\n",
      "reward :  -0.38086723350355406\n",
      "episode :  10\n",
      "current step :  247\n",
      "reward :  -0.2510915259579314\n",
      "episode :  10\n",
      "current step :  248\n",
      "reward :  -0.24456788757007156\n",
      "episode :  10\n",
      "current step :  249\n",
      "reward :  -0.29624883858361717\n",
      "episode :  10\n",
      "current step :  250\n",
      "reward :  -0.23372035442473546\n",
      "episode :  10\n",
      "current step :  251\n",
      "reward :  -0.37448234823235005\n",
      "episode :  10\n",
      "current step :  252\n",
      "reward :  -0.35524236816270055\n",
      "episode :  10\n",
      "current step :  253\n",
      "reward :  -0.3894334985716131\n",
      "episode :  10\n",
      "current step :  254\n",
      "reward :  -0.3937839176966888\n",
      "episode :  10\n",
      "current step :  255\n",
      "reward :  -0.3687124152748608\n",
      "episode :  10\n",
      "current step :  256\n",
      "reward :  -0.37197676233162635\n",
      "episode :  10\n",
      "current step :  257\n",
      "reward :  -0.4350362911974505\n",
      "episode :  10\n",
      "current step :  258\n",
      "reward :  -0.47708820120899\n",
      "episode :  10\n",
      "current step :  259\n",
      "reward :  -0.41737403036229503\n",
      "episode :  10\n",
      "current step :  260\n",
      "reward :  -0.32447850269993656\n",
      "episode :  10\n",
      "current step :  261\n",
      "reward :  -0.3369747248970808\n",
      "episode :  10\n",
      "current step :  262\n",
      "reward :  -0.3920617372493542\n",
      "episode :  10\n",
      "current step :  263\n",
      "reward :  -0.47051331511015526\n",
      "episode :  10\n",
      "current step :  264\n",
      "reward :  -0.2850295535289811\n",
      "episode :  10\n",
      "current step :  265\n",
      "reward :  -0.1960976283490832\n",
      "episode :  10\n",
      "current step :  266\n",
      "reward :  -0.2130095100338918\n",
      "episode :  10\n",
      "current step :  267\n",
      "reward :  -0.2652109377011107\n",
      "episode :  10\n",
      "current step :  268\n",
      "reward :  -0.36747678031695485\n",
      "episode :  10\n",
      "current step :  269\n",
      "reward :  -0.4397930091554179\n",
      "episode :  10\n",
      "current step :  270\n",
      "reward :  -0.3732216179294262\n",
      "episode :  10\n",
      "current step :  271\n",
      "reward :  -0.45969387037399995\n",
      "episode :  10\n",
      "current step :  272\n",
      "reward :  -0.4316192479416313\n",
      "episode :  10\n",
      "current step :  273\n",
      "reward :  -0.3513655950425087\n",
      "episode :  10\n",
      "current step :  274\n",
      "reward :  -0.4545681047867318\n",
      "episode :  10\n",
      "current step :  275\n",
      "reward :  -0.4642889616968411\n",
      "episode :  10\n",
      "current step :  276\n",
      "reward :  -0.3824340621411476\n",
      "episode :  10\n",
      "current step :  277\n",
      "reward :  -0.4055313231238765\n",
      "episode :  10\n",
      "current step :  278\n",
      "reward :  -0.4294004675301386\n",
      "episode :  10\n",
      "current step :  279\n",
      "reward :  -0.5113908373850732\n",
      "episode :  10\n",
      "current step :  280\n",
      "reward :  -0.3854740031488224\n",
      "episode :  10\n",
      "current step :  281\n",
      "reward :  -0.3555337660024155\n",
      "episode :  10\n",
      "current step :  282\n",
      "reward :  -0.45644981741478186\n",
      "episode :  10\n",
      "current step :  283\n",
      "reward :  -0.3546034672067356\n",
      "episode :  10\n",
      "current step :  284\n",
      "reward :  -0.19689715684639164\n",
      "episode :  10\n",
      "current step :  285\n",
      "reward :  -0.3076339345509421\n",
      "episode :  11\n",
      "current step :  0\n",
      "reward :  -0.16498842895615898\n",
      "episode :  11\n",
      "current step :  1\n",
      "reward :  -0.2060725271244048\n",
      "episode :  11\n",
      "current step :  2\n",
      "reward :  -0.3216310133284417\n",
      "episode :  11\n",
      "current step :  3\n",
      "reward :  -0.3455206229326915\n",
      "episode :  11\n",
      "current step :  4\n",
      "reward :  -0.3544680853541747\n",
      "episode :  11\n",
      "current step :  5\n",
      "reward :  -0.38203916571604507\n",
      "episode :  11\n",
      "current step :  6\n",
      "reward :  -0.3023429570058035\n",
      "episode :  11\n",
      "current step :  7\n",
      "reward :  -0.3416902609537153\n",
      "episode :  11\n",
      "current step :  8\n",
      "reward :  -0.24101241076244181\n",
      "episode :  11\n",
      "current step :  9\n",
      "reward :  -0.20855026993408937\n",
      "episode :  11\n",
      "current step :  10\n",
      "reward :  -0.2653550938080892\n",
      "episode :  11\n",
      "current step :  11\n",
      "reward :  -0.4299275375037533\n",
      "episode :  11\n",
      "current step :  12\n",
      "reward :  -0.4495907571307995\n",
      "episode :  11\n",
      "current step :  13\n",
      "reward :  -0.3818408488005341\n",
      "episode :  11\n",
      "current step :  14\n",
      "reward :  -0.3806949215455084\n",
      "episode :  11\n",
      "current step :  15\n",
      "reward :  -0.390468711783541\n",
      "episode :  11\n",
      "current step :  16\n",
      "reward :  -0.35871885523767677\n",
      "episode :  11\n",
      "current step :  17\n",
      "reward :  -0.32111498861223425\n",
      "episode :  11\n",
      "current step :  18\n",
      "reward :  -0.34182582271114786\n",
      "episode :  11\n",
      "current step :  19\n",
      "reward :  -0.30869606233139163\n",
      "episode :  11\n",
      "current step :  20\n",
      "reward :  -0.3328908805672605\n",
      "episode :  11\n",
      "current step :  21\n",
      "reward :  -0.30812984871549826\n",
      "episode :  11\n",
      "current step :  22\n",
      "reward :  -0.29682166466733556\n",
      "episode :  11\n",
      "current step :  23\n",
      "reward :  -0.2488354987148318\n",
      "episode :  11\n",
      "current step :  24\n",
      "reward :  -0.3310461097997006\n",
      "episode :  11\n",
      "current step :  25\n",
      "reward :  -0.3946241019819786\n",
      "episode :  11\n",
      "current step :  26\n",
      "reward :  -0.34376149686359236\n",
      "episode :  11\n",
      "current step :  27\n",
      "reward :  -0.4129159548923636\n",
      "episode :  11\n",
      "current step :  28\n",
      "reward :  -0.5651752844084895\n",
      "episode :  11\n",
      "current step :  29\n",
      "reward :  -0.6140686918781629\n",
      "episode :  11\n",
      "current step :  30\n",
      "reward :  -0.5780214208821454\n",
      "episode :  11\n",
      "current step :  31\n",
      "reward :  -0.5338169364653244\n",
      "episode :  11\n",
      "current step :  32\n",
      "reward :  -0.48900707059956827\n",
      "episode :  11\n",
      "current step :  33\n",
      "reward :  -0.4800294697219817\n",
      "episode :  11\n",
      "current step :  34\n",
      "reward :  -0.5259871832714287\n",
      "episode :  11\n",
      "current step :  35\n",
      "reward :  -0.5559841030116998\n",
      "episode :  11\n",
      "current step :  36\n",
      "reward :  -0.5406514288931917\n",
      "episode :  11\n",
      "current step :  37\n",
      "reward :  -0.4403913608738103\n",
      "episode :  11\n",
      "current step :  38\n",
      "reward :  -0.40584082127542626\n",
      "episode :  11\n",
      "current step :  39\n",
      "reward :  -0.32272294310557287\n",
      "episode :  11\n",
      "current step :  40\n",
      "reward :  -0.38328430866420476\n",
      "episode :  11\n",
      "current step :  41\n",
      "reward :  -0.2646744522785188\n",
      "episode :  11\n",
      "current step :  42\n",
      "reward :  -0.31933684949640256\n",
      "episode :  11\n",
      "current step :  43\n",
      "reward :  -0.5761565168320378\n",
      "episode :  11\n",
      "current step :  44\n",
      "reward :  -0.6838977548435063\n",
      "episode :  11\n",
      "current step :  45\n",
      "reward :  -0.5835185074011446\n",
      "episode :  11\n",
      "current step :  46\n",
      "reward :  -0.712405900982589\n",
      "episode :  11\n",
      "current step :  47\n",
      "reward :  -0.7448517958526447\n",
      "episode :  11\n",
      "current step :  48\n",
      "reward :  -0.7155563187072789\n",
      "episode :  11\n",
      "current step :  49\n",
      "reward :  -0.6746502691218047\n",
      "episode :  11\n",
      "current step :  50\n",
      "reward :  -0.739939188869837\n",
      "episode :  11\n",
      "current step :  51\n",
      "reward :  -0.6955493364881554\n",
      "episode :  11\n",
      "current step :  52\n",
      "reward :  -0.7253802753880201\n",
      "episode :  11\n",
      "current step :  53\n",
      "reward :  -0.6760014542496038\n",
      "episode :  11\n",
      "current step :  54\n",
      "reward :  -0.6183254044366472\n",
      "episode :  11\n",
      "current step :  55\n",
      "reward :  -0.5233918941020417\n",
      "episode :  11\n",
      "current step :  56\n",
      "reward :  -0.4908270123607196\n",
      "episode :  11\n",
      "current step :  57\n",
      "reward :  -0.4013435838044239\n",
      "episode :  11\n",
      "current step :  58\n",
      "reward :  -0.4179521948509928\n",
      "episode :  11\n",
      "current step :  59\n",
      "reward :  -0.4325686890599122\n",
      "episode :  11\n",
      "current step :  60\n",
      "reward :  -0.5213247231427894\n",
      "episode :  11\n",
      "current step :  61\n",
      "reward :  -0.4675401711755923\n",
      "episode :  11\n",
      "current step :  62\n",
      "reward :  -0.42528727848445547\n",
      "episode :  11\n",
      "current step :  63\n",
      "reward :  -0.5202778604237108\n",
      "episode :  11\n",
      "current step :  64\n",
      "reward :  -0.48634183262131203\n",
      "episode :  11\n",
      "current step :  65\n",
      "reward :  -0.4674400244900104\n",
      "episode :  11\n",
      "current step :  66\n",
      "reward :  -0.4387784359556849\n",
      "episode :  11\n",
      "current step :  67\n",
      "reward :  -0.5639570021229099\n",
      "episode :  11\n",
      "current step :  68\n",
      "reward :  -0.6133753898306149\n",
      "episode :  11\n",
      "current step :  69\n",
      "reward :  -0.6685286451012585\n",
      "episode :  11\n",
      "current step :  70\n",
      "reward :  -0.6814397121641887\n",
      "episode :  11\n",
      "current step :  71\n",
      "reward :  -0.6846819675550643\n",
      "episode :  11\n",
      "current step :  72\n",
      "reward :  -0.6897039377617533\n",
      "episode :  11\n",
      "current step :  73\n",
      "reward :  -0.66138042716531\n",
      "episode :  11\n",
      "current step :  74\n",
      "reward :  -0.6786080822054356\n",
      "episode :  11\n",
      "current step :  75\n",
      "reward :  -0.7074662532016625\n",
      "episode :  11\n",
      "current step :  76\n",
      "reward :  -0.6748397495242765\n",
      "episode :  11\n",
      "current step :  77\n",
      "reward :  -0.6526800637267027\n",
      "episode :  11\n",
      "current step :  78\n",
      "reward :  -0.6192736382051482\n",
      "episode :  11\n",
      "current step :  79\n",
      "reward :  -0.6517627697975258\n",
      "episode :  11\n",
      "current step :  80\n",
      "reward :  -0.6603930309908294\n",
      "episode :  11\n",
      "current step :  81\n",
      "reward :  -0.6442166396290376\n",
      "episode :  11\n",
      "current step :  82\n",
      "reward :  -0.6041991220418441\n",
      "episode :  11\n",
      "current step :  83\n",
      "reward :  -0.5402534590791046\n",
      "episode :  11\n",
      "current step :  84\n",
      "reward :  -0.3595335548515105\n",
      "episode :  11\n",
      "current step :  85\n",
      "reward :  -0.4455526565719744\n",
      "episode :  11\n",
      "current step :  86\n",
      "reward :  -0.5730106687828096\n",
      "episode :  11\n",
      "current step :  87\n",
      "reward :  -0.519849194582698\n",
      "episode :  11\n",
      "current step :  88\n",
      "reward :  -0.2900619825964104\n",
      "episode :  11\n",
      "current step :  89\n",
      "reward :  -0.2940661253108734\n",
      "episode :  11\n",
      "current step :  90\n",
      "reward :  -0.19361482602619767\n",
      "episode :  11\n",
      "current step :  91\n",
      "reward :  -0.1817811159248122\n",
      "episode :  11\n",
      "current step :  92\n",
      "reward :  -0.37898692096887554\n",
      "episode :  11\n",
      "current step :  93\n",
      "reward :  -0.47422504672774407\n",
      "episode :  11\n",
      "current step :  94\n",
      "reward :  -0.42341919132606487\n",
      "episode :  11\n",
      "current step :  95\n",
      "reward :  -0.35111784285748665\n",
      "episode :  11\n",
      "current step :  96\n",
      "reward :  -0.32960685584672056\n",
      "episode :  11\n",
      "current step :  97\n",
      "reward :  -0.4007204948972288\n",
      "episode :  11\n",
      "current step :  98\n",
      "reward :  -0.41077566362356005\n",
      "episode :  11\n",
      "current step :  99\n",
      "reward :  -0.4144461642583186\n",
      "episode :  11\n",
      "current step :  100\n",
      "reward :  -0.32858691972888326\n",
      "episode :  11\n",
      "current step :  101\n",
      "reward :  -0.2805056779092285\n",
      "episode :  11\n",
      "current step :  102\n",
      "reward :  -0.285397932737628\n",
      "episode :  11\n",
      "current step :  103\n",
      "reward :  -0.21602745658551628\n",
      "episode :  11\n",
      "current step :  104\n",
      "reward :  -0.310571630285176\n",
      "episode :  11\n",
      "current step :  105\n",
      "reward :  -0.40075661447016486\n",
      "episode :  11\n",
      "current step :  106\n",
      "reward :  -0.39196125709825597\n",
      "episode :  11\n",
      "current step :  107\n",
      "reward :  -0.411400161000388\n",
      "episode :  11\n",
      "current step :  108\n",
      "reward :  -0.32114613691266886\n",
      "episode :  11\n",
      "current step :  109\n",
      "reward :  -0.22495645737916936\n",
      "episode :  11\n",
      "current step :  110\n",
      "reward :  -0.20529647429728712\n",
      "episode :  11\n",
      "current step :  111\n",
      "reward :  -0.39560292179803563\n",
      "episode :  11\n",
      "current step :  112\n",
      "reward :  -0.4790199940788613\n",
      "episode :  11\n",
      "current step :  113\n",
      "reward :  -0.3747292163646835\n",
      "episode :  11\n",
      "current step :  114\n",
      "reward :  -0.19403602397277078\n",
      "episode :  11\n",
      "current step :  115\n",
      "reward :  -0.16208533147054777\n",
      "episode :  11\n",
      "current step :  116\n",
      "reward :  -0.29675929005808344\n",
      "episode :  11\n",
      "current step :  117\n",
      "reward :  -0.3345042849081925\n",
      "episode :  11\n",
      "current step :  118\n",
      "reward :  -0.33650937496319194\n",
      "episode :  11\n",
      "current step :  119\n",
      "reward :  -0.2085198407013104\n",
      "episode :  11\n",
      "current step :  120\n",
      "reward :  -0.18092469404440104\n",
      "episode :  11\n",
      "current step :  121\n",
      "reward :  -0.3028709707539015\n",
      "episode :  11\n",
      "current step :  122\n",
      "reward :  -0.2037913858595172\n",
      "episode :  11\n",
      "current step :  123\n",
      "reward :  -0.18461862553791428\n",
      "episode :  11\n",
      "current step :  124\n",
      "reward :  -0.23989549389634224\n",
      "episode :  11\n",
      "current step :  125\n",
      "reward :  -0.1547580028438782\n",
      "episode :  11\n",
      "current step :  126\n",
      "reward :  -0.1637299677532195\n",
      "episode :  11\n",
      "current step :  127\n",
      "reward :  -0.2923864348528146\n",
      "episode :  11\n",
      "current step :  128\n",
      "reward :  -0.24933099924094754\n",
      "episode :  11\n",
      "current step :  129\n",
      "reward :  -0.23025136216505157\n",
      "episode :  11\n",
      "current step :  130\n",
      "reward :  -0.22703916855152842\n",
      "episode :  11\n",
      "current step :  131\n",
      "reward :  -0.30352182231919234\n",
      "episode :  11\n",
      "current step :  132\n",
      "reward :  -0.36433645749749183\n",
      "episode :  11\n",
      "current step :  133\n",
      "reward :  -0.27395937285439725\n",
      "episode :  11\n",
      "current step :  134\n",
      "reward :  -0.22629624180402913\n",
      "episode :  11\n",
      "current step :  135\n",
      "reward :  -0.24233417137899563\n",
      "episode :  11\n",
      "current step :  136\n",
      "reward :  -0.3198799218081934\n",
      "episode :  11\n",
      "current step :  137\n",
      "reward :  -0.39302927738130083\n",
      "episode :  11\n",
      "current step :  138\n",
      "reward :  -0.40359560159296154\n",
      "episode :  11\n",
      "current step :  139\n",
      "reward :  -0.3201641355070641\n",
      "episode :  11\n",
      "current step :  140\n",
      "reward :  -0.2650139652112727\n",
      "episode :  11\n",
      "current step :  141\n",
      "reward :  -0.2963357566154205\n",
      "episode :  11\n",
      "current step :  142\n",
      "reward :  -0.3616729404114545\n",
      "episode :  11\n",
      "current step :  143\n",
      "reward :  -0.3561520948923081\n",
      "episode :  11\n",
      "current step :  144\n",
      "reward :  -0.4589934100587817\n",
      "episode :  11\n",
      "current step :  145\n",
      "reward :  -0.467039065429669\n",
      "episode :  11\n",
      "current step :  146\n",
      "reward :  -0.43594224417097943\n",
      "episode :  11\n",
      "current step :  147\n",
      "reward :  -0.39409705539469414\n",
      "episode :  11\n",
      "current step :  148\n",
      "reward :  -0.2645188260758382\n",
      "episode :  11\n",
      "current step :  149\n",
      "reward :  -0.3197576557907822\n",
      "episode :  11\n",
      "current step :  150\n",
      "reward :  -0.42741831805829317\n",
      "episode :  11\n",
      "current step :  151\n",
      "reward :  -0.5156983286356331\n",
      "episode :  11\n",
      "current step :  152\n",
      "reward :  -0.4923362644710491\n",
      "episode :  11\n",
      "current step :  153\n",
      "reward :  -0.483239525839645\n",
      "episode :  11\n",
      "current step :  154\n",
      "reward :  -0.5407875122048036\n",
      "episode :  11\n",
      "current step :  155\n",
      "reward :  -0.389998729957918\n",
      "episode :  11\n",
      "current step :  156\n",
      "reward :  -0.4958141566184543\n",
      "episode :  11\n",
      "current step :  157\n",
      "reward :  -0.567120802154474\n",
      "episode :  11\n",
      "current step :  158\n",
      "reward :  -0.5437812396034818\n",
      "episode :  11\n",
      "current step :  159\n",
      "reward :  -0.5009127794410689\n",
      "episode :  11\n",
      "current step :  160\n",
      "reward :  -0.4881779838910289\n",
      "episode :  11\n",
      "current step :  161\n",
      "reward :  -0.5403797426949585\n",
      "episode :  11\n",
      "current step :  162\n",
      "reward :  -0.539256135154094\n",
      "episode :  11\n",
      "current step :  163\n",
      "reward :  -0.3788521857447656\n",
      "episode :  11\n",
      "current step :  164\n",
      "reward :  -0.38570861989176547\n",
      "episode :  11\n",
      "current step :  165\n",
      "reward :  -0.3850794446466222\n",
      "episode :  11\n",
      "current step :  166\n",
      "reward :  -0.42952562030256664\n",
      "episode :  11\n",
      "current step :  167\n",
      "reward :  -0.4463522152070068\n",
      "episode :  11\n",
      "current step :  168\n",
      "reward :  -0.30414125445805745\n",
      "episode :  11\n",
      "current step :  169\n",
      "reward :  -0.33924633850773717\n",
      "episode :  11\n",
      "current step :  170\n",
      "reward :  -0.46430385235828003\n",
      "episode :  11\n",
      "current step :  171\n",
      "reward :  -0.4882201912156567\n",
      "episode :  11\n",
      "current step :  172\n",
      "reward :  -0.48365820930918374\n",
      "episode :  11\n",
      "current step :  173\n",
      "reward :  -0.46656713943045824\n",
      "episode :  11\n",
      "current step :  174\n",
      "reward :  -0.5183264120771364\n",
      "episode :  11\n",
      "current step :  175\n",
      "reward :  -0.5067137539440851\n",
      "episode :  11\n",
      "current step :  176\n",
      "reward :  -0.5837213104504028\n",
      "episode :  11\n",
      "current step :  177\n",
      "reward :  -0.5450555646248088\n",
      "episode :  11\n",
      "current step :  178\n",
      "reward :  -0.5151607836295109\n",
      "episode :  11\n",
      "current step :  179\n",
      "reward :  -0.5751008272831618\n",
      "episode :  11\n",
      "current step :  180\n",
      "reward :  -0.6118226850053963\n",
      "episode :  11\n",
      "current step :  181\n",
      "reward :  -0.5488120263015752\n",
      "episode :  11\n",
      "current step :  182\n",
      "reward :  -0.4080175568910736\n",
      "episode :  11\n",
      "current step :  183\n",
      "reward :  -0.44315612493392864\n",
      "episode :  11\n",
      "current step :  184\n",
      "reward :  -0.5276232828803401\n",
      "episode :  11\n",
      "current step :  185\n",
      "reward :  -0.5682627699817852\n",
      "episode :  11\n",
      "current step :  186\n",
      "reward :  -0.7204708323963477\n",
      "episode :  11\n",
      "current step :  187\n",
      "reward :  -0.739268207593536\n",
      "episode :  11\n",
      "current step :  188\n",
      "reward :  -0.61864614965991\n",
      "episode :  11\n",
      "current step :  189\n",
      "reward :  -0.43606351581435704\n",
      "episode :  11\n",
      "current step :  190\n",
      "reward :  -0.3644429344601409\n",
      "episode :  11\n",
      "current step :  191\n",
      "reward :  -0.33556804017593744\n",
      "episode :  11\n",
      "current step :  192\n",
      "reward :  -0.4034491058168858\n",
      "episode :  11\n",
      "current step :  193\n",
      "reward :  -0.41927568006761\n",
      "episode :  11\n",
      "current step :  194\n",
      "reward :  -0.4890932696079254\n",
      "episode :  11\n",
      "current step :  195\n",
      "reward :  -0.41037170481399654\n",
      "episode :  11\n",
      "current step :  196\n",
      "reward :  -0.4169637246590246\n",
      "episode :  11\n",
      "current step :  197\n",
      "reward :  -0.39856276068434804\n",
      "episode :  11\n",
      "current step :  198\n",
      "reward :  -0.39126778532378537\n",
      "episode :  11\n",
      "current step :  199\n",
      "reward :  -0.5461044629168383\n",
      "episode :  11\n",
      "current step :  200\n",
      "reward :  -0.5112275956892246\n",
      "episode :  11\n",
      "current step :  201\n",
      "reward :  -0.5403105540299703\n",
      "episode :  11\n",
      "current step :  202\n",
      "reward :  -0.5527963786672739\n",
      "episode :  11\n",
      "current step :  203\n",
      "reward :  -0.5482583599061278\n",
      "episode :  11\n",
      "current step :  204\n",
      "reward :  -0.4219636093579062\n",
      "episode :  11\n",
      "current step :  205\n",
      "reward :  -0.4101557742123106\n",
      "episode :  11\n",
      "current step :  206\n",
      "reward :  -0.36300431330096344\n",
      "episode :  11\n",
      "current step :  207\n",
      "reward :  -0.38072169141828066\n",
      "episode :  11\n",
      "current step :  208\n",
      "reward :  -0.36308883948348303\n",
      "episode :  11\n",
      "current step :  209\n",
      "reward :  -0.5486782240854032\n",
      "episode :  11\n",
      "current step :  210\n",
      "reward :  -0.5365748655872333\n",
      "episode :  11\n",
      "current step :  211\n",
      "reward :  -0.3634918209663044\n",
      "episode :  11\n",
      "current step :  212\n",
      "reward :  -0.39498212745027106\n",
      "episode :  11\n",
      "current step :  213\n",
      "reward :  -0.48575702590515524\n",
      "episode :  11\n",
      "current step :  214\n",
      "reward :  -0.5760548210815899\n",
      "episode :  11\n",
      "current step :  215\n",
      "reward :  -0.535241394522173\n",
      "episode :  11\n",
      "current step :  216\n",
      "reward :  -0.4376426442786994\n",
      "episode :  11\n",
      "current step :  217\n",
      "reward :  -0.45440262288551003\n",
      "episode :  11\n",
      "current step :  218\n",
      "reward :  -0.40754620067876335\n",
      "episode :  11\n",
      "current step :  219\n",
      "reward :  -0.43355051350449547\n",
      "episode :  11\n",
      "current step :  220\n",
      "reward :  -0.6568398895768657\n",
      "episode :  11\n",
      "current step :  221\n",
      "reward :  -0.5732724252475729\n",
      "episode :  11\n",
      "current step :  222\n",
      "reward :  -0.522254688816633\n",
      "episode :  11\n",
      "current step :  223\n",
      "reward :  -0.5119894402649182\n",
      "episode :  11\n",
      "current step :  224\n",
      "reward :  -0.5294706891516329\n",
      "episode :  11\n",
      "current step :  225\n",
      "reward :  -0.6414586078693542\n",
      "episode :  11\n",
      "current step :  226\n",
      "reward :  -0.6153100758318778\n",
      "episode :  11\n",
      "current step :  227\n",
      "reward :  -0.6553947254143098\n",
      "episode :  11\n",
      "current step :  228\n",
      "reward :  -0.536686481456073\n",
      "episode :  11\n",
      "current step :  229\n",
      "reward :  -0.4962474022931859\n",
      "episode :  11\n",
      "current step :  230\n",
      "reward :  -0.5032995002103063\n",
      "episode :  11\n",
      "current step :  231\n",
      "reward :  -0.5114868138204154\n",
      "episode :  11\n",
      "current step :  232\n",
      "reward :  -0.5081485813727769\n",
      "episode :  11\n",
      "current step :  233\n",
      "reward :  -0.4694924842880347\n",
      "episode :  11\n",
      "current step :  234\n",
      "reward :  -0.45735239503162656\n",
      "episode :  11\n",
      "current step :  235\n",
      "reward :  -0.4344935128915012\n",
      "episode :  11\n",
      "current step :  236\n",
      "reward :  -0.3926128027008881\n",
      "episode :  11\n",
      "current step :  237\n",
      "reward :  -0.4391146440613343\n",
      "episode :  11\n",
      "current step :  238\n",
      "reward :  -0.4095875451679166\n",
      "episode :  11\n",
      "current step :  239\n",
      "reward :  -0.4557715894091286\n",
      "episode :  11\n",
      "current step :  240\n",
      "reward :  -0.4500862746527006\n",
      "episode :  11\n",
      "current step :  241\n",
      "reward :  -0.4456454939736155\n",
      "episode :  11\n",
      "current step :  242\n",
      "reward :  -0.44870949403495786\n",
      "episode :  11\n",
      "current step :  243\n",
      "reward :  -0.4284832622189874\n",
      "episode :  11\n",
      "current step :  244\n",
      "reward :  -0.43929224134574363\n",
      "episode :  11\n",
      "current step :  245\n",
      "reward :  -0.49164260894606454\n",
      "episode :  11\n",
      "current step :  246\n",
      "reward :  -0.5017528405909691\n",
      "episode :  11\n",
      "current step :  247\n",
      "reward :  -0.3892155994582623\n",
      "episode :  11\n",
      "current step :  248\n",
      "reward :  -0.42154588415644545\n",
      "episode :  11\n",
      "current step :  249\n",
      "reward :  -0.3820801830479266\n",
      "episode :  11\n",
      "current step :  250\n",
      "reward :  -0.3393229805327347\n",
      "episode :  11\n",
      "current step :  251\n",
      "reward :  -0.336504662887884\n",
      "episode :  11\n",
      "current step :  252\n",
      "reward :  -0.43621447755695925\n",
      "episode :  11\n",
      "current step :  253\n",
      "reward :  -0.49714082882239996\n",
      "episode :  11\n",
      "current step :  254\n",
      "reward :  -0.41334154908928017\n",
      "episode :  11\n",
      "current step :  255\n",
      "reward :  -0.2871477228860684\n",
      "episode :  11\n",
      "current step :  256\n",
      "reward :  -0.2951538809575397\n",
      "episode :  11\n",
      "current step :  257\n",
      "reward :  -0.21809338045666293\n",
      "episode :  11\n",
      "current step :  258\n",
      "reward :  -0.2119523958762284\n",
      "episode :  11\n",
      "current step :  259\n",
      "reward :  -0.2879695477680676\n",
      "episode :  11\n",
      "current step :  260\n",
      "reward :  -0.46521770120711387\n",
      "episode :  11\n",
      "current step :  261\n",
      "reward :  -0.4670922006144913\n",
      "episode :  11\n",
      "current step :  262\n",
      "reward :  -0.3730934877677591\n",
      "episode :  11\n",
      "current step :  263\n",
      "reward :  -0.29624995188803693\n",
      "episode :  11\n",
      "current step :  264\n",
      "reward :  -0.36272722069613683\n",
      "episode :  11\n",
      "current step :  265\n",
      "reward :  -0.4168281821818684\n",
      "episode :  11\n",
      "current step :  266\n",
      "reward :  -0.40782528893974634\n",
      "episode :  11\n",
      "current step :  267\n",
      "reward :  -0.38295102686371313\n",
      "episode :  11\n",
      "current step :  268\n",
      "reward :  -0.31852083568078077\n",
      "episode :  11\n",
      "current step :  269\n",
      "reward :  -0.22641405349814356\n",
      "episode :  11\n",
      "current step :  270\n",
      "reward :  -0.28479842350521045\n",
      "episode :  11\n",
      "current step :  271\n",
      "reward :  -0.19607232797911106\n",
      "episode :  11\n",
      "current step :  272\n",
      "reward :  -0.25280818609267913\n",
      "episode :  11\n",
      "current step :  273\n",
      "reward :  -0.3134398085608678\n",
      "episode :  11\n",
      "current step :  274\n",
      "reward :  -0.4273143825777659\n",
      "episode :  11\n",
      "current step :  275\n",
      "reward :  -0.5017605638010899\n",
      "episode :  11\n",
      "current step :  276\n",
      "reward :  -0.5040911344048248\n",
      "episode :  11\n",
      "current step :  277\n",
      "reward :  -0.4433163744431777\n",
      "episode :  11\n",
      "current step :  278\n",
      "reward :  -0.4498016667594904\n",
      "episode :  11\n",
      "current step :  279\n",
      "reward :  -0.4007983825472995\n",
      "episode :  11\n",
      "current step :  280\n",
      "reward :  -0.43717613967019703\n",
      "episode :  11\n",
      "current step :  281\n",
      "reward :  -0.43789450866855234\n",
      "episode :  11\n",
      "current step :  282\n",
      "reward :  -0.37298760556526694\n",
      "episode :  11\n",
      "current step :  283\n",
      "reward :  -0.3559635190722074\n",
      "episode :  11\n",
      "current step :  284\n",
      "reward :  -0.36874074665265383\n",
      "episode :  11\n",
      "current step :  285\n",
      "reward :  -0.28504477781477305\n",
      "episode :  12\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 286      |\n",
      "|    ep_rew_mean     | -119     |\n",
      "| time/              |          |\n",
      "|    episodes        | 12       |\n",
      "|    fps             | 13       |\n",
      "|    time_elapsed    | 259      |\n",
      "|    total_timesteps | 3432     |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -71.8    |\n",
      "|    critic_loss     | 7.6      |\n",
      "|    ent_coef        | 0.368    |\n",
      "|    ent_coef_loss   | -22.9    |\n",
      "|    learning_rate   | 0.0003   |\n",
      "|    n_updates       | 3331     |\n",
      "---------------------------------\n",
      "current step :  0\n",
      "reward :  -0.4357732233628945\n",
      "episode :  12\n",
      "current step :  1\n",
      "reward :  -0.4414467994250911\n",
      "episode :  12\n",
      "current step :  2\n",
      "reward :  -0.3738187541416458\n",
      "episode :  12\n",
      "current step :  3\n",
      "reward :  -0.4832549626955442\n",
      "episode :  12\n",
      "current step :  4\n",
      "reward :  -0.35302804777310265\n",
      "episode :  12\n",
      "current step :  5\n",
      "reward :  -0.4228104792540933\n",
      "episode :  12\n",
      "current step :  6\n",
      "reward :  -0.36538967202207223\n",
      "episode :  12\n",
      "current step :  7\n",
      "reward :  -0.27297645001391857\n",
      "episode :  12\n",
      "current step :  8\n",
      "reward :  -0.21064002172329702\n",
      "episode :  12\n",
      "current step :  9\n",
      "reward :  -0.15165172111091532\n",
      "episode :  12\n",
      "current step :  10\n",
      "reward :  -0.30265289460845174\n",
      "episode :  12\n",
      "current step :  11\n",
      "reward :  -0.1916506881406668\n",
      "episode :  12\n",
      "current step :  12\n",
      "reward :  -0.320425254073722\n",
      "episode :  12\n",
      "current step :  13\n",
      "reward :  -0.26334950486154973\n",
      "episode :  12\n",
      "current step :  14\n",
      "reward :  -0.3276812205659196\n",
      "episode :  12\n",
      "current step :  15\n",
      "reward :  -0.3653303185125907\n",
      "episode :  12\n",
      "current step :  16\n",
      "reward :  -0.34123011375860246\n",
      "episode :  12\n",
      "current step :  17\n",
      "reward :  -0.3442038993824875\n",
      "episode :  12\n",
      "current step :  18\n",
      "reward :  -0.24485071557386792\n",
      "episode :  12\n",
      "current step :  19\n",
      "reward :  -0.21041591223992276\n",
      "episode :  12\n",
      "current step :  20\n",
      "reward :  -0.2932354137149967\n",
      "episode :  12\n",
      "current step :  21\n",
      "reward :  -0.20907636634765842\n",
      "episode :  12\n",
      "current step :  22\n",
      "reward :  -0.33281592015973627\n",
      "episode :  12\n",
      "current step :  23\n",
      "reward :  -0.38289447282345823\n",
      "episode :  12\n",
      "current step :  24\n",
      "reward :  -0.2700511390881711\n",
      "episode :  12\n",
      "current step :  25\n",
      "reward :  -0.2149157106710044\n",
      "episode :  12\n",
      "current step :  26\n",
      "reward :  -0.20344391254882174\n",
      "episode :  12\n",
      "current step :  27\n",
      "reward :  -0.2621487824427298\n",
      "episode :  12\n",
      "current step :  28\n",
      "reward :  -0.30486161368965575\n",
      "episode :  12\n",
      "current step :  29\n",
      "reward :  -0.30126604532822054\n",
      "episode :  12\n",
      "current step :  30\n",
      "reward :  -0.368195525575512\n",
      "episode :  12\n",
      "current step :  31\n",
      "reward :  -0.4608151225924582\n",
      "episode :  12\n",
      "current step :  32\n",
      "reward :  -0.5176660058668758\n",
      "episode :  12\n",
      "current step :  33\n",
      "reward :  -0.543485847185045\n",
      "episode :  12\n",
      "current step :  34\n",
      "reward :  -0.46783235834729786\n",
      "episode :  12\n",
      "current step :  35\n",
      "reward :  -0.46129792826731697\n",
      "episode :  12\n",
      "current step :  36\n",
      "reward :  -0.38870671882489816\n",
      "episode :  12\n",
      "current step :  37\n",
      "reward :  -0.38218618157048095\n",
      "episode :  12\n",
      "current step :  38\n",
      "reward :  -0.4242236292900109\n",
      "episode :  12\n",
      "current step :  39\n",
      "reward :  -0.4595381451131006\n",
      "episode :  12\n",
      "current step :  40\n",
      "reward :  -0.5155492751220241\n",
      "episode :  12\n",
      "current step :  41\n",
      "reward :  -0.5295403752162092\n",
      "episode :  12\n",
      "current step :  42\n",
      "reward :  -0.4027687355526203\n",
      "episode :  12\n",
      "current step :  43\n",
      "reward :  -0.39025631044465137\n",
      "episode :  12\n",
      "current step :  44\n",
      "reward :  -0.4656086739378004\n",
      "episode :  12\n",
      "current step :  45\n",
      "reward :  -0.5127661288701428\n",
      "episode :  12\n",
      "current step :  46\n",
      "reward :  -0.378192869825987\n",
      "episode :  12\n",
      "current step :  47\n",
      "reward :  -0.4402562627520549\n",
      "episode :  12\n",
      "current step :  48\n",
      "reward :  -0.5846960573140256\n",
      "episode :  12\n",
      "current step :  49\n",
      "reward :  -0.6221734552079763\n",
      "episode :  12\n",
      "current step :  50\n",
      "reward :  -0.6652240272926077\n",
      "episode :  12\n",
      "current step :  51\n",
      "reward :  -0.5464280333877748\n",
      "episode :  12\n",
      "current step :  52\n",
      "reward :  -0.41534098217443494\n",
      "episode :  12\n",
      "current step :  53\n",
      "reward :  -0.48744631278295647\n",
      "episode :  12\n",
      "current step :  54\n",
      "reward :  -0.6014755254531825\n",
      "episode :  12\n",
      "current step :  55\n",
      "reward :  -0.6076788654883445\n",
      "episode :  12\n",
      "current step :  56\n",
      "reward :  -0.5439481753292129\n",
      "episode :  12\n",
      "current step :  57\n",
      "reward :  -0.5558480589988358\n",
      "episode :  12\n",
      "current step :  58\n",
      "reward :  -0.6531645740776075\n",
      "episode :  12\n",
      "current step :  59\n",
      "reward :  -0.6735726298595371\n",
      "episode :  12\n",
      "current step :  60\n",
      "reward :  -0.6870279560291679\n",
      "episode :  12\n",
      "current step :  61\n",
      "reward :  -0.6095340155936573\n",
      "episode :  12\n",
      "current step :  62\n",
      "reward :  -0.518669642069805\n",
      "episode :  12\n",
      "current step :  63\n",
      "reward :  -0.490242581044413\n",
      "episode :  12\n",
      "current step :  64\n",
      "reward :  -0.5360896616756011\n",
      "episode :  12\n",
      "current step :  65\n",
      "reward :  -0.5200610177181493\n",
      "episode :  12\n",
      "current step :  66\n",
      "reward :  -0.6018201930642585\n",
      "episode :  12\n",
      "current step :  67\n",
      "reward :  -0.6700547445839434\n",
      "episode :  12\n",
      "current step :  68\n",
      "reward :  -0.5748718965617766\n",
      "episode :  12\n",
      "current step :  69\n",
      "reward :  -0.4616617463301277\n",
      "episode :  12\n",
      "current step :  70\n",
      "reward :  -0.48693168003460896\n",
      "episode :  12\n",
      "current step :  71\n",
      "reward :  -0.4989767180972475\n",
      "episode :  12\n",
      "current step :  72\n",
      "reward :  -0.6502400549873293\n",
      "episode :  12\n",
      "current step :  73\n",
      "reward :  -0.6572123738453938\n",
      "episode :  12\n",
      "current step :  74\n",
      "reward :  -0.6006900716850362\n",
      "episode :  12\n",
      "current step :  75\n",
      "reward :  -0.6061658303988202\n",
      "episode :  12\n",
      "current step :  76\n",
      "reward :  -0.6560239489720187\n",
      "episode :  12\n",
      "current step :  77\n",
      "reward :  -0.5749895156265652\n",
      "episode :  12\n",
      "current step :  78\n",
      "reward :  -0.4319822003969776\n",
      "episode :  12\n",
      "current step :  79\n",
      "reward :  -0.5060321106181732\n",
      "episode :  12\n",
      "current step :  80\n",
      "reward :  -0.3972867353513587\n",
      "episode :  12\n",
      "current step :  81\n",
      "reward :  -0.4292847148232169\n",
      "episode :  12\n",
      "current step :  82\n",
      "reward :  -0.44603634536810705\n",
      "episode :  12\n",
      "current step :  83\n",
      "reward :  -0.4526882868635712\n",
      "episode :  12\n",
      "current step :  84\n",
      "reward :  -0.38889303639171224\n",
      "episode :  12\n",
      "current step :  85\n",
      "reward :  -0.35197388253285106\n",
      "episode :  12\n",
      "current step :  86\n",
      "reward :  -0.356272275131674\n",
      "episode :  12\n",
      "current step :  87\n",
      "reward :  -0.36016937607628846\n",
      "episode :  12\n",
      "current step :  88\n",
      "reward :  -0.4178233908570956\n",
      "episode :  12\n",
      "current step :  89\n",
      "reward :  -0.46937515551230846\n",
      "episode :  12\n",
      "current step :  90\n",
      "reward :  -0.39976117133316164\n",
      "episode :  12\n",
      "current step :  91\n",
      "reward :  -0.31564146358340844\n",
      "episode :  12\n",
      "current step :  92\n",
      "reward :  -0.16771832716225998\n",
      "episode :  12\n",
      "current step :  93\n",
      "reward :  -0.3302334320132902\n",
      "episode :  12\n",
      "current step :  94\n",
      "reward :  -0.33340660467646316\n",
      "episode :  12\n",
      "current step :  95\n",
      "reward :  -0.2985057628272796\n",
      "episode :  12\n",
      "current step :  96\n",
      "reward :  -0.18179926994769716\n",
      "episode :  12\n",
      "current step :  97\n",
      "reward :  -0.25674638714358006\n",
      "episode :  12\n",
      "current step :  98\n",
      "reward :  -0.2804150785921134\n",
      "episode :  12\n",
      "current step :  99\n",
      "reward :  -0.23812665630808816\n",
      "episode :  12\n",
      "current step :  100\n",
      "reward :  -0.3351783951028457\n",
      "episode :  12\n",
      "current step :  101\n",
      "reward :  -0.42003501739878574\n",
      "episode :  12\n",
      "current step :  102\n",
      "reward :  -0.37663927000507136\n",
      "episode :  12\n",
      "current step :  103\n",
      "reward :  -0.2298178099947708\n",
      "episode :  12\n",
      "current step :  104\n",
      "reward :  -0.25237200349474254\n",
      "episode :  12\n",
      "current step :  105\n",
      "reward :  -0.3332995204782541\n",
      "episode :  12\n",
      "current step :  106\n",
      "reward :  -0.35194864455217356\n",
      "episode :  12\n",
      "current step :  107\n",
      "reward :  -0.37433254145979883\n",
      "episode :  12\n",
      "current step :  108\n",
      "reward :  -0.4181404394756395\n",
      "episode :  12\n",
      "current step :  109\n",
      "reward :  -0.41225443254891997\n",
      "episode :  12\n",
      "current step :  110\n",
      "reward :  -0.36070177384953694\n",
      "episode :  12\n",
      "current step :  111\n",
      "reward :  -0.34682120707772063\n",
      "episode :  12\n",
      "current step :  112\n",
      "reward :  -0.32137481773144494\n",
      "episode :  12\n",
      "current step :  113\n",
      "reward :  -0.29955149311593726\n",
      "episode :  12\n",
      "current step :  114\n",
      "reward :  -0.3266032206619919\n",
      "episode :  12\n",
      "current step :  115\n",
      "reward :  -0.4128295052717665\n",
      "episode :  12\n",
      "current step :  116\n",
      "reward :  -0.44033688410574046\n",
      "episode :  12\n",
      "current step :  117\n",
      "reward :  -0.4412667282245704\n",
      "episode :  12\n",
      "current step :  118\n",
      "reward :  -0.37504185423507985\n",
      "episode :  12\n",
      "current step :  119\n",
      "reward :  -0.37060009726341925\n",
      "episode :  12\n",
      "current step :  120\n",
      "reward :  -0.3986425653135376\n",
      "episode :  12\n",
      "current step :  121\n",
      "reward :  -0.3999247295404737\n",
      "episode :  12\n",
      "current step :  122\n",
      "reward :  -0.3409396302783268\n",
      "episode :  12\n",
      "current step :  123\n",
      "reward :  -0.29628239044694604\n",
      "episode :  12\n",
      "current step :  124\n",
      "reward :  -0.31047950762163207\n",
      "episode :  12\n",
      "current step :  125\n",
      "reward :  -0.3380583325310174\n",
      "episode :  12\n",
      "current step :  126\n",
      "reward :  -0.14680145853116608\n",
      "episode :  12\n",
      "current step :  127\n",
      "reward :  -0.20504756328007587\n",
      "episode :  12\n",
      "current step :  128\n",
      "reward :  -0.29878694716600424\n",
      "episode :  12\n",
      "current step :  129\n",
      "reward :  -0.22828643076505642\n",
      "episode :  12\n",
      "current step :  130\n",
      "reward :  -0.23843490768717385\n",
      "episode :  12\n",
      "current step :  131\n",
      "reward :  -0.29620854457078855\n",
      "episode :  12\n",
      "current step :  132\n",
      "reward :  -0.38649973347013616\n",
      "episode :  12\n",
      "current step :  133\n",
      "reward :  -0.31824004851411297\n",
      "episode :  12\n",
      "current step :  134\n",
      "reward :  -0.2647660121154713\n",
      "episode :  12\n",
      "current step :  135\n",
      "reward :  -0.32167881466338666\n",
      "episode :  12\n",
      "current step :  136\n",
      "reward :  -0.42266821901860824\n",
      "episode :  12\n",
      "current step :  137\n",
      "reward :  -0.31447354871371963\n",
      "episode :  12\n",
      "current step :  138\n",
      "reward :  -0.37539079310169793\n",
      "episode :  12\n",
      "current step :  139\n",
      "reward :  -0.28802056466024084\n",
      "episode :  12\n",
      "current step :  140\n",
      "reward :  -0.24914809692816348\n",
      "episode :  12\n",
      "current step :  141\n",
      "reward :  -0.27528280784006737\n",
      "episode :  12\n",
      "current step :  142\n",
      "reward :  -0.2345035046129842\n",
      "episode :  12\n",
      "current step :  143\n",
      "reward :  -0.35032519656106115\n",
      "episode :  12\n",
      "current step :  144\n",
      "reward :  -0.37165515230820434\n",
      "episode :  12\n",
      "current step :  145\n",
      "reward :  -0.31613826143355667\n",
      "episode :  12\n",
      "current step :  146\n",
      "reward :  -0.33262144240358965\n",
      "episode :  12\n",
      "current step :  147\n",
      "reward :  -0.23517862886152133\n",
      "episode :  12\n",
      "current step :  148\n",
      "reward :  -0.40607506692545015\n",
      "episode :  12\n",
      "current step :  149\n",
      "reward :  -0.4077333336855222\n",
      "episode :  12\n",
      "current step :  150\n",
      "reward :  -0.35914337772804045\n",
      "episode :  12\n",
      "current step :  151\n",
      "reward :  -0.48544852263720417\n",
      "episode :  12\n",
      "current step :  152\n",
      "reward :  -0.4013168436544848\n",
      "episode :  12\n",
      "current step :  153\n",
      "reward :  -0.41259707639073917\n",
      "episode :  12\n",
      "current step :  154\n",
      "reward :  -0.42565298130962764\n",
      "episode :  12\n",
      "current step :  155\n",
      "reward :  -0.43917004641760266\n",
      "episode :  12\n",
      "current step :  156\n",
      "reward :  -0.4679236105551798\n",
      "episode :  12\n",
      "current step :  157\n",
      "reward :  -0.5000104260054105\n",
      "episode :  12\n",
      "current step :  158\n",
      "reward :  -0.4886040555909603\n",
      "episode :  12\n",
      "current step :  159\n",
      "reward :  -0.5138482871983385\n",
      "episode :  12\n",
      "current step :  160\n",
      "reward :  -0.5089891339742102\n",
      "episode :  12\n",
      "current step :  161\n",
      "reward :  -0.49454750037896833\n",
      "episode :  12\n",
      "current step :  162\n",
      "reward :  -0.4201010941847718\n",
      "episode :  12\n",
      "current step :  163\n",
      "reward :  -0.4071475783198133\n",
      "episode :  12\n",
      "current step :  164\n",
      "reward :  -0.4037799731038789\n",
      "episode :  12\n",
      "current step :  165\n",
      "reward :  -0.4466463993023519\n",
      "episode :  12\n",
      "current step :  166\n",
      "reward :  -0.4368748255284694\n",
      "episode :  12\n",
      "current step :  167\n",
      "reward :  -0.4954622590473092\n",
      "episode :  12\n",
      "current step :  168\n",
      "reward :  -0.5961550008158131\n",
      "episode :  12\n",
      "current step :  169\n",
      "reward :  -0.48971809015746864\n",
      "episode :  12\n",
      "current step :  170\n",
      "reward :  -0.5950040260550329\n",
      "episode :  12\n",
      "current step :  171\n",
      "reward :  -0.6059829404027165\n",
      "episode :  12\n",
      "current step :  172\n",
      "reward :  -0.581739029362611\n",
      "episode :  12\n",
      "current step :  173\n",
      "reward :  -0.4894456929474472\n",
      "episode :  12\n",
      "current step :  174\n",
      "reward :  -0.499992831138822\n",
      "episode :  12\n",
      "current step :  175\n",
      "reward :  -0.5436509666088813\n",
      "episode :  12\n",
      "current step :  176\n",
      "reward :  -0.6885723541795825\n",
      "episode :  12\n",
      "current step :  177\n",
      "reward :  -0.6461977497156082\n",
      "episode :  12\n",
      "current step :  178\n",
      "reward :  -0.6015383119580051\n",
      "episode :  12\n",
      "current step :  179\n",
      "reward :  -0.5835641633067893\n",
      "episode :  12\n",
      "current step :  180\n",
      "reward :  -0.5287574058405363\n",
      "episode :  12\n",
      "current step :  181\n",
      "reward :  -0.5599849738983816\n",
      "episode :  12\n",
      "current step :  182\n",
      "reward :  -0.6839696117446753\n",
      "episode :  12\n",
      "current step :  183\n",
      "reward :  -0.6641902958252368\n",
      "episode :  12\n",
      "current step :  184\n",
      "reward :  -0.6764229961440894\n",
      "episode :  12\n",
      "current step :  185\n",
      "reward :  -0.6021147973313884\n",
      "episode :  12\n",
      "current step :  186\n",
      "reward :  -0.6576835568534238\n",
      "episode :  12\n",
      "current step :  187\n",
      "reward :  -0.5714451436120396\n",
      "episode :  12\n",
      "current step :  188\n",
      "reward :  -0.46118109807283725\n",
      "episode :  12\n",
      "current step :  189\n",
      "reward :  -0.553617552228923\n",
      "episode :  12\n",
      "current step :  190\n",
      "reward :  -0.5158508050286752\n",
      "episode :  12\n",
      "current step :  191\n",
      "reward :  -0.4821671719226815\n",
      "episode :  12\n",
      "current step :  192\n",
      "reward :  -0.4711397146949253\n",
      "episode :  12\n",
      "current step :  193\n",
      "reward :  -0.44925747539283767\n",
      "episode :  12\n",
      "current step :  194\n",
      "reward :  -0.369243428966726\n",
      "episode :  12\n",
      "current step :  195\n",
      "reward :  -0.3182876937110846\n",
      "episode :  12\n",
      "current step :  196\n",
      "reward :  -0.3479460820589378\n",
      "episode :  12\n",
      "current step :  197\n",
      "reward :  -0.31742197830081925\n",
      "episode :  12\n",
      "current step :  198\n",
      "reward :  -0.36431282389981595\n",
      "episode :  12\n",
      "current step :  199\n",
      "reward :  -0.34558231926248634\n",
      "episode :  12\n",
      "current step :  200\n",
      "reward :  -0.2802169894015146\n",
      "episode :  12\n",
      "current step :  201\n",
      "reward :  -0.30836379157738053\n",
      "episode :  12\n",
      "current step :  202\n",
      "reward :  -0.300840189935616\n",
      "episode :  12\n",
      "current step :  203\n",
      "reward :  -0.3046856676815532\n",
      "episode :  12\n",
      "current step :  204\n",
      "reward :  -0.2908950989354127\n",
      "episode :  12\n",
      "current step :  205\n",
      "reward :  -0.25226503401160594\n",
      "episode :  12\n",
      "current step :  206\n",
      "reward :  -0.2857481431462928\n",
      "episode :  12\n",
      "current step :  207\n",
      "reward :  -0.4024125175093998\n",
      "episode :  12\n",
      "current step :  208\n",
      "reward :  -0.43953867762261856\n",
      "episode :  12\n",
      "current step :  209\n",
      "reward :  -0.29251733312320205\n",
      "episode :  12\n",
      "current step :  210\n",
      "reward :  -0.40863268640687683\n",
      "episode :  12\n",
      "current step :  211\n",
      "reward :  -0.5386085664331477\n",
      "episode :  12\n",
      "current step :  212\n",
      "reward :  -0.3607146381260286\n",
      "episode :  12\n",
      "current step :  213\n",
      "reward :  -0.24464786444785278\n",
      "episode :  12\n",
      "current step :  214\n",
      "reward :  -0.2854392936187681\n",
      "episode :  12\n",
      "current step :  215\n",
      "reward :  -0.2513733928421659\n",
      "episode :  12\n",
      "current step :  216\n",
      "reward :  -0.38457664568120026\n",
      "episode :  12\n",
      "current step :  217\n",
      "reward :  -0.3617849511760582\n",
      "episode :  12\n",
      "current step :  218\n",
      "reward :  -0.3084773911857822\n",
      "episode :  12\n",
      "current step :  219\n",
      "reward :  -0.34541896871556693\n",
      "episode :  12\n",
      "current step :  220\n",
      "reward :  -0.35224152069492004\n",
      "episode :  12\n",
      "current step :  221\n",
      "reward :  -0.336400334072\n",
      "episode :  12\n",
      "current step :  222\n",
      "reward :  -0.358383919432626\n",
      "episode :  12\n",
      "current step :  223\n",
      "reward :  -0.4465714559852629\n",
      "episode :  12\n",
      "current step :  224\n",
      "reward :  -0.5403004020404528\n",
      "episode :  12\n",
      "current step :  225\n",
      "reward :  -0.48650668279490317\n",
      "episode :  12\n",
      "current step :  226\n",
      "reward :  -0.41949295438390044\n",
      "episode :  12\n",
      "current step :  227\n",
      "reward :  -0.5744334201553131\n",
      "episode :  12\n",
      "current step :  228\n",
      "reward :  -0.5557806181142969\n",
      "episode :  12\n",
      "current step :  229\n",
      "reward :  -0.4745782062131356\n",
      "episode :  12\n",
      "current step :  230\n",
      "reward :  -0.42245390846286723\n",
      "episode :  12\n",
      "current step :  231\n",
      "reward :  -0.4105508516177483\n",
      "episode :  12\n",
      "current step :  232\n",
      "reward :  -0.3070903460178821\n",
      "episode :  12\n",
      "current step :  233\n",
      "reward :  -0.44584466275475637\n",
      "episode :  12\n",
      "current step :  234\n",
      "reward :  -0.36220592693104176\n",
      "episode :  12\n",
      "current step :  235\n",
      "reward :  -0.3368451172686885\n",
      "episode :  12\n",
      "current step :  236\n",
      "reward :  -0.41967184686977016\n",
      "episode :  12\n",
      "current step :  237\n",
      "reward :  -0.5171199133030563\n",
      "episode :  12\n",
      "current step :  238\n",
      "reward :  -0.4785110553248129\n",
      "episode :  12\n",
      "current step :  239\n",
      "reward :  -0.41496279378632894\n",
      "episode :  12\n",
      "current step :  240\n",
      "reward :  -0.39364156713125575\n",
      "episode :  12\n",
      "current step :  241\n",
      "reward :  -0.4225638466521508\n",
      "episode :  12\n",
      "current step :  242\n",
      "reward :  -0.4156508283569209\n",
      "episode :  12\n",
      "current step :  243\n",
      "reward :  -0.3412110201868726\n",
      "episode :  12\n",
      "current step :  244\n",
      "reward :  -0.3158268111422638\n",
      "episode :  12\n",
      "current step :  245\n",
      "reward :  -0.33374863449782133\n",
      "episode :  12\n",
      "current step :  246\n",
      "reward :  -0.3394017253001832\n",
      "episode :  12\n",
      "current step :  247\n",
      "reward :  -0.3424200398122374\n",
      "episode :  12\n",
      "current step :  248\n",
      "reward :  -0.478392119990824\n",
      "episode :  12\n",
      "current step :  249\n",
      "reward :  -0.5618870296947776\n",
      "episode :  12\n",
      "current step :  250\n",
      "reward :  -0.49570355642338126\n",
      "episode :  12\n",
      "current step :  251\n",
      "reward :  -0.4478818185285175\n",
      "episode :  12\n",
      "current step :  252\n",
      "reward :  -0.4133627465954659\n",
      "episode :  12\n",
      "current step :  253\n",
      "reward :  -0.358184584646245\n",
      "episode :  12\n",
      "current step :  254\n",
      "reward :  -0.41731573057293114\n",
      "episode :  12\n",
      "current step :  255\n",
      "reward :  -0.36859087659538525\n",
      "episode :  12\n",
      "current step :  256\n",
      "reward :  -0.4211997676169622\n",
      "episode :  12\n",
      "current step :  257\n",
      "reward :  -0.5124790267553396\n",
      "episode :  12\n",
      "current step :  258\n",
      "reward :  -0.4326166434691283\n",
      "episode :  12\n",
      "current step :  259\n",
      "reward :  -0.34882070482123106\n",
      "episode :  12\n",
      "current step :  260\n",
      "reward :  -0.30701911949616434\n",
      "episode :  12\n",
      "current step :  261\n",
      "reward :  -0.3654622938686191\n",
      "episode :  12\n",
      "current step :  262\n",
      "reward :  -0.32975909775167805\n",
      "episode :  12\n",
      "current step :  263\n",
      "reward :  -0.3557719726957561\n",
      "episode :  12\n",
      "current step :  264\n",
      "reward :  -0.37085135698974103\n",
      "episode :  12\n",
      "current step :  265\n",
      "reward :  -0.37379595760282214\n",
      "episode :  12\n",
      "current step :  266\n",
      "reward :  -0.35102305839930825\n",
      "episode :  12\n",
      "current step :  267\n",
      "reward :  -0.43816882072206254\n",
      "episode :  12\n",
      "current step :  268\n",
      "reward :  -0.43457130913286457\n",
      "episode :  12\n",
      "current step :  269\n",
      "reward :  -0.3548251855243357\n",
      "episode :  12\n",
      "current step :  270\n",
      "reward :  -0.4647500804917239\n",
      "episode :  12\n",
      "current step :  271\n",
      "reward :  -0.42013015803811943\n",
      "episode :  12\n",
      "current step :  272\n",
      "reward :  -0.35815569316227935\n",
      "episode :  12\n",
      "current step :  273\n",
      "reward :  -0.33016504306492817\n",
      "episode :  12\n",
      "current step :  274\n",
      "reward :  -0.33860953815112765\n",
      "episode :  12\n",
      "current step :  275\n",
      "reward :  -0.28017235258860856\n",
      "episode :  12\n",
      "current step :  276\n",
      "reward :  -0.3002717932753929\n",
      "episode :  12\n",
      "current step :  277\n",
      "reward :  -0.3623644675786513\n",
      "episode :  12\n",
      "current step :  278\n",
      "reward :  -0.2415205543689324\n",
      "episode :  12\n",
      "current step :  279\n",
      "reward :  -0.31752046533275813\n",
      "episode :  12\n",
      "current step :  280\n",
      "reward :  -0.4306163438955197\n",
      "episode :  12\n",
      "current step :  281\n",
      "reward :  -0.3578262703873295\n",
      "episode :  12\n",
      "current step :  282\n",
      "reward :  -0.3378293326458102\n",
      "episode :  12\n",
      "current step :  283\n",
      "reward :  -0.44829992247979367\n",
      "episode :  12\n",
      "current step :  284\n",
      "reward :  -0.32376487785597424\n",
      "episode :  12\n",
      "current step :  285\n",
      "reward :  -0.3566964966265541\n",
      "episode :  13\n",
      "current step :  0\n",
      "reward :  -0.34279379656846176\n",
      "episode :  13\n",
      "current step :  1\n",
      "reward :  -0.29670691107089914\n",
      "episode :  13\n",
      "current step :  2\n",
      "reward :  -0.28075489188897246\n",
      "episode :  13\n",
      "current step :  3\n",
      "reward :  -0.1491306486217312\n",
      "episode :  13\n",
      "current step :  4\n",
      "reward :  -0.3707858928310856\n",
      "episode :  13\n",
      "current step :  5\n",
      "reward :  -0.5600232176552028\n",
      "episode :  13\n",
      "current step :  6\n",
      "reward :  -0.5338560102288644\n",
      "episode :  13\n",
      "current step :  7\n",
      "reward :  -0.44221450901651993\n",
      "episode :  13\n",
      "current step :  8\n",
      "reward :  -0.4142337753902028\n",
      "episode :  13\n",
      "current step :  9\n",
      "reward :  -0.31765770886725964\n",
      "episode :  13\n",
      "current step :  10\n",
      "reward :  -0.37417062872075385\n",
      "episode :  13\n",
      "current step :  11\n",
      "reward :  -0.24487585953113591\n",
      "episode :  13\n",
      "current step :  12\n",
      "reward :  -0.27319363009454195\n",
      "episode :  13\n",
      "current step :  13\n",
      "reward :  -0.20911417143941533\n",
      "episode :  13\n",
      "current step :  14\n",
      "reward :  -0.19402832502920012\n",
      "episode :  13\n",
      "current step :  15\n",
      "reward :  -0.26392551103787343\n",
      "episode :  13\n",
      "current step :  16\n",
      "reward :  -0.19107016083035497\n",
      "episode :  13\n",
      "current step :  17\n",
      "reward :  -0.3213282259362067\n",
      "episode :  13\n",
      "current step :  18\n",
      "reward :  -0.3535692304670381\n",
      "episode :  13\n",
      "current step :  19\n",
      "reward :  -0.1847598811718572\n",
      "episode :  13\n",
      "current step :  20\n",
      "reward :  -0.16659730443089216\n",
      "episode :  13\n",
      "current step :  21\n",
      "reward :  -0.12260339752464565\n",
      "episode :  13\n",
      "current step :  22\n",
      "reward :  -0.2186989600886308\n",
      "episode :  13\n",
      "current step :  23\n",
      "reward :  -0.3114801857727287\n",
      "episode :  13\n",
      "current step :  24\n",
      "reward :  -0.2980311387818868\n",
      "episode :  13\n",
      "current step :  25\n",
      "reward :  -0.1468992923780128\n",
      "episode :  13\n",
      "current step :  26\n",
      "reward :  -0.16966690803802026\n",
      "episode :  13\n",
      "current step :  27\n",
      "reward :  -0.22557439758841746\n",
      "episode :  13\n",
      "current step :  28\n",
      "reward :  -0.1838933939602759\n",
      "episode :  13\n",
      "current step :  29\n",
      "reward :  -0.3648153199440395\n",
      "episode :  13\n",
      "current step :  30\n",
      "reward :  -0.38018345460849146\n",
      "episode :  13\n",
      "current step :  31\n",
      "reward :  -0.44507719301945936\n",
      "episode :  13\n",
      "current step :  32\n",
      "reward :  -0.3954113722354896\n",
      "episode :  13\n",
      "current step :  33\n",
      "reward :  -0.3179282849955098\n",
      "episode :  13\n",
      "current step :  34\n",
      "reward :  -0.5628352086557282\n",
      "episode :  13\n",
      "current step :  35\n",
      "reward :  -0.6353677517136542\n",
      "episode :  13\n",
      "current step :  36\n",
      "reward :  -0.5545139595982671\n",
      "episode :  13\n",
      "current step :  37\n",
      "reward :  -0.617863752956492\n",
      "episode :  13\n",
      "current step :  38\n",
      "reward :  -0.617661886645982\n",
      "episode :  13\n",
      "current step :  39\n",
      "reward :  -0.5916494193253495\n",
      "episode :  13\n",
      "current step :  40\n",
      "reward :  -0.5640344376835914\n",
      "episode :  13\n",
      "current step :  41\n",
      "reward :  -0.601808138274801\n",
      "episode :  13\n",
      "current step :  42\n",
      "reward :  -0.6315534228126587\n",
      "episode :  13\n",
      "current step :  43\n",
      "reward :  -0.5919563515259053\n",
      "episode :  13\n",
      "current step :  44\n",
      "reward :  -0.5623804721218598\n",
      "episode :  13\n",
      "current step :  45\n",
      "reward :  -0.5915831225042225\n",
      "episode :  13\n",
      "current step :  46\n",
      "reward :  -0.5921240174256636\n",
      "episode :  13\n",
      "current step :  47\n",
      "reward :  -0.6506532052812081\n",
      "episode :  13\n",
      "current step :  48\n",
      "reward :  -0.6112938121460137\n",
      "episode :  13\n",
      "current step :  49\n",
      "reward :  -0.6326107357293028\n",
      "episode :  13\n",
      "current step :  50\n",
      "reward :  -0.660824010352821\n",
      "episode :  13\n",
      "current step :  51\n",
      "reward :  -0.6039236389209922\n",
      "episode :  13\n",
      "current step :  52\n",
      "reward :  -0.5483926668601942\n",
      "episode :  13\n",
      "current step :  53\n",
      "reward :  -0.48776328442194405\n",
      "episode :  13\n",
      "current step :  54\n",
      "reward :  -0.46323352681998203\n",
      "episode :  13\n",
      "current step :  55\n",
      "reward :  -0.4712870597065762\n",
      "episode :  13\n",
      "current step :  56\n",
      "reward :  -0.5413800441863537\n",
      "episode :  13\n",
      "current step :  57\n",
      "reward :  -0.48214405531665433\n",
      "episode :  13\n",
      "current step :  58\n",
      "reward :  -0.4970777540882777\n",
      "episode :  13\n",
      "current step :  59\n",
      "reward :  -0.42927950394400355\n",
      "episode :  13\n",
      "current step :  60\n",
      "reward :  -0.49151986968507105\n",
      "episode :  13\n",
      "current step :  61\n",
      "reward :  -0.4913549678051453\n",
      "episode :  13\n",
      "current step :  62\n",
      "reward :  -0.5038638973360687\n",
      "episode :  13\n",
      "current step :  63\n",
      "reward :  -0.5926881478457048\n",
      "episode :  13\n",
      "current step :  64\n",
      "reward :  -0.603241528738916\n",
      "episode :  13\n",
      "current step :  65\n",
      "reward :  -0.6650898574241864\n",
      "episode :  13\n",
      "current step :  66\n",
      "reward :  -0.7129693674682418\n",
      "episode :  13\n",
      "current step :  67\n",
      "reward :  -0.6932428553699632\n",
      "episode :  13\n",
      "current step :  68\n",
      "reward :  -0.6471400213930072\n",
      "episode :  13\n",
      "current step :  69\n",
      "reward :  -0.6259204234123888\n",
      "episode :  13\n",
      "current step :  70\n",
      "reward :  -0.5339081629610969\n",
      "episode :  13\n",
      "current step :  71\n",
      "reward :  -0.5266871480384061\n",
      "episode :  13\n",
      "current step :  72\n",
      "reward :  -0.45063131611045076\n",
      "episode :  13\n",
      "current step :  73\n",
      "reward :  -0.5047551065384271\n",
      "episode :  13\n",
      "current step :  74\n",
      "reward :  -0.505012318122845\n",
      "episode :  13\n",
      "current step :  75\n",
      "reward :  -0.5629220747668855\n",
      "episode :  13\n",
      "current step :  76\n",
      "reward :  -0.6149832521208671\n",
      "episode :  13\n",
      "current step :  77\n",
      "reward :  -0.5820956962474564\n",
      "episode :  13\n",
      "current step :  78\n",
      "reward :  -0.60220023015545\n",
      "episode :  13\n",
      "current step :  79\n",
      "reward :  -0.5426278438123486\n",
      "episode :  13\n",
      "current step :  80\n",
      "reward :  -0.5743602337898911\n",
      "episode :  13\n",
      "current step :  81\n",
      "reward :  -0.6406312720987914\n",
      "episode :  13\n",
      "current step :  82\n",
      "reward :  -0.6312320692212933\n",
      "episode :  13\n",
      "current step :  83\n",
      "reward :  -0.5874728317269299\n",
      "episode :  13\n",
      "current step :  84\n",
      "reward :  -0.4358410198231387\n",
      "episode :  13\n",
      "current step :  85\n",
      "reward :  -0.5119190675261022\n",
      "episode :  13\n",
      "current step :  86\n",
      "reward :  -0.4572970126660647\n",
      "episode :  13\n",
      "current step :  87\n",
      "reward :  -0.4838508463452487\n",
      "episode :  13\n",
      "current step :  88\n",
      "reward :  -0.4888566272727181\n",
      "episode :  13\n",
      "current step :  89\n",
      "reward :  -0.406775428089492\n",
      "episode :  13\n",
      "current step :  90\n",
      "reward :  -0.4219770032358198\n",
      "episode :  13\n",
      "current step :  91\n",
      "reward :  -0.4565136988240412\n",
      "episode :  13\n",
      "current step :  92\n",
      "reward :  -0.29307455199315907\n",
      "episode :  13\n",
      "current step :  93\n",
      "reward :  -0.1977208742869319\n",
      "episode :  13\n",
      "current step :  94\n",
      "reward :  -0.16820836818777526\n",
      "episode :  13\n",
      "current step :  95\n",
      "reward :  -0.22253252494879885\n",
      "episode :  13\n",
      "current step :  96\n",
      "reward :  -0.11041422536815519\n",
      "episode :  13\n",
      "current step :  97\n",
      "reward :  -0.17481668803501263\n",
      "episode :  13\n",
      "current step :  98\n",
      "reward :  -0.2834999257194489\n",
      "episode :  13\n",
      "current step :  99\n",
      "reward :  -0.38436305325667947\n",
      "episode :  13\n",
      "current step :  100\n",
      "reward :  -0.4251061992484313\n",
      "episode :  13\n",
      "current step :  101\n",
      "reward :  -0.2662842687994986\n",
      "episode :  13\n",
      "current step :  102\n",
      "reward :  -0.30794434506261464\n",
      "episode :  13\n",
      "current step :  103\n",
      "reward :  -0.32237257147163156\n",
      "episode :  13\n",
      "current step :  104\n",
      "reward :  -0.29253256354640883\n",
      "episode :  13\n",
      "current step :  105\n",
      "reward :  -0.2791582093251148\n",
      "episode :  13\n",
      "current step :  106\n",
      "reward :  -0.2638052437733057\n",
      "episode :  13\n",
      "current step :  107\n",
      "reward :  -0.34470325172292404\n",
      "episode :  13\n",
      "current step :  108\n",
      "reward :  -0.33339858890310387\n",
      "episode :  13\n",
      "current step :  109\n",
      "reward :  -0.09703897050612412\n",
      "episode :  13\n",
      "current step :  110\n",
      "reward :  -0.20700759351474926\n",
      "episode :  13\n",
      "current step :  111\n",
      "reward :  -0.2640222206655426\n",
      "episode :  13\n",
      "current step :  112\n",
      "reward :  -0.3703523102019713\n",
      "episode :  13\n",
      "current step :  113\n",
      "reward :  -0.4478346791254651\n",
      "episode :  13\n",
      "current step :  114\n",
      "reward :  -0.3743790332061198\n",
      "episode :  13\n",
      "current step :  115\n",
      "reward :  -0.3670595525741652\n",
      "episode :  13\n",
      "current step :  116\n",
      "reward :  -0.4440134215188909\n",
      "episode :  13\n",
      "current step :  117\n",
      "reward :  -0.41973573950108706\n",
      "episode :  13\n",
      "current step :  118\n",
      "reward :  -0.41677692995852106\n",
      "episode :  13\n",
      "current step :  119\n",
      "reward :  -0.2983897079904635\n",
      "episode :  13\n",
      "current step :  120\n",
      "reward :  -0.1324426070090074\n",
      "episode :  13\n",
      "current step :  121\n",
      "reward :  -0.21524568325184984\n",
      "episode :  13\n",
      "current step :  122\n",
      "reward :  -0.2348786904616357\n",
      "episode :  13\n",
      "current step :  123\n",
      "reward :  -0.2656565420069043\n",
      "episode :  13\n",
      "current step :  124\n",
      "reward :  -0.19748466253744268\n",
      "episode :  13\n",
      "current step :  125\n",
      "reward :  -0.16870685786452408\n",
      "episode :  13\n",
      "current step :  126\n",
      "reward :  -0.3428413997346649\n",
      "episode :  13\n",
      "current step :  127\n",
      "reward :  -0.14260093001332552\n",
      "episode :  13\n",
      "current step :  128\n",
      "reward :  -0.21784498176186107\n",
      "episode :  13\n",
      "current step :  129\n",
      "reward :  -0.22177943137523937\n",
      "episode :  13\n",
      "current step :  130\n",
      "reward :  -0.2642470569525042\n",
      "episode :  13\n",
      "current step :  131\n",
      "reward :  -0.14843529196800065\n",
      "episode :  13\n",
      "current step :  132\n",
      "reward :  -0.16100899901699173\n",
      "episode :  13\n",
      "current step :  133\n",
      "reward :  -0.21188952983035084\n",
      "episode :  13\n",
      "current step :  134\n",
      "reward :  -0.29287575192491105\n",
      "episode :  13\n",
      "current step :  135\n",
      "reward :  -0.3069054105359007\n",
      "episode :  13\n",
      "current step :  136\n",
      "reward :  -0.374502591074098\n",
      "episode :  13\n",
      "current step :  137\n",
      "reward :  -0.418889816169861\n",
      "episode :  13\n",
      "current step :  138\n",
      "reward :  -0.2958247240928552\n",
      "episode :  13\n",
      "current step :  139\n",
      "reward :  -0.2990993467799439\n",
      "episode :  13\n",
      "current step :  140\n",
      "reward :  -0.3773133436630568\n",
      "episode :  13\n",
      "current step :  141\n",
      "reward :  -0.32871258404492487\n",
      "episode :  13\n",
      "current step :  142\n",
      "reward :  -0.16868129104156582\n",
      "episode :  13\n",
      "current step :  143\n",
      "reward :  -0.30910610971230734\n",
      "episode :  13\n",
      "current step :  144\n",
      "reward :  -0.3096055923688439\n",
      "episode :  13\n",
      "current step :  145\n",
      "reward :  -0.2990557469185269\n",
      "episode :  13\n",
      "current step :  146\n",
      "reward :  -0.46654682202601716\n",
      "episode :  13\n",
      "current step :  147\n",
      "reward :  -0.5246862419659818\n",
      "episode :  13\n",
      "current step :  148\n",
      "reward :  -0.5448051552507681\n",
      "episode :  13\n",
      "current step :  149\n",
      "reward :  -0.4418385017167865\n",
      "episode :  13\n",
      "current step :  150\n",
      "reward :  -0.3940339441072466\n",
      "episode :  13\n",
      "current step :  151\n",
      "reward :  -0.5085900250004095\n",
      "episode :  13\n",
      "current step :  152\n",
      "reward :  -0.5527087865804506\n",
      "episode :  13\n",
      "current step :  153\n",
      "reward :  -0.49499948015271694\n",
      "episode :  13\n",
      "current step :  154\n",
      "reward :  -0.4889591558398043\n",
      "episode :  13\n",
      "current step :  155\n",
      "reward :  -0.5939041558660945\n",
      "episode :  13\n",
      "current step :  156\n",
      "reward :  -0.5939055216828357\n",
      "episode :  13\n",
      "current step :  157\n",
      "reward :  -0.5783802969205097\n",
      "episode :  13\n",
      "current step :  158\n",
      "reward :  -0.5423899257653405\n",
      "episode :  13\n",
      "current step :  159\n",
      "reward :  -0.5591875752721962\n",
      "episode :  13\n",
      "current step :  160\n",
      "reward :  -0.5640649623058018\n",
      "episode :  13\n",
      "current step :  161\n",
      "reward :  -0.6173657997522888\n",
      "episode :  13\n",
      "current step :  162\n",
      "reward :  -0.49509228420862733\n",
      "episode :  13\n",
      "current step :  163\n",
      "reward :  -0.4164724747374517\n",
      "episode :  13\n",
      "current step :  164\n",
      "reward :  -0.3979872970046153\n",
      "episode :  13\n",
      "current step :  165\n",
      "reward :  -0.3944825814290069\n",
      "episode :  13\n",
      "current step :  166\n",
      "reward :  -0.4628830515210867\n",
      "episode :  13\n",
      "current step :  167\n",
      "reward :  -0.497664064634518\n",
      "episode :  13\n",
      "current step :  168\n",
      "reward :  -0.5619950331419346\n",
      "episode :  13\n",
      "current step :  169\n",
      "reward :  -0.5783918212357774\n",
      "episode :  13\n",
      "current step :  170\n",
      "reward :  -0.5307451892171551\n",
      "episode :  13\n",
      "current step :  171\n",
      "reward :  -0.5218053617150129\n",
      "episode :  13\n",
      "current step :  172\n",
      "reward :  -0.5884217612114022\n",
      "episode :  13\n",
      "current step :  173\n",
      "reward :  -0.6153336584242932\n",
      "episode :  13\n",
      "current step :  174\n",
      "reward :  -0.567941100453247\n",
      "episode :  13\n",
      "current step :  175\n",
      "reward :  -0.5419732100535002\n",
      "episode :  13\n",
      "current step :  176\n",
      "reward :  -0.6222149566985045\n",
      "episode :  13\n",
      "current step :  177\n",
      "reward :  -0.6344663662243198\n",
      "episode :  13\n",
      "current step :  178\n",
      "reward :  -0.6245162944920692\n",
      "episode :  13\n",
      "current step :  179\n",
      "reward :  -0.6437274112266445\n",
      "episode :  13\n",
      "current step :  180\n",
      "reward :  -0.6233274893156373\n",
      "episode :  13\n",
      "current step :  181\n",
      "reward :  -0.6110745426561818\n",
      "episode :  13\n",
      "current step :  182\n",
      "reward :  -0.5545346576733069\n",
      "episode :  13\n",
      "current step :  183\n",
      "reward :  -0.5747945112153006\n",
      "episode :  13\n",
      "current step :  184\n",
      "reward :  -0.578478010884381\n",
      "episode :  13\n",
      "current step :  185\n",
      "reward :  -0.5191031698294074\n",
      "episode :  13\n",
      "current step :  186\n",
      "reward :  -0.5053679488671957\n",
      "episode :  13\n",
      "current step :  187\n",
      "reward :  -0.5826272544308903\n",
      "episode :  13\n",
      "current step :  188\n",
      "reward :  -0.614787128095402\n",
      "episode :  13\n",
      "current step :  189\n",
      "reward :  -0.6580110199524059\n",
      "episode :  13\n",
      "current step :  190\n",
      "reward :  -0.6368511802599738\n",
      "episode :  13\n",
      "current step :  191\n",
      "reward :  -0.4632349231820904\n",
      "episode :  13\n",
      "current step :  192\n",
      "reward :  -0.487961225025975\n",
      "episode :  13\n",
      "current step :  193\n",
      "reward :  -0.5737488573374474\n",
      "episode :  13\n",
      "current step :  194\n",
      "reward :  -0.5669053829839061\n",
      "episode :  13\n",
      "current step :  195\n",
      "reward :  -0.5200596922427281\n",
      "episode :  13\n",
      "current step :  196\n",
      "reward :  -0.5854141517826799\n",
      "episode :  13\n",
      "current step :  197\n",
      "reward :  -0.5920574111958564\n",
      "episode :  13\n",
      "current step :  198\n",
      "reward :  -0.5878727574846151\n",
      "episode :  13\n",
      "current step :  199\n",
      "reward :  -0.5962381503177386\n",
      "episode :  13\n",
      "current step :  200\n",
      "reward :  -0.6298611156852707\n",
      "episode :  13\n",
      "current step :  201\n",
      "reward :  -0.6815016615568708\n",
      "episode :  13\n",
      "current step :  202\n",
      "reward :  -0.7370086797583861\n",
      "episode :  13\n",
      "current step :  203\n",
      "reward :  -0.634448170445916\n",
      "episode :  13\n",
      "current step :  204\n",
      "reward :  -0.5959330242017103\n",
      "episode :  13\n",
      "current step :  205\n",
      "reward :  -0.5962879432325892\n",
      "episode :  13\n",
      "current step :  206\n",
      "reward :  -0.3677430496867294\n",
      "episode :  13\n",
      "current step :  207\n",
      "reward :  -0.34440736020682744\n",
      "episode :  13\n",
      "current step :  208\n",
      "reward :  -0.4471843667245006\n",
      "episode :  13\n",
      "current step :  209\n",
      "reward :  -0.4835937530199815\n",
      "episode :  13\n",
      "current step :  210\n",
      "reward :  -0.5032731588871475\n",
      "episode :  13\n",
      "current step :  211\n",
      "reward :  -0.493291396927656\n",
      "episode :  13\n",
      "current step :  212\n",
      "reward :  -0.5332632290903156\n",
      "episode :  13\n",
      "current step :  213\n",
      "reward :  -0.5512349853436882\n",
      "episode :  13\n",
      "current step :  214\n",
      "reward :  -0.4098192524974379\n",
      "episode :  13\n",
      "current step :  215\n",
      "reward :  -0.3392560996712843\n",
      "episode :  13\n",
      "current step :  216\n",
      "reward :  -0.4008088380376486\n",
      "episode :  13\n",
      "current step :  217\n",
      "reward :  -0.30616811422375567\n",
      "episode :  13\n",
      "current step :  218\n",
      "reward :  -0.39753860595278506\n",
      "episode :  13\n",
      "current step :  219\n",
      "reward :  -0.43844596549646514\n",
      "episode :  13\n",
      "current step :  220\n",
      "reward :  -0.4735477877896026\n",
      "episode :  13\n",
      "current step :  221\n",
      "reward :  -0.5550232130899787\n",
      "episode :  13\n",
      "current step :  222\n",
      "reward :  -0.49714519054019857\n",
      "episode :  13\n",
      "current step :  223\n",
      "reward :  -0.34845014960519344\n",
      "episode :  13\n",
      "current step :  224\n",
      "reward :  -0.274895776673792\n",
      "episode :  13\n",
      "current step :  225\n",
      "reward :  -0.4918943916621941\n",
      "episode :  13\n",
      "current step :  226\n",
      "reward :  -0.3850242339611501\n",
      "episode :  13\n",
      "current step :  227\n",
      "reward :  -0.5572038444826246\n",
      "episode :  13\n",
      "current step :  228\n",
      "reward :  -0.3210413154078144\n",
      "episode :  13\n",
      "current step :  229\n",
      "reward :  -0.42599434740051373\n",
      "episode :  13\n",
      "current step :  230\n",
      "reward :  -0.3207157612632373\n",
      "episode :  13\n",
      "current step :  231\n",
      "reward :  -0.4363709683161614\n",
      "episode :  13\n",
      "current step :  232\n",
      "reward :  -0.45539297014428964\n",
      "episode :  13\n",
      "current step :  233\n",
      "reward :  -0.4374839035017271\n",
      "episode :  13\n",
      "current step :  234\n",
      "reward :  -0.3738158791985253\n",
      "episode :  13\n",
      "current step :  235\n",
      "reward :  -0.20784225638054715\n",
      "episode :  13\n",
      "current step :  236\n",
      "reward :  -0.44515446179911644\n",
      "episode :  13\n",
      "current step :  237\n",
      "reward :  -0.37906979722742423\n",
      "episode :  13\n",
      "current step :  238\n",
      "reward :  -0.3490190936295229\n",
      "episode :  13\n",
      "current step :  239\n",
      "reward :  -0.4005659174513081\n",
      "episode :  13\n",
      "current step :  240\n",
      "reward :  -0.3834023767622619\n",
      "episode :  13\n",
      "current step :  241\n",
      "reward :  -0.4651967431720538\n",
      "episode :  13\n",
      "current step :  242\n",
      "reward :  -0.5976218163875142\n",
      "episode :  13\n",
      "current step :  243\n",
      "reward :  -0.437972182189557\n",
      "episode :  13\n",
      "current step :  244\n",
      "reward :  -0.4239787467895112\n",
      "episode :  13\n",
      "current step :  245\n",
      "reward :  -0.3762245070841495\n",
      "episode :  13\n",
      "current step :  246\n",
      "reward :  -0.2690632711950122\n",
      "episode :  13\n",
      "current step :  247\n",
      "reward :  -0.24585709467106273\n",
      "episode :  13\n",
      "current step :  248\n",
      "reward :  -0.46137949113528276\n",
      "episode :  13\n",
      "current step :  249\n",
      "reward :  -0.38627475097315084\n",
      "episode :  13\n",
      "current step :  250\n",
      "reward :  -0.3352580386463386\n",
      "episode :  13\n",
      "current step :  251\n",
      "reward :  -0.14442849420398243\n",
      "episode :  13\n",
      "current step :  252\n",
      "reward :  -0.35633375717612414\n",
      "episode :  13\n",
      "current step :  253\n",
      "reward :  -0.4379051587876776\n",
      "episode :  13\n",
      "current step :  254\n",
      "reward :  -0.2803437835702355\n",
      "episode :  13\n",
      "current step :  255\n",
      "reward :  -0.3440763856091104\n",
      "episode :  13\n",
      "current step :  256\n",
      "reward :  -0.26496895400460074\n",
      "episode :  13\n",
      "current step :  257\n",
      "reward :  -0.14865394500160317\n",
      "episode :  13\n",
      "current step :  258\n",
      "reward :  -0.26371519209707084\n",
      "episode :  13\n",
      "current step :  259\n",
      "reward :  -0.4264222175953853\n",
      "episode :  13\n",
      "current step :  260\n",
      "reward :  -0.36041830930541013\n",
      "episode :  13\n",
      "current step :  261\n",
      "reward :  -0.351585263019362\n",
      "episode :  13\n",
      "current step :  262\n",
      "reward :  -0.2691889910133879\n",
      "episode :  13\n",
      "current step :  263\n",
      "reward :  -0.19288775888577459\n",
      "episode :  13\n",
      "current step :  264\n",
      "reward :  -0.24070081945308924\n",
      "episode :  13\n",
      "current step :  265\n",
      "reward :  -0.34707609301979103\n",
      "episode :  13\n",
      "current step :  266\n",
      "reward :  -0.35259023841422427\n",
      "episode :  13\n",
      "current step :  267\n",
      "reward :  -0.4006446349305015\n",
      "episode :  13\n",
      "current step :  268\n",
      "reward :  -0.40796402369450363\n",
      "episode :  13\n",
      "current step :  269\n",
      "reward :  -0.4579493538770745\n",
      "episode :  13\n",
      "current step :  270\n",
      "reward :  -0.32873413910437144\n",
      "episode :  13\n",
      "current step :  271\n",
      "reward :  -0.31505676751249295\n",
      "episode :  13\n",
      "current step :  272\n",
      "reward :  -0.3185925560206568\n",
      "episode :  13\n",
      "current step :  273\n",
      "reward :  -0.3364829549524549\n",
      "episode :  13\n",
      "current step :  274\n",
      "reward :  -0.18666174907141408\n",
      "episode :  13\n",
      "current step :  275\n",
      "reward :  -0.23422350344535153\n",
      "episode :  13\n",
      "current step :  276\n",
      "reward :  -0.302318644015877\n",
      "episode :  13\n",
      "current step :  277\n",
      "reward :  -0.27481423489459395\n",
      "episode :  13\n",
      "current step :  278\n",
      "reward :  -0.2628443500192579\n",
      "episode :  13\n",
      "current step :  279\n",
      "reward :  -0.3237403866941635\n",
      "episode :  13\n",
      "current step :  280\n",
      "reward :  -0.3506810548985775\n",
      "episode :  13\n",
      "current step :  281\n",
      "reward :  -0.29137703961027994\n",
      "episode :  13\n",
      "current step :  282\n",
      "reward :  -0.20363687141860234\n",
      "episode :  13\n",
      "current step :  283\n",
      "reward :  -0.45141796229626896\n",
      "episode :  13\n",
      "current step :  284\n",
      "reward :  -0.31751345194277475\n",
      "episode :  13\n",
      "current step :  285\n",
      "reward :  -0.3411173521756076\n",
      "episode :  14\n",
      "current step :  0\n",
      "reward :  -0.17001756155384898\n",
      "episode :  14\n",
      "current step :  1\n",
      "reward :  -0.1808883953421875\n",
      "episode :  14\n",
      "current step :  2\n",
      "reward :  -0.45113797652280296\n",
      "episode :  14\n",
      "current step :  3\n",
      "reward :  -0.5631964624993226\n",
      "episode :  14\n",
      "current step :  4\n",
      "reward :  -0.4952662793368207\n",
      "episode :  14\n",
      "current step :  5\n",
      "reward :  -0.32056027515432844\n",
      "episode :  14\n",
      "current step :  6\n",
      "reward :  -0.49029508043319014\n",
      "episode :  14\n",
      "current step :  7\n",
      "reward :  -0.3602145979096699\n",
      "episode :  14\n",
      "current step :  8\n",
      "reward :  -0.35764949137785224\n",
      "episode :  14\n",
      "current step :  9\n",
      "reward :  -0.21495112990327234\n",
      "episode :  14\n",
      "current step :  10\n",
      "reward :  -0.31147158393084706\n",
      "episode :  14\n",
      "current step :  11\n",
      "reward :  -0.36999887814247484\n",
      "episode :  14\n",
      "current step :  12\n",
      "reward :  -0.4052444950006201\n",
      "episode :  14\n",
      "current step :  13\n",
      "reward :  -0.3670219370132023\n",
      "episode :  14\n",
      "current step :  14\n",
      "reward :  -0.3679726010945837\n",
      "episode :  14\n",
      "current step :  15\n",
      "reward :  -0.37403488897343123\n",
      "episode :  14\n",
      "current step :  16\n",
      "reward :  -0.19699194776006448\n",
      "episode :  14\n",
      "current step :  17\n",
      "reward :  -0.2694070273529422\n",
      "episode :  14\n",
      "current step :  18\n",
      "reward :  -0.24920226859954303\n",
      "episode :  14\n",
      "current step :  19\n",
      "reward :  -0.32936038191786093\n",
      "episode :  14\n",
      "current step :  20\n",
      "reward :  -0.3988437309587305\n",
      "episode :  14\n",
      "current step :  21\n",
      "reward :  -0.4254479155260812\n",
      "episode :  14\n",
      "current step :  22\n",
      "reward :  -0.19953039100691314\n",
      "episode :  14\n",
      "current step :  23\n",
      "reward :  -0.20998438107839998\n",
      "episode :  14\n",
      "current step :  24\n",
      "reward :  -0.31664746797064725\n",
      "episode :  14\n",
      "current step :  25\n",
      "reward :  -0.28974086735965954\n",
      "episode :  14\n",
      "current step :  26\n",
      "reward :  -0.33401109274872565\n",
      "episode :  14\n",
      "current step :  27\n",
      "reward :  -0.34379349036192564\n",
      "episode :  14\n",
      "current step :  28\n",
      "reward :  -0.3004555677949405\n",
      "episode :  14\n",
      "current step :  29\n",
      "reward :  -0.44384372871249794\n",
      "episode :  14\n",
      "current step :  30\n",
      "reward :  -0.4933777758025473\n",
      "episode :  14\n",
      "current step :  31\n",
      "reward :  -0.5276598905494329\n",
      "episode :  14\n",
      "current step :  32\n",
      "reward :  -0.5403330579473876\n",
      "episode :  14\n",
      "current step :  33\n",
      "reward :  -0.5883070823336077\n",
      "episode :  14\n",
      "current step :  34\n",
      "reward :  -0.4269267764900561\n",
      "episode :  14\n",
      "current step :  35\n",
      "reward :  -0.4620742532344054\n",
      "episode :  14\n",
      "current step :  36\n",
      "reward :  -0.5291686531001453\n",
      "episode :  14\n",
      "current step :  37\n",
      "reward :  -0.5067109923412144\n",
      "episode :  14\n",
      "current step :  38\n",
      "reward :  -0.5248855688004033\n",
      "episode :  14\n",
      "current step :  39\n",
      "reward :  -0.6100320439399929\n",
      "episode :  14\n",
      "current step :  40\n",
      "reward :  -0.6310653250602405\n",
      "episode :  14\n",
      "current step :  41\n",
      "reward :  -0.6500459846106489\n",
      "episode :  14\n",
      "current step :  42\n",
      "reward :  -0.5930878033888307\n",
      "episode :  14\n",
      "current step :  43\n",
      "reward :  -0.6270987176685056\n",
      "episode :  14\n",
      "current step :  44\n",
      "reward :  -0.632753993338048\n",
      "episode :  14\n",
      "current step :  45\n",
      "reward :  -0.6458463886570878\n",
      "episode :  14\n",
      "current step :  46\n",
      "reward :  -0.6198893035546519\n",
      "episode :  14\n",
      "current step :  47\n",
      "reward :  -0.6071387020548286\n",
      "episode :  14\n",
      "current step :  48\n",
      "reward :  -0.6021170731045892\n",
      "episode :  14\n",
      "current step :  49\n",
      "reward :  -0.565841689805684\n",
      "episode :  14\n",
      "current step :  50\n",
      "reward :  -0.6582123878504406\n",
      "episode :  14\n",
      "current step :  51\n",
      "reward :  -0.5896037765291738\n",
      "episode :  14\n",
      "current step :  52\n",
      "reward :  -0.5253592615544279\n",
      "episode :  14\n",
      "current step :  53\n",
      "reward :  -0.4391307817766158\n",
      "episode :  14\n",
      "current step :  54\n",
      "reward :  -0.6210161032951586\n",
      "episode :  14\n",
      "current step :  55\n",
      "reward :  -0.6219193694665495\n",
      "episode :  14\n",
      "current step :  56\n",
      "reward :  -0.4130084648311748\n",
      "episode :  14\n",
      "current step :  57\n",
      "reward :  -0.5133846671986366\n",
      "episode :  14\n",
      "current step :  58\n",
      "reward :  -0.47357383036703143\n",
      "episode :  14\n",
      "current step :  59\n",
      "reward :  -0.4502997391398312\n",
      "episode :  14\n",
      "current step :  60\n",
      "reward :  -0.4257955808722122\n",
      "episode :  14\n",
      "current step :  61\n",
      "reward :  -0.4319686292179598\n",
      "episode :  14\n",
      "current step :  62\n",
      "reward :  -0.3422896772974168\n",
      "episode :  14\n",
      "current step :  63\n",
      "reward :  -0.5721247605074922\n",
      "episode :  14\n",
      "current step :  64\n",
      "reward :  -0.5720068291745016\n",
      "episode :  14\n",
      "current step :  65\n",
      "reward :  -0.7617738225931521\n",
      "episode :  14\n",
      "current step :  66\n",
      "reward :  -0.7766184757986789\n",
      "episode :  14\n",
      "current step :  67\n",
      "reward :  -0.6887130105892156\n",
      "episode :  14\n",
      "current step :  68\n",
      "reward :  -0.5458718477068942\n",
      "episode :  14\n",
      "current step :  69\n",
      "reward :  -0.5445090385506927\n",
      "episode :  14\n",
      "current step :  70\n",
      "reward :  -0.5975932778622153\n",
      "episode :  14\n",
      "current step :  71\n",
      "reward :  -0.6168545637284503\n",
      "episode :  14\n",
      "current step :  72\n",
      "reward :  -0.5005073920239959\n",
      "episode :  14\n",
      "current step :  73\n",
      "reward :  -0.6622348979447501\n",
      "episode :  14\n",
      "current step :  74\n",
      "reward :  -0.6903545009786569\n",
      "episode :  14\n",
      "current step :  75\n",
      "reward :  -0.6986124277572284\n",
      "episode :  14\n",
      "current step :  76\n",
      "reward :  -0.5992580775572888\n",
      "episode :  14\n",
      "current step :  77\n",
      "reward :  -0.5740141517750845\n",
      "episode :  14\n",
      "current step :  78\n",
      "reward :  -0.510646278051939\n",
      "episode :  14\n",
      "current step :  79\n",
      "reward :  -0.4457106020847718\n",
      "episode :  14\n",
      "current step :  80\n",
      "reward :  -0.5608747531753121\n",
      "episode :  14\n",
      "current step :  81\n",
      "reward :  -0.48269391660942146\n",
      "episode :  14\n",
      "current step :  82\n",
      "reward :  -0.3248024633647567\n",
      "episode :  14\n",
      "current step :  83\n",
      "reward :  -0.447767976648891\n",
      "episode :  14\n",
      "current step :  84\n",
      "reward :  -0.3871888814822654\n",
      "episode :  14\n",
      "current step :  85\n",
      "reward :  -0.29959637837442665\n",
      "episode :  14\n",
      "current step :  86\n",
      "reward :  -0.3369664806798505\n",
      "episode :  14\n",
      "current step :  87\n",
      "reward :  -0.3746616400930097\n",
      "episode :  14\n",
      "current step :  88\n",
      "reward :  -0.1678370410634382\n",
      "episode :  14\n",
      "current step :  89\n",
      "reward :  -0.32199521182527596\n",
      "episode :  14\n",
      "current step :  90\n",
      "reward :  -0.49218816956115047\n",
      "episode :  14\n",
      "current step :  91\n",
      "reward :  -0.4157371861617828\n",
      "episode :  14\n",
      "current step :  92\n",
      "reward :  -0.5003853759322798\n",
      "episode :  14\n",
      "current step :  93\n",
      "reward :  -0.47390491169115573\n",
      "episode :  14\n",
      "current step :  94\n",
      "reward :  -0.2541964643133519\n",
      "episode :  14\n",
      "current step :  95\n",
      "reward :  -0.45440521714750615\n",
      "episode :  14\n",
      "current step :  96\n",
      "reward :  -0.3113407094608599\n",
      "episode :  14\n",
      "current step :  97\n",
      "reward :  -0.3594122521246432\n",
      "episode :  14\n",
      "current step :  98\n",
      "reward :  -0.448560249877705\n",
      "episode :  14\n",
      "current step :  99\n",
      "reward :  -0.4365606832423958\n",
      "episode :  14\n",
      "current step :  100\n",
      "reward :  -0.4653163924065068\n",
      "episode :  14\n",
      "current step :  101\n",
      "reward :  -0.4381542665647023\n",
      "episode :  14\n",
      "current step :  102\n",
      "reward :  -0.3754225851336307\n",
      "episode :  14\n",
      "current step :  103\n",
      "reward :  -0.4484771295325312\n",
      "episode :  14\n",
      "current step :  104\n",
      "reward :  -0.47488544883327\n",
      "episode :  14\n",
      "current step :  105\n",
      "reward :  -0.44384312067498066\n",
      "episode :  14\n",
      "current step :  106\n",
      "reward :  -0.4406427923114749\n",
      "episode :  14\n",
      "current step :  107\n",
      "reward :  -0.37318665380963006\n",
      "episode :  14\n",
      "current step :  108\n",
      "reward :  -0.39008864817175554\n",
      "episode :  14\n",
      "current step :  109\n",
      "reward :  -0.453290414119741\n",
      "episode :  14\n",
      "current step :  110\n",
      "reward :  -0.39865897442318055\n",
      "episode :  14\n",
      "current step :  111\n",
      "reward :  -0.47765462372597\n",
      "episode :  14\n",
      "current step :  112\n",
      "reward :  -0.4452030812569985\n",
      "episode :  14\n",
      "current step :  113\n",
      "reward :  -0.43483442264880906\n",
      "episode :  14\n",
      "current step :  114\n",
      "reward :  -0.47211559647363455\n",
      "episode :  14\n",
      "current step :  115\n",
      "reward :  -0.4701988840118508\n",
      "episode :  14\n",
      "current step :  116\n",
      "reward :  -0.3632316562549529\n",
      "episode :  14\n",
      "current step :  117\n",
      "reward :  -0.4310029131485777\n",
      "episode :  14\n",
      "current step :  118\n",
      "reward :  -0.4570597060218752\n",
      "episode :  14\n",
      "current step :  119\n",
      "reward :  -0.39791717360131157\n",
      "episode :  14\n",
      "current step :  120\n",
      "reward :  -0.22908080340299233\n",
      "episode :  14\n",
      "current step :  121\n",
      "reward :  -0.33035507487618604\n",
      "episode :  14\n",
      "current step :  122\n",
      "reward :  -0.33448282002952856\n",
      "episode :  14\n",
      "current step :  123\n",
      "reward :  -0.25632353680615155\n",
      "episode :  14\n",
      "current step :  124\n",
      "reward :  -0.2894703760122054\n",
      "episode :  14\n",
      "current step :  125\n",
      "reward :  -0.3242282966710388\n",
      "episode :  14\n",
      "current step :  126\n",
      "reward :  -0.2700561886506249\n",
      "episode :  14\n",
      "current step :  127\n",
      "reward :  -0.14431381756821188\n",
      "episode :  14\n",
      "current step :  128\n",
      "reward :  -0.17729031147217336\n",
      "episode :  14\n",
      "current step :  129\n",
      "reward :  -0.2788913112404551\n",
      "episode :  14\n",
      "current step :  130\n",
      "reward :  -0.22326091547173718\n",
      "episode :  14\n",
      "current step :  131\n",
      "reward :  -0.19218142281747871\n",
      "episode :  14\n",
      "current step :  132\n",
      "reward :  -0.36485549058298966\n",
      "episode :  14\n",
      "current step :  133\n",
      "reward :  -0.38184276494913844\n",
      "episode :  14\n",
      "current step :  134\n",
      "reward :  -0.29909634650516054\n",
      "episode :  14\n",
      "current step :  135\n",
      "reward :  -0.31395830128347163\n",
      "episode :  14\n",
      "current step :  136\n",
      "reward :  -0.42925701267385064\n",
      "episode :  14\n",
      "current step :  137\n",
      "reward :  -0.4241308829850487\n",
      "episode :  14\n",
      "current step :  138\n",
      "reward :  -0.4477351144198146\n",
      "episode :  14\n",
      "current step :  139\n",
      "reward :  -0.45487771937755817\n",
      "episode :  14\n",
      "current step :  140\n",
      "reward :  -0.44206642285748976\n",
      "episode :  14\n",
      "current step :  141\n",
      "reward :  -0.37150327271917977\n",
      "episode :  14\n",
      "current step :  142\n",
      "reward :  -0.2930041624677512\n",
      "episode :  14\n",
      "current step :  143\n",
      "reward :  -0.3251753397121945\n",
      "episode :  14\n",
      "current step :  144\n",
      "reward :  -0.34683838081206403\n",
      "episode :  14\n",
      "current step :  145\n",
      "reward :  -0.22506269093676187\n",
      "episode :  14\n",
      "current step :  146\n",
      "reward :  -0.3724102094075783\n",
      "episode :  14\n",
      "current step :  147\n",
      "reward :  -0.40310431393553925\n",
      "episode :  14\n",
      "current step :  148\n",
      "reward :  -0.4753946103297085\n",
      "episode :  14\n",
      "current step :  149\n",
      "reward :  -0.44544948569669285\n",
      "episode :  14\n",
      "current step :  150\n",
      "reward :  -0.4736853293580644\n",
      "episode :  14\n",
      "current step :  151\n",
      "reward :  -0.38608218022121904\n",
      "episode :  14\n",
      "current step :  152\n",
      "reward :  -0.34047881372556393\n",
      "episode :  14\n",
      "current step :  153\n",
      "reward :  -0.3375249589516324\n",
      "episode :  14\n",
      "current step :  154\n",
      "reward :  -0.3444838813470864\n",
      "episode :  14\n",
      "current step :  155\n",
      "reward :  -0.3464495951063145\n",
      "episode :  14\n",
      "current step :  156\n",
      "reward :  -0.34848874122694273\n",
      "episode :  14\n",
      "current step :  157\n",
      "reward :  -0.3515920078995049\n",
      "episode :  14\n",
      "current step :  158\n",
      "reward :  -0.4055157460844613\n",
      "episode :  14\n",
      "current step :  159\n",
      "reward :  -0.4269867537948173\n",
      "episode :  14\n",
      "current step :  160\n",
      "reward :  -0.5146003696818926\n",
      "episode :  14\n",
      "current step :  161\n",
      "reward :  -0.5450933318066086\n",
      "episode :  14\n",
      "current step :  162\n",
      "reward :  -0.509656434419055\n",
      "episode :  14\n",
      "current step :  163\n",
      "reward :  -0.5025611714934349\n",
      "episode :  14\n",
      "current step :  164\n",
      "reward :  -0.5006816042971854\n",
      "episode :  14\n",
      "current step :  165\n",
      "reward :  -0.5905945287642578\n",
      "episode :  14\n",
      "current step :  166\n",
      "reward :  -0.6068484970124393\n",
      "episode :  14\n",
      "current step :  167\n",
      "reward :  -0.6218383869467845\n",
      "episode :  14\n",
      "current step :  168\n",
      "reward :  -0.540604453180767\n",
      "episode :  14\n",
      "current step :  169\n",
      "reward :  -0.5423736236996995\n",
      "episode :  14\n",
      "current step :  170\n",
      "reward :  -0.4893393216885732\n",
      "episode :  14\n",
      "current step :  171\n",
      "reward :  -0.4387600262160417\n",
      "episode :  14\n",
      "current step :  172\n",
      "reward :  -0.5902137701566228\n",
      "episode :  14\n",
      "current step :  173\n",
      "reward :  -0.5665705976546147\n",
      "episode :  14\n",
      "current step :  174\n",
      "reward :  -0.5158728930654122\n",
      "episode :  14\n",
      "current step :  175\n",
      "reward :  -0.45612493107747853\n",
      "episode :  14\n",
      "current step :  176\n",
      "reward :  -0.4973504271111611\n",
      "episode :  14\n",
      "current step :  177\n",
      "reward :  -0.5558965238261211\n",
      "episode :  14\n",
      "current step :  178\n",
      "reward :  -0.4227340866377659\n",
      "episode :  14\n",
      "current step :  179\n",
      "reward :  -0.496708873844206\n",
      "episode :  14\n",
      "current step :  180\n",
      "reward :  -0.6413201061639128\n",
      "episode :  14\n",
      "current step :  181\n",
      "reward :  -0.6848142479545138\n",
      "episode :  14\n",
      "current step :  182\n",
      "reward :  -0.6198629659480621\n",
      "episode :  14\n",
      "current step :  183\n",
      "reward :  -0.6465017751276283\n",
      "episode :  14\n",
      "current step :  184\n",
      "reward :  -0.6453337924326772\n",
      "episode :  14\n",
      "current step :  185\n",
      "reward :  -0.6140147307888383\n",
      "episode :  14\n",
      "current step :  186\n",
      "reward :  -0.6844402962643067\n",
      "episode :  14\n",
      "current step :  187\n",
      "reward :  -0.654909721261552\n",
      "episode :  14\n",
      "current step :  188\n",
      "reward :  -0.5644608833796887\n",
      "episode :  14\n",
      "current step :  189\n",
      "reward :  -0.5512091655799249\n",
      "episode :  14\n",
      "current step :  190\n",
      "reward :  -0.5530408784651559\n",
      "episode :  14\n",
      "current step :  191\n",
      "reward :  -0.6357317056790114\n",
      "episode :  14\n",
      "current step :  192\n",
      "reward :  -0.6387260237586644\n",
      "episode :  14\n",
      "current step :  193\n",
      "reward :  -0.6102320975263819\n",
      "episode :  14\n",
      "current step :  194\n",
      "reward :  -0.5213242417126045\n",
      "episode :  14\n",
      "current step :  195\n",
      "reward :  -0.4763773741882916\n",
      "episode :  14\n",
      "current step :  196\n",
      "reward :  -0.42741205917486924\n",
      "episode :  14\n",
      "current step :  197\n",
      "reward :  -0.5511003617286286\n",
      "episode :  14\n",
      "current step :  198\n",
      "reward :  -0.4997907279160328\n",
      "episode :  14\n",
      "current step :  199\n",
      "reward :  -0.45614617874258817\n",
      "episode :  14\n",
      "current step :  200\n",
      "reward :  -0.4338548619107617\n",
      "episode :  14\n",
      "current step :  201\n",
      "reward :  -0.42016736758613943\n",
      "episode :  14\n",
      "current step :  202\n",
      "reward :  -0.37553597765774294\n",
      "episode :  14\n",
      "current step :  203\n",
      "reward :  -0.3604043216325722\n",
      "episode :  14\n",
      "current step :  204\n",
      "reward :  -0.536738165175823\n",
      "episode :  14\n",
      "current step :  205\n",
      "reward :  -0.44270938729529696\n",
      "episode :  14\n",
      "current step :  206\n",
      "reward :  -0.42487182911376464\n",
      "episode :  14\n",
      "current step :  207\n",
      "reward :  -0.33660225700377094\n",
      "episode :  14\n",
      "current step :  208\n",
      "reward :  -0.43537681288233165\n",
      "episode :  14\n",
      "current step :  209\n",
      "reward :  -0.46646546010024886\n",
      "episode :  14\n",
      "current step :  210\n",
      "reward :  -0.5958676016647166\n",
      "episode :  14\n",
      "current step :  211\n",
      "reward :  -0.5891587112944611\n",
      "episode :  14\n",
      "current step :  212\n",
      "reward :  -0.5326283298891653\n",
      "episode :  14\n",
      "current step :  213\n",
      "reward :  -0.5535489103545727\n",
      "episode :  14\n",
      "current step :  214\n",
      "reward :  -0.6701785003570506\n",
      "episode :  14\n",
      "current step :  215\n",
      "reward :  -0.6125412164964125\n",
      "episode :  14\n",
      "current step :  216\n",
      "reward :  -0.6365995673956727\n",
      "episode :  14\n",
      "current step :  217\n",
      "reward :  -0.47891132150146565\n",
      "episode :  14\n",
      "current step :  218\n",
      "reward :  -0.392186322887973\n",
      "episode :  14\n",
      "current step :  219\n",
      "reward :  -0.2701686218613994\n",
      "episode :  14\n",
      "current step :  220\n",
      "reward :  -0.34477045905527487\n",
      "episode :  14\n",
      "current step :  221\n",
      "reward :  -0.4499199687606663\n",
      "episode :  14\n",
      "current step :  222\n",
      "reward :  -0.4728803890845855\n",
      "episode :  14\n",
      "current step :  223\n",
      "reward :  -0.4472561091492831\n",
      "episode :  14\n",
      "current step :  224\n",
      "reward :  -0.40579378209707834\n",
      "episode :  14\n",
      "current step :  225\n",
      "reward :  -0.4696360424083247\n",
      "episode :  14\n",
      "current step :  226\n",
      "reward :  -0.37024501915544084\n",
      "episode :  14\n",
      "current step :  227\n",
      "reward :  -0.4150521666560907\n",
      "episode :  14\n",
      "current step :  228\n",
      "reward :  -0.5114325300948734\n",
      "episode :  14\n",
      "current step :  229\n",
      "reward :  -0.581683679357202\n",
      "episode :  14\n",
      "current step :  230\n",
      "reward :  -0.5866064190135636\n",
      "episode :  14\n",
      "current step :  231\n",
      "reward :  -0.48348108492688885\n",
      "episode :  14\n",
      "current step :  232\n",
      "reward :  -0.5052843441754444\n",
      "episode :  14\n",
      "current step :  233\n",
      "reward :  -0.6423030239267201\n",
      "episode :  14\n",
      "current step :  234\n",
      "reward :  -0.5039832645365789\n",
      "episode :  14\n",
      "current step :  235\n",
      "reward :  -0.4264403799726084\n",
      "episode :  14\n",
      "current step :  236\n",
      "reward :  -0.3901956555454391\n",
      "episode :  14\n",
      "current step :  237\n",
      "reward :  -0.28709805969713775\n",
      "episode :  14\n",
      "current step :  238\n",
      "reward :  -0.38322933349796867\n",
      "episode :  14\n",
      "current step :  239\n",
      "reward :  -0.36663173840771274\n",
      "episode :  14\n",
      "current step :  240\n",
      "reward :  -0.3439979831421909\n",
      "episode :  14\n",
      "current step :  241\n",
      "reward :  -0.4192144891078879\n",
      "episode :  14\n",
      "current step :  242\n",
      "reward :  -0.3629532753950058\n",
      "episode :  14\n",
      "current step :  243\n",
      "reward :  -0.2850585012915178\n",
      "episode :  14\n",
      "current step :  244\n",
      "reward :  -0.3441459907840598\n",
      "episode :  14\n",
      "current step :  245\n",
      "reward :  -0.5132989034222124\n",
      "episode :  14\n",
      "current step :  246\n",
      "reward :  -0.5443106622116034\n",
      "episode :  14\n",
      "current step :  247\n",
      "reward :  -0.5069807934342195\n",
      "episode :  14\n",
      "current step :  248\n",
      "reward :  -0.4231999995701908\n",
      "episode :  14\n",
      "current step :  249\n",
      "reward :  -0.32486871611887524\n",
      "episode :  14\n",
      "current step :  250\n",
      "reward :  -0.2822172594709432\n",
      "episode :  14\n",
      "current step :  251\n",
      "reward :  -0.2776855079756752\n",
      "episode :  14\n",
      "current step :  252\n",
      "reward :  -0.3297069140061067\n",
      "episode :  14\n",
      "current step :  253\n",
      "reward :  -0.14358464513585842\n",
      "episode :  14\n",
      "current step :  254\n",
      "reward :  -0.13029269361157572\n",
      "episode :  14\n",
      "current step :  255\n",
      "reward :  -0.27579456071480646\n",
      "episode :  14\n",
      "current step :  256\n",
      "reward :  -0.39071178076333524\n",
      "episode :  14\n",
      "current step :  257\n",
      "reward :  -0.5212510849601736\n",
      "episode :  14\n",
      "current step :  258\n",
      "reward :  -0.5124367000461832\n",
      "episode :  14\n",
      "current step :  259\n",
      "reward :  -0.454579052476414\n",
      "episode :  14\n",
      "current step :  260\n",
      "reward :  -0.3685497170454739\n",
      "episode :  14\n",
      "current step :  261\n",
      "reward :  -0.3311939172892966\n",
      "episode :  14\n",
      "current step :  262\n",
      "reward :  -0.31050712006303377\n",
      "episode :  14\n",
      "current step :  263\n",
      "reward :  -0.30811190627573737\n",
      "episode :  14\n",
      "current step :  264\n",
      "reward :  -0.2260569170452107\n",
      "episode :  14\n",
      "current step :  265\n",
      "reward :  -0.1886905337016982\n",
      "episode :  14\n",
      "current step :  266\n",
      "reward :  -0.26475007575389486\n",
      "episode :  14\n",
      "current step :  267\n",
      "reward :  -0.2571511817726641\n",
      "episode :  14\n",
      "current step :  268\n",
      "reward :  -0.2217115536979939\n",
      "episode :  14\n",
      "current step :  269\n",
      "reward :  -0.18256689570520965\n",
      "episode :  14\n",
      "current step :  270\n",
      "reward :  -0.3525898381262603\n",
      "episode :  14\n",
      "current step :  271\n",
      "reward :  -0.31630096350052644\n",
      "episode :  14\n",
      "current step :  272\n",
      "reward :  -0.283862660765131\n",
      "episode :  14\n",
      "current step :  273\n",
      "reward :  -0.16180572464315393\n",
      "episode :  14\n",
      "current step :  274\n",
      "reward :  -0.2411904874118823\n",
      "episode :  14\n",
      "current step :  275\n",
      "reward :  -0.24853082064948714\n",
      "episode :  14\n",
      "current step :  276\n",
      "reward :  -0.21457548301285803\n",
      "episode :  14\n",
      "current step :  277\n",
      "reward :  -0.36882224167757693\n",
      "episode :  14\n",
      "current step :  278\n",
      "reward :  -0.37597908626740384\n",
      "episode :  14\n",
      "current step :  279\n",
      "reward :  -0.28749396580514125\n",
      "episode :  14\n",
      "current step :  280\n",
      "reward :  -0.35150073236101836\n",
      "episode :  14\n",
      "current step :  281\n",
      "reward :  -0.15937724744260254\n",
      "episode :  14\n",
      "current step :  282\n",
      "reward :  -0.21677399074956016\n",
      "episode :  14\n",
      "current step :  283\n",
      "reward :  -0.331928932311295\n",
      "episode :  14\n",
      "current step :  284\n",
      "reward :  -0.2572577759299627\n",
      "episode :  14\n",
      "current step :  285\n",
      "reward :  -0.22202471967458065\n",
      "episode :  15\n",
      "current step :  0\n",
      "reward :  -0.2784538312436944\n",
      "episode :  15\n",
      "current step :  1\n",
      "reward :  -0.27914147668722206\n",
      "episode :  15\n",
      "current step :  2\n",
      "reward :  -0.36059729510076527\n",
      "episode :  15\n",
      "current step :  3\n",
      "reward :  -0.3065867937390839\n",
      "episode :  15\n",
      "current step :  4\n",
      "reward :  -0.3318313513599427\n",
      "episode :  15\n",
      "current step :  5\n",
      "reward :  -0.3784269554785846\n",
      "episode :  15\n",
      "current step :  6\n",
      "reward :  -0.3243749233145543\n",
      "episode :  15\n",
      "current step :  7\n",
      "reward :  -0.35547479886627326\n",
      "episode :  15\n",
      "current step :  8\n",
      "reward :  -0.2872887563704754\n",
      "episode :  15\n",
      "current step :  9\n",
      "reward :  -0.2516080678700784\n",
      "episode :  15\n",
      "current step :  10\n",
      "reward :  -0.23524775835687445\n",
      "episode :  15\n",
      "current step :  11\n",
      "reward :  -0.1896160959551912\n",
      "episode :  15\n",
      "current step :  12\n",
      "reward :  -0.3557300401508635\n",
      "episode :  15\n",
      "current step :  13\n",
      "reward :  -0.33313729300575995\n",
      "episode :  15\n",
      "current step :  14\n",
      "reward :  -0.34940553478785474\n",
      "episode :  15\n",
      "current step :  15\n",
      "reward :  -0.35514129520951876\n",
      "episode :  15\n",
      "current step :  16\n",
      "reward :  -0.33478074117934026\n",
      "episode :  15\n",
      "current step :  17\n",
      "reward :  -0.3491241488645839\n",
      "episode :  15\n",
      "current step :  18\n",
      "reward :  -0.33768227703166015\n",
      "episode :  15\n",
      "current step :  19\n",
      "reward :  -0.2682484773433588\n",
      "episode :  15\n",
      "current step :  20\n",
      "reward :  -0.27870804987980996\n",
      "episode :  15\n",
      "current step :  21\n",
      "reward :  -0.23506958880923573\n",
      "episode :  15\n",
      "current step :  22\n",
      "reward :  -0.23306699665293346\n",
      "episode :  15\n",
      "current step :  23\n",
      "reward :  -0.46395758274723986\n",
      "episode :  15\n",
      "current step :  24\n",
      "reward :  -0.30485182652923265\n",
      "episode :  15\n",
      "current step :  25\n",
      "reward :  -0.3466995079634865\n",
      "episode :  15\n",
      "current step :  26\n",
      "reward :  -0.5633674471669523\n",
      "episode :  15\n",
      "current step :  27\n",
      "reward :  -0.5657101793365384\n",
      "episode :  15\n",
      "current step :  28\n",
      "reward :  -0.47816064000808967\n",
      "episode :  15\n",
      "current step :  29\n",
      "reward :  -0.33279498799823787\n",
      "episode :  15\n",
      "current step :  30\n",
      "reward :  -0.3045976895528753\n",
      "episode :  15\n",
      "current step :  31\n",
      "reward :  -0.27175521314748113\n",
      "episode :  15\n",
      "current step :  32\n",
      "reward :  -0.45713127317422775\n",
      "episode :  15\n",
      "current step :  33\n",
      "reward :  -0.4440519327794221\n",
      "episode :  15\n",
      "current step :  34\n",
      "reward :  -0.49516521244627165\n",
      "episode :  15\n",
      "current step :  35\n",
      "reward :  -0.6309605669370656\n",
      "episode :  15\n",
      "current step :  36\n",
      "reward :  -0.4670574433055741\n",
      "episode :  15\n",
      "current step :  37\n",
      "reward :  -0.36414675751597964\n",
      "episode :  15\n",
      "current step :  38\n",
      "reward :  -0.378167268704919\n",
      "episode :  15\n",
      "current step :  39\n",
      "reward :  -0.2933233738394327\n",
      "episode :  15\n",
      "current step :  40\n",
      "reward :  -0.40845556296351254\n",
      "episode :  15\n",
      "current step :  41\n",
      "reward :  -0.31482677135465736\n",
      "episode :  15\n",
      "current step :  42\n",
      "reward :  -0.42111030651035014\n",
      "episode :  15\n",
      "current step :  43\n",
      "reward :  -0.4381797297532302\n",
      "episode :  15\n",
      "current step :  44\n",
      "reward :  -0.4872849106987214\n",
      "episode :  15\n",
      "current step :  45\n",
      "reward :  -0.3791601838403363\n",
      "episode :  15\n",
      "current step :  46\n",
      "reward :  -0.41662418723188477\n",
      "episode :  15\n",
      "current step :  47\n",
      "reward :  -0.29864413087206343\n",
      "episode :  15\n",
      "current step :  48\n",
      "reward :  -0.3997923513021169\n",
      "episode :  15\n",
      "current step :  49\n",
      "reward :  -0.5808548044865463\n",
      "episode :  15\n",
      "current step :  50\n",
      "reward :  -0.6011524806042136\n",
      "episode :  15\n",
      "current step :  51\n",
      "reward :  -0.5092959454581315\n",
      "episode :  15\n",
      "current step :  52\n",
      "reward :  -0.5510770097588663\n",
      "episode :  15\n",
      "current step :  53\n",
      "reward :  -0.7154092580502781\n",
      "episode :  15\n",
      "current step :  54\n",
      "reward :  -0.7432465418261138\n",
      "episode :  15\n",
      "current step :  55\n",
      "reward :  -0.7106344184564591\n",
      "episode :  15\n",
      "current step :  56\n",
      "reward :  -0.6992263526593855\n",
      "episode :  15\n",
      "current step :  57\n",
      "reward :  -0.7165153610323154\n",
      "episode :  15\n",
      "current step :  58\n",
      "reward :  -0.44039476810088013\n",
      "episode :  15\n",
      "current step :  59\n",
      "reward :  -0.6539640093060173\n",
      "episode :  15\n",
      "current step :  60\n",
      "reward :  -0.6594779728459358\n",
      "episode :  15\n",
      "current step :  61\n",
      "reward :  -0.7080370118304773\n",
      "episode :  15\n",
      "current step :  62\n",
      "reward :  -0.705054672189248\n",
      "episode :  15\n",
      "current step :  63\n",
      "reward :  -0.7401017116985087\n",
      "episode :  15\n",
      "current step :  64\n",
      "reward :  -0.6136764742668754\n",
      "episode :  15\n",
      "current step :  65\n",
      "reward :  -0.5197890850342172\n",
      "episode :  15\n",
      "current step :  66\n",
      "reward :  -0.5067699880964402\n",
      "episode :  15\n",
      "current step :  67\n",
      "reward :  -0.5774793423409453\n",
      "episode :  15\n",
      "current step :  68\n",
      "reward :  -0.6641957825314045\n",
      "episode :  15\n",
      "current step :  69\n",
      "reward :  -0.6594945565681865\n",
      "episode :  15\n",
      "current step :  70\n",
      "reward :  -0.6314814688369339\n",
      "episode :  15\n",
      "current step :  71\n",
      "reward :  -0.6822721029888983\n",
      "episode :  15\n",
      "current step :  72\n",
      "reward :  -0.6634775812043977\n",
      "episode :  15\n",
      "current step :  73\n",
      "reward :  -0.7634249108675085\n",
      "episode :  15\n",
      "current step :  74\n",
      "reward :  -0.773486685508785\n",
      "episode :  15\n",
      "current step :  75\n",
      "reward :  -0.7309386708114083\n",
      "episode :  15\n",
      "current step :  76\n",
      "reward :  -0.5951219302416689\n",
      "episode :  15\n",
      "current step :  77\n",
      "reward :  -0.538480050484495\n",
      "episode :  15\n",
      "current step :  78\n",
      "reward :  -0.5669633061204895\n",
      "episode :  15\n",
      "current step :  79\n",
      "reward :  -0.6157928844272197\n",
      "episode :  15\n",
      "current step :  80\n",
      "reward :  -0.5293398490519775\n",
      "episode :  15\n",
      "current step :  81\n",
      "reward :  -0.43621004969495464\n",
      "episode :  15\n",
      "current step :  82\n",
      "reward :  -0.5154084366797282\n",
      "episode :  15\n",
      "current step :  83\n",
      "reward :  -0.5060674272850894\n",
      "episode :  15\n",
      "current step :  84\n",
      "reward :  -0.4584407490343863\n",
      "episode :  15\n",
      "current step :  85\n",
      "reward :  -0.44115054535714826\n",
      "episode :  15\n",
      "current step :  86\n",
      "reward :  -0.4919030585697071\n",
      "episode :  15\n",
      "current step :  87\n",
      "reward :  -0.436652468125243\n",
      "episode :  15\n",
      "current step :  88\n",
      "reward :  -0.24926457434577987\n",
      "episode :  15\n",
      "current step :  89\n",
      "reward :  -0.5425059186605958\n",
      "episode :  15\n",
      "current step :  90\n",
      "reward :  -0.5853081931800527\n",
      "episode :  15\n",
      "current step :  91\n",
      "reward :  -0.508224206118779\n",
      "episode :  15\n",
      "current step :  92\n",
      "reward :  -0.5077287937540567\n",
      "episode :  15\n",
      "current step :  93\n",
      "reward :  -0.48572859704970545\n",
      "episode :  15\n",
      "current step :  94\n",
      "reward :  -0.347282332306806\n",
      "episode :  15\n",
      "current step :  95\n",
      "reward :  -0.34561137818461996\n",
      "episode :  15\n",
      "current step :  96\n",
      "reward :  -0.12069922239172778\n",
      "episode :  15\n",
      "current step :  97\n",
      "reward :  -0.26149984902667595\n",
      "episode :  15\n",
      "current step :  98\n",
      "reward :  -0.3489027530300356\n",
      "episode :  15\n",
      "current step :  99\n",
      "reward :  -0.2715639020939884\n",
      "episode :  15\n",
      "current step :  100\n",
      "reward :  -0.22332504538008868\n",
      "episode :  15\n",
      "current step :  101\n",
      "reward :  -0.3524780551926493\n",
      "episode :  15\n",
      "current step :  102\n",
      "reward :  -0.2715256276969135\n",
      "episode :  15\n",
      "current step :  103\n",
      "reward :  -0.28835462412675955\n",
      "episode :  15\n",
      "current step :  104\n",
      "reward :  -0.27513369033132207\n",
      "episode :  15\n",
      "current step :  105\n",
      "reward :  -0.24687309642465805\n",
      "episode :  15\n",
      "current step :  106\n",
      "reward :  -0.25342399937485577\n",
      "episode :  15\n",
      "current step :  107\n",
      "reward :  -0.19487761223423422\n",
      "episode :  15\n",
      "current step :  108\n",
      "reward :  -0.34011306108847444\n",
      "episode :  15\n",
      "current step :  109\n",
      "reward :  -0.4577926804199575\n",
      "episode :  15\n",
      "current step :  110\n",
      "reward :  -0.44883725945518754\n",
      "episode :  15\n",
      "current step :  111\n",
      "reward :  -0.3650228298480342\n",
      "episode :  15\n",
      "current step :  112\n",
      "reward :  -0.3513322961082751\n",
      "episode :  15\n",
      "current step :  113\n",
      "reward :  -0.4188306458562753\n",
      "episode :  15\n",
      "current step :  114\n",
      "reward :  -0.4414688662454008\n",
      "episode :  15\n",
      "current step :  115\n",
      "reward :  -0.44843618472805463\n",
      "episode :  15\n",
      "current step :  116\n",
      "reward :  -0.511237363992969\n",
      "episode :  15\n",
      "current step :  117\n",
      "reward :  -0.3296251142195052\n",
      "episode :  15\n",
      "current step :  118\n",
      "reward :  -0.30869481945256455\n",
      "episode :  15\n",
      "current step :  119\n",
      "reward :  -0.4061689880000529\n",
      "episode :  15\n",
      "current step :  120\n",
      "reward :  -0.40383862210136867\n",
      "episode :  15\n",
      "current step :  121\n",
      "reward :  -0.36857712279997035\n",
      "episode :  15\n",
      "current step :  122\n",
      "reward :  -0.2595544400188857\n",
      "episode :  15\n",
      "current step :  123\n",
      "reward :  -0.444068412311346\n",
      "episode :  15\n",
      "current step :  124\n",
      "reward :  -0.3242184925371054\n",
      "episode :  15\n",
      "current step :  125\n",
      "reward :  -0.3279227197504911\n",
      "episode :  15\n",
      "current step :  126\n",
      "reward :  -0.47611672592092097\n",
      "episode :  15\n",
      "current step :  127\n",
      "reward :  -0.37396138211956537\n",
      "episode :  15\n",
      "current step :  128\n",
      "reward :  -0.3679202158310031\n",
      "episode :  15\n",
      "current step :  129\n",
      "reward :  -0.28608161990831243\n",
      "episode :  15\n",
      "current step :  130\n",
      "reward :  -0.2654260019785282\n",
      "episode :  15\n",
      "current step :  131\n",
      "reward :  -0.325569580638969\n",
      "episode :  15\n",
      "current step :  132\n",
      "reward :  -0.14557902062611322\n",
      "episode :  15\n",
      "current step :  133\n",
      "reward :  -0.3701845752177391\n",
      "episode :  15\n",
      "current step :  134\n",
      "reward :  -0.38388093833389586\n",
      "episode :  15\n",
      "current step :  135\n",
      "reward :  -0.3943556168445784\n",
      "episode :  15\n",
      "current step :  136\n",
      "reward :  -0.3705170818862625\n",
      "episode :  15\n",
      "current step :  137\n",
      "reward :  -0.29957364399448794\n",
      "episode :  15\n",
      "current step :  138\n",
      "reward :  -0.4199896101274711\n",
      "episode :  15\n",
      "current step :  139\n",
      "reward :  -0.21880357473611559\n",
      "episode :  15\n",
      "current step :  140\n",
      "reward :  -0.2984685046042404\n",
      "episode :  15\n",
      "current step :  141\n",
      "reward :  -0.2350339469826456\n",
      "episode :  15\n",
      "current step :  142\n",
      "reward :  -0.2881408855788789\n",
      "episode :  15\n",
      "current step :  143\n",
      "reward :  -0.23786584469016647\n",
      "episode :  15\n",
      "current step :  144\n",
      "reward :  -0.24851724085326782\n",
      "episode :  15\n",
      "current step :  145\n",
      "reward :  -0.4229962656887052\n",
      "episode :  15\n",
      "current step :  146\n",
      "reward :  -0.4642282159133677\n",
      "episode :  15\n",
      "current step :  147\n",
      "reward :  -0.4722850950188067\n",
      "episode :  15\n",
      "current step :  148\n",
      "reward :  -0.37390664821013087\n",
      "episode :  15\n",
      "current step :  149\n",
      "reward :  -0.3104906118164299\n",
      "episode :  15\n",
      "current step :  150\n",
      "reward :  -0.29658622521041106\n",
      "episode :  15\n",
      "current step :  151\n",
      "reward :  -0.38811913766965306\n",
      "episode :  15\n",
      "current step :  152\n",
      "reward :  -0.4090248423983003\n",
      "episode :  15\n",
      "current step :  153\n",
      "reward :  -0.4029024235811243\n",
      "episode :  15\n",
      "current step :  154\n",
      "reward :  -0.3973000866772558\n",
      "episode :  15\n",
      "current step :  155\n",
      "reward :  -0.45328310713853837\n",
      "episode :  15\n",
      "current step :  156\n",
      "reward :  -0.4642997795654188\n",
      "episode :  15\n",
      "current step :  157\n",
      "reward :  -0.5827838744617279\n",
      "episode :  15\n",
      "current step :  158\n",
      "reward :  -0.5442163960292208\n",
      "episode :  15\n",
      "current step :  159\n",
      "reward :  -0.5114149966408119\n",
      "episode :  15\n",
      "current step :  160\n",
      "reward :  -0.38410353599295044\n",
      "episode :  15\n",
      "current step :  161\n",
      "reward :  -0.4046700966976498\n",
      "episode :  15\n",
      "current step :  162\n",
      "reward :  -0.43249561019756816\n",
      "episode :  15\n",
      "current step :  163\n",
      "reward :  -0.6047468199657555\n",
      "episode :  15\n",
      "current step :  164\n",
      "reward :  -0.6745228912598258\n",
      "episode :  15\n",
      "current step :  165\n",
      "reward :  -0.6424093600329724\n",
      "episode :  15\n",
      "current step :  166\n",
      "reward :  -0.6301575300291591\n",
      "episode :  15\n",
      "current step :  167\n",
      "reward :  -0.607401434486077\n",
      "episode :  15\n",
      "current step :  168\n",
      "reward :  -0.5981799206595807\n",
      "episode :  15\n",
      "current step :  169\n",
      "reward :  -0.6293568804038431\n",
      "episode :  15\n",
      "current step :  170\n",
      "reward :  -0.6270621422579572\n",
      "episode :  15\n",
      "current step :  171\n",
      "reward :  -0.5651665464303773\n",
      "episode :  15\n",
      "current step :  172\n",
      "reward :  -0.492575990949115\n",
      "episode :  15\n",
      "current step :  173\n",
      "reward :  -0.4290354583378201\n",
      "episode :  15\n",
      "current step :  174\n",
      "reward :  -0.44792072609252215\n",
      "episode :  15\n",
      "current step :  175\n",
      "reward :  -0.5631819323606299\n",
      "episode :  15\n",
      "current step :  176\n",
      "reward :  -0.5219498613748966\n",
      "episode :  15\n",
      "current step :  177\n",
      "reward :  -0.4830596686142303\n",
      "episode :  15\n",
      "current step :  178\n",
      "reward :  -0.5431570088037886\n",
      "episode :  15\n",
      "current step :  179\n",
      "reward :  -0.6415093610080173\n",
      "episode :  15\n",
      "current step :  180\n",
      "reward :  -0.6288297554983505\n",
      "episode :  15\n",
      "current step :  181\n",
      "reward :  -0.6387587266901698\n",
      "episode :  15\n",
      "current step :  182\n",
      "reward :  -0.6685171202665198\n",
      "episode :  15\n",
      "current step :  183\n",
      "reward :  -0.7105654015928209\n",
      "episode :  15\n",
      "current step :  184\n",
      "reward :  -0.7033784995078761\n",
      "episode :  15\n",
      "current step :  185\n",
      "reward :  -0.646334026983585\n",
      "episode :  15\n",
      "current step :  186\n",
      "reward :  -0.5701871457609775\n",
      "episode :  15\n",
      "current step :  187\n",
      "reward :  -0.5834715118645424\n",
      "episode :  15\n",
      "current step :  188\n",
      "reward :  -0.5604639194976047\n",
      "episode :  15\n",
      "current step :  189\n",
      "reward :  -0.4269591160599483\n",
      "episode :  15\n",
      "current step :  190\n",
      "reward :  -0.404788134521515\n",
      "episode :  15\n",
      "current step :  191\n",
      "reward :  -0.4016159475250129\n",
      "episode :  15\n",
      "current step :  192\n",
      "reward :  -0.3051964797478947\n",
      "episode :  15\n",
      "current step :  193\n",
      "reward :  -0.27241248971384735\n",
      "episode :  15\n",
      "current step :  194\n",
      "reward :  -0.26442171903028927\n",
      "episode :  15\n",
      "current step :  195\n",
      "reward :  -0.44134663567534066\n",
      "episode :  15\n",
      "current step :  196\n",
      "reward :  -0.4239683559489487\n",
      "episode :  15\n",
      "current step :  197\n",
      "reward :  -0.430369970394062\n",
      "episode :  15\n",
      "current step :  198\n",
      "reward :  -0.44365495378507636\n",
      "episode :  15\n",
      "current step :  199\n",
      "reward :  -0.48371270746628653\n",
      "episode :  15\n",
      "current step :  200\n",
      "reward :  -0.5080088751509515\n",
      "episode :  15\n",
      "current step :  201\n",
      "reward :  -0.599688643642059\n",
      "episode :  15\n",
      "current step :  202\n",
      "reward :  -0.5463007895164241\n",
      "episode :  15\n",
      "current step :  203\n",
      "reward :  -0.4057559529233943\n",
      "episode :  15\n",
      "current step :  204\n",
      "reward :  -0.43038200286034833\n",
      "episode :  15\n",
      "current step :  205\n",
      "reward :  -0.5605298639323896\n",
      "episode :  15\n",
      "current step :  206\n",
      "reward :  -0.5673300787145902\n",
      "episode :  15\n",
      "current step :  207\n",
      "reward :  -0.492542424152421\n",
      "episode :  15\n",
      "current step :  208\n",
      "reward :  -0.434351584399004\n",
      "episode :  15\n",
      "current step :  209\n",
      "reward :  -0.4026954520288649\n",
      "episode :  15\n",
      "current step :  210\n",
      "reward :  -0.3574862153913642\n",
      "episode :  15\n",
      "current step :  211\n",
      "reward :  -0.42750814878330384\n",
      "episode :  15\n",
      "current step :  212\n",
      "reward :  -0.2963767698228495\n",
      "episode :  15\n",
      "current step :  213\n",
      "reward :  -0.3641592262708471\n",
      "episode :  15\n",
      "current step :  214\n",
      "reward :  -0.3610715615608706\n",
      "episode :  15\n",
      "current step :  215\n",
      "reward :  -0.3969538861273763\n",
      "episode :  15\n",
      "current step :  216\n",
      "reward :  -0.37655200921829\n",
      "episode :  15\n",
      "current step :  217\n",
      "reward :  -0.5030417789709922\n",
      "episode :  15\n",
      "current step :  218\n",
      "reward :  -0.5623203407769688\n",
      "episode :  15\n",
      "current step :  219\n",
      "reward :  -0.5982597849056067\n",
      "episode :  15\n",
      "current step :  220\n",
      "reward :  -0.6191332800160586\n",
      "episode :  15\n",
      "current step :  221\n",
      "reward :  -0.6680018886722225\n",
      "episode :  15\n",
      "current step :  222\n",
      "reward :  -0.58119272922264\n",
      "episode :  15\n",
      "current step :  223\n",
      "reward :  -0.6247960986003547\n",
      "episode :  15\n",
      "current step :  224\n",
      "reward :  -0.5841663241488663\n",
      "episode :  15\n",
      "current step :  225\n",
      "reward :  -0.5203804097645713\n",
      "episode :  15\n",
      "current step :  226\n",
      "reward :  -0.5342609551078001\n",
      "episode :  15\n",
      "current step :  227\n",
      "reward :  -0.5243329944408921\n",
      "episode :  15\n",
      "current step :  228\n",
      "reward :  -0.5336792567572853\n",
      "episode :  15\n",
      "current step :  229\n",
      "reward :  -0.47313061200450574\n",
      "episode :  15\n",
      "current step :  230\n",
      "reward :  -0.5370054397276348\n",
      "episode :  15\n",
      "current step :  231\n",
      "reward :  -0.5924522551827067\n",
      "episode :  15\n",
      "current step :  232\n",
      "reward :  -0.5293248332870147\n",
      "episode :  15\n",
      "current step :  233\n",
      "reward :  -0.5567383521008243\n",
      "episode :  15\n",
      "current step :  234\n",
      "reward :  -0.5633521414055492\n",
      "episode :  15\n",
      "current step :  235\n",
      "reward :  -0.4900158045917576\n",
      "episode :  15\n",
      "current step :  236\n",
      "reward :  -0.4177309276137555\n",
      "episode :  15\n",
      "current step :  237\n",
      "reward :  -0.44374327376625017\n",
      "episode :  15\n",
      "current step :  238\n",
      "reward :  -0.523257389604571\n",
      "episode :  15\n",
      "current step :  239\n",
      "reward :  -0.4860559515824076\n",
      "episode :  15\n",
      "current step :  240\n",
      "reward :  -0.46579355091794317\n",
      "episode :  15\n",
      "current step :  241\n",
      "reward :  -0.4760833835859621\n",
      "episode :  15\n",
      "current step :  242\n",
      "reward :  -0.4620674552235472\n",
      "episode :  15\n",
      "current step :  243\n",
      "reward :  -0.4727663966238629\n",
      "episode :  15\n",
      "current step :  244\n",
      "reward :  -0.42107480928257807\n",
      "episode :  15\n",
      "current step :  245\n",
      "reward :  -0.3853973993838693\n",
      "episode :  15\n",
      "current step :  246\n",
      "reward :  -0.4443064280992445\n",
      "episode :  15\n",
      "current step :  247\n",
      "reward :  -0.34472722682425166\n",
      "episode :  15\n",
      "current step :  248\n",
      "reward :  -0.31683225017900085\n",
      "episode :  15\n",
      "current step :  249\n",
      "reward :  -0.39752425512819006\n",
      "episode :  15\n",
      "current step :  250\n",
      "reward :  -0.40495810765986684\n",
      "episode :  15\n",
      "current step :  251\n",
      "reward :  -0.3735531323783925\n",
      "episode :  15\n",
      "current step :  252\n",
      "reward :  -0.36615933356072117\n",
      "episode :  15\n",
      "current step :  253\n",
      "reward :  -0.2937385938666496\n",
      "episode :  15\n",
      "current step :  254\n",
      "reward :  -0.2739902454838238\n",
      "episode :  15\n",
      "current step :  255\n",
      "reward :  -0.22567120901335389\n",
      "episode :  15\n",
      "current step :  256\n",
      "reward :  -0.3167625851155313\n",
      "episode :  15\n",
      "current step :  257\n",
      "reward :  -0.33868019159143253\n",
      "episode :  15\n",
      "current step :  258\n",
      "reward :  -0.18221728804564674\n",
      "episode :  15\n",
      "current step :  259\n",
      "reward :  -0.2658572726408347\n",
      "episode :  15\n",
      "current step :  260\n",
      "reward :  -0.2706855891480811\n",
      "episode :  15\n",
      "current step :  261\n",
      "reward :  -0.23265071866827147\n",
      "episode :  15\n",
      "current step :  262\n",
      "reward :  -0.22871942767121656\n",
      "episode :  15\n",
      "current step :  263\n",
      "reward :  -0.19121798494504844\n",
      "episode :  15\n",
      "current step :  264\n",
      "reward :  -0.24085887510389933\n",
      "episode :  15\n",
      "current step :  265\n",
      "reward :  -0.3239067475696386\n",
      "episode :  15\n",
      "current step :  266\n",
      "reward :  -0.253810807446138\n",
      "episode :  15\n",
      "current step :  267\n",
      "reward :  -0.25849548851576054\n",
      "episode :  15\n",
      "current step :  268\n",
      "reward :  -0.18897208294240836\n",
      "episode :  15\n",
      "current step :  269\n",
      "reward :  -0.1988815423254265\n",
      "episode :  15\n",
      "current step :  270\n",
      "reward :  -0.3251381036590044\n",
      "episode :  15\n",
      "current step :  271\n",
      "reward :  -0.259556267697946\n",
      "episode :  15\n",
      "current step :  272\n",
      "reward :  -0.2851872722460681\n",
      "episode :  15\n",
      "current step :  273\n",
      "reward :  -0.2808558359035734\n",
      "episode :  15\n",
      "current step :  274\n",
      "reward :  -0.5163188679161587\n",
      "episode :  15\n",
      "current step :  275\n",
      "reward :  -0.51715190352445\n",
      "episode :  15\n",
      "current step :  276\n",
      "reward :  -0.4297455662337879\n",
      "episode :  15\n",
      "current step :  277\n",
      "reward :  -0.1736265154490476\n",
      "episode :  15\n",
      "current step :  278\n",
      "reward :  -0.371736004302973\n",
      "episode :  15\n",
      "current step :  279\n",
      "reward :  -0.2714357271052325\n",
      "episode :  15\n",
      "current step :  280\n",
      "reward :  -0.4191794265515609\n",
      "episode :  15\n",
      "current step :  281\n",
      "reward :  -0.323580787924168\n",
      "episode :  15\n",
      "current step :  282\n",
      "reward :  -0.3674647864499053\n",
      "episode :  15\n",
      "current step :  283\n",
      "reward :  -0.3485191602409185\n",
      "episode :  15\n",
      "current step :  284\n",
      "reward :  -0.2422122948247485\n",
      "episode :  15\n",
      "current step :  285\n",
      "reward :  -0.35435776783829925\n",
      "episode :  16\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 286      |\n",
      "|    ep_rew_mean     | -120     |\n",
      "| time/              |          |\n",
      "|    episodes        | 16       |\n",
      "|    fps             | 13       |\n",
      "|    time_elapsed    | 343      |\n",
      "|    total_timesteps | 4576     |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -75.7    |\n",
      "|    critic_loss     | 3.33     |\n",
      "|    ent_coef        | 0.263    |\n",
      "|    ent_coef_loss   | -29.6    |\n",
      "|    learning_rate   | 0.0003   |\n",
      "|    n_updates       | 4475     |\n",
      "---------------------------------\n",
      "current step :  0\n",
      "reward :  -0.1747267805383076\n",
      "episode :  16\n",
      "current step :  1\n",
      "reward :  -0.17312893805581162\n",
      "episode :  16\n",
      "current step :  2\n",
      "reward :  -0.26031440581103815\n",
      "episode :  16\n",
      "current step :  3\n",
      "reward :  -0.1396796709547835\n",
      "episode :  16\n",
      "current step :  4\n",
      "reward :  -0.36876581351302795\n",
      "episode :  16\n",
      "current step :  5\n",
      "reward :  -0.2689274919544624\n",
      "episode :  16\n",
      "current step :  6\n",
      "reward :  -0.1798576596207499\n",
      "episode :  16\n",
      "current step :  7\n",
      "reward :  -0.3672570029285441\n",
      "episode :  16\n",
      "current step :  8\n",
      "reward :  -0.3627423110700917\n",
      "episode :  16\n",
      "current step :  9\n",
      "reward :  -0.2121965781195551\n",
      "episode :  16\n",
      "current step :  10\n",
      "reward :  -0.2810643808302502\n",
      "episode :  16\n",
      "current step :  11\n",
      "reward :  -0.331983317154094\n",
      "episode :  16\n",
      "current step :  12\n",
      "reward :  -0.2827637553168831\n",
      "episode :  16\n",
      "current step :  13\n",
      "reward :  -0.2268310200070336\n",
      "episode :  16\n",
      "current step :  14\n",
      "reward :  -0.5249400818029731\n",
      "episode :  16\n",
      "current step :  15\n",
      "reward :  -0.40682440518451135\n",
      "episode :  16\n",
      "current step :  16\n",
      "reward :  -0.39094503324220636\n",
      "episode :  16\n",
      "current step :  17\n",
      "reward :  -0.3958388570518567\n",
      "episode :  16\n",
      "current step :  18\n",
      "reward :  -0.2691716018031822\n",
      "episode :  16\n",
      "current step :  19\n",
      "reward :  -0.4161027253603274\n",
      "episode :  16\n",
      "current step :  20\n",
      "reward :  -0.4407846954358074\n",
      "episode :  16\n",
      "current step :  21\n",
      "reward :  -0.34551162938723473\n",
      "episode :  16\n",
      "current step :  22\n",
      "reward :  -0.49824308262424855\n",
      "episode :  16\n",
      "current step :  23\n",
      "reward :  -0.5056611539991492\n",
      "episode :  16\n",
      "current step :  24\n",
      "reward :  -0.3366858545163402\n",
      "episode :  16\n",
      "current step :  25\n",
      "reward :  -0.3294215248077482\n",
      "episode :  16\n",
      "current step :  26\n",
      "reward :  -0.2245140573429247\n",
      "episode :  16\n",
      "current step :  27\n",
      "reward :  -0.2383766214425922\n",
      "episode :  16\n",
      "current step :  28\n",
      "reward :  -0.2593976876839324\n",
      "episode :  16\n",
      "current step :  29\n",
      "reward :  -0.2478566610637606\n",
      "episode :  16\n",
      "current step :  30\n",
      "reward :  -0.526810950953844\n",
      "episode :  16\n",
      "current step :  31\n",
      "reward :  -0.4272061400458329\n",
      "episode :  16\n",
      "current step :  32\n",
      "reward :  -0.30601518220036655\n",
      "episode :  16\n",
      "current step :  33\n",
      "reward :  -0.3138111492444025\n",
      "episode :  16\n",
      "current step :  34\n",
      "reward :  -0.5762652001465253\n",
      "episode :  16\n",
      "current step :  35\n",
      "reward :  -0.3983013964520893\n",
      "episode :  16\n",
      "current step :  36\n",
      "reward :  -0.33262043219932874\n",
      "episode :  16\n",
      "current step :  37\n",
      "reward :  -0.2873515621769445\n",
      "episode :  16\n",
      "current step :  38\n",
      "reward :  -0.33550097714506866\n",
      "episode :  16\n",
      "current step :  39\n",
      "reward :  -0.40792261164207816\n",
      "episode :  16\n",
      "current step :  40\n",
      "reward :  -0.47073198327156396\n",
      "episode :  16\n",
      "current step :  41\n",
      "reward :  -0.4415239137071856\n",
      "episode :  16\n",
      "current step :  42\n",
      "reward :  -0.3223242119474961\n",
      "episode :  16\n",
      "current step :  43\n",
      "reward :  -0.45309077528564473\n",
      "episode :  16\n",
      "current step :  44\n",
      "reward :  -0.507775087891692\n",
      "episode :  16\n",
      "current step :  45\n",
      "reward :  -0.500098711871372\n",
      "episode :  16\n",
      "current step :  46\n",
      "reward :  -0.6084704637374727\n",
      "episode :  16\n",
      "current step :  47\n",
      "reward :  -0.6073480556374549\n",
      "episode :  16\n",
      "current step :  48\n",
      "reward :  -0.6127755138094442\n",
      "episode :  16\n",
      "current step :  49\n",
      "reward :  -0.5511227695638169\n",
      "episode :  16\n",
      "current step :  50\n",
      "reward :  -0.6768052310983614\n",
      "episode :  16\n",
      "current step :  51\n",
      "reward :  -0.6675939009933027\n",
      "episode :  16\n",
      "current step :  52\n",
      "reward :  -0.6066786127637424\n",
      "episode :  16\n",
      "current step :  53\n",
      "reward :  -0.45761536158038374\n",
      "episode :  16\n",
      "current step :  54\n",
      "reward :  -0.468305556772988\n",
      "episode :  16\n",
      "current step :  55\n",
      "reward :  -0.4767408505737345\n",
      "episode :  16\n",
      "current step :  56\n",
      "reward :  -0.46665294490281284\n",
      "episode :  16\n",
      "current step :  57\n",
      "reward :  -0.41276749128494467\n",
      "episode :  16\n",
      "current step :  58\n",
      "reward :  -0.6150772194604612\n",
      "episode :  16\n",
      "current step :  59\n",
      "reward :  -0.5035517162486471\n",
      "episode :  16\n",
      "current step :  60\n",
      "reward :  -0.3598303639775727\n",
      "episode :  16\n",
      "current step :  61\n",
      "reward :  -0.3582422900620752\n",
      "episode :  16\n",
      "current step :  62\n",
      "reward :  -0.32976620223885944\n",
      "episode :  16\n",
      "current step :  63\n",
      "reward :  -0.36685641668055813\n",
      "episode :  16\n",
      "current step :  64\n",
      "reward :  -0.37162196792940094\n",
      "episode :  16\n",
      "current step :  65\n",
      "reward :  -0.5237568488048424\n",
      "episode :  16\n",
      "current step :  66\n",
      "reward :  -0.43085969613981556\n",
      "episode :  16\n",
      "current step :  67\n",
      "reward :  -0.39354989384364736\n",
      "episode :  16\n",
      "current step :  68\n",
      "reward :  -0.5456565384242027\n",
      "episode :  16\n",
      "current step :  69\n",
      "reward :  -0.48126974887059853\n",
      "episode :  16\n",
      "current step :  70\n",
      "reward :  -0.584142772205892\n",
      "episode :  16\n",
      "current step :  71\n",
      "reward :  -0.6436375125352266\n",
      "episode :  16\n",
      "current step :  72\n",
      "reward :  -0.6797580986675561\n",
      "episode :  16\n",
      "current step :  73\n",
      "reward :  -0.611764719597336\n",
      "episode :  16\n",
      "current step :  74\n",
      "reward :  -0.7036301231711596\n",
      "episode :  16\n",
      "current step :  75\n",
      "reward :  -0.6488005768011859\n",
      "episode :  16\n",
      "current step :  76\n",
      "reward :  -0.6086459573757053\n",
      "episode :  16\n",
      "current step :  77\n",
      "reward :  -0.5487307225300351\n",
      "episode :  16\n",
      "current step :  78\n",
      "reward :  -0.33962516412771276\n",
      "episode :  16\n",
      "current step :  79\n",
      "reward :  -0.5026468636958793\n",
      "episode :  16\n",
      "current step :  80\n",
      "reward :  -0.47560060355655914\n",
      "episode :  16\n",
      "current step :  81\n",
      "reward :  -0.5382912403572526\n",
      "episode :  16\n",
      "current step :  82\n",
      "reward :  -0.567349369247908\n",
      "episode :  16\n",
      "current step :  83\n",
      "reward :  -0.4978840813766182\n",
      "episode :  16\n",
      "current step :  84\n",
      "reward :  -0.58784139881189\n",
      "episode :  16\n",
      "current step :  85\n",
      "reward :  -0.4520616580648299\n",
      "episode :  16\n",
      "current step :  86\n",
      "reward :  -0.5121131108126873\n",
      "episode :  16\n",
      "current step :  87\n",
      "reward :  -0.48060150216097774\n",
      "episode :  16\n",
      "current step :  88\n",
      "reward :  -0.43381829912832864\n",
      "episode :  16\n",
      "current step :  89\n",
      "reward :  -0.3447870350372125\n",
      "episode :  16\n",
      "current step :  90\n",
      "reward :  -0.238849274813925\n",
      "episode :  16\n",
      "current step :  91\n",
      "reward :  -0.30931532896414726\n",
      "episode :  16\n",
      "current step :  92\n",
      "reward :  -0.517568911102592\n",
      "episode :  16\n",
      "current step :  93\n",
      "reward :  -0.5297180127643328\n",
      "episode :  16\n",
      "current step :  94\n",
      "reward :  -0.475839308607437\n",
      "episode :  16\n",
      "current step :  95\n",
      "reward :  -0.4418975289949928\n",
      "episode :  16\n",
      "current step :  96\n",
      "reward :  -0.3748567195313964\n",
      "episode :  16\n",
      "current step :  97\n",
      "reward :  -0.502007169926649\n",
      "episode :  16\n",
      "current step :  98\n",
      "reward :  -0.48873891240945616\n",
      "episode :  16\n",
      "current step :  99\n",
      "reward :  -0.457945985909749\n",
      "episode :  16\n",
      "current step :  100\n",
      "reward :  -0.34753059623342086\n",
      "episode :  16\n",
      "current step :  101\n",
      "reward :  -0.27216454192868883\n",
      "episode :  16\n",
      "current step :  102\n",
      "reward :  -0.34977881302024344\n",
      "episode :  16\n",
      "current step :  103\n",
      "reward :  -0.26843845276588685\n",
      "episode :  16\n",
      "current step :  104\n",
      "reward :  -0.3463299175226753\n",
      "episode :  16\n",
      "current step :  105\n",
      "reward :  -0.28630017311391764\n",
      "episode :  16\n",
      "current step :  106\n",
      "reward :  -0.2684022188127036\n",
      "episode :  16\n",
      "current step :  107\n",
      "reward :  -0.24083165960882855\n",
      "episode :  16\n",
      "current step :  108\n",
      "reward :  -0.25137464111373264\n",
      "episode :  16\n",
      "current step :  109\n",
      "reward :  -0.35002326586948634\n",
      "episode :  16\n",
      "current step :  110\n",
      "reward :  -0.2394543538362229\n",
      "episode :  16\n",
      "current step :  111\n",
      "reward :  -0.4340052213078258\n",
      "episode :  16\n",
      "current step :  112\n",
      "reward :  -0.33014792390473713\n",
      "episode :  16\n",
      "current step :  113\n",
      "reward :  -0.2707469833426884\n",
      "episode :  16\n",
      "current step :  114\n",
      "reward :  -0.36895425872937815\n",
      "episode :  16\n",
      "current step :  115\n",
      "reward :  -0.4653686121382861\n",
      "episode :  16\n",
      "current step :  116\n",
      "reward :  -0.27394784962739926\n",
      "episode :  16\n",
      "current step :  117\n",
      "reward :  -0.3883496605984186\n",
      "episode :  16\n",
      "current step :  118\n",
      "reward :  -0.46865834813745777\n",
      "episode :  16\n",
      "current step :  119\n",
      "reward :  -0.4462461911692492\n",
      "episode :  16\n",
      "current step :  120\n",
      "reward :  -0.28838571439856187\n",
      "episode :  16\n",
      "current step :  121\n",
      "reward :  -0.28250995942491225\n",
      "episode :  16\n",
      "current step :  122\n",
      "reward :  -0.37819345474254357\n",
      "episode :  16\n",
      "current step :  123\n",
      "reward :  -0.39848085201841843\n",
      "episode :  16\n",
      "current step :  124\n",
      "reward :  -0.28737358250948286\n",
      "episode :  16\n",
      "current step :  125\n",
      "reward :  -0.22411680571775056\n",
      "episode :  16\n",
      "current step :  126\n",
      "reward :  -0.3059247502920198\n",
      "episode :  16\n",
      "current step :  127\n",
      "reward :  -0.34068738478636784\n",
      "episode :  16\n",
      "current step :  128\n",
      "reward :  -0.3717923201159736\n",
      "episode :  16\n",
      "current step :  129\n",
      "reward :  -0.28833372505595495\n",
      "episode :  16\n",
      "current step :  130\n",
      "reward :  -0.2249015014799138\n",
      "episode :  16\n",
      "current step :  131\n",
      "reward :  -0.3115228892490689\n",
      "episode :  16\n",
      "current step :  132\n",
      "reward :  -0.4055406969454034\n",
      "episode :  16\n",
      "current step :  133\n",
      "reward :  -0.3955183279146537\n",
      "episode :  16\n",
      "current step :  134\n",
      "reward :  -0.271166211408278\n",
      "episode :  16\n",
      "current step :  135\n",
      "reward :  -0.3909533953458888\n",
      "episode :  16\n",
      "current step :  136\n",
      "reward :  -0.30482052736542525\n",
      "episode :  16\n",
      "current step :  137\n",
      "reward :  -0.26930590791540604\n",
      "episode :  16\n",
      "current step :  138\n",
      "reward :  -0.3743082963916736\n",
      "episode :  16\n",
      "current step :  139\n",
      "reward :  -0.31181555556222956\n",
      "episode :  16\n",
      "current step :  140\n",
      "reward :  -0.29448050625115496\n",
      "episode :  16\n",
      "current step :  141\n",
      "reward :  -0.4127840056566114\n",
      "episode :  16\n",
      "current step :  142\n",
      "reward :  -0.23404708332344104\n",
      "episode :  16\n",
      "current step :  143\n",
      "reward :  -0.33803643977981446\n",
      "episode :  16\n",
      "current step :  144\n",
      "reward :  -0.2741306869040831\n",
      "episode :  16\n",
      "current step :  145\n",
      "reward :  -0.33376114307950666\n",
      "episode :  16\n",
      "current step :  146\n",
      "reward :  -0.38953670308191657\n",
      "episode :  16\n",
      "current step :  147\n",
      "reward :  -0.3073050673309877\n",
      "episode :  16\n",
      "current step :  148\n",
      "reward :  -0.280229951259086\n",
      "episode :  16\n",
      "current step :  149\n",
      "reward :  -0.2051639801760989\n",
      "episode :  16\n",
      "current step :  150\n",
      "reward :  -0.3368167674321668\n",
      "episode :  16\n",
      "current step :  151\n",
      "reward :  -0.4366410049378204\n",
      "episode :  16\n",
      "current step :  152\n",
      "reward :  -0.48429879835927864\n",
      "episode :  16\n",
      "current step :  153\n",
      "reward :  -0.41173158797117015\n",
      "episode :  16\n",
      "current step :  154\n",
      "reward :  -0.3534494376225075\n",
      "episode :  16\n",
      "current step :  155\n",
      "reward :  -0.265159475147498\n",
      "episode :  16\n",
      "current step :  156\n",
      "reward :  -0.6041213571430936\n",
      "episode :  16\n",
      "current step :  157\n",
      "reward :  -0.5290494086791122\n",
      "episode :  16\n",
      "current step :  158\n",
      "reward :  -0.5139144071065079\n",
      "episode :  16\n",
      "current step :  159\n",
      "reward :  -0.3735141108355548\n",
      "episode :  16\n",
      "current step :  160\n",
      "reward :  -0.3374005502218292\n",
      "episode :  16\n",
      "current step :  161\n",
      "reward :  -0.31098463952145444\n",
      "episode :  16\n",
      "current step :  162\n",
      "reward :  -0.2951320741792114\n",
      "episode :  16\n",
      "current step :  163\n",
      "reward :  -0.33943913910036577\n",
      "episode :  16\n",
      "current step :  164\n",
      "reward :  -0.45585949739422804\n",
      "episode :  16\n",
      "current step :  165\n",
      "reward :  -0.33613301582957333\n",
      "episode :  16\n",
      "current step :  166\n",
      "reward :  -0.4358931204426831\n",
      "episode :  16\n",
      "current step :  167\n",
      "reward :  -0.2994191201715991\n",
      "episode :  16\n",
      "current step :  168\n",
      "reward :  -0.31823609622980614\n",
      "episode :  16\n",
      "current step :  169\n",
      "reward :  -0.264598902818199\n",
      "episode :  16\n",
      "current step :  170\n",
      "reward :  -0.3030394903007169\n",
      "episode :  16\n",
      "current step :  171\n",
      "reward :  -0.5009484456206512\n",
      "episode :  16\n",
      "current step :  172\n",
      "reward :  -0.34352473862391436\n",
      "episode :  16\n",
      "current step :  173\n",
      "reward :  -0.4518793641122038\n",
      "episode :  16\n",
      "current step :  174\n",
      "reward :  -0.5307475446130934\n",
      "episode :  16\n",
      "current step :  175\n",
      "reward :  -0.5343119210161422\n",
      "episode :  16\n",
      "current step :  176\n",
      "reward :  -0.38150059301848566\n",
      "episode :  16\n",
      "current step :  177\n",
      "reward :  -0.471431077209509\n",
      "episode :  16\n",
      "current step :  178\n",
      "reward :  -0.4506645064350724\n",
      "episode :  16\n",
      "current step :  179\n",
      "reward :  -0.43922018039648086\n",
      "episode :  16\n",
      "current step :  180\n",
      "reward :  -0.4843117292235738\n",
      "episode :  16\n",
      "current step :  181\n",
      "reward :  -0.5297225046991956\n",
      "episode :  16\n",
      "current step :  182\n",
      "reward :  -0.45729791840227646\n",
      "episode :  16\n",
      "current step :  183\n",
      "reward :  -0.6134995333416511\n",
      "episode :  16\n",
      "current step :  184\n",
      "reward :  -0.6248708802186231\n",
      "episode :  16\n",
      "current step :  185\n",
      "reward :  -0.614698090483984\n",
      "episode :  16\n",
      "current step :  186\n",
      "reward :  -0.6620794603515755\n",
      "episode :  16\n",
      "current step :  187\n",
      "reward :  -0.5339252389559089\n",
      "episode :  16\n",
      "current step :  188\n",
      "reward :  -0.5436166299798282\n",
      "episode :  16\n",
      "current step :  189\n",
      "reward :  -0.529262844064358\n",
      "episode :  16\n",
      "current step :  190\n",
      "reward :  -0.5591147417084936\n",
      "episode :  16\n",
      "current step :  191\n",
      "reward :  -0.6279636410927861\n",
      "episode :  16\n",
      "current step :  192\n",
      "reward :  -0.5152892717421562\n",
      "episode :  16\n",
      "current step :  193\n",
      "reward :  -0.4820199920916505\n",
      "episode :  16\n",
      "current step :  194\n",
      "reward :  -0.4879730959680438\n",
      "episode :  16\n",
      "current step :  195\n",
      "reward :  -0.49262693114406314\n",
      "episode :  16\n",
      "current step :  196\n",
      "reward :  -0.7015656861669959\n",
      "episode :  16\n",
      "current step :  197\n",
      "reward :  -0.650209202053203\n",
      "episode :  16\n",
      "current step :  198\n",
      "reward :  -0.6637218832066796\n",
      "episode :  16\n",
      "current step :  199\n",
      "reward :  -0.721252210719825\n",
      "episode :  16\n",
      "current step :  200\n",
      "reward :  -0.5006046151151462\n",
      "episode :  16\n",
      "current step :  201\n",
      "reward :  -0.757189689272006\n",
      "episode :  16\n",
      "current step :  202\n",
      "reward :  -0.711633311782987\n",
      "episode :  16\n",
      "current step :  203\n",
      "reward :  -0.7178937226008345\n",
      "episode :  16\n",
      "current step :  204\n",
      "reward :  -0.5866274999313066\n",
      "episode :  16\n",
      "current step :  205\n",
      "reward :  -0.5751975331432001\n",
      "episode :  16\n",
      "current step :  206\n",
      "reward :  -0.45767723326615173\n",
      "episode :  16\n",
      "current step :  207\n",
      "reward :  -0.46559952874795363\n",
      "episode :  16\n",
      "current step :  208\n",
      "reward :  -0.5524222979303282\n",
      "episode :  16\n",
      "current step :  209\n",
      "reward :  -0.6187042114858\n",
      "episode :  16\n",
      "current step :  210\n",
      "reward :  -0.5569135719927759\n",
      "episode :  16\n",
      "current step :  211\n",
      "reward :  -0.2879124787827866\n",
      "episode :  16\n",
      "current step :  212\n",
      "reward :  -0.5590965263180129\n",
      "episode :  16\n",
      "current step :  213\n",
      "reward :  -0.45947011528489984\n",
      "episode :  16\n",
      "current step :  214\n",
      "reward :  -0.3478410301206636\n",
      "episode :  16\n",
      "current step :  215\n",
      "reward :  -0.4892935003435914\n",
      "episode :  16\n",
      "current step :  216\n",
      "reward :  -0.35927673499360274\n",
      "episode :  16\n",
      "current step :  217\n",
      "reward :  -0.238736402268161\n",
      "episode :  16\n",
      "current step :  218\n",
      "reward :  -0.28783685493743544\n",
      "episode :  16\n",
      "current step :  219\n",
      "reward :  -0.39394540018592383\n",
      "episode :  16\n",
      "current step :  220\n",
      "reward :  -0.5575613252446712\n",
      "episode :  16\n",
      "current step :  221\n",
      "reward :  -0.471339635338907\n",
      "episode :  16\n",
      "current step :  222\n",
      "reward :  -0.5337892543633277\n",
      "episode :  16\n",
      "current step :  223\n",
      "reward :  -0.6377271528832965\n",
      "episode :  16\n",
      "current step :  224\n",
      "reward :  -0.4096462153144896\n",
      "episode :  16\n",
      "current step :  225\n",
      "reward :  -0.5508014809398322\n",
      "episode :  16\n",
      "current step :  226\n",
      "reward :  -0.7163293782782174\n",
      "episode :  16\n",
      "current step :  227\n",
      "reward :  -0.560333277780794\n",
      "episode :  16\n",
      "current step :  228\n",
      "reward :  -0.44419193612038005\n",
      "episode :  16\n",
      "current step :  229\n",
      "reward :  -0.3212922090271139\n",
      "episode :  16\n",
      "current step :  230\n",
      "reward :  -0.4497835340361007\n",
      "episode :  16\n",
      "current step :  231\n",
      "reward :  -0.5654333748553159\n",
      "episode :  16\n",
      "current step :  232\n",
      "reward :  -0.6760086763151334\n",
      "episode :  16\n",
      "current step :  233\n",
      "reward :  -0.5800218589154402\n",
      "episode :  16\n",
      "current step :  234\n",
      "reward :  -0.4245149911757292\n",
      "episode :  16\n",
      "current step :  235\n",
      "reward :  -0.31010709179756824\n",
      "episode :  16\n",
      "current step :  236\n",
      "reward :  -0.4749331807181309\n",
      "episode :  16\n",
      "current step :  237\n",
      "reward :  -0.5185299677937784\n",
      "episode :  16\n",
      "current step :  238\n",
      "reward :  -0.470333291551871\n",
      "episode :  16\n",
      "current step :  239\n",
      "reward :  -0.40334866311044365\n",
      "episode :  16\n",
      "current step :  240\n",
      "reward :  -0.4813279271265964\n",
      "episode :  16\n",
      "current step :  241\n",
      "reward :  -0.4921994879699628\n",
      "episode :  16\n",
      "current step :  242\n",
      "reward :  -0.4143476117758588\n",
      "episode :  16\n",
      "current step :  243\n",
      "reward :  -0.41273844374726837\n",
      "episode :  16\n",
      "current step :  244\n",
      "reward :  -0.3669205182525376\n",
      "episode :  16\n",
      "current step :  245\n",
      "reward :  -0.3521354695554953\n",
      "episode :  16\n",
      "current step :  246\n",
      "reward :  -0.2852336554088393\n",
      "episode :  16\n",
      "current step :  247\n",
      "reward :  -0.31123671665393454\n",
      "episode :  16\n",
      "current step :  248\n",
      "reward :  -0.37292856382064354\n",
      "episode :  16\n",
      "current step :  249\n",
      "reward :  -0.30030965470306537\n",
      "episode :  16\n",
      "current step :  250\n",
      "reward :  -0.18417777982292505\n",
      "episode :  16\n",
      "current step :  251\n",
      "reward :  -0.24488041881339928\n",
      "episode :  16\n",
      "current step :  252\n",
      "reward :  -0.22686276883702294\n",
      "episode :  16\n",
      "current step :  253\n",
      "reward :  -0.2595119972092846\n",
      "episode :  16\n",
      "current step :  254\n",
      "reward :  -0.3113843151113399\n",
      "episode :  16\n",
      "current step :  255\n",
      "reward :  -0.24479059844603104\n",
      "episode :  16\n",
      "current step :  256\n",
      "reward :  -0.3368591459644156\n",
      "episode :  16\n",
      "current step :  257\n",
      "reward :  -0.2309750569237602\n",
      "episode :  16\n",
      "current step :  258\n",
      "reward :  -0.26431549190939463\n",
      "episode :  16\n",
      "current step :  259\n",
      "reward :  -0.31645874028695065\n",
      "episode :  16\n",
      "current step :  260\n",
      "reward :  -0.4200869077955086\n",
      "episode :  16\n",
      "current step :  261\n",
      "reward :  -0.3263119691245295\n",
      "episode :  16\n",
      "current step :  262\n",
      "reward :  -0.3542560151240164\n",
      "episode :  16\n",
      "current step :  263\n",
      "reward :  -0.3951388727681059\n",
      "episode :  16\n",
      "current step :  264\n",
      "reward :  -0.4613918094249203\n",
      "episode :  16\n",
      "current step :  265\n",
      "reward :  -0.43378237171171213\n",
      "episode :  16\n",
      "current step :  266\n",
      "reward :  -0.06262327446467664\n",
      "episode :  16\n",
      "current step :  267\n",
      "reward :  -0.17936578860985078\n",
      "episode :  16\n",
      "current step :  268\n",
      "reward :  -0.18426008409248512\n",
      "episode :  16\n",
      "current step :  269\n",
      "reward :  -0.23216091031278352\n",
      "episode :  16\n",
      "current step :  270\n",
      "reward :  -0.2386441637087496\n",
      "episode :  16\n",
      "current step :  271\n",
      "reward :  -0.38070495832798584\n",
      "episode :  16\n",
      "current step :  272\n",
      "reward :  -0.4630969973175827\n",
      "episode :  16\n",
      "current step :  273\n",
      "reward :  -0.3005318910502346\n",
      "episode :  16\n",
      "current step :  274\n",
      "reward :  -0.14668247114400848\n",
      "episode :  16\n",
      "current step :  275\n",
      "reward :  -0.2175851613599279\n",
      "episode :  16\n",
      "current step :  276\n",
      "reward :  -0.451898559137441\n",
      "episode :  16\n",
      "current step :  277\n",
      "reward :  -0.4781120639149877\n",
      "episode :  16\n",
      "current step :  278\n",
      "reward :  -0.39770159620428913\n",
      "episode :  16\n",
      "current step :  279\n",
      "reward :  -0.4591161546215612\n",
      "episode :  16\n",
      "current step :  280\n",
      "reward :  -0.35185742172130424\n",
      "episode :  16\n",
      "current step :  281\n",
      "reward :  -0.29739739072929694\n",
      "episode :  16\n",
      "current step :  282\n",
      "reward :  -0.5093590079684067\n",
      "episode :  16\n",
      "current step :  283\n",
      "reward :  -0.5375647895138886\n",
      "episode :  16\n",
      "current step :  284\n",
      "reward :  -0.360122695966966\n",
      "episode :  16\n",
      "current step :  285\n",
      "reward :  -0.27102687031289546\n",
      "episode :  17\n",
      "current step :  0\n",
      "reward :  -0.1916089321370129\n",
      "episode :  17\n",
      "current step :  1\n",
      "reward :  -0.15455119944344778\n",
      "episode :  17\n",
      "current step :  2\n",
      "reward :  -0.18629091305492784\n",
      "episode :  17\n",
      "current step :  3\n",
      "reward :  -0.3601498146476918\n",
      "episode :  17\n",
      "current step :  4\n",
      "reward :  -0.21962656978185655\n",
      "episode :  17\n",
      "current step :  5\n",
      "reward :  -0.4120961126390877\n",
      "episode :  17\n",
      "current step :  6\n",
      "reward :  -0.4241096039362694\n",
      "episode :  17\n",
      "current step :  7\n",
      "reward :  -0.4095219077040356\n",
      "episode :  17\n",
      "current step :  8\n",
      "reward :  -0.2769383723985666\n",
      "episode :  17\n",
      "current step :  9\n",
      "reward :  -0.24902517174301886\n",
      "episode :  17\n",
      "current step :  10\n",
      "reward :  -0.3151007136029274\n",
      "episode :  17\n",
      "current step :  11\n",
      "reward :  -0.3710992022438855\n",
      "episode :  17\n",
      "current step :  12\n",
      "reward :  -0.39174039461981025\n",
      "episode :  17\n",
      "current step :  13\n",
      "reward :  -0.23778022219470438\n",
      "episode :  17\n",
      "current step :  14\n",
      "reward :  -0.4024888304694641\n",
      "episode :  17\n",
      "current step :  15\n",
      "reward :  -0.2966625485984683\n",
      "episode :  17\n",
      "current step :  16\n",
      "reward :  -0.3078702934560646\n",
      "episode :  17\n",
      "current step :  17\n",
      "reward :  -0.47201271868226674\n",
      "episode :  17\n",
      "current step :  18\n",
      "reward :  -0.4739677497769639\n",
      "episode :  17\n",
      "current step :  19\n",
      "reward :  -0.1658279194356544\n",
      "episode :  17\n",
      "current step :  20\n",
      "reward :  -0.284396783084486\n",
      "episode :  17\n",
      "current step :  21\n",
      "reward :  -0.3162568278753851\n",
      "episode :  17\n",
      "current step :  22\n",
      "reward :  -0.4365258383590049\n",
      "episode :  17\n",
      "current step :  23\n",
      "reward :  -0.3360672833904031\n",
      "episode :  17\n",
      "current step :  24\n",
      "reward :  -0.34805408166148993\n",
      "episode :  17\n",
      "current step :  25\n",
      "reward :  -0.3682653628225147\n",
      "episode :  17\n",
      "current step :  26\n",
      "reward :  -0.3753482472497787\n",
      "episode :  17\n",
      "current step :  27\n",
      "reward :  -0.534750050377702\n",
      "episode :  17\n",
      "current step :  28\n",
      "reward :  -0.38418183871003087\n",
      "episode :  17\n",
      "current step :  29\n",
      "reward :  -0.42523115690829305\n",
      "episode :  17\n",
      "current step :  30\n",
      "reward :  -0.2703580251822452\n",
      "episode :  17\n",
      "current step :  31\n",
      "reward :  -0.46858694270651613\n",
      "episode :  17\n",
      "current step :  32\n",
      "reward :  -0.41183829750297785\n",
      "episode :  17\n",
      "current step :  33\n",
      "reward :  -0.4287766062613657\n",
      "episode :  17\n",
      "current step :  34\n",
      "reward :  -0.31850853235924764\n",
      "episode :  17\n",
      "current step :  35\n",
      "reward :  -0.44477392658315196\n",
      "episode :  17\n",
      "current step :  36\n",
      "reward :  -0.636958522735641\n",
      "episode :  17\n",
      "current step :  37\n",
      "reward :  -0.48732330038011834\n",
      "episode :  17\n",
      "current step :  38\n",
      "reward :  -0.38752803153103693\n",
      "episode :  17\n",
      "current step :  39\n",
      "reward :  -0.34426516206879476\n",
      "episode :  17\n",
      "current step :  40\n",
      "reward :  -0.5443285790758741\n",
      "episode :  17\n",
      "current step :  41\n",
      "reward :  -0.44862459238441027\n",
      "episode :  17\n",
      "current step :  42\n",
      "reward :  -0.4809143662438004\n",
      "episode :  17\n",
      "current step :  43\n",
      "reward :  -0.5393260818304974\n",
      "episode :  17\n",
      "current step :  44\n",
      "reward :  -0.41880214615740574\n",
      "episode :  17\n",
      "current step :  45\n",
      "reward :  -0.4242117979629674\n",
      "episode :  17\n",
      "current step :  46\n",
      "reward :  -0.7472998873282658\n",
      "episode :  17\n",
      "current step :  47\n",
      "reward :  -0.7375643620731026\n",
      "episode :  17\n",
      "current step :  48\n",
      "reward :  -0.5491682043310234\n",
      "episode :  17\n",
      "current step :  49\n",
      "reward :  -0.5053501963089043\n",
      "episode :  17\n",
      "current step :  50\n",
      "reward :  -0.39619951260510783\n",
      "episode :  17\n",
      "current step :  51\n",
      "reward :  -0.5326844313338364\n",
      "episode :  17\n",
      "current step :  52\n",
      "reward :  -0.5172237553597112\n",
      "episode :  17\n",
      "current step :  53\n",
      "reward :  -0.7019723347882342\n",
      "episode :  17\n",
      "current step :  54\n",
      "reward :  -0.6224932484749238\n",
      "episode :  17\n",
      "current step :  55\n",
      "reward :  -0.7624787065477758\n",
      "episode :  17\n",
      "current step :  56\n",
      "reward :  -0.6885757377837337\n",
      "episode :  17\n",
      "current step :  57\n",
      "reward :  -0.6255583417444717\n",
      "episode :  17\n",
      "current step :  58\n",
      "reward :  -0.5504503056043563\n",
      "episode :  17\n",
      "current step :  59\n",
      "reward :  -0.547914279300555\n",
      "episode :  17\n",
      "current step :  60\n",
      "reward :  -0.5613206617620321\n",
      "episode :  17\n",
      "current step :  61\n",
      "reward :  -0.45568643261269653\n",
      "episode :  17\n",
      "current step :  62\n",
      "reward :  -0.38708387354351603\n",
      "episode :  17\n",
      "current step :  63\n",
      "reward :  -0.36914597579336195\n",
      "episode :  17\n",
      "current step :  64\n",
      "reward :  -0.49374567276476417\n",
      "episode :  17\n",
      "current step :  65\n",
      "reward :  -0.5701644190113758\n",
      "episode :  17\n",
      "current step :  66\n",
      "reward :  -0.6334908480948712\n",
      "episode :  17\n",
      "current step :  67\n",
      "reward :  -0.5569451300081022\n",
      "episode :  17\n",
      "current step :  68\n",
      "reward :  -0.5080509610948859\n",
      "episode :  17\n",
      "current step :  69\n",
      "reward :  -0.43205330991969604\n",
      "episode :  17\n",
      "current step :  70\n",
      "reward :  -0.46213613329946807\n",
      "episode :  17\n",
      "current step :  71\n",
      "reward :  -0.5081557190055399\n",
      "episode :  17\n",
      "current step :  72\n",
      "reward :  -0.6709712430233199\n",
      "episode :  17\n",
      "current step :  73\n",
      "reward :  -0.511420015173237\n",
      "episode :  17\n",
      "current step :  74\n",
      "reward :  -0.5701513160933483\n",
      "episode :  17\n",
      "current step :  75\n",
      "reward :  -0.48115741482417684\n",
      "episode :  17\n",
      "current step :  76\n",
      "reward :  -0.5430999977977468\n",
      "episode :  17\n",
      "current step :  77\n",
      "reward :  -0.46760437086108897\n",
      "episode :  17\n",
      "current step :  78\n",
      "reward :  -0.4837493123190585\n",
      "episode :  17\n",
      "current step :  79\n",
      "reward :  -0.5749444202820533\n",
      "episode :  17\n",
      "current step :  80\n",
      "reward :  -0.5730234083616462\n",
      "episode :  17\n",
      "current step :  81\n",
      "reward :  -0.3892406894683223\n",
      "episode :  17\n",
      "current step :  82\n",
      "reward :  -0.3819925508488295\n",
      "episode :  17\n",
      "current step :  83\n",
      "reward :  -0.5460765679342119\n",
      "episode :  17\n",
      "current step :  84\n",
      "reward :  -0.4461539913734233\n",
      "episode :  17\n",
      "current step :  85\n",
      "reward :  -0.41322524069377936\n",
      "episode :  17\n",
      "current step :  86\n",
      "reward :  -0.39766236005767475\n",
      "episode :  17\n",
      "current step :  87\n",
      "reward :  -0.2288708935595994\n",
      "episode :  17\n",
      "current step :  88\n",
      "reward :  -0.35499449709611036\n",
      "episode :  17\n",
      "current step :  89\n",
      "reward :  -0.3625632623282716\n",
      "episode :  17\n",
      "current step :  90\n",
      "reward :  -0.3189944797818851\n",
      "episode :  17\n",
      "current step :  91\n",
      "reward :  -0.3953943042672312\n",
      "episode :  17\n",
      "current step :  92\n",
      "reward :  -0.5579175185973462\n",
      "episode :  17\n",
      "current step :  93\n",
      "reward :  -0.4910247853763167\n",
      "episode :  17\n",
      "current step :  94\n",
      "reward :  -0.49567723133798\n",
      "episode :  17\n",
      "current step :  95\n",
      "reward :  -0.1870383334037804\n",
      "episode :  17\n",
      "current step :  96\n",
      "reward :  -0.14284586924993237\n",
      "episode :  17\n",
      "current step :  97\n",
      "reward :  -0.13153871903263203\n",
      "episode :  17\n",
      "current step :  98\n",
      "reward :  -0.24424734596425973\n",
      "episode :  17\n",
      "current step :  99\n",
      "reward :  -0.33212611142232135\n",
      "episode :  17\n",
      "current step :  100\n",
      "reward :  -0.5076932501207926\n",
      "episode :  17\n",
      "current step :  101\n",
      "reward :  -0.4624758058160489\n",
      "episode :  17\n",
      "current step :  102\n",
      "reward :  -0.344284612971023\n",
      "episode :  17\n",
      "current step :  103\n",
      "reward :  -0.3145029728046342\n",
      "episode :  17\n",
      "current step :  104\n",
      "reward :  -0.25579645569368925\n",
      "episode :  17\n",
      "current step :  105\n",
      "reward :  -0.3445254960612572\n",
      "episode :  17\n",
      "current step :  106\n",
      "reward :  -0.3687746217737913\n",
      "episode :  17\n",
      "current step :  107\n",
      "reward :  -0.3195764095097575\n",
      "episode :  17\n",
      "current step :  108\n",
      "reward :  -0.3443935315577358\n",
      "episode :  17\n",
      "current step :  109\n",
      "reward :  -0.27517516567001193\n",
      "episode :  17\n",
      "current step :  110\n",
      "reward :  -0.3161468498169762\n",
      "episode :  17\n",
      "current step :  111\n",
      "reward :  -0.26170771179652397\n",
      "episode :  17\n",
      "current step :  112\n",
      "reward :  -0.2519510025818758\n",
      "episode :  17\n",
      "current step :  113\n",
      "reward :  -0.2584014962149307\n",
      "episode :  17\n",
      "current step :  114\n",
      "reward :  -0.2797288544828379\n",
      "episode :  17\n",
      "current step :  115\n",
      "reward :  -0.23100833271526605\n",
      "episode :  17\n",
      "current step :  116\n",
      "reward :  -0.1516373238862883\n",
      "episode :  17\n",
      "current step :  117\n",
      "reward :  -0.37206932639661794\n",
      "episode :  17\n",
      "current step :  118\n",
      "reward :  -0.3420820133891399\n",
      "episode :  17\n",
      "current step :  119\n",
      "reward :  -0.29037460425397604\n",
      "episode :  17\n",
      "current step :  120\n",
      "reward :  -0.3874787331910076\n",
      "episode :  17\n",
      "current step :  121\n",
      "reward :  -0.429786697128214\n",
      "episode :  17\n",
      "current step :  122\n",
      "reward :  -0.5188618260205783\n",
      "episode :  17\n",
      "current step :  123\n",
      "reward :  -0.48628228960275127\n",
      "episode :  17\n",
      "current step :  124\n",
      "reward :  -0.29754780318096685\n",
      "episode :  17\n",
      "current step :  125\n",
      "reward :  -0.28363574776977596\n",
      "episode :  17\n",
      "current step :  126\n",
      "reward :  -0.30769540974761667\n",
      "episode :  17\n",
      "current step :  127\n",
      "reward :  -0.25290901507263835\n",
      "episode :  17\n",
      "current step :  128\n",
      "reward :  -0.3071099312087878\n",
      "episode :  17\n",
      "current step :  129\n",
      "reward :  -0.3522669226810193\n",
      "episode :  17\n",
      "current step :  130\n",
      "reward :  -0.3885227357302259\n",
      "episode :  17\n",
      "current step :  131\n",
      "reward :  -0.4183295215454648\n",
      "episode :  17\n",
      "current step :  132\n",
      "reward :  -0.3559969388731584\n",
      "episode :  17\n",
      "current step :  133\n",
      "reward :  -0.4924689899668702\n",
      "episode :  17\n",
      "current step :  134\n",
      "reward :  -0.48564969701160715\n",
      "episode :  17\n",
      "current step :  135\n",
      "reward :  -0.43625022075111924\n",
      "episode :  17\n",
      "current step :  136\n",
      "reward :  -0.40261483266341475\n",
      "episode :  17\n",
      "current step :  137\n",
      "reward :  -0.3414886817575247\n",
      "episode :  17\n",
      "current step :  138\n",
      "reward :  -0.48476616288421315\n",
      "episode :  17\n",
      "current step :  139\n",
      "reward :  -0.20707797290046587\n",
      "episode :  17\n",
      "current step :  140\n",
      "reward :  -0.2882619407275114\n",
      "episode :  17\n",
      "current step :  141\n",
      "reward :  -0.26635512641993725\n",
      "episode :  17\n",
      "current step :  142\n",
      "reward :  -0.29284304826295016\n",
      "episode :  17\n",
      "current step :  143\n",
      "reward :  -0.27634990242223145\n",
      "episode :  17\n",
      "current step :  144\n",
      "reward :  -0.4102674047884939\n",
      "episode :  17\n",
      "current step :  145\n",
      "reward :  -0.3796211248522782\n",
      "episode :  17\n",
      "current step :  146\n",
      "reward :  -0.4066657245371595\n",
      "episode :  17\n",
      "current step :  147\n",
      "reward :  -0.4044666713396889\n",
      "episode :  17\n",
      "current step :  148\n",
      "reward :  -0.4497871383413683\n",
      "episode :  17\n",
      "current step :  149\n",
      "reward :  -0.39938643614109776\n",
      "episode :  17\n",
      "current step :  150\n",
      "reward :  -0.39625300391179724\n",
      "episode :  17\n",
      "current step :  151\n",
      "reward :  -0.3752346225685273\n",
      "episode :  17\n",
      "current step :  152\n",
      "reward :  -0.2922826017239223\n",
      "episode :  17\n",
      "current step :  153\n",
      "reward :  -0.3222170738225696\n",
      "episode :  17\n",
      "current step :  154\n",
      "reward :  -0.19051045569524336\n",
      "episode :  17\n",
      "current step :  155\n",
      "reward :  -0.3156659182610216\n",
      "episode :  17\n",
      "current step :  156\n",
      "reward :  -0.4582627116106502\n",
      "episode :  17\n",
      "current step :  157\n",
      "reward :  -0.5477668477730304\n",
      "episode :  17\n",
      "current step :  158\n",
      "reward :  -0.594531058086586\n",
      "episode :  17\n",
      "current step :  159\n",
      "reward :  -0.5732678907158906\n",
      "episode :  17\n",
      "current step :  160\n",
      "reward :  -0.6135430540584796\n",
      "episode :  17\n",
      "current step :  161\n",
      "reward :  -0.4610908051129005\n",
      "episode :  17\n",
      "current step :  162\n",
      "reward :  -0.5307850969727863\n",
      "episode :  17\n",
      "current step :  163\n",
      "reward :  -0.5959141764846445\n",
      "episode :  17\n",
      "current step :  164\n",
      "reward :  -0.47902649928343466\n",
      "episode :  17\n",
      "current step :  165\n",
      "reward :  -0.47325314206696917\n",
      "episode :  17\n",
      "current step :  166\n",
      "reward :  -0.545688146015078\n",
      "episode :  17\n",
      "current step :  167\n",
      "reward :  -0.43584450225431975\n",
      "episode :  17\n",
      "current step :  168\n",
      "reward :  -0.31825211191070735\n",
      "episode :  17\n",
      "current step :  169\n",
      "reward :  -0.3775135918474912\n",
      "episode :  17\n",
      "current step :  170\n",
      "reward :  -0.5489134896630724\n",
      "episode :  17\n",
      "current step :  171\n",
      "reward :  -0.6362154931437172\n",
      "episode :  17\n",
      "current step :  172\n",
      "reward :  -0.660582426860492\n",
      "episode :  17\n",
      "current step :  173\n",
      "reward :  -0.5163620638664134\n",
      "episode :  17\n",
      "current step :  174\n",
      "reward :  -0.7172851625209645\n",
      "episode :  17\n",
      "current step :  175\n",
      "reward :  -0.6603491921881113\n",
      "episode :  17\n",
      "current step :  176\n",
      "reward :  -0.39131287884575067\n",
      "episode :  17\n",
      "current step :  177\n",
      "reward :  -0.3102658941513824\n",
      "episode :  17\n",
      "current step :  178\n",
      "reward :  -0.315314996047035\n",
      "episode :  17\n",
      "current step :  179\n",
      "reward :  -0.26953086098249945\n",
      "episode :  17\n",
      "current step :  180\n",
      "reward :  -0.5714279898240296\n",
      "episode :  17\n",
      "current step :  181\n",
      "reward :  -0.4907307302386277\n",
      "episode :  17\n",
      "current step :  182\n",
      "reward :  -0.4472489618722112\n",
      "episode :  17\n",
      "current step :  183\n",
      "reward :  -0.3967415959738529\n",
      "episode :  17\n",
      "current step :  184\n",
      "reward :  -0.5347625132177133\n",
      "episode :  17\n",
      "current step :  185\n",
      "reward :  -0.6934761045869371\n",
      "episode :  17\n",
      "current step :  186\n",
      "reward :  -0.6077726555238043\n",
      "episode :  17\n",
      "current step :  187\n",
      "reward :  -0.6694488763356337\n",
      "episode :  17\n",
      "current step :  188\n",
      "reward :  -0.6675782923523068\n",
      "episode :  17\n",
      "current step :  189\n",
      "reward :  -0.7322620443224669\n",
      "episode :  17\n",
      "current step :  190\n",
      "reward :  -0.6889638253455433\n",
      "episode :  17\n",
      "current step :  191\n",
      "reward :  -0.6517350074597452\n",
      "episode :  17\n",
      "current step :  192\n",
      "reward :  -0.4541625599072805\n",
      "episode :  17\n",
      "current step :  193\n",
      "reward :  -0.4812326371996003\n",
      "episode :  17\n",
      "current step :  194\n",
      "reward :  -0.6216988879808668\n",
      "episode :  17\n",
      "current step :  195\n",
      "reward :  -0.6310725664018285\n",
      "episode :  17\n",
      "current step :  196\n",
      "reward :  -0.649975543278818\n",
      "episode :  17\n",
      "current step :  197\n",
      "reward :  -0.5975961503253114\n",
      "episode :  17\n",
      "current step :  198\n",
      "reward :  -0.44707965470339345\n",
      "episode :  17\n",
      "current step :  199\n",
      "reward :  -0.4853429683218829\n",
      "episode :  17\n",
      "current step :  200\n",
      "reward :  -0.452668733635508\n",
      "episode :  17\n",
      "current step :  201\n",
      "reward :  -0.5750427690215055\n",
      "episode :  17\n",
      "current step :  202\n",
      "reward :  -0.5040187831540661\n",
      "episode :  17\n",
      "current step :  203\n",
      "reward :  -0.5362331167155193\n",
      "episode :  17\n",
      "current step :  204\n",
      "reward :  -0.5802756973195708\n",
      "episode :  17\n",
      "current step :  205\n",
      "reward :  -0.6305062829486512\n",
      "episode :  17\n",
      "current step :  206\n",
      "reward :  -0.62082690481932\n",
      "episode :  17\n",
      "current step :  207\n",
      "reward :  -0.5292982392325931\n",
      "episode :  17\n",
      "current step :  208\n",
      "reward :  -0.71560181178278\n",
      "episode :  17\n",
      "current step :  209\n",
      "reward :  -0.7022034191243144\n",
      "episode :  17\n",
      "current step :  210\n",
      "reward :  -0.6314500708725476\n",
      "episode :  17\n",
      "current step :  211\n",
      "reward :  -0.55946042576393\n",
      "episode :  17\n",
      "current step :  212\n",
      "reward :  -0.5207576751945487\n",
      "episode :  17\n",
      "current step :  213\n",
      "reward :  -0.6370185480911059\n",
      "episode :  17\n",
      "current step :  214\n",
      "reward :  -0.6340512838316209\n",
      "episode :  17\n",
      "current step :  215\n",
      "reward :  -0.3189988229537923\n",
      "episode :  17\n",
      "current step :  216\n",
      "reward :  -0.5366387090159896\n",
      "episode :  17\n",
      "current step :  217\n",
      "reward :  -0.6198399134178266\n",
      "episode :  17\n",
      "current step :  218\n",
      "reward :  -0.4482505064090871\n",
      "episode :  17\n",
      "current step :  219\n",
      "reward :  -0.46439707309632583\n",
      "episode :  17\n",
      "current step :  220\n",
      "reward :  -0.5835313272373989\n",
      "episode :  17\n",
      "current step :  221\n",
      "reward :  -0.6363559480851104\n",
      "episode :  17\n",
      "current step :  222\n",
      "reward :  -0.6195765336722463\n",
      "episode :  17\n",
      "current step :  223\n",
      "reward :  -0.5550111083109688\n",
      "episode :  17\n",
      "current step :  224\n",
      "reward :  -0.3904921435489063\n",
      "episode :  17\n",
      "current step :  225\n",
      "reward :  -0.33428124231495615\n",
      "episode :  17\n",
      "current step :  226\n",
      "reward :  -0.43524339917627825\n",
      "episode :  17\n",
      "current step :  227\n",
      "reward :  -0.40782380518004124\n",
      "episode :  17\n",
      "current step :  228\n",
      "reward :  -0.44832551479458677\n",
      "episode :  17\n",
      "current step :  229\n",
      "reward :  -0.4277777320900097\n",
      "episode :  17\n",
      "current step :  230\n",
      "reward :  -0.5850330635234001\n",
      "episode :  17\n",
      "current step :  231\n",
      "reward :  -0.41065942496819335\n",
      "episode :  17\n",
      "current step :  232\n",
      "reward :  -0.4802980321054713\n",
      "episode :  17\n",
      "current step :  233\n",
      "reward :  -0.4107073391498822\n",
      "episode :  17\n",
      "current step :  234\n",
      "reward :  -0.3643510992476516\n",
      "episode :  17\n",
      "current step :  235\n",
      "reward :  -0.24624670151396616\n",
      "episode :  17\n",
      "current step :  236\n",
      "reward :  -0.29204266370078164\n",
      "episode :  17\n",
      "current step :  237\n",
      "reward :  -0.22663442818159388\n",
      "episode :  17\n",
      "current step :  238\n",
      "reward :  -0.053557941150703996\n",
      "episode :  17\n",
      "current step :  239\n",
      "reward :  -0.15787353444758417\n",
      "episode :  17\n",
      "current step :  240\n",
      "reward :  -0.1610511429344836\n",
      "episode :  17\n",
      "current step :  241\n",
      "reward :  -0.2363423079856508\n",
      "episode :  17\n",
      "current step :  242\n",
      "reward :  -0.29688058686843344\n",
      "episode :  17\n",
      "current step :  243\n",
      "reward :  -0.5638403771932333\n",
      "episode :  17\n",
      "current step :  244\n",
      "reward :  -0.383179311207443\n",
      "episode :  17\n",
      "current step :  245\n",
      "reward :  -0.4835414302976157\n",
      "episode :  17\n",
      "current step :  246\n",
      "reward :  -0.45347134795198923\n",
      "episode :  17\n",
      "current step :  247\n",
      "reward :  -0.43565663507008334\n",
      "episode :  17\n",
      "current step :  248\n",
      "reward :  -0.34140983690720234\n",
      "episode :  17\n",
      "current step :  249\n",
      "reward :  -0.3235348134345123\n",
      "episode :  17\n",
      "current step :  250\n",
      "reward :  -0.3466678746951053\n",
      "episode :  17\n",
      "current step :  251\n",
      "reward :  -0.44501085178145\n",
      "episode :  17\n",
      "current step :  252\n",
      "reward :  -0.556196215731808\n",
      "episode :  17\n",
      "current step :  253\n",
      "reward :  -0.5101543646692426\n",
      "episode :  17\n",
      "current step :  254\n",
      "reward :  -0.5323526971223416\n",
      "episode :  17\n",
      "current step :  255\n",
      "reward :  -0.41845068273950276\n",
      "episode :  17\n",
      "current step :  256\n",
      "reward :  -0.5461139159760119\n",
      "episode :  17\n",
      "current step :  257\n",
      "reward :  -0.42388773276480957\n",
      "episode :  17\n",
      "current step :  258\n",
      "reward :  -0.5135060578559821\n",
      "episode :  17\n",
      "current step :  259\n",
      "reward :  -0.5380480434087286\n",
      "episode :  17\n",
      "current step :  260\n",
      "reward :  -0.4103657778276287\n",
      "episode :  17\n",
      "current step :  261\n",
      "reward :  -0.3643118734882957\n",
      "episode :  17\n",
      "current step :  262\n",
      "reward :  -0.3800179869007992\n",
      "episode :  17\n",
      "current step :  263\n",
      "reward :  -0.42556337486736456\n",
      "episode :  17\n",
      "current step :  264\n",
      "reward :  -0.3067881440630393\n",
      "episode :  17\n",
      "current step :  265\n",
      "reward :  -0.3604478363913928\n",
      "episode :  17\n",
      "current step :  266\n",
      "reward :  -0.38457380957215\n",
      "episode :  17\n",
      "current step :  267\n",
      "reward :  -0.5330108898419245\n",
      "episode :  17\n",
      "current step :  268\n",
      "reward :  -0.303557892115704\n",
      "episode :  17\n",
      "current step :  269\n",
      "reward :  -0.47226966799477765\n",
      "episode :  17\n",
      "current step :  270\n",
      "reward :  -0.45460674924984346\n",
      "episode :  17\n",
      "current step :  271\n",
      "reward :  -0.45154505693489766\n",
      "episode :  17\n",
      "current step :  272\n",
      "reward :  -0.49041050255514623\n",
      "episode :  17\n",
      "current step :  273\n",
      "reward :  -0.4328317191084853\n",
      "episode :  17\n",
      "current step :  274\n",
      "reward :  -0.36834279045796453\n",
      "episode :  17\n",
      "current step :  275\n",
      "reward :  -0.32253819608487266\n",
      "episode :  17\n",
      "current step :  276\n",
      "reward :  -0.4581920684474822\n",
      "episode :  17\n",
      "current step :  277\n",
      "reward :  -0.4605519243149947\n",
      "episode :  17\n",
      "current step :  278\n",
      "reward :  -0.34320116363227576\n",
      "episode :  17\n",
      "current step :  279\n",
      "reward :  -0.43995211471162715\n",
      "episode :  17\n",
      "current step :  280\n",
      "reward :  -0.43150207851726213\n",
      "episode :  17\n",
      "current step :  281\n",
      "reward :  -0.41633701653374916\n",
      "episode :  17\n",
      "current step :  282\n",
      "reward :  -0.47376524059981934\n",
      "episode :  17\n",
      "current step :  283\n",
      "reward :  -0.40331821552684455\n",
      "episode :  17\n",
      "current step :  284\n",
      "reward :  -0.4602398651760843\n",
      "episode :  17\n",
      "current step :  285\n",
      "reward :  -0.5129658645785994\n",
      "episode :  18\n",
      "current step :  0\n",
      "reward :  -0.3205263003145351\n",
      "episode :  18\n",
      "current step :  1\n",
      "reward :  -0.1453377935446435\n",
      "episode :  18\n",
      "current step :  2\n",
      "reward :  -0.22979937833469344\n",
      "episode :  18\n",
      "current step :  3\n",
      "reward :  -0.3981257427604005\n",
      "episode :  18\n",
      "current step :  4\n",
      "reward :  -0.44758334382341697\n",
      "episode :  18\n",
      "current step :  5\n",
      "reward :  -0.3239264936935363\n",
      "episode :  18\n",
      "current step :  6\n",
      "reward :  -0.29705136377082414\n",
      "episode :  18\n",
      "current step :  7\n",
      "reward :  -0.45918583785463474\n",
      "episode :  18\n",
      "current step :  8\n",
      "reward :  -0.49704579588518905\n",
      "episode :  18\n",
      "current step :  9\n",
      "reward :  -0.3188136191271724\n",
      "episode :  18\n",
      "current step :  10\n",
      "reward :  -0.3344600776345637\n",
      "episode :  18\n",
      "current step :  11\n",
      "reward :  -0.29021835094507525\n",
      "episode :  18\n",
      "current step :  12\n",
      "reward :  -0.3459320166337327\n",
      "episode :  18\n",
      "current step :  13\n",
      "reward :  -0.39211218179942947\n",
      "episode :  18\n",
      "current step :  14\n",
      "reward :  -0.5110930340445454\n",
      "episode :  18\n",
      "current step :  15\n",
      "reward :  -0.40742772637468394\n",
      "episode :  18\n",
      "current step :  16\n",
      "reward :  -0.35596609598895906\n",
      "episode :  18\n",
      "current step :  17\n",
      "reward :  -0.24890430604033384\n",
      "episode :  18\n",
      "current step :  18\n",
      "reward :  -0.2901010146866407\n",
      "episode :  18\n",
      "current step :  19\n",
      "reward :  -0.20982970049026328\n",
      "episode :  18\n",
      "current step :  20\n",
      "reward :  -0.23444815887706053\n",
      "episode :  18\n",
      "current step :  21\n",
      "reward :  -0.4195998515714204\n",
      "episode :  18\n",
      "current step :  22\n",
      "reward :  -0.3799419530229274\n",
      "episode :  18\n",
      "current step :  23\n",
      "reward :  -0.329640392259472\n",
      "episode :  18\n",
      "current step :  24\n",
      "reward :  -0.4965583192384944\n",
      "episode :  18\n",
      "current step :  25\n",
      "reward :  -0.511536327222499\n",
      "episode :  18\n",
      "current step :  26\n",
      "reward :  -0.30182338307815704\n",
      "episode :  18\n",
      "current step :  27\n",
      "reward :  -0.3693544882249481\n",
      "episode :  18\n",
      "current step :  28\n",
      "reward :  -0.536096092088773\n",
      "episode :  18\n",
      "current step :  29\n",
      "reward :  -0.37037428973618436\n",
      "episode :  18\n",
      "current step :  30\n",
      "reward :  -0.43338404595788943\n",
      "episode :  18\n",
      "current step :  31\n",
      "reward :  -0.3035150685335932\n",
      "episode :  18\n",
      "current step :  32\n",
      "reward :  -0.3513299861914317\n",
      "episode :  18\n",
      "current step :  33\n",
      "reward :  -0.3136538003479923\n",
      "episode :  18\n",
      "current step :  34\n",
      "reward :  -0.36758264667574586\n",
      "episode :  18\n",
      "current step :  35\n",
      "reward :  -0.490933956214355\n",
      "episode :  18\n",
      "current step :  36\n",
      "reward :  -0.4848308008347909\n",
      "episode :  18\n",
      "current step :  37\n",
      "reward :  -0.5472372651950196\n",
      "episode :  18\n",
      "current step :  38\n",
      "reward :  -0.5272126592144135\n",
      "episode :  18\n",
      "current step :  39\n",
      "reward :  -0.4035579782404378\n",
      "episode :  18\n",
      "current step :  40\n",
      "reward :  -0.41768411851571163\n",
      "episode :  18\n",
      "current step :  41\n",
      "reward :  -0.5695384450276102\n",
      "episode :  18\n",
      "current step :  42\n",
      "reward :  -0.6581728757721008\n",
      "episode :  18\n",
      "current step :  43\n",
      "reward :  -0.6953094035215291\n",
      "episode :  18\n",
      "current step :  44\n",
      "reward :  -0.5914202536946708\n",
      "episode :  18\n",
      "current step :  45\n",
      "reward :  -0.47024874344774925\n",
      "episode :  18\n",
      "current step :  46\n",
      "reward :  -0.42292798010667254\n",
      "episode :  18\n",
      "current step :  47\n",
      "reward :  -0.47949416967991143\n",
      "episode :  18\n",
      "current step :  48\n",
      "reward :  -0.5876629950440587\n",
      "episode :  18\n",
      "current step :  49\n",
      "reward :  -0.6305353072320791\n",
      "episode :  18\n",
      "current step :  50\n",
      "reward :  -0.5233298318640641\n",
      "episode :  18\n",
      "current step :  51\n",
      "reward :  -0.4988029313870044\n",
      "episode :  18\n",
      "current step :  52\n",
      "reward :  -0.43592832521970293\n",
      "episode :  18\n",
      "current step :  53\n",
      "reward :  -0.46248597496258925\n",
      "episode :  18\n",
      "current step :  54\n",
      "reward :  -0.47108706970834974\n",
      "episode :  18\n",
      "current step :  55\n",
      "reward :  -0.4310320164955858\n",
      "episode :  18\n",
      "current step :  56\n",
      "reward :  -0.4877258504573459\n",
      "episode :  18\n",
      "current step :  57\n",
      "reward :  -0.4602259184417614\n",
      "episode :  18\n",
      "current step :  58\n",
      "reward :  -0.36218993610545813\n",
      "episode :  18\n",
      "current step :  59\n",
      "reward :  -0.42273503320864\n",
      "episode :  18\n",
      "current step :  60\n",
      "reward :  -0.35178892825714064\n",
      "episode :  18\n",
      "current step :  61\n",
      "reward :  -0.39407303025115104\n",
      "episode :  18\n",
      "current step :  62\n",
      "reward :  -0.5233827194113698\n",
      "episode :  18\n",
      "current step :  63\n",
      "reward :  -0.6179625605422558\n",
      "episode :  18\n",
      "current step :  64\n",
      "reward :  -0.6181701843893246\n",
      "episode :  18\n",
      "current step :  65\n",
      "reward :  -0.38486036717184474\n",
      "episode :  18\n",
      "current step :  66\n",
      "reward :  -0.5577650726480248\n",
      "episode :  18\n",
      "current step :  67\n",
      "reward :  -0.33340842470718024\n",
      "episode :  18\n",
      "current step :  68\n",
      "reward :  -0.31870824533616676\n",
      "episode :  18\n",
      "current step :  69\n",
      "reward :  -0.5063974005460444\n",
      "episode :  18\n",
      "current step :  70\n",
      "reward :  -0.6264097377051446\n",
      "episode :  18\n",
      "current step :  71\n",
      "reward :  -0.6386676229813183\n",
      "episode :  18\n",
      "current step :  72\n",
      "reward :  -0.6004104920860431\n",
      "episode :  18\n",
      "current step :  73\n",
      "reward :  -0.4677223270831733\n",
      "episode :  18\n",
      "current step :  74\n",
      "reward :  -0.5567530824725834\n",
      "episode :  18\n",
      "current step :  75\n",
      "reward :  -0.5697594154699627\n",
      "episode :  18\n",
      "current step :  76\n",
      "reward :  -0.4944748734434099\n",
      "episode :  18\n",
      "current step :  77\n",
      "reward :  -0.5214290816262951\n",
      "episode :  18\n",
      "current step :  78\n",
      "reward :  -0.4699721849621016\n",
      "episode :  18\n",
      "current step :  79\n",
      "reward :  -0.36048271343181476\n",
      "episode :  18\n",
      "current step :  80\n",
      "reward :  -0.36409204167166437\n",
      "episode :  18\n",
      "current step :  81\n",
      "reward :  -0.37032374368009113\n",
      "episode :  18\n",
      "current step :  82\n",
      "reward :  -0.43314295422567234\n",
      "episode :  18\n",
      "current step :  83\n",
      "reward :  -0.4284341162147362\n",
      "episode :  18\n",
      "current step :  84\n",
      "reward :  -0.31130530793206795\n",
      "episode :  18\n",
      "current step :  85\n",
      "reward :  -0.2233522781414688\n",
      "episode :  18\n",
      "current step :  86\n",
      "reward :  -0.2980648028329926\n",
      "episode :  18\n",
      "current step :  87\n",
      "reward :  -0.291523702385773\n",
      "episode :  18\n",
      "current step :  88\n",
      "reward :  -0.37590081396448904\n",
      "episode :  18\n",
      "current step :  89\n",
      "reward :  -0.49259403466985213\n",
      "episode :  18\n",
      "current step :  90\n",
      "reward :  -0.4958653817496078\n",
      "episode :  18\n",
      "current step :  91\n",
      "reward :  -0.37917629460704716\n",
      "episode :  18\n",
      "current step :  92\n",
      "reward :  -0.18198787685610293\n",
      "episode :  18\n",
      "current step :  93\n",
      "reward :  -0.2584939729588481\n",
      "episode :  18\n",
      "current step :  94\n",
      "reward :  -0.430676063263134\n",
      "episode :  18\n",
      "current step :  95\n",
      "reward :  -0.5202704931682632\n",
      "episode :  18\n",
      "current step :  96\n",
      "reward :  -0.24589643516781853\n",
      "episode :  18\n",
      "current step :  97\n",
      "reward :  -0.48938615300627986\n",
      "episode :  18\n",
      "current step :  98\n",
      "reward :  -0.43271312128140044\n",
      "episode :  18\n",
      "current step :  99\n",
      "reward :  -0.6196937445138865\n",
      "episode :  18\n",
      "current step :  100\n",
      "reward :  -0.4990729357831297\n",
      "episode :  18\n",
      "current step :  101\n",
      "reward :  -0.35053451447740996\n",
      "episode :  18\n",
      "current step :  102\n",
      "reward :  -0.3943810426078664\n",
      "episode :  18\n",
      "current step :  103\n",
      "reward :  -0.3153970965341274\n",
      "episode :  18\n",
      "current step :  104\n",
      "reward :  -0.2995728408938255\n",
      "episode :  18\n",
      "current step :  105\n",
      "reward :  -0.3509508037879635\n",
      "episode :  18\n",
      "current step :  106\n",
      "reward :  -0.407421871751681\n",
      "episode :  18\n",
      "current step :  107\n",
      "reward :  -0.3405704204210136\n",
      "episode :  18\n",
      "current step :  108\n",
      "reward :  -0.43121757349114054\n",
      "episode :  18\n",
      "current step :  109\n",
      "reward :  -0.4009215808600331\n",
      "episode :  18\n",
      "current step :  110\n",
      "reward :  -0.5534144990560644\n",
      "episode :  18\n",
      "current step :  111\n",
      "reward :  -0.47148507757425645\n",
      "episode :  18\n",
      "current step :  112\n",
      "reward :  -0.5207112430913423\n",
      "episode :  18\n",
      "current step :  113\n",
      "reward :  -0.3169114564862468\n",
      "episode :  18\n",
      "current step :  114\n",
      "reward :  -0.3882049111596142\n",
      "episode :  18\n",
      "current step :  115\n",
      "reward :  -0.4233080078218176\n",
      "episode :  18\n",
      "current step :  116\n",
      "reward :  -0.3940876204264419\n",
      "episode :  18\n",
      "current step :  117\n",
      "reward :  -0.4588659828812651\n",
      "episode :  18\n",
      "current step :  118\n",
      "reward :  -0.531243495623476\n",
      "episode :  18\n",
      "current step :  119\n",
      "reward :  -0.532981993862942\n",
      "episode :  18\n",
      "current step :  120\n",
      "reward :  -0.335897370391931\n",
      "episode :  18\n",
      "current step :  121\n",
      "reward :  -0.15552147489833126\n",
      "episode :  18\n",
      "current step :  122\n",
      "reward :  -0.2557363587164534\n",
      "episode :  18\n",
      "current step :  123\n",
      "reward :  -0.3740972014783072\n",
      "episode :  18\n",
      "current step :  124\n",
      "reward :  -0.26931319162628636\n",
      "episode :  18\n",
      "current step :  125\n",
      "reward :  -0.25675792621683413\n",
      "episode :  18\n",
      "current step :  126\n",
      "reward :  -0.15446018161342367\n",
      "episode :  18\n",
      "current step :  127\n",
      "reward :  -0.2165792076120806\n",
      "episode :  18\n",
      "current step :  128\n",
      "reward :  -0.3788185428736062\n",
      "episode :  18\n",
      "current step :  129\n",
      "reward :  -0.411109507268881\n",
      "episode :  18\n",
      "current step :  130\n",
      "reward :  -0.3366092720246386\n",
      "episode :  18\n",
      "current step :  131\n",
      "reward :  -0.48999099829741394\n",
      "episode :  18\n",
      "current step :  132\n",
      "reward :  -0.4854688759445263\n",
      "episode :  18\n",
      "current step :  133\n",
      "reward :  -0.3854219466490015\n",
      "episode :  18\n",
      "current step :  134\n",
      "reward :  -0.2983720437795715\n",
      "episode :  18\n",
      "current step :  135\n",
      "reward :  -0.42084718029193774\n",
      "episode :  18\n",
      "current step :  136\n",
      "reward :  -0.3114468473103386\n",
      "episode :  18\n",
      "current step :  137\n",
      "reward :  -0.40071098635327884\n",
      "episode :  18\n",
      "current step :  138\n",
      "reward :  -0.3130199378253262\n",
      "episode :  18\n",
      "current step :  139\n",
      "reward :  -0.20863396471716178\n",
      "episode :  18\n",
      "current step :  140\n",
      "reward :  -0.31430462284494026\n",
      "episode :  18\n",
      "current step :  141\n",
      "reward :  -0.3329456598265895\n",
      "episode :  18\n",
      "current step :  142\n",
      "reward :  -0.3591803292576684\n",
      "episode :  18\n",
      "current step :  143\n",
      "reward :  -0.2906291691044182\n",
      "episode :  18\n",
      "current step :  144\n",
      "reward :  -0.2541104126101927\n",
      "episode :  18\n",
      "current step :  145\n",
      "reward :  -0.32910310373202867\n",
      "episode :  18\n",
      "current step :  146\n",
      "reward :  -0.36799581045222424\n",
      "episode :  18\n",
      "current step :  147\n",
      "reward :  -0.37250468168637\n",
      "episode :  18\n",
      "current step :  148\n",
      "reward :  -0.3495562597779161\n",
      "episode :  18\n",
      "current step :  149\n",
      "reward :  -0.2732672791283037\n",
      "episode :  18\n",
      "current step :  150\n",
      "reward :  -0.3424615413942313\n",
      "episode :  18\n",
      "current step :  151\n",
      "reward :  -0.43836625613122693\n",
      "episode :  18\n",
      "current step :  152\n",
      "reward :  -0.5943598552100432\n",
      "episode :  18\n",
      "current step :  153\n",
      "reward :  -0.6572075959682224\n",
      "episode :  18\n",
      "current step :  154\n",
      "reward :  -0.38570142337922503\n",
      "episode :  18\n",
      "current step :  155\n",
      "reward :  -0.46200412656477563\n",
      "episode :  18\n",
      "current step :  156\n",
      "reward :  -0.3134840584316486\n",
      "episode :  18\n",
      "current step :  157\n",
      "reward :  -0.5867794390384214\n",
      "episode :  18\n",
      "current step :  158\n",
      "reward :  -0.5048635166458921\n",
      "episode :  18\n",
      "current step :  159\n",
      "reward :  -0.3475780241230453\n",
      "episode :  18\n",
      "current step :  160\n",
      "reward :  -0.3957432115953191\n",
      "episode :  18\n",
      "current step :  161\n",
      "reward :  -0.389101638392608\n",
      "episode :  18\n",
      "current step :  162\n",
      "reward :  -0.3208476232654203\n",
      "episode :  18\n",
      "current step :  163\n",
      "reward :  -0.4562685963316607\n",
      "episode :  18\n",
      "current step :  164\n",
      "reward :  -0.7203609604840893\n",
      "episode :  18\n",
      "current step :  165\n",
      "reward :  -0.540136251764159\n",
      "episode :  18\n",
      "current step :  166\n",
      "reward :  -0.582628096390936\n",
      "episode :  18\n",
      "current step :  167\n",
      "reward :  -0.4401593032485364\n",
      "episode :  18\n",
      "current step :  168\n",
      "reward :  -0.47631471254007474\n",
      "episode :  18\n",
      "current step :  169\n",
      "reward :  -0.5812232199466907\n",
      "episode :  18\n",
      "current step :  170\n",
      "reward :  -0.6013206665734026\n",
      "episode :  18\n",
      "current step :  171\n",
      "reward :  -0.5527525094487016\n",
      "episode :  18\n",
      "current step :  172\n",
      "reward :  -0.6236359206321683\n",
      "episode :  18\n",
      "current step :  173\n",
      "reward :  -0.4743324723433697\n",
      "episode :  18\n",
      "current step :  174\n",
      "reward :  -0.4828722912002546\n",
      "episode :  18\n",
      "current step :  175\n",
      "reward :  -0.5049938741912507\n",
      "episode :  18\n",
      "current step :  176\n",
      "reward :  -0.6342690170328236\n",
      "episode :  18\n",
      "current step :  177\n",
      "reward :  -0.6627220557986682\n",
      "episode :  18\n",
      "current step :  178\n",
      "reward :  -0.5551351535451797\n",
      "episode :  18\n",
      "current step :  179\n",
      "reward :  -0.376358284017074\n",
      "episode :  18\n",
      "current step :  180\n",
      "reward :  -0.40987745507210704\n",
      "episode :  18\n",
      "current step :  181\n",
      "reward :  -0.6225970070790442\n",
      "episode :  18\n",
      "current step :  182\n",
      "reward :  -0.6624702891841253\n",
      "episode :  18\n",
      "current step :  183\n",
      "reward :  -0.5281119360026427\n",
      "episode :  18\n",
      "current step :  184\n",
      "reward :  -0.42635331996408216\n",
      "episode :  18\n",
      "current step :  185\n",
      "reward :  -0.3923946560401805\n",
      "episode :  18\n",
      "current step :  186\n",
      "reward :  -0.47643374502613206\n",
      "episode :  18\n",
      "current step :  187\n",
      "reward :  -0.6037707588601408\n",
      "episode :  18\n",
      "current step :  188\n",
      "reward :  -0.596506440711254\n",
      "episode :  18\n",
      "current step :  189\n",
      "reward :  -0.46126742123095504\n",
      "episode :  18\n",
      "current step :  190\n",
      "reward :  -0.48903518793391\n",
      "episode :  18\n",
      "current step :  191\n",
      "reward :  -0.49385075296125264\n",
      "episode :  18\n",
      "current step :  192\n",
      "reward :  -0.39400725540795034\n",
      "episode :  18\n",
      "current step :  193\n",
      "reward :  -0.4347923112930871\n",
      "episode :  18\n",
      "current step :  194\n",
      "reward :  -0.31948277983425244\n",
      "episode :  18\n",
      "current step :  195\n",
      "reward :  -0.2157384930641236\n",
      "episode :  18\n",
      "current step :  196\n",
      "reward :  -0.5467782534584281\n",
      "episode :  18\n",
      "current step :  197\n",
      "reward :  -0.3847847005617229\n",
      "episode :  18\n",
      "current step :  198\n",
      "reward :  -0.5313074628704023\n",
      "episode :  18\n",
      "current step :  199\n",
      "reward :  -0.5952661148166737\n",
      "episode :  18\n",
      "current step :  200\n",
      "reward :  -0.4588185112922708\n",
      "episode :  18\n",
      "current step :  201\n",
      "reward :  -0.4147140227171816\n",
      "episode :  18\n",
      "current step :  202\n",
      "reward :  -0.33942303083518\n",
      "episode :  18\n",
      "current step :  203\n",
      "reward :  -0.4727022238623684\n",
      "episode :  18\n",
      "current step :  204\n",
      "reward :  -0.4955554804938754\n",
      "episode :  18\n",
      "current step :  205\n",
      "reward :  -0.4543031835965564\n",
      "episode :  18\n",
      "current step :  206\n",
      "reward :  -0.576910644390901\n",
      "episode :  18\n",
      "current step :  207\n",
      "reward :  -0.7311280514984116\n",
      "episode :  18\n",
      "current step :  208\n",
      "reward :  -0.5583898742521486\n",
      "episode :  18\n",
      "current step :  209\n",
      "reward :  -0.5275791306914631\n",
      "episode :  18\n",
      "current step :  210\n",
      "reward :  -0.4459793441981818\n",
      "episode :  18\n",
      "current step :  211\n",
      "reward :  -0.5221547691624316\n",
      "episode :  18\n",
      "current step :  212\n",
      "reward :  -0.6101043729485837\n",
      "episode :  18\n",
      "current step :  213\n",
      "reward :  -0.5607755879427728\n",
      "episode :  18\n",
      "current step :  214\n",
      "reward :  -0.6253488355775397\n",
      "episode :  18\n",
      "current step :  215\n",
      "reward :  -0.6074821033874375\n",
      "episode :  18\n",
      "current step :  216\n",
      "reward :  -0.632338151794987\n",
      "episode :  18\n",
      "current step :  217\n",
      "reward :  -0.7260254876140506\n",
      "episode :  18\n",
      "current step :  218\n",
      "reward :  -0.5516279922352163\n",
      "episode :  18\n",
      "current step :  219\n",
      "reward :  -0.5777932560981694\n",
      "episode :  18\n",
      "current step :  220\n",
      "reward :  -0.5265319823627711\n",
      "episode :  18\n",
      "current step :  221\n",
      "reward :  -0.48798132987669995\n",
      "episode :  18\n",
      "current step :  222\n",
      "reward :  -0.5098447468240325\n",
      "episode :  18\n",
      "current step :  223\n",
      "reward :  -0.5245915503068331\n",
      "episode :  18\n",
      "current step :  224\n",
      "reward :  -0.4880845309697612\n",
      "episode :  18\n",
      "current step :  225\n",
      "reward :  -0.49211553720392887\n",
      "episode :  18\n",
      "current step :  226\n",
      "reward :  -0.4442759242768319\n",
      "episode :  18\n",
      "current step :  227\n",
      "reward :  -0.5408500602804095\n",
      "episode :  18\n",
      "current step :  228\n",
      "reward :  -0.41802296621047424\n",
      "episode :  18\n",
      "current step :  229\n",
      "reward :  -0.48895170197573085\n",
      "episode :  18\n",
      "current step :  230\n",
      "reward :  -0.41843661178064484\n",
      "episode :  18\n",
      "current step :  231\n",
      "reward :  -0.3042774375168169\n",
      "episode :  18\n",
      "current step :  232\n",
      "reward :  -0.2823294710243329\n",
      "episode :  18\n",
      "current step :  233\n",
      "reward :  -0.4847613891178056\n",
      "episode :  18\n",
      "current step :  234\n",
      "reward :  -0.218696475570815\n",
      "episode :  18\n",
      "current step :  235\n",
      "reward :  -0.31547997919366144\n",
      "episode :  18\n",
      "current step :  236\n",
      "reward :  -0.2894677382589224\n",
      "episode :  18\n",
      "current step :  237\n",
      "reward :  -0.33068562027869025\n",
      "episode :  18\n",
      "current step :  238\n",
      "reward :  -0.49342064776018596\n",
      "episode :  18\n",
      "current step :  239\n",
      "reward :  -0.476714763596282\n",
      "episode :  18\n",
      "current step :  240\n",
      "reward :  -0.47019030133616607\n",
      "episode :  18\n",
      "current step :  241\n",
      "reward :  -0.4583714092073468\n",
      "episode :  18\n",
      "current step :  242\n",
      "reward :  -0.3352858256045795\n",
      "episode :  18\n",
      "current step :  243\n",
      "reward :  -0.46419746848932775\n",
      "episode :  18\n",
      "current step :  244\n",
      "reward :  -0.3375802386330192\n",
      "episode :  18\n",
      "current step :  245\n",
      "reward :  -0.35422588083890255\n",
      "episode :  18\n",
      "current step :  246\n",
      "reward :  -0.29038580120808555\n",
      "episode :  18\n",
      "current step :  247\n",
      "reward :  -0.3740285833817855\n",
      "episode :  18\n",
      "current step :  248\n",
      "reward :  -0.28342108282528483\n",
      "episode :  18\n",
      "current step :  249\n",
      "reward :  -0.46204062164631904\n",
      "episode :  18\n",
      "current step :  250\n",
      "reward :  -0.4955899422079213\n",
      "episode :  18\n",
      "current step :  251\n",
      "reward :  -0.49505208574694715\n",
      "episode :  18\n",
      "current step :  252\n",
      "reward :  -0.3761662033518633\n",
      "episode :  18\n",
      "current step :  253\n",
      "reward :  -0.3312437639088523\n",
      "episode :  18\n",
      "current step :  254\n",
      "reward :  -0.3077175664207963\n",
      "episode :  18\n",
      "current step :  255\n",
      "reward :  -0.29812573767637396\n",
      "episode :  18\n",
      "current step :  256\n",
      "reward :  -0.3996300823340809\n",
      "episode :  18\n",
      "current step :  257\n",
      "reward :  -0.44970687276143545\n",
      "episode :  18\n",
      "current step :  258\n",
      "reward :  -0.3891624088343664\n",
      "episode :  18\n",
      "current step :  259\n",
      "reward :  -0.4249080302356282\n",
      "episode :  18\n",
      "current step :  260\n",
      "reward :  -0.2650032822258366\n",
      "episode :  18\n",
      "current step :  261\n",
      "reward :  -0.4512349383303798\n",
      "episode :  18\n",
      "current step :  262\n",
      "reward :  -0.37100658972890055\n",
      "episode :  18\n",
      "current step :  263\n",
      "reward :  -0.38739059432984413\n",
      "episode :  18\n",
      "current step :  264\n",
      "reward :  -0.48722666750658306\n",
      "episode :  18\n",
      "current step :  265\n",
      "reward :  -0.2798465860730446\n",
      "episode :  18\n",
      "current step :  266\n",
      "reward :  -0.32941188072151917\n",
      "episode :  18\n",
      "current step :  267\n",
      "reward :  -0.5756810435940799\n",
      "episode :  18\n",
      "current step :  268\n",
      "reward :  -0.22128623513810305\n",
      "episode :  18\n",
      "current step :  269\n",
      "reward :  -0.37154912314662286\n",
      "episode :  18\n",
      "current step :  270\n",
      "reward :  -0.5219982663508189\n",
      "episode :  18\n",
      "current step :  271\n",
      "reward :  -0.43755203838027096\n",
      "episode :  18\n",
      "current step :  272\n",
      "reward :  -0.3628211669847495\n",
      "episode :  18\n",
      "current step :  273\n",
      "reward :  -0.3527531177326769\n",
      "episode :  18\n",
      "current step :  274\n",
      "reward :  -0.34351439755959823\n",
      "episode :  18\n",
      "current step :  275\n",
      "reward :  -0.3215328425749215\n",
      "episode :  18\n",
      "current step :  276\n",
      "reward :  -0.595814087945734\n",
      "episode :  18\n",
      "current step :  277\n",
      "reward :  -0.5931326769977564\n",
      "episode :  18\n",
      "current step :  278\n",
      "reward :  -0.4930002233499464\n",
      "episode :  18\n",
      "current step :  279\n",
      "reward :  -0.42859658737895223\n",
      "episode :  18\n",
      "current step :  280\n",
      "reward :  -0.47821834707393923\n",
      "episode :  18\n",
      "current step :  281\n",
      "reward :  -0.4366221308620275\n",
      "episode :  18\n",
      "current step :  282\n",
      "reward :  -0.5345016816569823\n",
      "episode :  18\n",
      "current step :  283\n",
      "reward :  -0.5563243163550808\n",
      "episode :  18\n",
      "current step :  284\n",
      "reward :  -0.4857416676865949\n",
      "episode :  18\n",
      "current step :  285\n",
      "reward :  -0.422038682061642\n",
      "episode :  19\n",
      "current step :  0\n",
      "reward :  -0.2922012545279335\n",
      "episode :  19\n",
      "current step :  1\n",
      "reward :  -0.2739298661616204\n",
      "episode :  19\n",
      "current step :  2\n",
      "reward :  -0.36792594811845547\n",
      "episode :  19\n",
      "current step :  3\n",
      "reward :  -0.4504935285336535\n",
      "episode :  19\n",
      "current step :  4\n",
      "reward :  -0.28481271389960744\n",
      "episode :  19\n",
      "current step :  5\n",
      "reward :  -0.4509220804579923\n",
      "episode :  19\n",
      "current step :  6\n",
      "reward :  -0.37172657553705435\n",
      "episode :  19\n",
      "current step :  7\n",
      "reward :  -0.48021944988427046\n",
      "episode :  19\n",
      "current step :  8\n",
      "reward :  -0.5418555934743634\n",
      "episode :  19\n",
      "current step :  9\n",
      "reward :  -0.3889816534575429\n",
      "episode :  19\n",
      "current step :  10\n",
      "reward :  -0.5027644638489381\n",
      "episode :  19\n",
      "current step :  11\n",
      "reward :  -0.467646577460116\n",
      "episode :  19\n",
      "current step :  12\n",
      "reward :  -0.46204803338297895\n",
      "episode :  19\n",
      "current step :  13\n",
      "reward :  -0.4193610239664024\n",
      "episode :  19\n",
      "current step :  14\n",
      "reward :  -0.3933991266382299\n",
      "episode :  19\n",
      "current step :  15\n",
      "reward :  -0.42901647503171936\n",
      "episode :  19\n",
      "current step :  16\n",
      "reward :  -0.5377121290052439\n",
      "episode :  19\n",
      "current step :  17\n",
      "reward :  -0.5165855754777955\n",
      "episode :  19\n",
      "current step :  18\n",
      "reward :  -0.4941543843225413\n",
      "episode :  19\n",
      "current step :  19\n",
      "reward :  -0.5023278218575759\n",
      "episode :  19\n",
      "current step :  20\n",
      "reward :  -0.43882302988556604\n",
      "episode :  19\n",
      "current step :  21\n",
      "reward :  -0.4461767359050686\n",
      "episode :  19\n",
      "current step :  22\n",
      "reward :  -0.4697667512017938\n",
      "episode :  19\n",
      "current step :  23\n",
      "reward :  -0.43649118545874355\n",
      "episode :  19\n",
      "current step :  24\n",
      "reward :  -0.43059761051709683\n",
      "episode :  19\n",
      "current step :  25\n",
      "reward :  -0.436775181989261\n",
      "episode :  19\n",
      "current step :  26\n",
      "reward :  -0.43577606128998697\n",
      "episode :  19\n",
      "current step :  27\n",
      "reward :  -0.44278314352118076\n",
      "episode :  19\n",
      "current step :  28\n",
      "reward :  -0.4511848525133314\n",
      "episode :  19\n",
      "current step :  29\n",
      "reward :  -0.4624482257447234\n",
      "episode :  19\n",
      "current step :  30\n",
      "reward :  -0.46673256746993086\n",
      "episode :  19\n",
      "current step :  31\n",
      "reward :  -0.4740947465510886\n",
      "episode :  19\n",
      "current step :  32\n",
      "reward :  -0.48443952361954346\n",
      "episode :  19\n",
      "current step :  33\n",
      "reward :  -0.5021775763317161\n",
      "episode :  19\n",
      "current step :  34\n",
      "reward :  -0.5153563509108667\n",
      "episode :  19\n",
      "current step :  35\n",
      "reward :  -0.5260692017147683\n",
      "episode :  19\n",
      "current step :  36\n",
      "reward :  -0.5337917064743188\n",
      "episode :  19\n",
      "current step :  37\n",
      "reward :  -0.5392241821663126\n",
      "episode :  19\n",
      "current step :  38\n",
      "reward :  -0.5455587412123181\n",
      "episode :  19\n",
      "current step :  39\n",
      "reward :  -0.5501285417985583\n",
      "episode :  19\n",
      "current step :  40\n",
      "reward :  -0.5541300960085254\n",
      "episode :  19\n",
      "current step :  41\n",
      "reward :  -0.5485855009064625\n",
      "episode :  19\n",
      "current step :  42\n",
      "reward :  -0.5613142238089395\n",
      "episode :  19\n",
      "current step :  43\n",
      "reward :  -0.5715153401337525\n",
      "episode :  19\n",
      "current step :  44\n",
      "reward :  -0.5751623909852741\n",
      "episode :  19\n",
      "current step :  45\n",
      "reward :  -0.5768648844032238\n",
      "episode :  19\n",
      "current step :  46\n",
      "reward :  -0.5837391510918369\n",
      "episode :  19\n",
      "current step :  47\n",
      "reward :  -0.586248932706851\n",
      "episode :  19\n",
      "current step :  48\n",
      "reward :  -0.5895926710617632\n",
      "episode :  19\n",
      "current step :  49\n",
      "reward :  -0.5997455765939743\n",
      "episode :  19\n",
      "current step :  50\n",
      "reward :  -0.6004992942465341\n",
      "episode :  19\n",
      "current step :  51\n",
      "reward :  -0.6100508611815648\n",
      "episode :  19\n",
      "current step :  52\n",
      "reward :  -0.6107014408946878\n",
      "episode :  19\n",
      "current step :  53\n",
      "reward :  -0.6171149617657935\n",
      "episode :  19\n",
      "current step :  54\n",
      "reward :  -0.6222225991818847\n",
      "episode :  19\n",
      "current step :  55\n",
      "reward :  -0.6232002912247586\n",
      "episode :  19\n",
      "current step :  56\n",
      "reward :  -0.6242577566069093\n",
      "episode :  19\n",
      "current step :  57\n",
      "reward :  -0.6261748487701565\n",
      "episode :  19\n",
      "current step :  58\n",
      "reward :  -0.6240915085241032\n",
      "episode :  19\n",
      "current step :  59\n",
      "reward :  -0.6248671997286481\n",
      "episode :  19\n",
      "current step :  60\n",
      "reward :  -0.6233793617700539\n",
      "episode :  19\n",
      "current step :  61\n",
      "reward :  -0.6256892593022332\n",
      "episode :  19\n",
      "current step :  62\n",
      "reward :  -0.6217811970848545\n",
      "episode :  19\n",
      "current step :  63\n",
      "reward :  -0.6226672257619562\n",
      "episode :  19\n",
      "current step :  64\n",
      "reward :  -0.6209181423629726\n",
      "episode :  19\n",
      "current step :  65\n",
      "reward :  -0.6283556679138546\n",
      "episode :  19\n",
      "current step :  66\n",
      "reward :  -0.6214082304333476\n",
      "episode :  19\n",
      "current step :  67\n",
      "reward :  -0.6175556243203776\n",
      "episode :  19\n",
      "current step :  68\n",
      "reward :  -0.6121548572841369\n",
      "episode :  19\n",
      "current step :  69\n",
      "reward :  -0.6055723549957522\n",
      "episode :  19\n",
      "current step :  70\n",
      "reward :  -0.5739766946176437\n",
      "episode :  19\n",
      "current step :  71\n",
      "reward :  -0.5634971823490904\n",
      "episode :  19\n",
      "current step :  72\n",
      "reward :  -0.5951051075818656\n",
      "episode :  19\n",
      "current step :  73\n",
      "reward :  -0.589915871744947\n",
      "episode :  19\n",
      "current step :  74\n",
      "reward :  -0.5432823541765714\n",
      "episode :  19\n",
      "current step :  75\n",
      "reward :  -0.5420806710862417\n",
      "episode :  19\n",
      "current step :  76\n",
      "reward :  -0.5744388033460227\n",
      "episode :  19\n",
      "current step :  77\n",
      "reward :  -0.5604705546280894\n",
      "episode :  19\n",
      "current step :  78\n",
      "reward :  -0.5272359129952846\n",
      "episode :  19\n",
      "current step :  79\n",
      "reward :  -0.557458868018444\n",
      "episode :  19\n",
      "current step :  80\n",
      "reward :  -0.5095999167347781\n",
      "episode :  19\n",
      "current step :  81\n",
      "reward :  -0.5193135352347538\n",
      "episode :  19\n",
      "current step :  82\n",
      "reward :  -0.4560261677900645\n",
      "episode :  19\n",
      "current step :  83\n",
      "reward :  -0.5018365364974978\n",
      "episode :  19\n",
      "current step :  84\n",
      "reward :  -0.5063891056829457\n",
      "episode :  19\n",
      "current step :  85\n",
      "reward :  -0.4890174906664026\n",
      "episode :  19\n",
      "current step :  86\n",
      "reward :  -0.4781576825978998\n",
      "episode :  19\n",
      "current step :  87\n",
      "reward :  -0.4689591133372485\n",
      "episode :  19\n",
      "current step :  88\n",
      "reward :  -0.4644651848721854\n",
      "episode :  19\n",
      "current step :  89\n",
      "reward :  -0.44660961038475855\n",
      "episode :  19\n",
      "current step :  90\n",
      "reward :  -0.4352186384797276\n",
      "episode :  19\n",
      "current step :  91\n",
      "reward :  -0.4346768570630865\n",
      "episode :  19\n",
      "current step :  92\n",
      "reward :  -0.43590672294478555\n",
      "episode :  19\n",
      "current step :  93\n",
      "reward :  -0.4363444803227798\n",
      "episode :  19\n",
      "current step :  94\n",
      "reward :  -0.4665913428074068\n",
      "episode :  19\n",
      "current step :  95\n",
      "reward :  -0.5010587799115198\n",
      "episode :  19\n",
      "current step :  96\n",
      "reward :  -0.4867803067127739\n",
      "episode :  19\n",
      "current step :  97\n",
      "reward :  -0.46382439251926627\n",
      "episode :  19\n",
      "current step :  98\n",
      "reward :  -0.4457425460318737\n",
      "episode :  19\n",
      "current step :  99\n",
      "reward :  -0.46933167546891175\n",
      "episode :  19\n",
      "current step :  100\n",
      "reward :  -0.4659245417809525\n",
      "episode :  19\n",
      "current step :  101\n",
      "reward :  -0.5253710066527458\n",
      "episode :  19\n",
      "current step :  102\n",
      "reward :  -0.5032315871349212\n",
      "episode :  19\n",
      "current step :  103\n",
      "reward :  -0.49518720147636913\n",
      "episode :  19\n",
      "current step :  104\n",
      "reward :  -0.49192775188506904\n",
      "episode :  19\n",
      "current step :  105\n",
      "reward :  -0.5029392534729105\n",
      "episode :  19\n",
      "current step :  106\n",
      "reward :  -0.5286000638087466\n",
      "episode :  19\n",
      "current step :  107\n",
      "reward :  -0.5209176968166733\n",
      "episode :  19\n",
      "current step :  108\n",
      "reward :  -0.5189561384612436\n",
      "episode :  19\n",
      "current step :  109\n",
      "reward :  -0.5445740124717923\n",
      "episode :  19\n",
      "current step :  110\n",
      "reward :  -0.5326505513504995\n",
      "episode :  19\n",
      "current step :  111\n",
      "reward :  -0.5349937958979935\n",
      "episode :  19\n",
      "current step :  112\n",
      "reward :  -0.5378848705521372\n",
      "episode :  19\n",
      "current step :  113\n",
      "reward :  -0.54074973348708\n",
      "episode :  19\n",
      "current step :  114\n",
      "reward :  -0.5559295469494422\n",
      "episode :  19\n",
      "current step :  115\n",
      "reward :  -0.5701688795371934\n",
      "episode :  19\n",
      "current step :  116\n",
      "reward :  -0.5699426186256851\n",
      "episode :  19\n",
      "current step :  117\n",
      "reward :  -0.5738972278406436\n",
      "episode :  19\n",
      "current step :  118\n",
      "reward :  -0.5717350992576193\n",
      "episode :  19\n",
      "current step :  119\n",
      "reward :  -0.5651822862876604\n",
      "episode :  19\n",
      "current step :  120\n",
      "reward :  -0.5441246976869539\n",
      "episode :  19\n",
      "current step :  121\n",
      "reward :  -0.5457488694152145\n",
      "episode :  19\n",
      "current step :  122\n",
      "reward :  -0.5434035640949026\n",
      "episode :  19\n",
      "current step :  123\n",
      "reward :  -0.5597288437873768\n",
      "episode :  19\n",
      "current step :  124\n",
      "reward :  -0.54646296161289\n",
      "episode :  19\n",
      "current step :  125\n",
      "reward :  -0.5391122409300517\n",
      "episode :  19\n",
      "current step :  126\n",
      "reward :  -0.5623308061346659\n",
      "episode :  19\n",
      "current step :  127\n",
      "reward :  -0.5581195839026261\n",
      "episode :  19\n",
      "current step :  128\n",
      "reward :  -0.5517352655707614\n",
      "episode :  19\n",
      "current step :  129\n",
      "reward :  -0.5354356520361305\n",
      "episode :  19\n",
      "current step :  130\n",
      "reward :  -0.5616893210370065\n",
      "episode :  19\n",
      "current step :  131\n",
      "reward :  -0.5188408851081036\n",
      "episode :  19\n",
      "current step :  132\n",
      "reward :  -0.5478334231591601\n",
      "episode :  19\n",
      "current step :  133\n",
      "reward :  -0.5731644057852672\n",
      "episode :  19\n",
      "current step :  134\n",
      "reward :  -0.5837459360789043\n",
      "episode :  19\n",
      "current step :  135\n",
      "reward :  -0.56761974438938\n",
      "episode :  19\n",
      "current step :  136\n",
      "reward :  -0.5386295535447687\n",
      "episode :  19\n",
      "current step :  137\n",
      "reward :  -0.49964415330353135\n",
      "episode :  19\n",
      "current step :  138\n",
      "reward :  -0.495987631407641\n",
      "episode :  19\n",
      "current step :  139\n",
      "reward :  -0.48031218622985067\n",
      "episode :  19\n",
      "current step :  140\n",
      "reward :  -0.47533118423872006\n",
      "episode :  19\n",
      "current step :  141\n",
      "reward :  -0.47267583982328126\n",
      "episode :  19\n",
      "current step :  142\n",
      "reward :  -0.49465106874798515\n",
      "episode :  19\n",
      "current step :  143\n",
      "reward :  -0.5291742277625291\n",
      "episode :  19\n",
      "current step :  144\n",
      "reward :  -0.5329046488483031\n",
      "episode :  19\n",
      "current step :  145\n",
      "reward :  -0.4902277405873126\n",
      "episode :  19\n",
      "current step :  146\n",
      "reward :  -0.4523349367588328\n",
      "episode :  19\n",
      "current step :  147\n",
      "reward :  -0.5419099304299299\n",
      "episode :  19\n",
      "current step :  148\n",
      "reward :  -0.5408503234299059\n",
      "episode :  19\n",
      "current step :  149\n",
      "reward :  -0.5490778201737784\n",
      "episode :  19\n",
      "current step :  150\n",
      "reward :  -0.5513245754975837\n",
      "episode :  19\n",
      "current step :  151\n",
      "reward :  -0.5566409037661697\n",
      "episode :  19\n",
      "current step :  152\n",
      "reward :  -0.5641716685508654\n",
      "episode :  19\n",
      "current step :  153\n",
      "reward :  -0.5788309310717769\n",
      "episode :  19\n",
      "current step :  154\n",
      "reward :  -0.5767459194372602\n",
      "episode :  19\n",
      "current step :  155\n",
      "reward :  -0.5801779132442874\n",
      "episode :  19\n",
      "current step :  156\n",
      "reward :  -0.5865156460507326\n",
      "episode :  19\n",
      "current step :  157\n",
      "reward :  -0.5905906076238373\n",
      "episode :  19\n",
      "current step :  158\n",
      "reward :  -0.5968183661538453\n",
      "episode :  19\n",
      "current step :  159\n",
      "reward :  -0.5919026148927061\n",
      "episode :  19\n",
      "current step :  160\n",
      "reward :  -0.6126103099613224\n",
      "episode :  19\n",
      "current step :  161\n",
      "reward :  -0.5922748665709486\n",
      "episode :  19\n",
      "current step :  162\n",
      "reward :  -0.6339394750289937\n",
      "episode :  19\n",
      "current step :  163\n",
      "reward :  -0.6386514355586896\n",
      "episode :  19\n",
      "current step :  164\n",
      "reward :  -0.6420484242452825\n",
      "episode :  19\n",
      "current step :  165\n",
      "reward :  -0.6497225311824514\n",
      "episode :  19\n",
      "current step :  166\n",
      "reward :  -0.6538028806459537\n",
      "episode :  19\n",
      "current step :  167\n",
      "reward :  -0.6570523126758679\n",
      "episode :  19\n",
      "current step :  168\n",
      "reward :  -0.6597515608378466\n",
      "episode :  19\n",
      "current step :  169\n",
      "reward :  -0.665057897376468\n",
      "episode :  19\n",
      "current step :  170\n",
      "reward :  -0.6674771271100437\n",
      "episode :  19\n",
      "current step :  171\n",
      "reward :  -0.6762904003622162\n",
      "episode :  19\n",
      "current step :  172\n",
      "reward :  -0.6768549145485092\n",
      "episode :  19\n",
      "current step :  173\n",
      "reward :  -0.6866582165784528\n",
      "episode :  19\n",
      "current step :  174\n",
      "reward :  -0.6847823996076291\n",
      "episode :  19\n",
      "current step :  175\n",
      "reward :  -0.6890550327552631\n",
      "episode :  19\n",
      "current step :  176\n",
      "reward :  -0.6911231495541548\n",
      "episode :  19\n",
      "current step :  177\n",
      "reward :  -0.6887243379488944\n",
      "episode :  19\n",
      "current step :  178\n",
      "reward :  -0.678249932351472\n",
      "episode :  19\n",
      "current step :  179\n",
      "reward :  -0.6860213530433156\n",
      "episode :  19\n",
      "current step :  180\n",
      "reward :  -0.6888458039767709\n",
      "episode :  19\n",
      "current step :  181\n",
      "reward :  -0.6975819473395346\n",
      "episode :  19\n",
      "current step :  182\n",
      "reward :  -0.6986535057513628\n",
      "episode :  19\n",
      "current step :  183\n",
      "reward :  -0.6805339246437083\n",
      "episode :  19\n",
      "current step :  184\n",
      "reward :  -0.7007455277732739\n",
      "episode :  19\n",
      "current step :  185\n",
      "reward :  -0.7000958556746026\n",
      "episode :  19\n",
      "current step :  186\n",
      "reward :  -0.6997135017025711\n",
      "episode :  19\n",
      "current step :  187\n",
      "reward :  -0.7042874153192944\n",
      "episode :  19\n",
      "current step :  188\n",
      "reward :  -0.667202507962003\n",
      "episode :  19\n",
      "current step :  189\n",
      "reward :  -0.6841463743650515\n",
      "episode :  19\n",
      "current step :  190\n",
      "reward :  -0.6896312924286947\n",
      "episode :  19\n",
      "current step :  191\n",
      "reward :  -0.6926202952509793\n",
      "episode :  19\n",
      "current step :  192\n",
      "reward :  -0.6991740524172824\n",
      "episode :  19\n",
      "current step :  193\n",
      "reward :  -0.6987090750261004\n",
      "episode :  19\n",
      "current step :  194\n",
      "reward :  -0.6997121491147903\n",
      "episode :  19\n",
      "current step :  195\n",
      "reward :  -0.6992600370788453\n",
      "episode :  19\n",
      "current step :  196\n",
      "reward :  -0.700070967641198\n",
      "episode :  19\n",
      "current step :  197\n",
      "reward :  -0.6998508441370659\n",
      "episode :  19\n",
      "current step :  198\n",
      "reward :  -0.7004243033091135\n",
      "episode :  19\n",
      "current step :  199\n",
      "reward :  -0.6753921668449463\n",
      "episode :  19\n",
      "current step :  200\n",
      "reward :  -0.6901490399624857\n",
      "episode :  19\n",
      "current step :  201\n",
      "reward :  -0.6968858611602875\n",
      "episode :  19\n",
      "current step :  202\n",
      "reward :  -0.6949020501465326\n",
      "episode :  19\n",
      "current step :  203\n",
      "reward :  -0.6937421853897368\n",
      "episode :  19\n",
      "current step :  204\n",
      "reward :  -0.6927274127115584\n",
      "episode :  19\n",
      "current step :  205\n",
      "reward :  -0.6843899085417836\n",
      "episode :  19\n",
      "current step :  206\n",
      "reward :  -0.6869352221010127\n",
      "episode :  19\n",
      "current step :  207\n",
      "reward :  -0.6873550270045212\n",
      "episode :  19\n",
      "current step :  208\n",
      "reward :  -0.6824479574492057\n",
      "episode :  19\n",
      "current step :  209\n",
      "reward :  -0.6924551054855982\n",
      "episode :  19\n",
      "current step :  210\n",
      "reward :  -0.6912840953832592\n",
      "episode :  19\n",
      "current step :  211\n",
      "reward :  -0.6883150700126279\n",
      "episode :  19\n",
      "current step :  212\n",
      "reward :  -0.6948186117772576\n",
      "episode :  19\n",
      "current step :  213\n",
      "reward :  -0.6939064436123776\n",
      "episode :  19\n",
      "current step :  214\n",
      "reward :  -0.664948951407691\n",
      "episode :  19\n",
      "current step :  215\n",
      "reward :  -0.6854797005487008\n",
      "episode :  19\n",
      "current step :  216\n",
      "reward :  -0.6811879218130641\n",
      "episode :  19\n",
      "current step :  217\n",
      "reward :  -0.6598793290225731\n",
      "episode :  19\n",
      "current step :  218\n",
      "reward :  -0.6675393416418868\n",
      "episode :  19\n",
      "current step :  219\n",
      "reward :  -0.638052292357018\n",
      "episode :  19\n",
      "current step :  220\n",
      "reward :  -0.651283488240387\n",
      "episode :  19\n",
      "current step :  221\n",
      "reward :  -0.645700992740789\n",
      "episode :  19\n",
      "current step :  222\n",
      "reward :  -0.6455852439627693\n",
      "episode :  19\n",
      "current step :  223\n",
      "reward :  -0.6460704129851478\n",
      "episode :  19\n",
      "current step :  224\n",
      "reward :  -0.6388594898849618\n",
      "episode :  19\n",
      "current step :  225\n",
      "reward :  -0.6301279078396185\n",
      "episode :  19\n",
      "current step :  226\n",
      "reward :  -0.627530863726495\n",
      "episode :  19\n",
      "current step :  227\n",
      "reward :  -0.6194152254827864\n",
      "episode :  19\n",
      "current step :  228\n",
      "reward :  -0.6147260069000652\n",
      "episode :  19\n",
      "current step :  229\n",
      "reward :  -0.6111157244837939\n",
      "episode :  19\n",
      "current step :  230\n",
      "reward :  -0.6001050535043916\n",
      "episode :  19\n",
      "current step :  231\n",
      "reward :  -0.5983177787706281\n",
      "episode :  19\n",
      "current step :  232\n",
      "reward :  -0.5924617417417679\n",
      "episode :  19\n",
      "current step :  233\n",
      "reward :  -0.5738918503700006\n",
      "episode :  19\n",
      "current step :  234\n",
      "reward :  -0.5774291565182367\n",
      "episode :  19\n",
      "current step :  235\n",
      "reward :  -0.5799581631017086\n",
      "episode :  19\n",
      "current step :  236\n",
      "reward :  -0.5670325752104043\n",
      "episode :  19\n",
      "current step :  237\n",
      "reward :  -0.53386305872694\n",
      "episode :  19\n",
      "current step :  238\n",
      "reward :  -0.5457411674852003\n",
      "episode :  19\n",
      "current step :  239\n",
      "reward :  -0.5245747880089433\n",
      "episode :  19\n",
      "current step :  240\n",
      "reward :  -0.5429548971176806\n",
      "episode :  19\n",
      "current step :  241\n",
      "reward :  -0.5361508996171099\n",
      "episode :  19\n",
      "current step :  242\n",
      "reward :  -0.5324681162857672\n",
      "episode :  19\n",
      "current step :  243\n",
      "reward :  -0.5312789510725419\n",
      "episode :  19\n",
      "current step :  244\n",
      "reward :  -0.5250282812209908\n",
      "episode :  19\n",
      "current step :  245\n",
      "reward :  -0.5252781572256324\n",
      "episode :  19\n",
      "current step :  246\n",
      "reward :  -0.520134409830372\n",
      "episode :  19\n",
      "current step :  247\n",
      "reward :  -0.4713222169526855\n",
      "episode :  19\n",
      "current step :  248\n",
      "reward :  -0.4057704526142993\n",
      "episode :  19\n",
      "current step :  249\n",
      "reward :  -0.442945871111467\n",
      "episode :  19\n",
      "current step :  250\n",
      "reward :  -0.5095823740347207\n",
      "episode :  19\n",
      "current step :  251\n",
      "reward :  -0.5008124346032922\n",
      "episode :  19\n",
      "current step :  252\n",
      "reward :  -0.5077261738729396\n",
      "episode :  19\n",
      "current step :  253\n",
      "reward :  -0.5360710648387627\n",
      "episode :  19\n",
      "current step :  254\n",
      "reward :  -0.5035555145997801\n",
      "episode :  19\n",
      "current step :  255\n",
      "reward :  -0.3896755513593942\n",
      "episode :  19\n",
      "current step :  256\n",
      "reward :  -0.47453961975489467\n",
      "episode :  19\n",
      "current step :  257\n",
      "reward :  -0.4200340439142424\n",
      "episode :  19\n",
      "current step :  258\n",
      "reward :  -0.5137751716687414\n",
      "episode :  19\n",
      "current step :  259\n",
      "reward :  -0.5662960558414184\n",
      "episode :  19\n",
      "current step :  260\n",
      "reward :  -0.5288121971685007\n",
      "episode :  19\n",
      "current step :  261\n",
      "reward :  -0.5560417314201452\n",
      "episode :  19\n",
      "current step :  262\n",
      "reward :  -0.6015595924688114\n",
      "episode :  19\n",
      "current step :  263\n",
      "reward :  -0.5719968254345792\n",
      "episode :  19\n",
      "current step :  264\n",
      "reward :  -0.5190045502409332\n",
      "episode :  19\n",
      "current step :  265\n",
      "reward :  -0.4750988215024954\n",
      "episode :  19\n",
      "current step :  266\n",
      "reward :  -0.4841218139389117\n",
      "episode :  19\n",
      "current step :  267\n",
      "reward :  -0.48832589249270403\n",
      "episode :  19\n",
      "current step :  268\n",
      "reward :  -0.4978207996983375\n",
      "episode :  19\n",
      "current step :  269\n",
      "reward :  -0.5373869789741507\n",
      "episode :  19\n",
      "current step :  270\n",
      "reward :  -0.5442336750438269\n",
      "episode :  19\n",
      "current step :  271\n",
      "reward :  -0.5504515852713573\n",
      "episode :  19\n",
      "current step :  272\n",
      "reward :  -0.5508944455798339\n",
      "episode :  19\n",
      "current step :  273\n",
      "reward :  -0.5595200153661329\n",
      "episode :  19\n",
      "current step :  274\n",
      "reward :  -0.5558376726388614\n",
      "episode :  19\n",
      "current step :  275\n",
      "reward :  -0.5510570469978477\n",
      "episode :  19\n",
      "current step :  276\n",
      "reward :  -0.5446344158876016\n",
      "episode :  19\n",
      "current step :  277\n",
      "reward :  -0.5720199873971984\n",
      "episode :  19\n",
      "current step :  278\n",
      "reward :  -0.5645392854769525\n",
      "episode :  19\n",
      "current step :  279\n",
      "reward :  -0.6049177216500166\n",
      "episode :  19\n",
      "current step :  280\n",
      "reward :  -0.606867450853681\n",
      "episode :  19\n",
      "current step :  281\n",
      "reward :  -0.5674804417188977\n",
      "episode :  19\n",
      "current step :  282\n",
      "reward :  -0.5551993534276701\n",
      "episode :  19\n",
      "current step :  283\n",
      "reward :  -0.5418448270659426\n",
      "episode :  19\n",
      "current step :  284\n",
      "reward :  -0.5692571620864848\n",
      "episode :  19\n",
      "current step :  285\n",
      "reward :  -0.5296915423946015\n",
      "episode :  20\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 286      |\n",
      "|    ep_rew_mean     | -122     |\n",
      "| time/              |          |\n",
      "|    episodes        | 20       |\n",
      "|    fps             | 13       |\n",
      "|    time_elapsed    | 410      |\n",
      "|    total_timesteps | 5720     |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -77.7    |\n",
      "|    critic_loss     | 3        |\n",
      "|    ent_coef        | 0.2      |\n",
      "|    ent_coef_loss   | -7.53    |\n",
      "|    learning_rate   | 0.0003   |\n",
      "|    n_updates       | 5619     |\n",
      "---------------------------------\n",
      "current step :  0\n",
      "reward :  -0.5683009545753432\n",
      "episode :  20\n",
      "current step :  1\n",
      "reward :  -0.5440511105151483\n",
      "episode :  20\n",
      "current step :  2\n",
      "reward :  -0.5404006079763748\n",
      "episode :  20\n",
      "current step :  3\n",
      "reward :  -0.5156005920423848\n",
      "episode :  20\n",
      "current step :  4\n",
      "reward :  -0.55088440863811\n",
      "episode :  20\n",
      "current step :  5\n",
      "reward :  -0.5772948089822445\n",
      "episode :  20\n",
      "current step :  6\n",
      "reward :  -0.5655416383373238\n",
      "episode :  20\n",
      "current step :  7\n",
      "reward :  -0.5625983691058575\n",
      "episode :  20\n",
      "current step :  8\n",
      "reward :  -0.5625061398324457\n",
      "episode :  20\n",
      "current step :  9\n",
      "reward :  -0.5573803305219223\n",
      "episode :  20\n",
      "current step :  10\n",
      "reward :  -0.5590337220845026\n",
      "episode :  20\n",
      "current step :  11\n",
      "reward :  -0.5576664099010554\n",
      "episode :  20\n",
      "current step :  12\n",
      "reward :  -0.5562540665516694\n",
      "episode :  20\n",
      "current step :  13\n",
      "reward :  -0.5495412087311707\n",
      "episode :  20\n",
      "current step :  14\n",
      "reward :  -0.5472673331953879\n",
      "episode :  20\n",
      "current step :  15\n",
      "reward :  -0.5331077065698872\n",
      "episode :  20\n",
      "current step :  16\n",
      "reward :  -0.526861212472996\n",
      "episode :  20\n",
      "current step :  17\n",
      "reward :  -0.5075897260642636\n",
      "episode :  20\n",
      "current step :  18\n",
      "reward :  -0.4808998488574102\n",
      "episode :  20\n",
      "current step :  19\n",
      "reward :  -0.5056534812244837\n",
      "episode :  20\n",
      "current step :  20\n",
      "reward :  -0.4810371044820753\n",
      "episode :  20\n",
      "current step :  21\n",
      "reward :  -0.4745635514957871\n",
      "episode :  20\n",
      "current step :  22\n",
      "reward :  -0.48849004407445173\n",
      "episode :  20\n",
      "current step :  23\n",
      "reward :  -0.4803385809884101\n",
      "episode :  20\n",
      "current step :  24\n",
      "reward :  -0.484079817399089\n",
      "episode :  20\n",
      "current step :  25\n",
      "reward :  -0.48818741268901844\n",
      "episode :  20\n",
      "current step :  26\n",
      "reward :  -0.48098105615435854\n",
      "episode :  20\n",
      "current step :  27\n",
      "reward :  -0.48789911079378384\n",
      "episode :  20\n",
      "current step :  28\n",
      "reward :  -0.5038276015287649\n",
      "episode :  20\n",
      "current step :  29\n",
      "reward :  -0.5389515226001436\n",
      "episode :  20\n",
      "current step :  30\n",
      "reward :  -0.5192477846834551\n",
      "episode :  20\n",
      "current step :  31\n",
      "reward :  -0.5245466882462488\n",
      "episode :  20\n",
      "current step :  32\n",
      "reward :  -0.5130799114297675\n",
      "episode :  20\n",
      "current step :  33\n",
      "reward :  -0.5119839141947977\n",
      "episode :  20\n",
      "current step :  34\n",
      "reward :  -0.5540166724208122\n",
      "episode :  20\n",
      "current step :  35\n",
      "reward :  -0.5597887503214867\n",
      "episode :  20\n",
      "current step :  36\n",
      "reward :  -0.5306703199127696\n",
      "episode :  20\n",
      "current step :  37\n",
      "reward :  -0.5253983235702111\n",
      "episode :  20\n",
      "current step :  38\n",
      "reward :  -0.5576816108429022\n",
      "episode :  20\n",
      "current step :  39\n",
      "reward :  -0.5767329639936681\n",
      "episode :  20\n",
      "current step :  40\n",
      "reward :  -0.5349267286512128\n",
      "episode :  20\n",
      "current step :  41\n",
      "reward :  -0.526455726419282\n",
      "episode :  20\n",
      "current step :  42\n",
      "reward :  -0.55217634826684\n",
      "episode :  20\n",
      "current step :  43\n",
      "reward :  -0.49218184446601243\n",
      "episode :  20\n",
      "current step :  44\n",
      "reward :  -0.49210635287777477\n",
      "episode :  20\n",
      "current step :  45\n",
      "reward :  -0.5147504646461577\n",
      "episode :  20\n",
      "current step :  46\n",
      "reward :  -0.5032126155692395\n",
      "episode :  20\n",
      "current step :  47\n",
      "reward :  -0.5272852161129726\n",
      "episode :  20\n",
      "current step :  48\n",
      "reward :  -0.5122463279347975\n",
      "episode :  20\n",
      "current step :  49\n",
      "reward :  -0.4851337927630315\n",
      "episode :  20\n",
      "current step :  50\n",
      "reward :  -0.5209721973882236\n",
      "episode :  20\n",
      "current step :  51\n",
      "reward :  -0.5506609379752351\n",
      "episode :  20\n",
      "current step :  52\n",
      "reward :  -0.5393869829809607\n",
      "episode :  20\n",
      "current step :  53\n",
      "reward :  -0.5476182023993784\n",
      "episode :  20\n",
      "current step :  54\n",
      "reward :  -0.5357172994901629\n",
      "episode :  20\n",
      "current step :  55\n",
      "reward :  -0.5161924830509881\n",
      "episode :  20\n",
      "current step :  56\n",
      "reward :  -0.49130700563953766\n",
      "episode :  20\n",
      "current step :  57\n",
      "reward :  -0.536694385419628\n",
      "episode :  20\n",
      "current step :  58\n",
      "reward :  -0.5518035672354711\n",
      "episode :  20\n",
      "current step :  59\n",
      "reward :  -0.5424110983452075\n",
      "episode :  20\n",
      "current step :  60\n",
      "reward :  -0.546944443285968\n",
      "episode :  20\n",
      "current step :  61\n",
      "reward :  -0.5549239601749327\n",
      "episode :  20\n",
      "current step :  62\n",
      "reward :  -0.5651033346693598\n",
      "episode :  20\n",
      "current step :  63\n",
      "reward :  -0.5345346547787777\n",
      "episode :  20\n",
      "current step :  64\n",
      "reward :  -0.5942955674673774\n",
      "episode :  20\n",
      "current step :  65\n",
      "reward :  -0.5831937943805059\n",
      "episode :  20\n",
      "current step :  66\n",
      "reward :  -0.5428477124802994\n",
      "episode :  20\n",
      "current step :  67\n",
      "reward :  -0.5486044959803144\n",
      "episode :  20\n",
      "current step :  68\n",
      "reward :  -0.5091608851408802\n",
      "episode :  20\n",
      "current step :  69\n",
      "reward :  -0.5195384186312986\n",
      "episode :  20\n",
      "current step :  70\n",
      "reward :  -0.5184631522077142\n",
      "episode :  20\n",
      "current step :  71\n",
      "reward :  -0.528070427161716\n",
      "episode :  20\n",
      "current step :  72\n",
      "reward :  -0.5487508235200099\n",
      "episode :  20\n",
      "current step :  73\n",
      "reward :  -0.527205145300935\n",
      "episode :  20\n",
      "current step :  74\n",
      "reward :  -0.5177413862132995\n",
      "episode :  20\n",
      "current step :  75\n",
      "reward :  -0.44782765092156634\n",
      "episode :  20\n",
      "current step :  76\n",
      "reward :  -0.46586276015422134\n",
      "episode :  20\n",
      "current step :  77\n",
      "reward :  -0.4236593801145963\n",
      "episode :  20\n",
      "current step :  78\n",
      "reward :  -0.42020637660516386\n",
      "episode :  20\n",
      "current step :  79\n",
      "reward :  -0.434928626500159\n",
      "episode :  20\n",
      "current step :  80\n",
      "reward :  -0.43642247346901214\n",
      "episode :  20\n",
      "current step :  81\n",
      "reward :  -0.436069156390926\n",
      "episode :  20\n",
      "current step :  82\n",
      "reward :  -0.44660088966601\n",
      "episode :  20\n",
      "current step :  83\n",
      "reward :  -0.449369787239104\n",
      "episode :  20\n",
      "current step :  84\n",
      "reward :  -0.46893072548683407\n",
      "episode :  20\n",
      "current step :  85\n",
      "reward :  -0.4406745858999543\n",
      "episode :  20\n",
      "current step :  86\n",
      "reward :  -0.43577545359166353\n",
      "episode :  20\n",
      "current step :  87\n",
      "reward :  -0.4429899643548087\n",
      "episode :  20\n",
      "current step :  88\n",
      "reward :  -0.4592351098025911\n",
      "episode :  20\n",
      "current step :  89\n",
      "reward :  -0.44946841260247655\n",
      "episode :  20\n",
      "current step :  90\n",
      "reward :  -0.45391276110216267\n",
      "episode :  20\n",
      "current step :  91\n",
      "reward :  -0.4575145205781839\n",
      "episode :  20\n",
      "current step :  92\n",
      "reward :  -0.4552615312664432\n",
      "episode :  20\n",
      "current step :  93\n",
      "reward :  -0.4654770930342696\n",
      "episode :  20\n",
      "current step :  94\n",
      "reward :  -0.4836229484743863\n",
      "episode :  20\n",
      "current step :  95\n",
      "reward :  -0.48348562409007256\n",
      "episode :  20\n",
      "current step :  96\n",
      "reward :  -0.4920217096151144\n",
      "episode :  20\n",
      "current step :  97\n",
      "reward :  -0.464116167792011\n",
      "episode :  20\n",
      "current step :  98\n",
      "reward :  -0.46592074707428577\n",
      "episode :  20\n",
      "current step :  99\n",
      "reward :  -0.4627951994740341\n",
      "episode :  20\n",
      "current step :  100\n",
      "reward :  -0.4677512307291321\n",
      "episode :  20\n",
      "current step :  101\n",
      "reward :  -0.49062876936550187\n",
      "episode :  20\n",
      "current step :  102\n",
      "reward :  -0.5185866382013675\n",
      "episode :  20\n",
      "current step :  103\n",
      "reward :  -0.5231731259114585\n",
      "episode :  20\n",
      "current step :  104\n",
      "reward :  -0.5369451645921562\n",
      "episode :  20\n",
      "current step :  105\n",
      "reward :  -0.5096814982797635\n",
      "episode :  20\n",
      "current step :  106\n",
      "reward :  -0.5330807038374609\n",
      "episode :  20\n",
      "current step :  107\n",
      "reward :  -0.4881122858247102\n",
      "episode :  20\n",
      "current step :  108\n",
      "reward :  -0.5164987255353146\n",
      "episode :  20\n",
      "current step :  109\n",
      "reward :  -0.5418927006617879\n",
      "episode :  20\n",
      "current step :  110\n",
      "reward :  -0.5825515852909183\n",
      "episode :  20\n",
      "current step :  111\n",
      "reward :  -0.5756739230496731\n",
      "episode :  20\n",
      "current step :  112\n",
      "reward :  -0.5629800406111962\n",
      "episode :  20\n",
      "current step :  113\n",
      "reward :  -0.4982336999601154\n",
      "episode :  20\n",
      "current step :  114\n",
      "reward :  -0.44562149042076243\n",
      "episode :  20\n",
      "current step :  115\n",
      "reward :  -0.4313693568960375\n",
      "episode :  20\n",
      "current step :  116\n",
      "reward :  -0.45814483784664567\n",
      "episode :  20\n",
      "current step :  117\n",
      "reward :  -0.4364992803790374\n",
      "episode :  20\n",
      "current step :  118\n",
      "reward :  -0.43677761323327535\n",
      "episode :  20\n",
      "current step :  119\n",
      "reward :  -0.43207827137092264\n",
      "episode :  20\n",
      "current step :  120\n",
      "reward :  -0.4345190294092918\n",
      "episode :  20\n",
      "current step :  121\n",
      "reward :  -0.4351212829426414\n",
      "episode :  20\n",
      "current step :  122\n",
      "reward :  -0.4672044731008903\n",
      "episode :  20\n",
      "current step :  123\n",
      "reward :  -0.5517191899133458\n",
      "episode :  20\n",
      "current step :  124\n",
      "reward :  -0.5716165437719577\n",
      "episode :  20\n",
      "current step :  125\n",
      "reward :  -0.5533110550355065\n",
      "episode :  20\n",
      "current step :  126\n",
      "reward :  -0.4826237679243151\n",
      "episode :  20\n",
      "current step :  127\n",
      "reward :  -0.43590242194138\n",
      "episode :  20\n",
      "current step :  128\n",
      "reward :  -0.42410466088362564\n",
      "episode :  20\n",
      "current step :  129\n",
      "reward :  -0.41863013730783316\n",
      "episode :  20\n",
      "current step :  130\n",
      "reward :  -0.4517219569592661\n",
      "episode :  20\n",
      "current step :  131\n",
      "reward :  -0.44301453899141907\n",
      "episode :  20\n",
      "current step :  132\n",
      "reward :  -0.42584059262821045\n",
      "episode :  20\n",
      "current step :  133\n",
      "reward :  -0.4327308735833888\n",
      "episode :  20\n",
      "current step :  134\n",
      "reward :  -0.4192236804391727\n",
      "episode :  20\n",
      "current step :  135\n",
      "reward :  -0.4078204085437385\n",
      "episode :  20\n",
      "current step :  136\n",
      "reward :  -0.3373097567224669\n",
      "episode :  20\n",
      "current step :  137\n",
      "reward :  -0.46381654513229686\n",
      "episode :  20\n",
      "current step :  138\n",
      "reward :  -0.5318567906520699\n",
      "episode :  20\n",
      "current step :  139\n",
      "reward :  -0.5031804753695405\n",
      "episode :  20\n",
      "current step :  140\n",
      "reward :  -0.4341461257658919\n",
      "episode :  20\n",
      "current step :  141\n",
      "reward :  -0.4711093678261747\n",
      "episode :  20\n",
      "current step :  142\n",
      "reward :  -0.40576606284187194\n",
      "episode :  20\n",
      "current step :  143\n",
      "reward :  -0.36321757400510135\n",
      "episode :  20\n",
      "current step :  144\n",
      "reward :  -0.44485699580343285\n",
      "episode :  20\n",
      "current step :  145\n",
      "reward :  -0.4048795554606473\n",
      "episode :  20\n",
      "current step :  146\n",
      "reward :  -0.4432095621537068\n",
      "episode :  20\n",
      "current step :  147\n",
      "reward :  -0.42829567684685915\n",
      "episode :  20\n",
      "current step :  148\n",
      "reward :  -0.43910976713049826\n",
      "episode :  20\n",
      "current step :  149\n",
      "reward :  -0.47056391063571695\n",
      "episode :  20\n",
      "current step :  150\n",
      "reward :  -0.46085758179308123\n",
      "episode :  20\n",
      "current step :  151\n",
      "reward :  -0.39311104005964187\n",
      "episode :  20\n",
      "current step :  152\n",
      "reward :  -0.5109604286819086\n",
      "episode :  20\n",
      "current step :  153\n",
      "reward :  -0.5277199185843083\n",
      "episode :  20\n",
      "current step :  154\n",
      "reward :  -0.5429403273034723\n",
      "episode :  20\n",
      "current step :  155\n",
      "reward :  -0.5260389579021897\n",
      "episode :  20\n",
      "current step :  156\n",
      "reward :  -0.5064227548728982\n",
      "episode :  20\n",
      "current step :  157\n",
      "reward :  -0.4752643126903668\n",
      "episode :  20\n",
      "current step :  158\n",
      "reward :  -0.4550765975691126\n",
      "episode :  20\n",
      "current step :  159\n",
      "reward :  -0.5210490209794661\n",
      "episode :  20\n",
      "current step :  160\n",
      "reward :  -0.5163078620158756\n",
      "episode :  20\n",
      "current step :  161\n",
      "reward :  -0.46791483536399636\n",
      "episode :  20\n",
      "current step :  162\n",
      "reward :  -0.5846672884994943\n",
      "episode :  20\n",
      "current step :  163\n",
      "reward :  -0.5923691071977415\n",
      "episode :  20\n",
      "current step :  164\n",
      "reward :  -0.5693641413090035\n",
      "episode :  20\n",
      "current step :  165\n",
      "reward :  -0.4960637835851761\n",
      "episode :  20\n",
      "current step :  166\n",
      "reward :  -0.5054209239168779\n",
      "episode :  20\n",
      "current step :  167\n",
      "reward :  -0.5101643594269732\n",
      "episode :  20\n",
      "current step :  168\n",
      "reward :  -0.5269648217505465\n",
      "episode :  20\n",
      "current step :  169\n",
      "reward :  -0.5464465481742089\n",
      "episode :  20\n",
      "current step :  170\n",
      "reward :  -0.5898235946912765\n",
      "episode :  20\n",
      "current step :  171\n",
      "reward :  -0.5507463825156156\n",
      "episode :  20\n",
      "current step :  172\n",
      "reward :  -0.6636765646864955\n",
      "episode :  20\n",
      "current step :  173\n",
      "reward :  -0.5996500341304856\n",
      "episode :  20\n",
      "current step :  174\n",
      "reward :  -0.5856534689750404\n",
      "episode :  20\n",
      "current step :  175\n",
      "reward :  -0.5818270716352917\n",
      "episode :  20\n",
      "current step :  176\n",
      "reward :  -0.6204023726164044\n",
      "episode :  20\n",
      "current step :  177\n",
      "reward :  -0.6208329318362333\n",
      "episode :  20\n",
      "current step :  178\n",
      "reward :  -0.5939454045702133\n",
      "episode :  20\n",
      "current step :  179\n",
      "reward :  -0.6750502873100369\n",
      "episode :  20\n",
      "current step :  180\n",
      "reward :  -0.5842487397097793\n",
      "episode :  20\n",
      "current step :  181\n",
      "reward :  -0.5696787403517988\n",
      "episode :  20\n",
      "current step :  182\n",
      "reward :  -0.5779521050922555\n",
      "episode :  20\n",
      "current step :  183\n",
      "reward :  -0.5717965934977784\n",
      "episode :  20\n",
      "current step :  184\n",
      "reward :  -0.5567790146991742\n",
      "episode :  20\n",
      "current step :  185\n",
      "reward :  -0.5617578640746131\n",
      "episode :  20\n",
      "current step :  186\n",
      "reward :  -0.570184807378677\n",
      "episode :  20\n",
      "current step :  187\n",
      "reward :  -0.5703539166204674\n",
      "episode :  20\n",
      "current step :  188\n",
      "reward :  -0.5801240286397172\n",
      "episode :  20\n",
      "current step :  189\n",
      "reward :  -0.5702668833858031\n",
      "episode :  20\n",
      "current step :  190\n",
      "reward :  -0.5662472355643609\n",
      "episode :  20\n",
      "current step :  191\n",
      "reward :  -0.616944392345999\n",
      "episode :  20\n",
      "current step :  192\n",
      "reward :  -0.6218678214126623\n",
      "episode :  20\n",
      "current step :  193\n",
      "reward :  -0.6737521229329655\n",
      "episode :  20\n",
      "current step :  194\n",
      "reward :  -0.6356700740828093\n",
      "episode :  20\n",
      "current step :  195\n",
      "reward :  -0.5709129309281298\n",
      "episode :  20\n",
      "current step :  196\n",
      "reward :  -0.6024226979452879\n",
      "episode :  20\n",
      "current step :  197\n",
      "reward :  -0.6507373465052418\n",
      "episode :  20\n",
      "current step :  198\n",
      "reward :  -0.5898263769215386\n",
      "episode :  20\n",
      "current step :  199\n",
      "reward :  -0.569621335121681\n",
      "episode :  20\n",
      "current step :  200\n",
      "reward :  -0.5843941854469376\n",
      "episode :  20\n",
      "current step :  201\n",
      "reward :  -0.5873110039303002\n",
      "episode :  20\n",
      "current step :  202\n",
      "reward :  -0.6716100313562838\n",
      "episode :  20\n",
      "current step :  203\n",
      "reward :  -0.638227586841673\n",
      "episode :  20\n",
      "current step :  204\n",
      "reward :  -0.638988113072285\n",
      "episode :  20\n",
      "current step :  205\n",
      "reward :  -0.6253193888371233\n",
      "episode :  20\n",
      "current step :  206\n",
      "reward :  -0.6122879107276791\n",
      "episode :  20\n",
      "current step :  207\n",
      "reward :  -0.5671725834145018\n",
      "episode :  20\n",
      "current step :  208\n",
      "reward :  -0.6184118371142017\n",
      "episode :  20\n",
      "current step :  209\n",
      "reward :  -0.5653036394708623\n",
      "episode :  20\n",
      "current step :  210\n",
      "reward :  -0.5732601911425211\n",
      "episode :  20\n",
      "current step :  211\n",
      "reward :  -0.5944158009388496\n",
      "episode :  20\n",
      "current step :  212\n",
      "reward :  -0.6254542255395293\n",
      "episode :  20\n",
      "current step :  213\n",
      "reward :  -0.6217839921323337\n",
      "episode :  20\n",
      "current step :  214\n",
      "reward :  -0.6172930285165785\n",
      "episode :  20\n",
      "current step :  215\n",
      "reward :  -0.6129055375121406\n",
      "episode :  20\n",
      "current step :  216\n",
      "reward :  -0.6044573378184709\n",
      "episode :  20\n",
      "current step :  217\n",
      "reward :  -0.5974537640357486\n",
      "episode :  20\n",
      "current step :  218\n",
      "reward :  -0.5878007071335873\n",
      "episode :  20\n",
      "current step :  219\n",
      "reward :  -0.5775905807453567\n",
      "episode :  20\n",
      "current step :  220\n",
      "reward :  -0.5688505838334409\n",
      "episode :  20\n",
      "current step :  221\n",
      "reward :  -0.5597089349603206\n",
      "episode :  20\n",
      "current step :  222\n",
      "reward :  -0.5486689292597494\n",
      "episode :  20\n",
      "current step :  223\n",
      "reward :  -0.5429062350003584\n",
      "episode :  20\n",
      "current step :  224\n",
      "reward :  -0.5369041501891167\n",
      "episode :  20\n",
      "current step :  225\n",
      "reward :  -0.5293240516887908\n",
      "episode :  20\n",
      "current step :  226\n",
      "reward :  -0.5207108919233138\n",
      "episode :  20\n",
      "current step :  227\n",
      "reward :  -0.49402175042937135\n",
      "episode :  20\n",
      "current step :  228\n",
      "reward :  -0.41902674912001786\n",
      "episode :  20\n",
      "current step :  229\n",
      "reward :  -0.43511262703709486\n",
      "episode :  20\n",
      "current step :  230\n",
      "reward :  -0.4930911025259255\n",
      "episode :  20\n",
      "current step :  231\n",
      "reward :  -0.48719438690263095\n",
      "episode :  20\n",
      "current step :  232\n",
      "reward :  -0.4819067616747186\n",
      "episode :  20\n",
      "current step :  233\n",
      "reward :  -0.4808683864981635\n",
      "episode :  20\n",
      "current step :  234\n",
      "reward :  -0.476724632828938\n",
      "episode :  20\n",
      "current step :  235\n",
      "reward :  -0.46716695089235494\n",
      "episode :  20\n",
      "current step :  236\n",
      "reward :  -0.47259625279134687\n",
      "episode :  20\n",
      "current step :  237\n",
      "reward :  -0.46897575148589726\n",
      "episode :  20\n",
      "current step :  238\n",
      "reward :  -0.4447316845552187\n",
      "episode :  20\n",
      "current step :  239\n",
      "reward :  -0.4241904250840668\n",
      "episode :  20\n",
      "current step :  240\n",
      "reward :  -0.3642679084301709\n",
      "episode :  20\n",
      "current step :  241\n",
      "reward :  -0.3578656344431745\n",
      "episode :  20\n",
      "current step :  242\n",
      "reward :  -0.4522253324280075\n",
      "episode :  20\n",
      "current step :  243\n",
      "reward :  -0.4617047128403886\n",
      "episode :  20\n",
      "current step :  244\n",
      "reward :  -0.4398410944246639\n",
      "episode :  20\n",
      "current step :  245\n",
      "reward :  -0.393476261510566\n",
      "episode :  20\n",
      "current step :  246\n",
      "reward :  -0.4705013073672759\n",
      "episode :  20\n",
      "current step :  247\n",
      "reward :  -0.4082293865190888\n",
      "episode :  20\n",
      "current step :  248\n",
      "reward :  -0.47630448104579615\n",
      "episode :  20\n",
      "current step :  249\n",
      "reward :  -0.48512107299755747\n",
      "episode :  20\n",
      "current step :  250\n",
      "reward :  -0.46876338728282124\n",
      "episode :  20\n",
      "current step :  251\n",
      "reward :  -0.4839678526293557\n",
      "episode :  20\n",
      "current step :  252\n",
      "reward :  -0.44762807721738845\n",
      "episode :  20\n",
      "current step :  253\n",
      "reward :  -0.486424693650415\n",
      "episode :  20\n",
      "current step :  254\n",
      "reward :  -0.490181266760504\n",
      "episode :  20\n",
      "current step :  255\n",
      "reward :  -0.4971913374339924\n",
      "episode :  20\n",
      "current step :  256\n",
      "reward :  -0.49440855675765105\n",
      "episode :  20\n",
      "current step :  257\n",
      "reward :  -0.5002516970533302\n",
      "episode :  20\n",
      "current step :  258\n",
      "reward :  -0.49908519243603705\n",
      "episode :  20\n",
      "current step :  259\n",
      "reward :  -0.5015492550955031\n",
      "episode :  20\n",
      "current step :  260\n",
      "reward :  -0.5111486575322427\n",
      "episode :  20\n",
      "current step :  261\n",
      "reward :  -0.5133168539664092\n",
      "episode :  20\n",
      "current step :  262\n",
      "reward :  -0.5195071867262788\n",
      "episode :  20\n",
      "current step :  263\n",
      "reward :  -0.5203265415055048\n",
      "episode :  20\n",
      "current step :  264\n",
      "reward :  -0.4741960452169768\n",
      "episode :  20\n",
      "current step :  265\n",
      "reward :  -0.4741957030910645\n",
      "episode :  20\n",
      "current step :  266\n",
      "reward :  -0.5256632901349093\n",
      "episode :  20\n",
      "current step :  267\n",
      "reward :  -0.5214673168624385\n",
      "episode :  20\n",
      "current step :  268\n",
      "reward :  -0.5131405370083224\n",
      "episode :  20\n",
      "current step :  269\n",
      "reward :  -0.5289556641258002\n",
      "episode :  20\n",
      "current step :  270\n",
      "reward :  -0.5266153327853254\n",
      "episode :  20\n",
      "current step :  271\n",
      "reward :  -0.5299474813848648\n",
      "episode :  20\n",
      "current step :  272\n",
      "reward :  -0.5343290071082197\n",
      "episode :  20\n",
      "current step :  273\n",
      "reward :  -0.5008379553025324\n",
      "episode :  20\n",
      "current step :  274\n",
      "reward :  -0.5333155974725051\n",
      "episode :  20\n",
      "current step :  275\n",
      "reward :  -0.5321452186440301\n",
      "episode :  20\n",
      "current step :  276\n",
      "reward :  -0.5337681292580398\n",
      "episode :  20\n",
      "current step :  277\n",
      "reward :  -0.5336422711441996\n",
      "episode :  20\n",
      "current step :  278\n",
      "reward :  -0.5205000812991075\n",
      "episode :  20\n",
      "current step :  279\n",
      "reward :  -0.5365172271035535\n",
      "episode :  20\n",
      "current step :  280\n",
      "reward :  -0.533008377661845\n",
      "episode :  20\n",
      "current step :  281\n",
      "reward :  -0.5331357869376401\n",
      "episode :  20\n",
      "current step :  282\n",
      "reward :  -0.5345551115991325\n",
      "episode :  20\n",
      "current step :  283\n",
      "reward :  -0.5369634158658584\n",
      "episode :  20\n",
      "current step :  284\n",
      "reward :  -0.5309572761190704\n",
      "episode :  20\n",
      "current step :  285\n",
      "reward :  -0.40840452411530814\n",
      "episode :  21\n",
      "current step :  0\n",
      "reward :  -0.49855384715123024\n",
      "episode :  21\n",
      "current step :  1\n",
      "reward :  -0.4919483857837066\n",
      "episode :  21\n",
      "current step :  2\n",
      "reward :  -0.5234972115138106\n",
      "episode :  21\n",
      "current step :  3\n",
      "reward :  -0.5325403986996852\n",
      "episode :  21\n",
      "current step :  4\n",
      "reward :  -0.5453937180226659\n",
      "episode :  21\n",
      "current step :  5\n",
      "reward :  -0.5555891221378056\n",
      "episode :  21\n",
      "current step :  6\n",
      "reward :  -0.5590630429080885\n",
      "episode :  21\n",
      "current step :  7\n",
      "reward :  -0.5458098876972133\n",
      "episode :  21\n",
      "current step :  8\n",
      "reward :  -0.5442561629809461\n",
      "episode :  21\n",
      "current step :  9\n",
      "reward :  -0.4710354945719927\n",
      "episode :  21\n",
      "current step :  10\n",
      "reward :  -0.47603238175769386\n",
      "episode :  21\n",
      "current step :  11\n",
      "reward :  -0.5411182283861419\n",
      "episode :  21\n",
      "current step :  12\n",
      "reward :  -0.5403579129254843\n",
      "episode :  21\n",
      "current step :  13\n",
      "reward :  -0.5372086883641736\n",
      "episode :  21\n",
      "current step :  14\n",
      "reward :  -0.5476991105034821\n",
      "episode :  21\n",
      "current step :  15\n",
      "reward :  -0.5362669770842567\n",
      "episode :  21\n",
      "current step :  16\n",
      "reward :  -0.5479757992420329\n",
      "episode :  21\n",
      "current step :  17\n",
      "reward :  -0.5438139427696602\n",
      "episode :  21\n",
      "current step :  18\n",
      "reward :  -0.5489108521473032\n",
      "episode :  21\n",
      "current step :  19\n",
      "reward :  -0.5477595415969871\n",
      "episode :  21\n",
      "current step :  20\n",
      "reward :  -0.5277136538146577\n",
      "episode :  21\n",
      "current step :  21\n",
      "reward :  -0.4883344219783032\n",
      "episode :  21\n",
      "current step :  22\n",
      "reward :  -0.5118921510447401\n",
      "episode :  21\n",
      "current step :  23\n",
      "reward :  -0.5083202297979895\n",
      "episode :  21\n",
      "current step :  24\n",
      "reward :  -0.5314860826937602\n",
      "episode :  21\n",
      "current step :  25\n",
      "reward :  -0.43058459459694665\n",
      "episode :  21\n",
      "current step :  26\n",
      "reward :  -0.4881505187103352\n",
      "episode :  21\n",
      "current step :  27\n",
      "reward :  -0.5407689406619196\n",
      "episode :  21\n",
      "current step :  28\n",
      "reward :  -0.5380788675830293\n",
      "episode :  21\n",
      "current step :  29\n",
      "reward :  -0.5437951026525555\n",
      "episode :  21\n",
      "current step :  30\n",
      "reward :  -0.5218329782784801\n",
      "episode :  21\n",
      "current step :  31\n",
      "reward :  -0.49642962518895045\n",
      "episode :  21\n",
      "current step :  32\n",
      "reward :  -0.40762943083930253\n",
      "episode :  21\n",
      "current step :  33\n",
      "reward :  -0.341799944370825\n",
      "episode :  21\n",
      "current step :  34\n",
      "reward :  -0.42038671940636024\n",
      "episode :  21\n",
      "current step :  35\n",
      "reward :  -0.47393394795579946\n",
      "episode :  21\n",
      "current step :  36\n",
      "reward :  -0.49618846858308274\n",
      "episode :  21\n",
      "current step :  37\n",
      "reward :  -0.5017742081704477\n",
      "episode :  21\n",
      "current step :  38\n",
      "reward :  -0.47979839929976503\n",
      "episode :  21\n",
      "current step :  39\n",
      "reward :  -0.42676244526013074\n",
      "episode :  21\n",
      "current step :  40\n",
      "reward :  -0.5055668717000591\n",
      "episode :  21\n",
      "current step :  41\n",
      "reward :  -0.5012250989688504\n",
      "episode :  21\n",
      "current step :  42\n",
      "reward :  -0.5161121892682163\n",
      "episode :  21\n",
      "current step :  43\n",
      "reward :  -0.4239650215810642\n",
      "episode :  21\n",
      "current step :  44\n",
      "reward :  -0.48354322327787475\n",
      "episode :  21\n",
      "current step :  45\n",
      "reward :  -0.4991008512496846\n",
      "episode :  21\n",
      "current step :  46\n",
      "reward :  -0.5009785042842034\n",
      "episode :  21\n",
      "current step :  47\n",
      "reward :  -0.513998636293569\n",
      "episode :  21\n",
      "current step :  48\n",
      "reward :  -0.5408805019323354\n",
      "episode :  21\n",
      "current step :  49\n",
      "reward :  -0.5598534473421788\n",
      "episode :  21\n",
      "current step :  50\n",
      "reward :  -0.5389438939735604\n",
      "episode :  21\n",
      "current step :  51\n",
      "reward :  -0.5269121204110226\n",
      "episode :  21\n",
      "current step :  52\n",
      "reward :  -0.5056472836886817\n",
      "episode :  21\n",
      "current step :  53\n",
      "reward :  -0.5412142058843556\n",
      "episode :  21\n",
      "current step :  54\n",
      "reward :  -0.5284060193404905\n",
      "episode :  21\n",
      "current step :  55\n",
      "reward :  -0.49911737912575715\n",
      "episode :  21\n",
      "current step :  56\n",
      "reward :  -0.5375254399710822\n",
      "episode :  21\n",
      "current step :  57\n",
      "reward :  -0.5732718377865561\n",
      "episode :  21\n",
      "current step :  58\n",
      "reward :  -0.534173657919292\n",
      "episode :  21\n",
      "current step :  59\n",
      "reward :  -0.533961092338621\n",
      "episode :  21\n",
      "current step :  60\n",
      "reward :  -0.5668850643572168\n",
      "episode :  21\n",
      "current step :  61\n",
      "reward :  -0.5635499266652144\n",
      "episode :  21\n",
      "current step :  62\n",
      "reward :  -0.5413047799609794\n",
      "episode :  21\n",
      "current step :  63\n",
      "reward :  -0.5493437583004267\n",
      "episode :  21\n",
      "current step :  64\n",
      "reward :  -0.5644434520849971\n",
      "episode :  21\n",
      "current step :  65\n",
      "reward :  -0.5409553584345216\n",
      "episode :  21\n",
      "current step :  66\n",
      "reward :  -0.5544955643490579\n",
      "episode :  21\n",
      "current step :  67\n",
      "reward :  -0.6320379896625279\n",
      "episode :  21\n",
      "current step :  68\n",
      "reward :  -0.545346651216336\n",
      "episode :  21\n",
      "current step :  69\n",
      "reward :  -0.5259977091022501\n",
      "episode :  21\n",
      "current step :  70\n",
      "reward :  -0.5634009392033265\n",
      "episode :  21\n",
      "current step :  71\n",
      "reward :  -0.5678275927541866\n",
      "episode :  21\n",
      "current step :  72\n",
      "reward :  -0.5772770802427731\n",
      "episode :  21\n",
      "current step :  73\n",
      "reward :  -0.5652598470745596\n",
      "episode :  21\n",
      "current step :  74\n",
      "reward :  -0.5895097599776717\n",
      "episode :  21\n",
      "current step :  75\n",
      "reward :  -0.5798968171709998\n",
      "episode :  21\n",
      "current step :  76\n",
      "reward :  -0.5088327088993871\n",
      "episode :  21\n",
      "current step :  77\n",
      "reward :  -0.5090360974237206\n",
      "episode :  21\n",
      "current step :  78\n",
      "reward :  -0.4996602444523528\n",
      "episode :  21\n",
      "current step :  79\n",
      "reward :  -0.5459315086527046\n",
      "episode :  21\n",
      "current step :  80\n",
      "reward :  -0.561046640988186\n",
      "episode :  21\n",
      "current step :  81\n",
      "reward :  -0.5059363892942057\n",
      "episode :  21\n",
      "current step :  82\n",
      "reward :  -0.5443554579269285\n",
      "episode :  21\n",
      "current step :  83\n",
      "reward :  -0.5361263133570395\n",
      "episode :  21\n",
      "current step :  84\n",
      "reward :  -0.51666208561259\n",
      "episode :  21\n",
      "current step :  85\n",
      "reward :  -0.48061727005042654\n",
      "episode :  21\n",
      "current step :  86\n",
      "reward :  -0.4874445553325003\n",
      "episode :  21\n",
      "current step :  87\n",
      "reward :  -0.5221269357710632\n",
      "episode :  21\n",
      "current step :  88\n",
      "reward :  -0.5161805912134338\n",
      "episode :  21\n",
      "current step :  89\n",
      "reward :  -0.5131897102713991\n",
      "episode :  21\n",
      "current step :  90\n",
      "reward :  -0.47295558926903664\n",
      "episode :  21\n",
      "current step :  91\n",
      "reward :  -0.5028421205907513\n",
      "episode :  21\n",
      "current step :  92\n",
      "reward :  -0.5094993738621467\n",
      "episode :  21\n",
      "current step :  93\n",
      "reward :  -0.5285079687924491\n",
      "episode :  21\n",
      "current step :  94\n",
      "reward :  -0.5573386549352097\n",
      "episode :  21\n",
      "current step :  95\n",
      "reward :  -0.54825967166335\n",
      "episode :  21\n",
      "current step :  96\n",
      "reward :  -0.5372805442829275\n",
      "episode :  21\n",
      "current step :  97\n",
      "reward :  -0.5391324468996979\n",
      "episode :  21\n",
      "current step :  98\n",
      "reward :  -0.5741325792559796\n",
      "episode :  21\n",
      "current step :  99\n",
      "reward :  -0.5670033103003216\n",
      "episode :  21\n",
      "current step :  100\n",
      "reward :  -0.5158309632607482\n",
      "episode :  21\n",
      "current step :  101\n",
      "reward :  -0.5133205457166906\n",
      "episode :  21\n",
      "current step :  102\n",
      "reward :  -0.5202615445763651\n",
      "episode :  21\n",
      "current step :  103\n",
      "reward :  -0.500796620891172\n",
      "episode :  21\n",
      "current step :  104\n",
      "reward :  -0.517687876006295\n",
      "episode :  21\n",
      "current step :  105\n",
      "reward :  -0.47879211009067807\n",
      "episode :  21\n",
      "current step :  106\n",
      "reward :  -0.481155242269057\n",
      "episode :  21\n",
      "current step :  107\n",
      "reward :  -0.49331731120186084\n",
      "episode :  21\n",
      "current step :  108\n",
      "reward :  -0.5034805892920537\n",
      "episode :  21\n",
      "current step :  109\n",
      "reward :  -0.46917505776676816\n",
      "episode :  21\n",
      "current step :  110\n",
      "reward :  -0.48377985894299746\n",
      "episode :  21\n",
      "current step :  111\n",
      "reward :  -0.463982434663961\n",
      "episode :  21\n",
      "current step :  112\n",
      "reward :  -0.47498948708949995\n",
      "episode :  21\n",
      "current step :  113\n",
      "reward :  -0.46236365732240275\n",
      "episode :  21\n",
      "current step :  114\n",
      "reward :  -0.47003821784674515\n",
      "episode :  21\n",
      "current step :  115\n",
      "reward :  -0.4723241458703976\n",
      "episode :  21\n",
      "current step :  116\n",
      "reward :  -0.47066566433924917\n",
      "episode :  21\n",
      "current step :  117\n",
      "reward :  -0.4696638490533711\n",
      "episode :  21\n",
      "current step :  118\n",
      "reward :  -0.4697856242473187\n",
      "episode :  21\n",
      "current step :  119\n",
      "reward :  -0.4581725418695028\n",
      "episode :  21\n",
      "current step :  120\n",
      "reward :  -0.46647646438811735\n",
      "episode :  21\n",
      "current step :  121\n",
      "reward :  -0.4528696388309649\n",
      "episode :  21\n",
      "current step :  122\n",
      "reward :  -0.46580152011418724\n",
      "episode :  21\n",
      "current step :  123\n",
      "reward :  -0.46683371005345675\n",
      "episode :  21\n",
      "current step :  124\n",
      "reward :  -0.4685461896137549\n",
      "episode :  21\n",
      "current step :  125\n",
      "reward :  -0.45588087048360126\n",
      "episode :  21\n",
      "current step :  126\n",
      "reward :  -0.4460200782967004\n",
      "episode :  21\n",
      "current step :  127\n",
      "reward :  -0.4544724561276717\n",
      "episode :  21\n",
      "current step :  128\n",
      "reward :  -0.4561942541317248\n",
      "episode :  21\n",
      "current step :  129\n",
      "reward :  -0.4449992628518123\n",
      "episode :  21\n",
      "current step :  130\n",
      "reward :  -0.43930493186244784\n",
      "episode :  21\n",
      "current step :  131\n",
      "reward :  -0.44528641572682176\n",
      "episode :  21\n",
      "current step :  132\n",
      "reward :  -0.4386937125167252\n",
      "episode :  21\n",
      "current step :  133\n",
      "reward :  -0.42930956550990984\n",
      "episode :  21\n",
      "current step :  134\n",
      "reward :  -0.45935269365486964\n",
      "episode :  21\n",
      "current step :  135\n",
      "reward :  -0.4280876733053603\n",
      "episode :  21\n",
      "current step :  136\n",
      "reward :  -0.45365584864452063\n",
      "episode :  21\n",
      "current step :  137\n",
      "reward :  -0.5131288791382943\n",
      "episode :  21\n",
      "current step :  138\n",
      "reward :  -0.5649737199198107\n",
      "episode :  21\n",
      "current step :  139\n",
      "reward :  -0.5257007710072148\n",
      "episode :  21\n",
      "current step :  140\n",
      "reward :  -0.5160052733411571\n",
      "episode :  21\n",
      "current step :  141\n",
      "reward :  -0.5434280856727555\n",
      "episode :  21\n",
      "current step :  142\n",
      "reward :  -0.5408098033763882\n",
      "episode :  21\n",
      "current step :  143\n",
      "reward :  -0.5233899092025195\n",
      "episode :  21\n",
      "current step :  144\n",
      "reward :  -0.5131217029792193\n",
      "episode :  21\n",
      "current step :  145\n",
      "reward :  -0.5320207305237913\n",
      "episode :  21\n",
      "current step :  146\n",
      "reward :  -0.4987344134747003\n",
      "episode :  21\n",
      "current step :  147\n",
      "reward :  -0.5154288032557532\n",
      "episode :  21\n",
      "current step :  148\n",
      "reward :  -0.5525181018820567\n",
      "episode :  21\n",
      "current step :  149\n",
      "reward :  -0.5388840593925321\n",
      "episode :  21\n",
      "current step :  150\n",
      "reward :  -0.5473226605594077\n",
      "episode :  21\n",
      "current step :  151\n",
      "reward :  -0.5320407393591229\n",
      "episode :  21\n",
      "current step :  152\n",
      "reward :  -0.5269446973275586\n",
      "episode :  21\n",
      "current step :  153\n",
      "reward :  -0.5099668198713064\n",
      "episode :  21\n",
      "current step :  154\n",
      "reward :  -0.5506556196892997\n",
      "episode :  21\n",
      "current step :  155\n",
      "reward :  -0.5638222485399507\n",
      "episode :  21\n",
      "current step :  156\n",
      "reward :  -0.5630274556812118\n",
      "episode :  21\n",
      "current step :  157\n",
      "reward :  -0.5515517686420641\n",
      "episode :  21\n",
      "current step :  158\n",
      "reward :  -0.5558296524694316\n",
      "episode :  21\n",
      "current step :  159\n",
      "reward :  -0.5580546054957195\n",
      "episode :  21\n",
      "current step :  160\n",
      "reward :  -0.5580307623804414\n",
      "episode :  21\n",
      "current step :  161\n",
      "reward :  -0.5922275558130694\n",
      "episode :  21\n",
      "current step :  162\n",
      "reward :  -0.6182174600764914\n",
      "episode :  21\n",
      "current step :  163\n",
      "reward :  -0.6137589470446664\n",
      "episode :  21\n",
      "current step :  164\n",
      "reward :  -0.6250908177626272\n",
      "episode :  21\n",
      "current step :  165\n",
      "reward :  -0.6103366798525561\n",
      "episode :  21\n",
      "current step :  166\n",
      "reward :  -0.6362611584274515\n",
      "episode :  21\n",
      "current step :  167\n",
      "reward :  -0.6266845221702506\n",
      "episode :  21\n",
      "current step :  168\n",
      "reward :  -0.6357441735368361\n",
      "episode :  21\n",
      "current step :  169\n",
      "reward :  -0.6543608011986963\n",
      "episode :  21\n",
      "current step :  170\n",
      "reward :  -0.6737532540135699\n",
      "episode :  21\n",
      "current step :  171\n",
      "reward :  -0.6617748937963093\n",
      "episode :  21\n",
      "current step :  172\n",
      "reward :  -0.6378595186399368\n",
      "episode :  21\n",
      "current step :  173\n",
      "reward :  -0.6516784983216782\n",
      "episode :  21\n",
      "current step :  174\n",
      "reward :  -0.655764120210419\n",
      "episode :  21\n",
      "current step :  175\n",
      "reward :  -0.6557623760960157\n",
      "episode :  21\n",
      "current step :  176\n",
      "reward :  -0.6546391570715878\n",
      "episode :  21\n",
      "current step :  177\n",
      "reward :  -0.6510619097684377\n",
      "episode :  21\n",
      "current step :  178\n",
      "reward :  -0.7028986677970372\n",
      "episode :  21\n",
      "current step :  179\n",
      "reward :  -0.7126620714574671\n",
      "episode :  21\n",
      "current step :  180\n",
      "reward :  -0.7193414597983011\n",
      "episode :  21\n",
      "current step :  181\n",
      "reward :  -0.6832658672893921\n",
      "episode :  21\n",
      "current step :  182\n",
      "reward :  -0.7078287435133593\n",
      "episode :  21\n",
      "current step :  183\n",
      "reward :  -0.6934391312960357\n",
      "episode :  21\n",
      "current step :  184\n",
      "reward :  -0.6886565635650145\n",
      "episode :  21\n",
      "current step :  185\n",
      "reward :  -0.6704954564084822\n",
      "episode :  21\n",
      "current step :  186\n",
      "reward :  -0.7133957462169718\n",
      "episode :  21\n",
      "current step :  187\n",
      "reward :  -0.6856424379100273\n",
      "episode :  21\n",
      "current step :  188\n",
      "reward :  -0.7361030128281629\n",
      "episode :  21\n",
      "current step :  189\n",
      "reward :  -0.7552528836865954\n",
      "episode :  21\n",
      "current step :  190\n",
      "reward :  -0.7369815878107391\n",
      "episode :  21\n",
      "current step :  191\n",
      "reward :  -0.7397760894571223\n",
      "episode :  21\n",
      "current step :  192\n",
      "reward :  -0.6734470053868861\n",
      "episode :  21\n",
      "current step :  193\n",
      "reward :  -0.7297630200350868\n",
      "episode :  21\n",
      "current step :  194\n",
      "reward :  -0.7483283946253881\n",
      "episode :  21\n",
      "current step :  195\n",
      "reward :  -0.7558332537280833\n",
      "episode :  21\n",
      "current step :  196\n",
      "reward :  -0.7387830507765486\n",
      "episode :  21\n",
      "current step :  197\n",
      "reward :  -0.6647156022942798\n",
      "episode :  21\n",
      "current step :  198\n",
      "reward :  -0.7269053774774947\n",
      "episode :  21\n",
      "current step :  199\n",
      "reward :  -0.7369059023890762\n",
      "episode :  21\n",
      "current step :  200\n",
      "reward :  -0.7420860322008086\n",
      "episode :  21\n",
      "current step :  201\n",
      "reward :  -0.7408445051305084\n",
      "episode :  21\n",
      "current step :  202\n",
      "reward :  -0.7326456173307168\n",
      "episode :  21\n",
      "current step :  203\n",
      "reward :  -0.6776444491251\n",
      "episode :  21\n",
      "current step :  204\n",
      "reward :  -0.7220435909525741\n",
      "episode :  21\n",
      "current step :  205\n",
      "reward :  -0.6702804085785891\n",
      "episode :  21\n",
      "current step :  206\n",
      "reward :  -0.6602074387902036\n",
      "episode :  21\n",
      "current step :  207\n",
      "reward :  -0.6452308301848972\n",
      "episode :  21\n",
      "current step :  208\n",
      "reward :  -0.6598451026575586\n",
      "episode :  21\n",
      "current step :  209\n",
      "reward :  -0.65335010552654\n",
      "episode :  21\n",
      "current step :  210\n",
      "reward :  -0.6827804474978132\n",
      "episode :  21\n",
      "current step :  211\n",
      "reward :  -0.6796552524324639\n",
      "episode :  21\n",
      "current step :  212\n",
      "reward :  -0.7023248815623018\n",
      "episode :  21\n",
      "current step :  213\n",
      "reward :  -0.661274993060238\n",
      "episode :  21\n",
      "current step :  214\n",
      "reward :  -0.6814208255409292\n",
      "episode :  21\n",
      "current step :  215\n",
      "reward :  -0.6905006603222531\n",
      "episode :  21\n",
      "current step :  216\n",
      "reward :  -0.7179542526135622\n",
      "episode :  21\n",
      "current step :  217\n",
      "reward :  -0.7265611239204515\n",
      "episode :  21\n",
      "current step :  218\n",
      "reward :  -0.7416652106587701\n",
      "episode :  21\n",
      "current step :  219\n",
      "reward :  -0.7110388113990426\n",
      "episode :  21\n",
      "current step :  220\n",
      "reward :  -0.694282138004612\n",
      "episode :  21\n",
      "current step :  221\n",
      "reward :  -0.609757657992501\n",
      "episode :  21\n",
      "current step :  222\n",
      "reward :  -0.6349547898985906\n",
      "episode :  21\n",
      "current step :  223\n",
      "reward :  -0.6826737069152294\n",
      "episode :  21\n",
      "current step :  224\n",
      "reward :  -0.6944916976681634\n",
      "episode :  21\n",
      "current step :  225\n",
      "reward :  -0.6744116703663596\n",
      "episode :  21\n",
      "current step :  226\n",
      "reward :  -0.6738723208501112\n",
      "episode :  21\n",
      "current step :  227\n",
      "reward :  -0.6047412165646511\n",
      "episode :  21\n",
      "current step :  228\n",
      "reward :  -0.6128881834874186\n",
      "episode :  21\n",
      "current step :  229\n",
      "reward :  -0.6358637570057962\n",
      "episode :  21\n",
      "current step :  230\n",
      "reward :  -0.6542517390198909\n",
      "episode :  21\n",
      "current step :  231\n",
      "reward :  -0.6734659140865038\n",
      "episode :  21\n",
      "current step :  232\n",
      "reward :  -0.6680458968200403\n",
      "episode :  21\n",
      "current step :  233\n",
      "reward :  -0.6033195403766761\n",
      "episode :  21\n",
      "current step :  234\n",
      "reward :  -0.6361177099406083\n",
      "episode :  21\n",
      "current step :  235\n",
      "reward :  -0.647039532538099\n",
      "episode :  21\n",
      "current step :  236\n",
      "reward :  -0.6377255645836666\n",
      "episode :  21\n",
      "current step :  237\n",
      "reward :  -0.5767297336154538\n",
      "episode :  21\n",
      "current step :  238\n",
      "reward :  -0.5554387501472564\n",
      "episode :  21\n",
      "current step :  239\n",
      "reward :  -0.5274846069506269\n",
      "episode :  21\n",
      "current step :  240\n",
      "reward :  -0.5484867727150841\n",
      "episode :  21\n",
      "current step :  241\n",
      "reward :  -0.5584607921990536\n",
      "episode :  21\n",
      "current step :  242\n",
      "reward :  -0.5123462558046491\n",
      "episode :  21\n",
      "current step :  243\n",
      "reward :  -0.5152769517307461\n",
      "episode :  21\n",
      "current step :  244\n",
      "reward :  -0.521547892503845\n",
      "episode :  21\n",
      "current step :  245\n",
      "reward :  -0.5007102059715071\n",
      "episode :  21\n",
      "current step :  246\n",
      "reward :  -0.5384319413611179\n",
      "episode :  21\n",
      "current step :  247\n",
      "reward :  -0.493301095711349\n",
      "episode :  21\n",
      "current step :  248\n",
      "reward :  -0.4908814096561616\n",
      "episode :  21\n",
      "current step :  249\n",
      "reward :  -0.5381011607693058\n",
      "episode :  21\n",
      "current step :  250\n",
      "reward :  -0.5823354472919712\n",
      "episode :  21\n",
      "current step :  251\n",
      "reward :  -0.5815754657201464\n",
      "episode :  21\n",
      "current step :  252\n",
      "reward :  -0.5169715548210746\n",
      "episode :  21\n",
      "current step :  253\n",
      "reward :  -0.50651647852482\n",
      "episode :  21\n",
      "current step :  254\n",
      "reward :  -0.4891463478667551\n",
      "episode :  21\n",
      "current step :  255\n",
      "reward :  -0.5420099750978734\n",
      "episode :  21\n",
      "current step :  256\n",
      "reward :  -0.49892519583953565\n",
      "episode :  21\n",
      "current step :  257\n",
      "reward :  -0.40364590225120944\n",
      "episode :  21\n",
      "current step :  258\n",
      "reward :  -0.48617604499733313\n",
      "episode :  21\n",
      "current step :  259\n",
      "reward :  -0.6107351616407898\n",
      "episode :  21\n",
      "current step :  260\n",
      "reward :  -0.5441808195372727\n",
      "episode :  21\n",
      "current step :  261\n",
      "reward :  -0.48957976008738585\n",
      "episode :  21\n",
      "current step :  262\n",
      "reward :  -0.5117850945074663\n",
      "episode :  21\n",
      "current step :  263\n",
      "reward :  -0.5454441458806065\n",
      "episode :  21\n",
      "current step :  264\n",
      "reward :  -0.5667792725931293\n",
      "episode :  21\n",
      "current step :  265\n",
      "reward :  -0.5230403063811263\n",
      "episode :  21\n",
      "current step :  266\n",
      "reward :  -0.5299546390937441\n",
      "episode :  21\n",
      "current step :  267\n",
      "reward :  -0.5695841720997254\n",
      "episode :  21\n",
      "current step :  268\n",
      "reward :  -0.4955897259026074\n",
      "episode :  21\n",
      "current step :  269\n",
      "reward :  -0.469983243068214\n",
      "episode :  21\n",
      "current step :  270\n",
      "reward :  -0.49698936306062375\n",
      "episode :  21\n",
      "current step :  271\n",
      "reward :  -0.5194345856514074\n",
      "episode :  21\n",
      "current step :  272\n",
      "reward :  -0.5035078292498751\n",
      "episode :  21\n",
      "current step :  273\n",
      "reward :  -0.5113424339052921\n",
      "episode :  21\n",
      "current step :  274\n",
      "reward :  -0.4953505278443089\n",
      "episode :  21\n",
      "current step :  275\n",
      "reward :  -0.5006834515978905\n",
      "episode :  21\n",
      "current step :  276\n",
      "reward :  -0.5106326172752956\n",
      "episode :  21\n",
      "current step :  277\n",
      "reward :  -0.5251654730248154\n",
      "episode :  21\n",
      "current step :  278\n",
      "reward :  -0.5250636748156031\n",
      "episode :  21\n",
      "current step :  279\n",
      "reward :  -0.5416610099181942\n",
      "episode :  21\n",
      "current step :  280\n",
      "reward :  -0.5550174023660492\n",
      "episode :  21\n",
      "current step :  281\n",
      "reward :  -0.5152918984983714\n",
      "episode :  21\n",
      "current step :  282\n",
      "reward :  -0.5119044039960855\n",
      "episode :  21\n",
      "current step :  283\n",
      "reward :  -0.5146028501196483\n",
      "episode :  21\n",
      "current step :  284\n",
      "reward :  -0.5105797290366144\n",
      "episode :  21\n",
      "current step :  285\n",
      "reward :  -0.5079956966144064\n",
      "episode :  22\n",
      "current step :  0\n",
      "reward :  -0.35328509722206675\n",
      "episode :  22\n",
      "current step :  1\n",
      "reward :  -0.34778477276778585\n",
      "episode :  22\n",
      "current step :  2\n",
      "reward :  -0.474628226480964\n",
      "episode :  22\n",
      "current step :  3\n",
      "reward :  -0.47560399396345976\n",
      "episode :  22\n",
      "current step :  4\n",
      "reward :  -0.5047284975556782\n",
      "episode :  22\n",
      "current step :  5\n",
      "reward :  -0.542726826512767\n",
      "episode :  22\n",
      "current step :  6\n",
      "reward :  -0.5443991477602554\n",
      "episode :  22\n",
      "current step :  7\n",
      "reward :  -0.5737226719777854\n",
      "episode :  22\n",
      "current step :  8\n",
      "reward :  -0.5743225202778227\n",
      "episode :  22\n",
      "current step :  9\n",
      "reward :  -0.5259190246706703\n",
      "episode :  22\n",
      "current step :  10\n",
      "reward :  -0.524011697196731\n",
      "episode :  22\n",
      "current step :  11\n",
      "reward :  -0.5337697375212155\n",
      "episode :  22\n",
      "current step :  12\n",
      "reward :  -0.5478157579981268\n",
      "episode :  22\n",
      "current step :  13\n",
      "reward :  -0.5122682742257431\n",
      "episode :  22\n",
      "current step :  14\n",
      "reward :  -0.5476034017947193\n",
      "episode :  22\n",
      "current step :  15\n",
      "reward :  -0.5302674353595834\n",
      "episode :  22\n",
      "current step :  16\n",
      "reward :  -0.4572847339572774\n",
      "episode :  22\n",
      "current step :  17\n",
      "reward :  -0.4577735617855449\n",
      "episode :  22\n",
      "current step :  18\n",
      "reward :  -0.541658595567567\n",
      "episode :  22\n",
      "current step :  19\n",
      "reward :  -0.5262005863238711\n",
      "episode :  22\n",
      "current step :  20\n",
      "reward :  -0.5130952888698274\n",
      "episode :  22\n",
      "current step :  21\n",
      "reward :  -0.5062433622928941\n",
      "episode :  22\n",
      "current step :  22\n",
      "reward :  -0.50372074385438\n",
      "episode :  22\n",
      "current step :  23\n",
      "reward :  -0.5030383566978741\n",
      "episode :  22\n",
      "current step :  24\n",
      "reward :  -0.5366291853143094\n",
      "episode :  22\n",
      "current step :  25\n",
      "reward :  -0.5166882884235313\n",
      "episode :  22\n",
      "current step :  26\n",
      "reward :  -0.5111534783163081\n",
      "episode :  22\n",
      "current step :  27\n",
      "reward :  -0.5021109465055056\n",
      "episode :  22\n",
      "current step :  28\n",
      "reward :  -0.5047254049168328\n",
      "episode :  22\n",
      "current step :  29\n",
      "reward :  -0.5080774632895861\n",
      "episode :  22\n",
      "current step :  30\n",
      "reward :  -0.5200722945933278\n",
      "episode :  22\n",
      "current step :  31\n",
      "reward :  -0.5247177032006609\n",
      "episode :  22\n",
      "current step :  32\n",
      "reward :  -0.5994267105710489\n",
      "episode :  22\n",
      "current step :  33\n",
      "reward :  -0.6161272826497849\n",
      "episode :  22\n",
      "current step :  34\n",
      "reward :  -0.6230974557543695\n",
      "episode :  22\n",
      "current step :  35\n",
      "reward :  -0.6559049884579928\n",
      "episode :  22\n",
      "current step :  36\n",
      "reward :  -0.618652695962229\n",
      "episode :  22\n",
      "current step :  37\n",
      "reward :  -0.6454468483335188\n",
      "episode :  22\n",
      "current step :  38\n",
      "reward :  -0.6227271900503953\n",
      "episode :  22\n",
      "current step :  39\n",
      "reward :  -0.622871313616305\n",
      "episode :  22\n",
      "current step :  40\n",
      "reward :  -0.6245335679446685\n",
      "episode :  22\n",
      "current step :  41\n",
      "reward :  -0.6657053499412598\n",
      "episode :  22\n",
      "current step :  42\n",
      "reward :  -0.6582551306232515\n",
      "episode :  22\n",
      "current step :  43\n",
      "reward :  -0.6140915938928918\n",
      "episode :  22\n",
      "current step :  44\n",
      "reward :  -0.6296094427063584\n",
      "episode :  22\n",
      "current step :  45\n",
      "reward :  -0.5628962257664243\n",
      "episode :  22\n",
      "current step :  46\n",
      "reward :  -0.5903848695080954\n",
      "episode :  22\n",
      "current step :  47\n",
      "reward :  -0.6007599654979118\n",
      "episode :  22\n",
      "current step :  48\n",
      "reward :  -0.6587053787094167\n",
      "episode :  22\n",
      "current step :  49\n",
      "reward :  -0.7065796633023286\n",
      "episode :  22\n",
      "current step :  50\n",
      "reward :  -0.6981677106886877\n",
      "episode :  22\n",
      "current step :  51\n",
      "reward :  -0.7151852111467724\n",
      "episode :  22\n",
      "current step :  52\n",
      "reward :  -0.6761890364423824\n",
      "episode :  22\n",
      "current step :  53\n",
      "reward :  -0.673720725576013\n",
      "episode :  22\n",
      "current step :  54\n",
      "reward :  -0.7296535801868326\n",
      "episode :  22\n",
      "current step :  55\n",
      "reward :  -0.6926723114699179\n",
      "episode :  22\n",
      "current step :  56\n",
      "reward :  -0.7111519632579535\n",
      "episode :  22\n",
      "current step :  57\n",
      "reward :  -0.7116045650691507\n",
      "episode :  22\n",
      "current step :  58\n",
      "reward :  -0.7045235771191563\n",
      "episode :  22\n",
      "current step :  59\n",
      "reward :  -0.7276971329752455\n",
      "episode :  22\n",
      "current step :  60\n",
      "reward :  -0.7322589146651115\n",
      "episode :  22\n",
      "current step :  61\n",
      "reward :  -0.7329596639590096\n",
      "episode :  22\n",
      "current step :  62\n",
      "reward :  -0.7335352994519858\n",
      "episode :  22\n",
      "current step :  63\n",
      "reward :  -0.7267751307552341\n",
      "episode :  22\n",
      "current step :  64\n",
      "reward :  -0.7251060919910796\n",
      "episode :  22\n",
      "current step :  65\n",
      "reward :  -0.7167275339125829\n",
      "episode :  22\n",
      "current step :  66\n",
      "reward :  -0.7116599838424499\n",
      "episode :  22\n",
      "current step :  67\n",
      "reward :  -0.720359396929963\n",
      "episode :  22\n",
      "current step :  68\n",
      "reward :  -0.7158859408927443\n",
      "episode :  22\n",
      "current step :  69\n",
      "reward :  -0.7163716474345916\n",
      "episode :  22\n",
      "current step :  70\n",
      "reward :  -0.7225802868788054\n",
      "episode :  22\n",
      "current step :  71\n",
      "reward :  -0.7206745274577944\n",
      "episode :  22\n",
      "current step :  72\n",
      "reward :  -0.7257417030312425\n",
      "episode :  22\n",
      "current step :  73\n",
      "reward :  -0.7215337134981076\n",
      "episode :  22\n",
      "current step :  74\n",
      "reward :  -0.7207179686988469\n",
      "episode :  22\n",
      "current step :  75\n",
      "reward :  -0.720686570142361\n",
      "episode :  22\n",
      "current step :  76\n",
      "reward :  -0.7205778937606047\n",
      "episode :  22\n",
      "current step :  77\n",
      "reward :  -0.7177170953733081\n",
      "episode :  22\n",
      "current step :  78\n",
      "reward :  -0.7155230124913802\n",
      "episode :  22\n",
      "current step :  79\n",
      "reward :  -0.7027221684973095\n",
      "episode :  22\n",
      "current step :  80\n",
      "reward :  -0.710536696001092\n",
      "episode :  22\n",
      "current step :  81\n",
      "reward :  -0.6998470993541549\n",
      "episode :  22\n",
      "current step :  82\n",
      "reward :  -0.6871081359988951\n",
      "episode :  22\n",
      "current step :  83\n",
      "reward :  -0.6866370389061345\n",
      "episode :  22\n",
      "current step :  84\n",
      "reward :  -0.6712375998977307\n",
      "episode :  22\n",
      "current step :  85\n",
      "reward :  -0.6615121050957699\n",
      "episode :  22\n",
      "current step :  86\n",
      "reward :  -0.6569313889916856\n",
      "episode :  22\n",
      "current step :  87\n",
      "reward :  -0.6405565978046484\n",
      "episode :  22\n",
      "current step :  88\n",
      "reward :  -0.6303206684919723\n",
      "episode :  22\n",
      "current step :  89\n",
      "reward :  -0.6247291098700161\n",
      "episode :  22\n",
      "current step :  90\n",
      "reward :  -0.6140686345412484\n",
      "episode :  22\n",
      "current step :  91\n",
      "reward :  -0.6063062164172375\n",
      "episode :  22\n",
      "current step :  92\n",
      "reward :  -0.5954319955418397\n",
      "episode :  22\n",
      "current step :  93\n",
      "reward :  -0.5867114859968152\n",
      "episode :  22\n",
      "current step :  94\n",
      "reward :  -0.5803122815841272\n",
      "episode :  22\n",
      "current step :  95\n",
      "reward :  -0.5753664419848938\n",
      "episode :  22\n",
      "current step :  96\n",
      "reward :  -0.5747500773001645\n",
      "episode :  22\n",
      "current step :  97\n",
      "reward :  -0.5735211846730026\n",
      "episode :  22\n",
      "current step :  98\n",
      "reward :  -0.5731996893040654\n",
      "episode :  22\n",
      "current step :  99\n",
      "reward :  -0.5745392400917223\n",
      "episode :  22\n",
      "current step :  100\n",
      "reward :  -0.5730419744110795\n",
      "episode :  22\n",
      "current step :  101\n",
      "reward :  -0.5753522444847201\n",
      "episode :  22\n",
      "current step :  102\n",
      "reward :  -0.5760188947010105\n",
      "episode :  22\n",
      "current step :  103\n",
      "reward :  -0.5763184581119428\n",
      "episode :  22\n",
      "current step :  104\n",
      "reward :  -0.5753646049609713\n",
      "episode :  22\n",
      "current step :  105\n",
      "reward :  -0.5774105701759807\n",
      "episode :  22\n",
      "current step :  106\n",
      "reward :  -0.5776596895507703\n",
      "episode :  22\n",
      "current step :  107\n",
      "reward :  -0.5771881724572943\n",
      "episode :  22\n",
      "current step :  108\n",
      "reward :  -0.5767671713502741\n",
      "episode :  22\n",
      "current step :  109\n",
      "reward :  -0.5769370698615053\n",
      "episode :  22\n",
      "current step :  110\n",
      "reward :  -0.5762422436193865\n",
      "episode :  22\n",
      "current step :  111\n",
      "reward :  -0.5752377927426553\n",
      "episode :  22\n",
      "current step :  112\n",
      "reward :  -0.5737200822495586\n",
      "episode :  22\n",
      "current step :  113\n",
      "reward :  -0.5729057147595619\n",
      "episode :  22\n",
      "current step :  114\n",
      "reward :  -0.5727195404845995\n",
      "episode :  22\n",
      "current step :  115\n",
      "reward :  -0.5720610996766391\n",
      "episode :  22\n",
      "current step :  116\n",
      "reward :  -0.5712232134626518\n",
      "episode :  22\n",
      "current step :  117\n",
      "reward :  -0.5712138937941262\n",
      "episode :  22\n",
      "current step :  118\n",
      "reward :  -0.5718597101968542\n",
      "episode :  22\n",
      "current step :  119\n",
      "reward :  -0.5725731306443145\n",
      "episode :  22\n",
      "current step :  120\n",
      "reward :  -0.5734998369678206\n",
      "episode :  22\n",
      "current step :  121\n",
      "reward :  -0.5746456491724871\n",
      "episode :  22\n",
      "current step :  122\n",
      "reward :  -0.5756591254829989\n",
      "episode :  22\n",
      "current step :  123\n",
      "reward :  -0.5756943309673438\n",
      "episode :  22\n",
      "current step :  124\n",
      "reward :  -0.577477356442314\n",
      "episode :  22\n",
      "current step :  125\n",
      "reward :  -0.5788108218099927\n",
      "episode :  22\n",
      "current step :  126\n",
      "reward :  -0.5804539622382495\n",
      "episode :  22\n",
      "current step :  127\n",
      "reward :  -0.5817321217128285\n",
      "episode :  22\n",
      "current step :  128\n",
      "reward :  -0.5827234068923723\n",
      "episode :  22\n",
      "current step :  129\n",
      "reward :  -0.582773237004015\n",
      "episode :  22\n",
      "current step :  130\n",
      "reward :  -0.5820438155604418\n",
      "episode :  22\n",
      "current step :  131\n",
      "reward :  -0.5828951441817437\n",
      "episode :  22\n",
      "current step :  132\n",
      "reward :  -0.5835066687868755\n",
      "episode :  22\n",
      "current step :  133\n",
      "reward :  -0.5822091241562766\n",
      "episode :  22\n",
      "current step :  134\n",
      "reward :  -0.5803302317365366\n",
      "episode :  22\n",
      "current step :  135\n",
      "reward :  -0.5808153604109879\n",
      "episode :  22\n",
      "current step :  136\n",
      "reward :  -0.5804915176412623\n",
      "episode :  22\n",
      "current step :  137\n",
      "reward :  -0.5787677706946063\n",
      "episode :  22\n",
      "current step :  138\n",
      "reward :  -0.575183011187183\n",
      "episode :  22\n",
      "current step :  139\n",
      "reward :  -0.5743384614957915\n",
      "episode :  22\n",
      "current step :  140\n",
      "reward :  -0.572057660125647\n",
      "episode :  22\n",
      "current step :  141\n",
      "reward :  -0.5678350706728698\n",
      "episode :  22\n",
      "current step :  142\n",
      "reward :  -0.566463653712024\n",
      "episode :  22\n",
      "current step :  143\n",
      "reward :  -0.5657703921316921\n",
      "episode :  22\n",
      "current step :  144\n",
      "reward :  -0.5608993298750132\n",
      "episode :  22\n",
      "current step :  145\n",
      "reward :  -0.5587775695983249\n",
      "episode :  22\n",
      "current step :  146\n",
      "reward :  -0.5539460066944041\n",
      "episode :  22\n",
      "current step :  147\n",
      "reward :  -0.5466799927832101\n",
      "episode :  22\n",
      "current step :  148\n",
      "reward :  -0.5429619313490519\n",
      "episode :  22\n",
      "current step :  149\n",
      "reward :  -0.5416602257416663\n",
      "episode :  22\n",
      "current step :  150\n",
      "reward :  -0.5418088388112093\n",
      "episode :  22\n",
      "current step :  151\n",
      "reward :  -0.5411580960273329\n",
      "episode :  22\n",
      "current step :  152\n",
      "reward :  -0.5400597275990106\n",
      "episode :  22\n",
      "current step :  153\n",
      "reward :  -0.5468051465288988\n",
      "episode :  22\n",
      "current step :  154\n",
      "reward :  -0.5375251176766007\n",
      "episode :  22\n",
      "current step :  155\n",
      "reward :  -0.5358565364399234\n",
      "episode :  22\n",
      "current step :  156\n",
      "reward :  -0.5335504639160134\n",
      "episode :  22\n",
      "current step :  157\n",
      "reward :  -0.532516866088708\n",
      "episode :  22\n",
      "current step :  158\n",
      "reward :  -0.5310683549925531\n",
      "episode :  22\n",
      "current step :  159\n",
      "reward :  -0.5307048035243657\n",
      "episode :  22\n",
      "current step :  160\n",
      "reward :  -0.5287822935979352\n",
      "episode :  22\n",
      "current step :  161\n",
      "reward :  -0.5394270261428145\n",
      "episode :  22\n",
      "current step :  162\n",
      "reward :  -0.5437955307025804\n",
      "episode :  22\n",
      "current step :  163\n",
      "reward :  -0.5497270534384818\n",
      "episode :  22\n",
      "current step :  164\n",
      "reward :  -0.5460968152336999\n",
      "episode :  22\n",
      "current step :  165\n",
      "reward :  -0.5385736847676557\n",
      "episode :  22\n",
      "current step :  166\n",
      "reward :  -0.5285209298841328\n",
      "episode :  22\n",
      "current step :  167\n",
      "reward :  -0.5331513268401643\n",
      "episode :  22\n",
      "current step :  168\n",
      "reward :  -0.5288420652172264\n",
      "episode :  22\n",
      "current step :  169\n",
      "reward :  -0.5267744446857671\n",
      "episode :  22\n",
      "current step :  170\n",
      "reward :  -0.5393987366714573\n",
      "episode :  22\n",
      "current step :  171\n",
      "reward :  -0.5322316431181042\n",
      "episode :  22\n",
      "current step :  172\n",
      "reward :  -0.5341799202427233\n",
      "episode :  22\n",
      "current step :  173\n",
      "reward :  -0.534750035718112\n",
      "episode :  22\n",
      "current step :  174\n",
      "reward :  -0.5329450115708292\n",
      "episode :  22\n",
      "current step :  175\n",
      "reward :  -0.5332941066312483\n",
      "episode :  22\n",
      "current step :  176\n",
      "reward :  -0.5319875330354874\n",
      "episode :  22\n",
      "current step :  177\n",
      "reward :  -0.529202681338603\n",
      "episode :  22\n",
      "current step :  178\n",
      "reward :  -0.5304034228370104\n",
      "episode :  22\n",
      "current step :  179\n",
      "reward :  -0.5340857148948956\n",
      "episode :  22\n",
      "current step :  180\n",
      "reward :  -0.5461810736326933\n",
      "episode :  22\n",
      "current step :  181\n",
      "reward :  -0.550580840135968\n",
      "episode :  22\n",
      "current step :  182\n",
      "reward :  -0.5380482554618701\n",
      "episode :  22\n",
      "current step :  183\n",
      "reward :  -0.5473479371662588\n",
      "episode :  22\n",
      "current step :  184\n",
      "reward :  -0.5392765115745537\n",
      "episode :  22\n",
      "current step :  185\n",
      "reward :  -0.5501524832954998\n",
      "episode :  22\n",
      "current step :  186\n",
      "reward :  -0.5513756011513178\n",
      "episode :  22\n",
      "current step :  187\n",
      "reward :  -0.5428686075419863\n",
      "episode :  22\n",
      "current step :  188\n",
      "reward :  -0.5576930213711098\n",
      "episode :  22\n",
      "current step :  189\n",
      "reward :  -0.5564045218686446\n",
      "episode :  22\n",
      "current step :  190\n",
      "reward :  -0.5471818304195579\n",
      "episode :  22\n",
      "current step :  191\n",
      "reward :  -0.5515307124731536\n",
      "episode :  22\n",
      "current step :  192\n",
      "reward :  -0.551298364196423\n",
      "episode :  22\n",
      "current step :  193\n",
      "reward :  -0.5523374824252846\n",
      "episode :  22\n",
      "current step :  194\n",
      "reward :  -0.5547657095169531\n",
      "episode :  22\n",
      "current step :  195\n",
      "reward :  -0.5538003080828555\n",
      "episode :  22\n",
      "current step :  196\n",
      "reward :  -0.5394387701358677\n",
      "episode :  22\n",
      "current step :  197\n",
      "reward :  -0.5452834417153298\n",
      "episode :  22\n",
      "current step :  198\n",
      "reward :  -0.5529319720438065\n",
      "episode :  22\n",
      "current step :  199\n",
      "reward :  -0.5546531825982757\n",
      "episode :  22\n",
      "current step :  200\n",
      "reward :  -0.5545065588440418\n",
      "episode :  22\n",
      "current step :  201\n",
      "reward :  -0.5522847180492901\n",
      "episode :  22\n",
      "current step :  202\n",
      "reward :  -0.5517334417060337\n",
      "episode :  22\n",
      "current step :  203\n",
      "reward :  -0.552890212771467\n",
      "episode :  22\n",
      "current step :  204\n",
      "reward :  -0.5559720426999795\n",
      "episode :  22\n",
      "current step :  205\n",
      "reward :  -0.5402290899750526\n",
      "episode :  22\n",
      "current step :  206\n",
      "reward :  -0.5524397780160732\n",
      "episode :  22\n",
      "current step :  207\n",
      "reward :  -0.5540108442097164\n",
      "episode :  22\n",
      "current step :  208\n",
      "reward :  -0.5550402248188285\n",
      "episode :  22\n",
      "current step :  209\n",
      "reward :  -0.5519720968286858\n",
      "episode :  22\n",
      "current step :  210\n",
      "reward :  -0.5573135885782351\n",
      "episode :  22\n",
      "current step :  211\n",
      "reward :  -0.5484435413068622\n",
      "episode :  22\n",
      "current step :  212\n",
      "reward :  -0.5391168756538524\n",
      "episode :  22\n",
      "current step :  213\n",
      "reward :  -0.5509732314301218\n",
      "episode :  22\n",
      "current step :  214\n",
      "reward :  -0.551223000681656\n",
      "episode :  22\n",
      "current step :  215\n",
      "reward :  -0.548585687690075\n",
      "episode :  22\n",
      "current step :  216\n",
      "reward :  -0.5455147265705872\n",
      "episode :  22\n",
      "current step :  217\n",
      "reward :  -0.54450168977634\n",
      "episode :  22\n",
      "current step :  218\n",
      "reward :  -0.5390063084058014\n",
      "episode :  22\n",
      "current step :  219\n",
      "reward :  -0.5366042722107699\n",
      "episode :  22\n",
      "current step :  220\n",
      "reward :  -0.5205066688731812\n",
      "episode :  22\n",
      "current step :  221\n",
      "reward :  -0.5137278107125832\n",
      "episode :  22\n",
      "current step :  222\n",
      "reward :  -0.5234661599878017\n",
      "episode :  22\n",
      "current step :  223\n",
      "reward :  -0.5259058349741484\n",
      "episode :  22\n",
      "current step :  224\n",
      "reward :  -0.5239365865374705\n",
      "episode :  22\n",
      "current step :  225\n",
      "reward :  -0.5132318337065318\n",
      "episode :  22\n",
      "current step :  226\n",
      "reward :  -0.5201257548896728\n",
      "episode :  22\n",
      "current step :  227\n",
      "reward :  -0.5215164279210038\n",
      "episode :  22\n",
      "current step :  228\n",
      "reward :  -0.5223183497171812\n",
      "episode :  22\n",
      "current step :  229\n",
      "reward :  -0.5190523390109805\n",
      "episode :  22\n",
      "current step :  230\n",
      "reward :  -0.524568702675254\n",
      "episode :  22\n",
      "current step :  231\n",
      "reward :  -0.519196217564315\n",
      "episode :  22\n",
      "current step :  232\n",
      "reward :  -0.5188882988800445\n",
      "episode :  22\n",
      "current step :  233\n",
      "reward :  -0.5095775099735009\n",
      "episode :  22\n",
      "current step :  234\n",
      "reward :  -0.5181953556912761\n",
      "episode :  22\n",
      "current step :  235\n",
      "reward :  -0.5113426893255987\n",
      "episode :  22\n",
      "current step :  236\n",
      "reward :  -0.526612584700075\n",
      "episode :  22\n",
      "current step :  237\n",
      "reward :  -0.527132128661005\n",
      "episode :  22\n",
      "current step :  238\n",
      "reward :  -0.5290714208575623\n",
      "episode :  22\n",
      "current step :  239\n",
      "reward :  -0.5340281417437948\n",
      "episode :  22\n",
      "current step :  240\n",
      "reward :  -0.5305466617223749\n",
      "episode :  22\n",
      "current step :  241\n",
      "reward :  -0.5412940374719883\n",
      "episode :  22\n",
      "current step :  242\n",
      "reward :  -0.5416694532744646\n",
      "episode :  22\n",
      "current step :  243\n",
      "reward :  -0.5459140679054274\n",
      "episode :  22\n",
      "current step :  244\n",
      "reward :  -0.555288997740769\n",
      "episode :  22\n",
      "current step :  245\n",
      "reward :  -0.5602546158889913\n",
      "episode :  22\n",
      "current step :  246\n",
      "reward :  -0.5666245499467485\n",
      "episode :  22\n",
      "current step :  247\n",
      "reward :  -0.5709805275966957\n",
      "episode :  22\n",
      "current step :  248\n",
      "reward :  -0.5761067102412804\n",
      "episode :  22\n",
      "current step :  249\n",
      "reward :  -0.5775231072450708\n",
      "episode :  22\n",
      "current step :  250\n",
      "reward :  -0.5838839403296134\n",
      "episode :  22\n",
      "current step :  251\n",
      "reward :  -0.5849382901265175\n",
      "episode :  22\n",
      "current step :  252\n",
      "reward :  -0.5864218238797456\n",
      "episode :  22\n",
      "current step :  253\n",
      "reward :  -0.5839853936866032\n",
      "episode :  22\n",
      "current step :  254\n",
      "reward :  -0.5835616370728879\n",
      "episode :  22\n",
      "current step :  255\n",
      "reward :  -0.5876116128392903\n",
      "episode :  22\n",
      "current step :  256\n",
      "reward :  -0.5893288383960462\n",
      "episode :  22\n",
      "current step :  257\n",
      "reward :  -0.5894274596882845\n",
      "episode :  22\n",
      "current step :  258\n",
      "reward :  -0.5906321595874795\n",
      "episode :  22\n",
      "current step :  259\n",
      "reward :  -0.5892448358711185\n",
      "episode :  22\n",
      "current step :  260\n",
      "reward :  -0.5932849075690613\n",
      "episode :  22\n",
      "current step :  261\n",
      "reward :  -0.5920656543059245\n",
      "episode :  22\n",
      "current step :  262\n",
      "reward :  -0.5940353768580335\n",
      "episode :  22\n",
      "current step :  263\n",
      "reward :  -0.5937280078992683\n",
      "episode :  22\n",
      "current step :  264\n",
      "reward :  -0.5986664786312798\n",
      "episode :  22\n",
      "current step :  265\n",
      "reward :  -0.593384484691863\n",
      "episode :  22\n",
      "current step :  266\n",
      "reward :  -0.591886860992382\n",
      "episode :  22\n",
      "current step :  267\n",
      "reward :  -0.5868032330167923\n",
      "episode :  22\n",
      "current step :  268\n",
      "reward :  -0.5954995831161236\n",
      "episode :  22\n",
      "current step :  269\n",
      "reward :  -0.5886149973362563\n",
      "episode :  22\n",
      "current step :  270\n",
      "reward :  -0.5915773089834518\n",
      "episode :  22\n",
      "current step :  271\n",
      "reward :  -0.5852758135055025\n",
      "episode :  22\n",
      "current step :  272\n",
      "reward :  -0.5856955202838016\n",
      "episode :  22\n",
      "current step :  273\n",
      "reward :  -0.586521308090898\n",
      "episode :  22\n",
      "current step :  274\n",
      "reward :  -0.5829978343953611\n",
      "episode :  22\n",
      "current step :  275\n",
      "reward :  -0.5835628086982174\n",
      "episode :  22\n",
      "current step :  276\n",
      "reward :  -0.5810702744967898\n",
      "episode :  22\n",
      "current step :  277\n",
      "reward :  -0.5808064820557277\n",
      "episode :  22\n",
      "current step :  278\n",
      "reward :  -0.5831666472028065\n",
      "episode :  22\n",
      "current step :  279\n",
      "reward :  -0.5808006308500281\n",
      "episode :  22\n",
      "current step :  280\n",
      "reward :  -0.5847373201643324\n",
      "episode :  22\n",
      "current step :  281\n",
      "reward :  -0.5852198110980705\n",
      "episode :  22\n",
      "current step :  282\n",
      "reward :  -0.5824138233072659\n",
      "episode :  22\n",
      "current step :  283\n",
      "reward :  -0.5863762675840613\n",
      "episode :  22\n",
      "current step :  284\n",
      "reward :  -0.5875530564045596\n",
      "episode :  22\n",
      "current step :  285\n",
      "reward :  -0.5878325563840693\n",
      "episode :  23\n",
      "current step :  0\n",
      "reward :  -0.5997204268649047\n",
      "episode :  23\n",
      "current step :  1\n",
      "reward :  -0.5993736832611295\n",
      "episode :  23\n",
      "current step :  2\n",
      "reward :  -0.5990506005282271\n",
      "episode :  23\n",
      "current step :  3\n",
      "reward :  -0.6040123665093445\n",
      "episode :  23\n",
      "current step :  4\n",
      "reward :  -0.601877043569596\n",
      "episode :  23\n",
      "current step :  5\n",
      "reward :  -0.592198474471887\n",
      "episode :  23\n",
      "current step :  6\n",
      "reward :  -0.5986377048272884\n",
      "episode :  23\n",
      "current step :  7\n",
      "reward :  -0.6006054627590943\n",
      "episode :  23\n",
      "current step :  8\n",
      "reward :  -0.5951921997364343\n",
      "episode :  23\n",
      "current step :  9\n",
      "reward :  -0.5929949104852438\n",
      "episode :  23\n",
      "current step :  10\n",
      "reward :  -0.5989418374715779\n",
      "episode :  23\n",
      "current step :  11\n",
      "reward :  -0.5880764170837689\n",
      "episode :  23\n",
      "current step :  12\n",
      "reward :  -0.5982175062128591\n",
      "episode :  23\n",
      "current step :  13\n",
      "reward :  -0.5915658308018032\n",
      "episode :  23\n",
      "current step :  14\n",
      "reward :  -0.598115840404479\n",
      "episode :  23\n",
      "current step :  15\n",
      "reward :  -0.598976453346916\n",
      "episode :  23\n",
      "current step :  16\n",
      "reward :  -0.5969606590931275\n",
      "episode :  23\n",
      "current step :  17\n",
      "reward :  -0.5944959771557675\n",
      "episode :  23\n",
      "current step :  18\n",
      "reward :  -0.5932196382869647\n",
      "episode :  23\n",
      "current step :  19\n",
      "reward :  -0.5933386991352652\n",
      "episode :  23\n",
      "current step :  20\n",
      "reward :  -0.5916719147271257\n",
      "episode :  23\n",
      "current step :  21\n",
      "reward :  -0.5983215784417338\n",
      "episode :  23\n",
      "current step :  22\n",
      "reward :  -0.5984016809758692\n",
      "episode :  23\n",
      "current step :  23\n",
      "reward :  -0.5997821531877969\n",
      "episode :  23\n",
      "current step :  24\n",
      "reward :  -0.5904788386274926\n",
      "episode :  23\n",
      "current step :  25\n",
      "reward :  -0.5901900421522382\n",
      "episode :  23\n",
      "current step :  26\n",
      "reward :  -0.6046505980312855\n",
      "episode :  23\n",
      "current step :  27\n",
      "reward :  -0.6048552300168273\n",
      "episode :  23\n",
      "current step :  28\n",
      "reward :  -0.6061513654534456\n",
      "episode :  23\n",
      "current step :  29\n",
      "reward :  -0.6140402557165133\n",
      "episode :  23\n",
      "current step :  30\n",
      "reward :  -0.6148605469258241\n",
      "episode :  23\n",
      "current step :  31\n",
      "reward :  -0.6169510443917848\n",
      "episode :  23\n",
      "current step :  32\n",
      "reward :  -0.6170955738886478\n",
      "episode :  23\n",
      "current step :  33\n",
      "reward :  -0.6196393881017338\n",
      "episode :  23\n",
      "current step :  34\n",
      "reward :  -0.6202943669120847\n",
      "episode :  23\n",
      "current step :  35\n",
      "reward :  -0.6105250581286502\n",
      "episode :  23\n",
      "current step :  36\n",
      "reward :  -0.6235688493374207\n",
      "episode :  23\n",
      "current step :  37\n",
      "reward :  -0.6169451447167977\n",
      "episode :  23\n",
      "current step :  38\n",
      "reward :  -0.6421836881366253\n",
      "episode :  23\n",
      "current step :  39\n",
      "reward :  -0.642142794809754\n",
      "episode :  23\n",
      "current step :  40\n",
      "reward :  -0.6472483138831725\n",
      "episode :  23\n",
      "current step :  41\n",
      "reward :  -0.6445386493546189\n",
      "episode :  23\n",
      "current step :  42\n",
      "reward :  -0.6532411741325916\n",
      "episode :  23\n",
      "current step :  43\n",
      "reward :  -0.6662189578629898\n",
      "episode :  23\n",
      "current step :  44\n",
      "reward :  -0.6669978304068493\n",
      "episode :  23\n",
      "current step :  45\n",
      "reward :  -0.6755638113771419\n",
      "episode :  23\n",
      "current step :  46\n",
      "reward :  -0.6656685862555459\n",
      "episode :  23\n",
      "current step :  47\n",
      "reward :  -0.6300626091486996\n",
      "episode :  23\n",
      "current step :  48\n",
      "reward :  -0.6852301956205172\n",
      "episode :  23\n",
      "current step :  49\n",
      "reward :  -0.708237324505998\n",
      "episode :  23\n",
      "current step :  50\n",
      "reward :  -0.725597432152546\n",
      "episode :  23\n",
      "current step :  51\n",
      "reward :  -0.7299653429242171\n",
      "episode :  23\n",
      "current step :  52\n",
      "reward :  -0.7350391141444976\n",
      "episode :  23\n",
      "current step :  53\n",
      "reward :  -0.7209917624123876\n",
      "episode :  23\n",
      "current step :  54\n",
      "reward :  -0.725607219239891\n",
      "episode :  23\n",
      "current step :  55\n",
      "reward :  -0.732738816375911\n",
      "episode :  23\n",
      "current step :  56\n",
      "reward :  -0.7313862073178393\n",
      "episode :  23\n",
      "current step :  57\n",
      "reward :  -0.7272259366665599\n",
      "episode :  23\n",
      "current step :  58\n",
      "reward :  -0.7403785726046679\n",
      "episode :  23\n",
      "current step :  59\n",
      "reward :  -0.7395846408463509\n",
      "episode :  23\n",
      "current step :  60\n",
      "reward :  -0.7279101046868228\n",
      "episode :  23\n",
      "current step :  61\n",
      "reward :  -0.7290492405320186\n",
      "episode :  23\n",
      "current step :  62\n",
      "reward :  -0.7328293974326244\n",
      "episode :  23\n",
      "current step :  63\n",
      "reward :  -0.7354393127436086\n",
      "episode :  23\n",
      "current step :  64\n",
      "reward :  -0.7331040482417317\n",
      "episode :  23\n",
      "current step :  65\n",
      "reward :  -0.7246595391908205\n",
      "episode :  23\n",
      "current step :  66\n",
      "reward :  -0.7158896333378559\n",
      "episode :  23\n",
      "current step :  67\n",
      "reward :  -0.7311899554070095\n",
      "episode :  23\n",
      "current step :  68\n",
      "reward :  -0.7234063858112112\n",
      "episode :  23\n",
      "current step :  69\n",
      "reward :  -0.7189197173224587\n",
      "episode :  23\n",
      "current step :  70\n",
      "reward :  -0.7266763399480177\n",
      "episode :  23\n",
      "current step :  71\n",
      "reward :  -0.7295374464182643\n",
      "episode :  23\n",
      "current step :  72\n",
      "reward :  -0.7207533886652098\n",
      "episode :  23\n",
      "current step :  73\n",
      "reward :  -0.7157551025774337\n",
      "episode :  23\n",
      "current step :  74\n",
      "reward :  -0.7233086339177088\n",
      "episode :  23\n",
      "current step :  75\n",
      "reward :  -0.7178559776470744\n",
      "episode :  23\n",
      "current step :  76\n",
      "reward :  -0.6948022595844798\n",
      "episode :  23\n",
      "current step :  77\n",
      "reward :  -0.7000009278084806\n",
      "episode :  23\n",
      "current step :  78\n",
      "reward :  -0.6910627902984569\n",
      "episode :  23\n",
      "current step :  79\n",
      "reward :  -0.6973302794004124\n",
      "episode :  23\n",
      "current step :  80\n",
      "reward :  -0.684684751886777\n",
      "episode :  23\n",
      "current step :  81\n",
      "reward :  -0.663218923164907\n",
      "episode :  23\n",
      "current step :  82\n",
      "reward :  -0.5922024786403001\n",
      "episode :  23\n",
      "current step :  83\n",
      "reward :  -0.5843565795404082\n",
      "episode :  23\n",
      "current step :  84\n",
      "reward :  -0.6179035846440762\n",
      "episode :  23\n",
      "current step :  85\n",
      "reward :  -0.6247866321469187\n",
      "episode :  23\n",
      "current step :  86\n",
      "reward :  -0.6010251671448831\n",
      "episode :  23\n",
      "current step :  87\n",
      "reward :  -0.552346323159665\n",
      "episode :  23\n",
      "current step :  88\n",
      "reward :  -0.5283760656751021\n",
      "episode :  23\n",
      "current step :  89\n",
      "reward :  -0.5143012578765465\n",
      "episode :  23\n",
      "current step :  90\n",
      "reward :  -0.524994088458599\n",
      "episode :  23\n",
      "current step :  91\n",
      "reward :  -0.5184452828086128\n",
      "episode :  23\n",
      "current step :  92\n",
      "reward :  -0.5208529733518467\n",
      "episode :  23\n",
      "current step :  93\n",
      "reward :  -0.5088434128819093\n",
      "episode :  23\n",
      "current step :  94\n",
      "reward :  -0.5314444791018198\n",
      "episode :  23\n",
      "current step :  95\n",
      "reward :  -0.5403620698489173\n",
      "episode :  23\n",
      "current step :  96\n",
      "reward :  -0.5570206027603803\n",
      "episode :  23\n",
      "current step :  97\n",
      "reward :  -0.56493138538108\n",
      "episode :  23\n",
      "current step :  98\n",
      "reward :  -0.5374830350711174\n",
      "episode :  23\n",
      "current step :  99\n",
      "reward :  -0.5737630213215816\n",
      "episode :  23\n",
      "current step :  100\n",
      "reward :  -0.5465046315630353\n",
      "episode :  23\n",
      "current step :  101\n",
      "reward :  -0.5313028903429852\n",
      "episode :  23\n",
      "current step :  102\n",
      "reward :  -0.5123139495889073\n",
      "episode :  23\n",
      "current step :  103\n",
      "reward :  -0.537114790777806\n",
      "episode :  23\n",
      "current step :  104\n",
      "reward :  -0.5194665828641284\n",
      "episode :  23\n",
      "current step :  105\n",
      "reward :  -0.5361433230632259\n",
      "episode :  23\n",
      "current step :  106\n",
      "reward :  -0.5271286388326006\n",
      "episode :  23\n",
      "current step :  107\n",
      "reward :  -0.5234864940348138\n",
      "episode :  23\n",
      "current step :  108\n",
      "reward :  -0.5453293353978504\n",
      "episode :  23\n",
      "current step :  109\n",
      "reward :  -0.572524917238897\n",
      "episode :  23\n",
      "current step :  110\n",
      "reward :  -0.5568256023594396\n",
      "episode :  23\n",
      "current step :  111\n",
      "reward :  -0.534077629174542\n",
      "episode :  23\n",
      "current step :  112\n",
      "reward :  -0.5348149795240699\n",
      "episode :  23\n",
      "current step :  113\n",
      "reward :  -0.5404001042373721\n",
      "episode :  23\n",
      "current step :  114\n",
      "reward :  -0.543013053597618\n",
      "episode :  23\n",
      "current step :  115\n",
      "reward :  -0.5580151786264185\n",
      "episode :  23\n",
      "current step :  116\n",
      "reward :  -0.5509949150521606\n",
      "episode :  23\n",
      "current step :  117\n",
      "reward :  -0.5479246059774662\n",
      "episode :  23\n",
      "current step :  118\n",
      "reward :  -0.5513497799631523\n",
      "episode :  23\n",
      "current step :  119\n",
      "reward :  -0.5529879890586767\n",
      "episode :  23\n",
      "current step :  120\n",
      "reward :  -0.565156787418928\n",
      "episode :  23\n",
      "current step :  121\n",
      "reward :  -0.54931649511652\n",
      "episode :  23\n",
      "current step :  122\n",
      "reward :  -0.5519781652875855\n",
      "episode :  23\n",
      "current step :  123\n",
      "reward :  -0.5582815190527839\n",
      "episode :  23\n",
      "current step :  124\n",
      "reward :  -0.5629211316601761\n",
      "episode :  23\n",
      "current step :  125\n",
      "reward :  -0.5572655851958519\n",
      "episode :  23\n",
      "current step :  126\n",
      "reward :  -0.5531048658608473\n",
      "episode :  23\n",
      "current step :  127\n",
      "reward :  -0.5530036154576969\n",
      "episode :  23\n",
      "current step :  128\n",
      "reward :  -0.5588159767217001\n",
      "episode :  23\n",
      "current step :  129\n",
      "reward :  -0.5737590207276265\n",
      "episode :  23\n",
      "current step :  130\n",
      "reward :  -0.5672922809834637\n",
      "episode :  23\n",
      "current step :  131\n",
      "reward :  -0.5673310989572392\n",
      "episode :  23\n",
      "current step :  132\n",
      "reward :  -0.5666935692645108\n",
      "episode :  23\n",
      "current step :  133\n",
      "reward :  -0.5635336897619899\n",
      "episode :  23\n",
      "current step :  134\n",
      "reward :  -0.566410781918774\n",
      "episode :  23\n",
      "current step :  135\n",
      "reward :  -0.5525954487168196\n",
      "episode :  23\n",
      "current step :  136\n",
      "reward :  -0.56013919079994\n",
      "episode :  23\n",
      "current step :  137\n",
      "reward :  -0.55017301308607\n",
      "episode :  23\n",
      "current step :  138\n",
      "reward :  -0.5485207552998973\n",
      "episode :  23\n",
      "current step :  139\n",
      "reward :  -0.5442419647857463\n",
      "episode :  23\n",
      "current step :  140\n",
      "reward :  -0.5435177037535712\n",
      "episode :  23\n",
      "current step :  141\n",
      "reward :  -0.5430797840908503\n",
      "episode :  23\n",
      "current step :  142\n",
      "reward :  -0.5456192503086174\n",
      "episode :  23\n",
      "current step :  143\n",
      "reward :  -0.547020677082647\n",
      "episode :  23\n",
      "current step :  144\n",
      "reward :  -0.5460385412376498\n",
      "episode :  23\n",
      "current step :  145\n",
      "reward :  -0.5420357273152402\n",
      "episode :  23\n",
      "current step :  146\n",
      "reward :  -0.5425528428726103\n",
      "episode :  23\n",
      "current step :  147\n",
      "reward :  -0.5412103078286287\n",
      "episode :  23\n",
      "current step :  148\n",
      "reward :  -0.540347969989375\n",
      "episode :  23\n",
      "current step :  149\n",
      "reward :  -0.5426599708232026\n",
      "episode :  23\n",
      "current step :  150\n",
      "reward :  -0.5440186096457784\n",
      "episode :  23\n",
      "current step :  151\n",
      "reward :  -0.5428154513775385\n",
      "episode :  23\n",
      "current step :  152\n",
      "reward :  -0.5416903438155478\n",
      "episode :  23\n",
      "current step :  153\n",
      "reward :  -0.5421378825766946\n",
      "episode :  23\n",
      "current step :  154\n",
      "reward :  -0.5456058961536808\n",
      "episode :  23\n",
      "current step :  155\n",
      "reward :  -0.5497533657701165\n",
      "episode :  23\n",
      "current step :  156\n",
      "reward :  -0.5512232109424338\n",
      "episode :  23\n",
      "current step :  157\n",
      "reward :  -0.5501490752874609\n",
      "episode :  23\n",
      "current step :  158\n",
      "reward :  -0.5528793540832021\n",
      "episode :  23\n",
      "current step :  159\n",
      "reward :  -0.5555646567003171\n",
      "episode :  23\n",
      "current step :  160\n",
      "reward :  -0.5525357304175688\n",
      "episode :  23\n",
      "current step :  161\n",
      "reward :  -0.5534075525329065\n",
      "episode :  23\n",
      "current step :  162\n",
      "reward :  -0.5504038091826682\n",
      "episode :  23\n",
      "current step :  163\n",
      "reward :  -0.5491230190285803\n",
      "episode :  23\n",
      "current step :  164\n",
      "reward :  -0.5463103933441724\n",
      "episode :  23\n",
      "current step :  165\n",
      "reward :  -0.5499314162195815\n",
      "episode :  23\n",
      "current step :  166\n",
      "reward :  -0.5538987490949173\n",
      "episode :  23\n",
      "current step :  167\n",
      "reward :  -0.55518101668607\n",
      "episode :  23\n",
      "current step :  168\n",
      "reward :  -0.5549197870386235\n",
      "episode :  23\n",
      "current step :  169\n",
      "reward :  -0.5505359122437206\n",
      "episode :  23\n",
      "current step :  170\n",
      "reward :  -0.5507915352876889\n",
      "episode :  23\n",
      "current step :  171\n",
      "reward :  -0.5520663018048666\n",
      "episode :  23\n",
      "current step :  172\n",
      "reward :  -0.5537432500380582\n",
      "episode :  23\n",
      "current step :  173\n",
      "reward :  -0.5534785897449604\n",
      "episode :  23\n",
      "current step :  174\n",
      "reward :  -0.5433929153712473\n",
      "episode :  23\n",
      "current step :  175\n",
      "reward :  -0.5516766877920234\n",
      "episode :  23\n",
      "current step :  176\n",
      "reward :  -0.5505187022824876\n",
      "episode :  23\n",
      "current step :  177\n",
      "reward :  -0.5448437286405138\n",
      "episode :  23\n",
      "current step :  178\n",
      "reward :  -0.5523482141638708\n",
      "episode :  23\n",
      "current step :  179\n",
      "reward :  -0.5602214601441264\n",
      "episode :  23\n",
      "current step :  180\n",
      "reward :  -0.5611057989686092\n",
      "episode :  23\n",
      "current step :  181\n",
      "reward :  -0.563835772497429\n",
      "episode :  23\n",
      "current step :  182\n",
      "reward :  -0.5616723500388126\n",
      "episode :  23\n",
      "current step :  183\n",
      "reward :  -0.558109725253491\n",
      "episode :  23\n",
      "current step :  184\n",
      "reward :  -0.5564310743529981\n",
      "episode :  23\n",
      "current step :  185\n",
      "reward :  -0.5595461853572877\n",
      "episode :  23\n",
      "current step :  186\n",
      "reward :  -0.5573146678697294\n",
      "episode :  23\n",
      "current step :  187\n",
      "reward :  -0.5507651147743605\n",
      "episode :  23\n",
      "current step :  188\n",
      "reward :  -0.5440203492586093\n",
      "episode :  23\n",
      "current step :  189\n",
      "reward :  -0.5428095092010026\n",
      "episode :  23\n",
      "current step :  190\n",
      "reward :  -0.5580540475859825\n",
      "episode :  23\n",
      "current step :  191\n",
      "reward :  -0.562990978439912\n",
      "episode :  23\n",
      "current step :  192\n",
      "reward :  -0.5579962914511075\n",
      "episode :  23\n",
      "current step :  193\n",
      "reward :  -0.5554782423264206\n",
      "episode :  23\n",
      "current step :  194\n",
      "reward :  -0.5604823243169613\n",
      "episode :  23\n",
      "current step :  195\n",
      "reward :  -0.560483055561071\n",
      "episode :  23\n",
      "current step :  196\n",
      "reward :  -0.5652762484084422\n",
      "episode :  23\n",
      "current step :  197\n",
      "reward :  -0.5648623717685497\n",
      "episode :  23\n",
      "current step :  198\n",
      "reward :  -0.5652142020384777\n",
      "episode :  23\n",
      "current step :  199\n",
      "reward :  -0.5642503779368034\n",
      "episode :  23\n",
      "current step :  200\n",
      "reward :  -0.5629971782648058\n",
      "episode :  23\n",
      "current step :  201\n",
      "reward :  -0.5605806880213718\n",
      "episode :  23\n",
      "current step :  202\n",
      "reward :  -0.5605760060194325\n",
      "episode :  23\n",
      "current step :  203\n",
      "reward :  -0.5527423636971363\n",
      "episode :  23\n",
      "current step :  204\n",
      "reward :  -0.5620754006047257\n",
      "episode :  23\n",
      "current step :  205\n",
      "reward :  -0.5586462173703421\n",
      "episode :  23\n",
      "current step :  206\n",
      "reward :  -0.5552300722343205\n",
      "episode :  23\n",
      "current step :  207\n",
      "reward :  -0.5524952523890359\n",
      "episode :  23\n",
      "current step :  208\n",
      "reward :  -0.5628668777194327\n",
      "episode :  23\n",
      "current step :  209\n",
      "reward :  -0.5584182228814435\n",
      "episode :  23\n",
      "current step :  210\n",
      "reward :  -0.5531890411678335\n",
      "episode :  23\n",
      "current step :  211\n",
      "reward :  -0.5605216419897143\n",
      "episode :  23\n",
      "current step :  212\n",
      "reward :  -0.5614600593580307\n",
      "episode :  23\n",
      "current step :  213\n",
      "reward :  -0.5634659327652263\n",
      "episode :  23\n",
      "current step :  214\n",
      "reward :  -0.5616175394620816\n",
      "episode :  23\n",
      "current step :  215\n",
      "reward :  -0.5641031631431617\n",
      "episode :  23\n",
      "current step :  216\n",
      "reward :  -0.5623158695201476\n",
      "episode :  23\n",
      "current step :  217\n",
      "reward :  -0.559960354147914\n",
      "episode :  23\n",
      "current step :  218\n",
      "reward :  -0.5603408088034358\n",
      "episode :  23\n",
      "current step :  219\n",
      "reward :  -0.5586074883351629\n",
      "episode :  23\n",
      "current step :  220\n",
      "reward :  -0.558546668082882\n",
      "episode :  23\n",
      "current step :  221\n",
      "reward :  -0.5533655505903231\n",
      "episode :  23\n",
      "current step :  222\n",
      "reward :  -0.5566503294037748\n",
      "episode :  23\n",
      "current step :  223\n",
      "reward :  -0.5582653749435592\n",
      "episode :  23\n",
      "current step :  224\n",
      "reward :  -0.5536504299263098\n",
      "episode :  23\n",
      "current step :  225\n",
      "reward :  -0.548481709112574\n",
      "episode :  23\n",
      "current step :  226\n",
      "reward :  -0.5522821720966854\n",
      "episode :  23\n",
      "current step :  227\n",
      "reward :  -0.5494891192477332\n",
      "episode :  23\n",
      "current step :  228\n",
      "reward :  -0.5177018672277847\n",
      "episode :  23\n",
      "current step :  229\n",
      "reward :  -0.5334173389755413\n",
      "episode :  23\n",
      "current step :  230\n",
      "reward :  -0.5535890750268222\n",
      "episode :  23\n",
      "current step :  231\n",
      "reward :  -0.5612595839197126\n",
      "episode :  23\n",
      "current step :  232\n",
      "reward :  -0.5446890873633841\n",
      "episode :  23\n",
      "current step :  233\n",
      "reward :  -0.5321463484063916\n",
      "episode :  23\n",
      "current step :  234\n",
      "reward :  -0.5176068213726434\n",
      "episode :  23\n",
      "current step :  235\n",
      "reward :  -0.5209649035158596\n",
      "episode :  23\n",
      "current step :  236\n",
      "reward :  -0.5177945749669144\n",
      "episode :  23\n",
      "current step :  237\n",
      "reward :  -0.5290839253606913\n",
      "episode :  23\n",
      "current step :  238\n",
      "reward :  -0.5384277917616302\n",
      "episode :  23\n",
      "current step :  239\n",
      "reward :  -0.5405516306438836\n",
      "episode :  23\n",
      "current step :  240\n",
      "reward :  -0.5362747404804347\n",
      "episode :  23\n",
      "current step :  241\n",
      "reward :  -0.5356652912095768\n",
      "episode :  23\n",
      "current step :  242\n",
      "reward :  -0.5346249957458602\n",
      "episode :  23\n",
      "current step :  243\n",
      "reward :  -0.530679202485272\n",
      "episode :  23\n",
      "current step :  244\n",
      "reward :  -0.5317792499106236\n",
      "episode :  23\n",
      "current step :  245\n",
      "reward :  -0.5333296508188453\n",
      "episode :  23\n",
      "current step :  246\n",
      "reward :  -0.533699976306587\n",
      "episode :  23\n",
      "current step :  247\n",
      "reward :  -0.5317364979899181\n",
      "episode :  23\n",
      "current step :  248\n",
      "reward :  -0.5359823678156473\n",
      "episode :  23\n",
      "current step :  249\n",
      "reward :  -0.5351058043015714\n",
      "episode :  23\n",
      "current step :  250\n",
      "reward :  -0.5384987342417874\n",
      "episode :  23\n",
      "current step :  251\n",
      "reward :  -0.5310227145943365\n",
      "episode :  23\n",
      "current step :  252\n",
      "reward :  -0.5338273268280923\n",
      "episode :  23\n",
      "current step :  253\n",
      "reward :  -0.5352873165640415\n",
      "episode :  23\n",
      "current step :  254\n",
      "reward :  -0.5397206695538554\n",
      "episode :  23\n",
      "current step :  255\n",
      "reward :  -0.5494602203604325\n",
      "episode :  23\n",
      "current step :  256\n",
      "reward :  -0.5480222806529508\n",
      "episode :  23\n",
      "current step :  257\n",
      "reward :  -0.541725829430361\n",
      "episode :  23\n",
      "current step :  258\n",
      "reward :  -0.5430529338453898\n",
      "episode :  23\n",
      "current step :  259\n",
      "reward :  -0.5239045619820132\n",
      "episode :  23\n",
      "current step :  260\n",
      "reward :  -0.5280941756108192\n",
      "episode :  23\n",
      "current step :  261\n",
      "reward :  -0.5154069698249065\n",
      "episode :  23\n",
      "current step :  262\n",
      "reward :  -0.5218024686633578\n",
      "episode :  23\n",
      "current step :  263\n",
      "reward :  -0.5246918597792467\n",
      "episode :  23\n",
      "current step :  264\n",
      "reward :  -0.5295477462953938\n",
      "episode :  23\n",
      "current step :  265\n",
      "reward :  -0.5404643893420819\n",
      "episode :  23\n",
      "current step :  266\n",
      "reward :  -0.5516657289310801\n",
      "episode :  23\n",
      "current step :  267\n",
      "reward :  -0.5491419121977399\n",
      "episode :  23\n",
      "current step :  268\n",
      "reward :  -0.532861106706013\n",
      "episode :  23\n",
      "current step :  269\n",
      "reward :  -0.5474868770192134\n",
      "episode :  23\n",
      "current step :  270\n",
      "reward :  -0.5695632819659087\n",
      "episode :  23\n",
      "current step :  271\n",
      "reward :  -0.5510421854708258\n",
      "episode :  23\n",
      "current step :  272\n",
      "reward :  -0.5500348588682286\n",
      "episode :  23\n",
      "current step :  273\n",
      "reward :  -0.5446499744494414\n",
      "episode :  23\n",
      "current step :  274\n",
      "reward :  -0.5576727012600347\n",
      "episode :  23\n",
      "current step :  275\n",
      "reward :  -0.5359430727972446\n",
      "episode :  23\n",
      "current step :  276\n",
      "reward :  -0.5614814669641941\n",
      "episode :  23\n",
      "current step :  277\n",
      "reward :  -0.563298162643546\n",
      "episode :  23\n",
      "current step :  278\n",
      "reward :  -0.5519844617933213\n",
      "episode :  23\n",
      "current step :  279\n",
      "reward :  -0.5612193021288004\n",
      "episode :  23\n",
      "current step :  280\n",
      "reward :  -0.5567418223667142\n",
      "episode :  23\n",
      "current step :  281\n",
      "reward :  -0.5561840035912644\n",
      "episode :  23\n",
      "current step :  282\n",
      "reward :  -0.5527430002359676\n",
      "episode :  23\n",
      "current step :  283\n",
      "reward :  -0.5343631363930655\n",
      "episode :  23\n",
      "current step :  284\n",
      "reward :  -0.5479899170501343\n",
      "episode :  23\n",
      "current step :  285\n",
      "reward :  -0.5635376536923615\n",
      "episode :  24\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 286      |\n",
      "|    ep_rew_mean     | -128     |\n",
      "| time/              |          |\n",
      "|    episodes        | 24       |\n",
      "|    fps             | 14       |\n",
      "|    time_elapsed    | 485      |\n",
      "|    total_timesteps | 6864     |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -81.1    |\n",
      "|    critic_loss     | 9.32     |\n",
      "|    ent_coef        | 0.162    |\n",
      "|    ent_coef_loss   | -15.6    |\n",
      "|    learning_rate   | 0.0003   |\n",
      "|    n_updates       | 6763     |\n",
      "---------------------------------\n",
      "current step :  0\n",
      "reward :  -0.5772924105325741\n",
      "episode :  24\n",
      "current step :  1\n",
      "reward :  -0.5974263358968825\n",
      "episode :  24\n",
      "current step :  2\n",
      "reward :  -0.5470159217853959\n",
      "episode :  24\n",
      "current step :  3\n",
      "reward :  -0.5487317546995728\n",
      "episode :  24\n",
      "current step :  4\n",
      "reward :  -0.5593715883582897\n",
      "episode :  24\n",
      "current step :  5\n",
      "reward :  -0.5204934200508519\n",
      "episode :  24\n",
      "current step :  6\n",
      "reward :  -0.505807796013136\n",
      "episode :  24\n",
      "current step :  7\n",
      "reward :  -0.5254725265836037\n",
      "episode :  24\n",
      "current step :  8\n",
      "reward :  -0.5154774512043134\n",
      "episode :  24\n",
      "current step :  9\n",
      "reward :  -0.5339219556816215\n",
      "episode :  24\n",
      "current step :  10\n",
      "reward :  -0.5286498446144517\n",
      "episode :  24\n",
      "current step :  11\n",
      "reward :  -0.5228837984269802\n",
      "episode :  24\n",
      "current step :  12\n",
      "reward :  -0.4860457347980062\n",
      "episode :  24\n",
      "current step :  13\n",
      "reward :  -0.4188793821096076\n",
      "episode :  24\n",
      "current step :  14\n",
      "reward :  -0.4934694980360439\n",
      "episode :  24\n",
      "current step :  15\n",
      "reward :  -0.4914488890732213\n",
      "episode :  24\n",
      "current step :  16\n",
      "reward :  -0.4667724772634034\n",
      "episode :  24\n",
      "current step :  17\n",
      "reward :  -0.44296523437677326\n",
      "episode :  24\n",
      "current step :  18\n",
      "reward :  -0.45007915414811756\n",
      "episode :  24\n",
      "current step :  19\n",
      "reward :  -0.5065467551277149\n",
      "episode :  24\n",
      "current step :  20\n",
      "reward :  -0.422229580788097\n",
      "episode :  24\n",
      "current step :  21\n",
      "reward :  -0.5125639579847083\n",
      "episode :  24\n",
      "current step :  22\n",
      "reward :  -0.4541617237468264\n",
      "episode :  24\n",
      "current step :  23\n",
      "reward :  -0.3881387094370153\n",
      "episode :  24\n",
      "current step :  24\n",
      "reward :  -0.3831885598018156\n",
      "episode :  24\n",
      "current step :  25\n",
      "reward :  -0.41744939254808894\n",
      "episode :  24\n",
      "current step :  26\n",
      "reward :  -0.4294721715973137\n",
      "episode :  24\n",
      "current step :  27\n",
      "reward :  -0.3957754788306645\n",
      "episode :  24\n",
      "current step :  28\n",
      "reward :  -0.4789364136668299\n",
      "episode :  24\n",
      "current step :  29\n",
      "reward :  -0.536668588142306\n",
      "episode :  24\n",
      "current step :  30\n",
      "reward :  -0.6075952222213776\n",
      "episode :  24\n",
      "current step :  31\n",
      "reward :  -0.5345240503035036\n",
      "episode :  24\n",
      "current step :  32\n",
      "reward :  -0.5202696458791228\n",
      "episode :  24\n",
      "current step :  33\n",
      "reward :  -0.5528092884725124\n",
      "episode :  24\n",
      "current step :  34\n",
      "reward :  -0.5832538208608448\n",
      "episode :  24\n",
      "current step :  35\n",
      "reward :  -0.5959758742900686\n",
      "episode :  24\n",
      "current step :  36\n",
      "reward :  -0.4895913120902696\n",
      "episode :  24\n",
      "current step :  37\n",
      "reward :  -0.5136017034039543\n",
      "episode :  24\n",
      "current step :  38\n",
      "reward :  -0.6054752612845024\n",
      "episode :  24\n",
      "current step :  39\n",
      "reward :  -0.6324253625463522\n",
      "episode :  24\n",
      "current step :  40\n",
      "reward :  -0.6277005205950461\n",
      "episode :  24\n",
      "current step :  41\n",
      "reward :  -0.6523581902972109\n",
      "episode :  24\n",
      "current step :  42\n",
      "reward :  -0.6570650208660347\n",
      "episode :  24\n",
      "current step :  43\n",
      "reward :  -0.6634894057074583\n",
      "episode :  24\n",
      "current step :  44\n",
      "reward :  -0.6697417094447943\n",
      "episode :  24\n",
      "current step :  45\n",
      "reward :  -0.663811669734904\n",
      "episode :  24\n",
      "current step :  46\n",
      "reward :  -0.6559187977502235\n",
      "episode :  24\n",
      "current step :  47\n",
      "reward :  -0.6958504224180024\n",
      "episode :  24\n",
      "current step :  48\n",
      "reward :  -0.6742291559635828\n",
      "episode :  24\n",
      "current step :  49\n",
      "reward :  -0.589655383585532\n",
      "episode :  24\n",
      "current step :  50\n",
      "reward :  -0.5538287389377287\n",
      "episode :  24\n",
      "current step :  51\n",
      "reward :  -0.5560586073805416\n",
      "episode :  24\n",
      "current step :  52\n",
      "reward :  -0.6054545437492104\n",
      "episode :  24\n",
      "current step :  53\n",
      "reward :  -0.6325429246347907\n",
      "episode :  24\n",
      "current step :  54\n",
      "reward :  -0.5480480788946405\n",
      "episode :  24\n",
      "current step :  55\n",
      "reward :  -0.5042757643385838\n",
      "episode :  24\n",
      "current step :  56\n",
      "reward :  -0.5346777126309801\n",
      "episode :  24\n",
      "current step :  57\n",
      "reward :  -0.549123324378961\n",
      "episode :  24\n",
      "current step :  58\n",
      "reward :  -0.601257442280823\n",
      "episode :  24\n",
      "current step :  59\n",
      "reward :  -0.6025911361985644\n",
      "episode :  24\n",
      "current step :  60\n",
      "reward :  -0.7179580731335964\n",
      "episode :  24\n",
      "current step :  61\n",
      "reward :  -0.693233406236937\n",
      "episode :  24\n",
      "current step :  62\n",
      "reward :  -0.6606330369964931\n",
      "episode :  24\n",
      "current step :  63\n",
      "reward :  -0.6481149605768404\n",
      "episode :  24\n",
      "current step :  64\n",
      "reward :  -0.6381080465235335\n",
      "episode :  24\n",
      "current step :  65\n",
      "reward :  -0.6618454088026152\n",
      "episode :  24\n",
      "current step :  66\n",
      "reward :  -0.7041950974145029\n",
      "episode :  24\n",
      "current step :  67\n",
      "reward :  -0.6996105671987958\n",
      "episode :  24\n",
      "current step :  68\n",
      "reward :  -0.694754110878777\n",
      "episode :  24\n",
      "current step :  69\n",
      "reward :  -0.7303861398627665\n",
      "episode :  24\n",
      "current step :  70\n",
      "reward :  -0.6802327912871134\n",
      "episode :  24\n",
      "current step :  71\n",
      "reward :  -0.732721855804933\n",
      "episode :  24\n",
      "current step :  72\n",
      "reward :  -0.7269175247420905\n",
      "episode :  24\n",
      "current step :  73\n",
      "reward :  -0.710354426909471\n",
      "episode :  24\n",
      "current step :  74\n",
      "reward :  -0.6594148697018347\n",
      "episode :  24\n",
      "current step :  75\n",
      "reward :  -0.5641869041818804\n",
      "episode :  24\n",
      "current step :  76\n",
      "reward :  -0.6860933616926448\n",
      "episode :  24\n",
      "current step :  77\n",
      "reward :  -0.7176455350055527\n",
      "episode :  24\n",
      "current step :  78\n",
      "reward :  -0.7181546555681578\n",
      "episode :  24\n",
      "current step :  79\n",
      "reward :  -0.7053958526115353\n",
      "episode :  24\n",
      "current step :  80\n",
      "reward :  -0.6556316192362905\n",
      "episode :  24\n",
      "current step :  81\n",
      "reward :  -0.6894624729684791\n",
      "episode :  24\n",
      "current step :  82\n",
      "reward :  -0.6883394991010423\n",
      "episode :  24\n",
      "current step :  83\n",
      "reward :  -0.6797064815673265\n",
      "episode :  24\n",
      "current step :  84\n",
      "reward :  -0.6713337576499574\n",
      "episode :  24\n",
      "current step :  85\n",
      "reward :  -0.6418034376497332\n",
      "episode :  24\n",
      "current step :  86\n",
      "reward :  -0.5206496460548791\n",
      "episode :  24\n",
      "current step :  87\n",
      "reward :  -0.475866049702624\n",
      "episode :  24\n",
      "current step :  88\n",
      "reward :  -0.5470109848913483\n",
      "episode :  24\n",
      "current step :  89\n",
      "reward :  -0.5641365655935274\n",
      "episode :  24\n",
      "current step :  90\n",
      "reward :  -0.4892509580629568\n",
      "episode :  24\n",
      "current step :  91\n",
      "reward :  -0.469118365682524\n",
      "episode :  24\n",
      "current step :  92\n",
      "reward :  -0.576052081188167\n",
      "episode :  24\n",
      "current step :  93\n",
      "reward :  -0.5541385560777027\n",
      "episode :  24\n",
      "current step :  94\n",
      "reward :  -0.5104327371978682\n",
      "episode :  24\n",
      "current step :  95\n",
      "reward :  -0.45106489957539125\n",
      "episode :  24\n",
      "current step :  96\n",
      "reward :  -0.48503073803520375\n",
      "episode :  24\n",
      "current step :  97\n",
      "reward :  -0.5729303605489386\n",
      "episode :  24\n",
      "current step :  98\n",
      "reward :  -0.4911818679804025\n",
      "episode :  24\n",
      "current step :  99\n",
      "reward :  -0.44617555290034033\n",
      "episode :  24\n",
      "current step :  100\n",
      "reward :  -0.5342514181194963\n",
      "episode :  24\n",
      "current step :  101\n",
      "reward :  -0.5729335231210874\n",
      "episode :  24\n",
      "current step :  102\n",
      "reward :  -0.528988604694991\n",
      "episode :  24\n",
      "current step :  103\n",
      "reward :  -0.5534248538951189\n",
      "episode :  24\n",
      "current step :  104\n",
      "reward :  -0.5317782175021535\n",
      "episode :  24\n",
      "current step :  105\n",
      "reward :  -0.46583679294892366\n",
      "episode :  24\n",
      "current step :  106\n",
      "reward :  -0.5643191884689911\n",
      "episode :  24\n",
      "current step :  107\n",
      "reward :  -0.55645614838816\n",
      "episode :  24\n",
      "current step :  108\n",
      "reward :  -0.5524241884594417\n",
      "episode :  24\n",
      "current step :  109\n",
      "reward :  -0.5367860782345206\n",
      "episode :  24\n",
      "current step :  110\n",
      "reward :  -0.5718746101077632\n",
      "episode :  24\n",
      "current step :  111\n",
      "reward :  -0.5694403952151128\n",
      "episode :  24\n",
      "current step :  112\n",
      "reward :  -0.5618268634032024\n",
      "episode :  24\n",
      "current step :  113\n",
      "reward :  -0.5073788212675385\n",
      "episode :  24\n",
      "current step :  114\n",
      "reward :  -0.5644454857024861\n",
      "episode :  24\n",
      "current step :  115\n",
      "reward :  -0.5534045397640872\n",
      "episode :  24\n",
      "current step :  116\n",
      "reward :  -0.5661877500871384\n",
      "episode :  24\n",
      "current step :  117\n",
      "reward :  -0.5594763879417565\n",
      "episode :  24\n",
      "current step :  118\n",
      "reward :  -0.5286731196781113\n",
      "episode :  24\n",
      "current step :  119\n",
      "reward :  -0.49686566749390676\n",
      "episode :  24\n",
      "current step :  120\n",
      "reward :  -0.42100443099913565\n",
      "episode :  24\n",
      "current step :  121\n",
      "reward :  -0.5228049831410019\n",
      "episode :  24\n",
      "current step :  122\n",
      "reward :  -0.5634213198787832\n",
      "episode :  24\n",
      "current step :  123\n",
      "reward :  -0.5398847559697691\n",
      "episode :  24\n",
      "current step :  124\n",
      "reward :  -0.5639876651688027\n",
      "episode :  24\n",
      "current step :  125\n",
      "reward :  -0.5679025500033291\n",
      "episode :  24\n",
      "current step :  126\n",
      "reward :  -0.5557674957887168\n",
      "episode :  24\n",
      "current step :  127\n",
      "reward :  -0.57293859854565\n",
      "episode :  24\n",
      "current step :  128\n",
      "reward :  -0.5748757441401098\n",
      "episode :  24\n",
      "current step :  129\n",
      "reward :  -0.5748809451022837\n",
      "episode :  24\n",
      "current step :  130\n",
      "reward :  -0.5762790369842122\n",
      "episode :  24\n",
      "current step :  131\n",
      "reward :  -0.5786225876312054\n",
      "episode :  24\n",
      "current step :  132\n",
      "reward :  -0.5760016545112463\n",
      "episode :  24\n",
      "current step :  133\n",
      "reward :  -0.5768100250129257\n",
      "episode :  24\n",
      "current step :  134\n",
      "reward :  -0.5820992505365433\n",
      "episode :  24\n",
      "current step :  135\n",
      "reward :  -0.583097626587301\n",
      "episode :  24\n",
      "current step :  136\n",
      "reward :  -0.5751027941480995\n",
      "episode :  24\n",
      "current step :  137\n",
      "reward :  -0.5747557391582816\n",
      "episode :  24\n",
      "current step :  138\n",
      "reward :  -0.5708212385049355\n",
      "episode :  24\n",
      "current step :  139\n",
      "reward :  -0.5395671952168989\n",
      "episode :  24\n",
      "current step :  140\n",
      "reward :  -0.5673227522364994\n",
      "episode :  24\n",
      "current step :  141\n",
      "reward :  -0.5598549054522611\n",
      "episode :  24\n",
      "current step :  142\n",
      "reward :  -0.5607368739043064\n",
      "episode :  24\n",
      "current step :  143\n",
      "reward :  -0.5544801216847065\n",
      "episode :  24\n",
      "current step :  144\n",
      "reward :  -0.5525276912560417\n",
      "episode :  24\n",
      "current step :  145\n",
      "reward :  -0.5547742198447604\n",
      "episode :  24\n",
      "current step :  146\n",
      "reward :  -0.5502196538049312\n",
      "episode :  24\n",
      "current step :  147\n",
      "reward :  -0.5507946331694289\n",
      "episode :  24\n",
      "current step :  148\n",
      "reward :  -0.5467925863946694\n",
      "episode :  24\n",
      "current step :  149\n",
      "reward :  -0.5219637032124412\n",
      "episode :  24\n",
      "current step :  150\n",
      "reward :  -0.5384517337532425\n",
      "episode :  24\n",
      "current step :  151\n",
      "reward :  -0.5238687085771887\n",
      "episode :  24\n",
      "current step :  152\n",
      "reward :  -0.5353106315337967\n",
      "episode :  24\n",
      "current step :  153\n",
      "reward :  -0.5349853018878983\n",
      "episode :  24\n",
      "current step :  154\n",
      "reward :  -0.5353957921026505\n",
      "episode :  24\n",
      "current step :  155\n",
      "reward :  -0.5438073674102115\n",
      "episode :  24\n",
      "current step :  156\n",
      "reward :  -0.5429864744758902\n",
      "episode :  24\n",
      "current step :  157\n",
      "reward :  -0.5447841288678292\n",
      "episode :  24\n",
      "current step :  158\n",
      "reward :  -0.5325127727469705\n",
      "episode :  24\n",
      "current step :  159\n",
      "reward :  -0.5446419762099851\n",
      "episode :  24\n",
      "current step :  160\n",
      "reward :  -0.5286533188297503\n",
      "episode :  24\n",
      "current step :  161\n",
      "reward :  -0.5415527939239646\n",
      "episode :  24\n",
      "current step :  162\n",
      "reward :  -0.5320204853270372\n",
      "episode :  24\n",
      "current step :  163\n",
      "reward :  -0.5298082230394139\n",
      "episode :  24\n",
      "current step :  164\n",
      "reward :  -0.5310109597274093\n",
      "episode :  24\n",
      "current step :  165\n",
      "reward :  -0.5352434879008925\n",
      "episode :  24\n",
      "current step :  166\n",
      "reward :  -0.5189633642472553\n",
      "episode :  24\n",
      "current step :  167\n",
      "reward :  -0.5353634851986551\n",
      "episode :  24\n",
      "current step :  168\n",
      "reward :  -0.4962892024249254\n",
      "episode :  24\n",
      "current step :  169\n",
      "reward :  -0.5285639198446755\n",
      "episode :  24\n",
      "current step :  170\n",
      "reward :  -0.5038418774661384\n",
      "episode :  24\n",
      "current step :  171\n",
      "reward :  -0.5420616951734128\n",
      "episode :  24\n",
      "current step :  172\n",
      "reward :  -0.54144970664105\n",
      "episode :  24\n",
      "current step :  173\n",
      "reward :  -0.534443828914859\n",
      "episode :  24\n",
      "current step :  174\n",
      "reward :  -0.5276282045247038\n",
      "episode :  24\n",
      "current step :  175\n",
      "reward :  -0.5215853033109796\n",
      "episode :  24\n",
      "current step :  176\n",
      "reward :  -0.5361698222077229\n",
      "episode :  24\n",
      "current step :  177\n",
      "reward :  -0.5359839189232901\n",
      "episode :  24\n",
      "current step :  178\n",
      "reward :  -0.5363162145265639\n",
      "episode :  24\n",
      "current step :  179\n",
      "reward :  -0.5348314716343896\n",
      "episode :  24\n",
      "current step :  180\n",
      "reward :  -0.5390237726563408\n",
      "episode :  24\n",
      "current step :  181\n",
      "reward :  -0.5443167108781424\n",
      "episode :  24\n",
      "current step :  182\n",
      "reward :  -0.5436247338942588\n",
      "episode :  24\n",
      "current step :  183\n",
      "reward :  -0.5444586093449585\n",
      "episode :  24\n",
      "current step :  184\n",
      "reward :  -0.5398459776058864\n",
      "episode :  24\n",
      "current step :  185\n",
      "reward :  -0.5510621381040116\n",
      "episode :  24\n",
      "current step :  186\n",
      "reward :  -0.5366911135443494\n",
      "episode :  24\n",
      "current step :  187\n",
      "reward :  -0.5515398510711439\n",
      "episode :  24\n",
      "current step :  188\n",
      "reward :  -0.553312009706935\n",
      "episode :  24\n",
      "current step :  189\n",
      "reward :  -0.5532927460117303\n",
      "episode :  24\n",
      "current step :  190\n",
      "reward :  -0.5490011427064632\n",
      "episode :  24\n",
      "current step :  191\n",
      "reward :  -0.5284517077421111\n",
      "episode :  24\n",
      "current step :  192\n",
      "reward :  -0.5074673125161026\n",
      "episode :  24\n",
      "current step :  193\n",
      "reward :  -0.546585890910395\n",
      "episode :  24\n",
      "current step :  194\n",
      "reward :  -0.541626799499696\n",
      "episode :  24\n",
      "current step :  195\n",
      "reward :  -0.5475667688485489\n",
      "episode :  24\n",
      "current step :  196\n",
      "reward :  -0.5365368236769616\n",
      "episode :  24\n",
      "current step :  197\n",
      "reward :  -0.5206181863280933\n",
      "episode :  24\n",
      "current step :  198\n",
      "reward :  -0.5400455597149852\n",
      "episode :  24\n",
      "current step :  199\n",
      "reward :  -0.5492901568523237\n",
      "episode :  24\n",
      "current step :  200\n",
      "reward :  -0.5405786369976127\n",
      "episode :  24\n",
      "current step :  201\n",
      "reward :  -0.5242989113756081\n",
      "episode :  24\n",
      "current step :  202\n",
      "reward :  -0.5377178825051264\n",
      "episode :  24\n",
      "current step :  203\n",
      "reward :  -0.5351168040575405\n",
      "episode :  24\n",
      "current step :  204\n",
      "reward :  -0.5309013480339081\n",
      "episode :  24\n",
      "current step :  205\n",
      "reward :  -0.5457754391190326\n",
      "episode :  24\n",
      "current step :  206\n",
      "reward :  -0.5493766065608257\n",
      "episode :  24\n",
      "current step :  207\n",
      "reward :  -0.5398722441143231\n",
      "episode :  24\n",
      "current step :  208\n",
      "reward :  -0.431271458485912\n",
      "episode :  24\n",
      "current step :  209\n",
      "reward :  -0.43832423386223923\n",
      "episode :  24\n",
      "current step :  210\n",
      "reward :  -0.47097973994943987\n",
      "episode :  24\n",
      "current step :  211\n",
      "reward :  -0.5377229153364808\n",
      "episode :  24\n",
      "current step :  212\n",
      "reward :  -0.42581440850162905\n",
      "episode :  24\n",
      "current step :  213\n",
      "reward :  -0.5329255531419392\n",
      "episode :  24\n",
      "current step :  214\n",
      "reward :  -0.5161776352360632\n",
      "episode :  24\n",
      "current step :  215\n",
      "reward :  -0.385597109886114\n",
      "episode :  24\n",
      "current step :  216\n",
      "reward :  -0.3864200915085563\n",
      "episode :  24\n",
      "current step :  217\n",
      "reward :  -0.36300388446125936\n",
      "episode :  24\n",
      "current step :  218\n",
      "reward :  -0.45059816144877296\n",
      "episode :  24\n",
      "current step :  219\n",
      "reward :  -0.4076978308635088\n",
      "episode :  24\n",
      "current step :  220\n",
      "reward :  -0.46762368940494514\n",
      "episode :  24\n",
      "current step :  221\n",
      "reward :  -0.474617989296916\n",
      "episode :  24\n",
      "current step :  222\n",
      "reward :  -0.47020898079791845\n",
      "episode :  24\n",
      "current step :  223\n",
      "reward :  -0.3453105260547763\n",
      "episode :  24\n",
      "current step :  224\n",
      "reward :  -0.35708011503320497\n",
      "episode :  24\n",
      "current step :  225\n",
      "reward :  -0.34481413619864637\n",
      "episode :  24\n",
      "current step :  226\n",
      "reward :  -0.33407311282859076\n",
      "episode :  24\n",
      "current step :  227\n",
      "reward :  -0.39280429512113313\n",
      "episode :  24\n",
      "current step :  228\n",
      "reward :  -0.47766383118322997\n",
      "episode :  24\n",
      "current step :  229\n",
      "reward :  -0.3364891578699681\n",
      "episode :  24\n",
      "current step :  230\n",
      "reward :  -0.35562890917741047\n",
      "episode :  24\n",
      "current step :  231\n",
      "reward :  -0.35817760038358804\n",
      "episode :  24\n",
      "current step :  232\n",
      "reward :  -0.3533362236087577\n",
      "episode :  24\n",
      "current step :  233\n",
      "reward :  -0.4399140574196226\n",
      "episode :  24\n",
      "current step :  234\n",
      "reward :  -0.37165363227125614\n",
      "episode :  24\n",
      "current step :  235\n",
      "reward :  -0.44669319661497525\n",
      "episode :  24\n",
      "current step :  236\n",
      "reward :  -0.37357897956356634\n",
      "episode :  24\n",
      "current step :  237\n",
      "reward :  -0.36664594025483055\n",
      "episode :  24\n",
      "current step :  238\n",
      "reward :  -0.4604288845443749\n",
      "episode :  24\n",
      "current step :  239\n",
      "reward :  -0.3840806174494367\n",
      "episode :  24\n",
      "current step :  240\n",
      "reward :  -0.42176564834050023\n",
      "episode :  24\n",
      "current step :  241\n",
      "reward :  -0.47442337333796347\n",
      "episode :  24\n",
      "current step :  242\n",
      "reward :  -0.39798786451389967\n",
      "episode :  24\n",
      "current step :  243\n",
      "reward :  -0.3888632223117058\n",
      "episode :  24\n",
      "current step :  244\n",
      "reward :  -0.46770965277887117\n",
      "episode :  24\n",
      "current step :  245\n",
      "reward :  -0.33526655161292124\n",
      "episode :  24\n",
      "current step :  246\n",
      "reward :  -0.35955288790898676\n",
      "episode :  24\n",
      "current step :  247\n",
      "reward :  -0.46077006623887584\n",
      "episode :  24\n",
      "current step :  248\n",
      "reward :  -0.3535422361981114\n",
      "episode :  24\n",
      "current step :  249\n",
      "reward :  -0.35432579480080295\n",
      "episode :  24\n",
      "current step :  250\n",
      "reward :  -0.3713082051368677\n",
      "episode :  24\n",
      "current step :  251\n",
      "reward :  -0.3464018229785946\n",
      "episode :  24\n",
      "current step :  252\n",
      "reward :  -0.4994422298824103\n",
      "episode :  24\n",
      "current step :  253\n",
      "reward :  -0.45723124421738526\n",
      "episode :  24\n",
      "current step :  254\n",
      "reward :  -0.39334998280743577\n",
      "episode :  24\n",
      "current step :  255\n",
      "reward :  -0.34392859187758845\n",
      "episode :  24\n",
      "current step :  256\n",
      "reward :  -0.3521151943957234\n",
      "episode :  24\n",
      "current step :  257\n",
      "reward :  -0.34837602095229075\n",
      "episode :  24\n",
      "current step :  258\n",
      "reward :  -0.4426568291434066\n",
      "episode :  24\n",
      "current step :  259\n",
      "reward :  -0.4290543979753758\n",
      "episode :  24\n",
      "current step :  260\n",
      "reward :  -0.37881690420444414\n",
      "episode :  24\n",
      "current step :  261\n",
      "reward :  -0.3398954967198157\n",
      "episode :  24\n",
      "current step :  262\n",
      "reward :  -0.3896127491783663\n",
      "episode :  24\n",
      "current step :  263\n",
      "reward :  -0.3490711287496977\n",
      "episode :  24\n",
      "current step :  264\n",
      "reward :  -0.4127779363071593\n",
      "episode :  24\n",
      "current step :  265\n",
      "reward :  -0.3705956700214859\n",
      "episode :  24\n",
      "current step :  266\n",
      "reward :  -0.4748874759768153\n",
      "episode :  24\n",
      "current step :  267\n",
      "reward :  -0.447692177422423\n",
      "episode :  24\n",
      "current step :  268\n",
      "reward :  -0.34905956919242564\n",
      "episode :  24\n",
      "current step :  269\n",
      "reward :  -0.36515080395962973\n",
      "episode :  24\n",
      "current step :  270\n",
      "reward :  -0.3709368357276346\n",
      "episode :  24\n",
      "current step :  271\n",
      "reward :  -0.34554563910298464\n",
      "episode :  24\n",
      "current step :  272\n",
      "reward :  -0.44027490509692485\n",
      "episode :  24\n",
      "current step :  273\n",
      "reward :  -0.347294702606991\n",
      "episode :  24\n",
      "current step :  274\n",
      "reward :  -0.3658723699657749\n",
      "episode :  24\n",
      "current step :  275\n",
      "reward :  -0.405703235659571\n",
      "episode :  24\n",
      "current step :  276\n",
      "reward :  -0.444257648463136\n",
      "episode :  24\n",
      "current step :  277\n",
      "reward :  -0.4009917536981722\n",
      "episode :  24\n",
      "current step :  278\n",
      "reward :  -0.40787582129964384\n",
      "episode :  24\n",
      "current step :  279\n",
      "reward :  -0.3541744435986601\n",
      "episode :  24\n",
      "current step :  280\n",
      "reward :  -0.3831242170401642\n",
      "episode :  24\n",
      "current step :  281\n",
      "reward :  -0.35445710496390936\n",
      "episode :  24\n",
      "current step :  282\n",
      "reward :  -0.3411406536682375\n",
      "episode :  24\n",
      "current step :  283\n",
      "reward :  -0.3481914827753998\n",
      "episode :  24\n",
      "current step :  284\n",
      "reward :  -0.3956733965361695\n",
      "episode :  24\n",
      "current step :  285\n",
      "reward :  -0.33964924264387686\n",
      "episode :  25\n",
      "current step :  0\n",
      "reward :  -0.3644911864358043\n",
      "episode :  25\n",
      "current step :  1\n",
      "reward :  -0.36181131708473163\n",
      "episode :  25\n",
      "current step :  2\n",
      "reward :  -0.3820619289388277\n",
      "episode :  25\n",
      "current step :  3\n",
      "reward :  -0.4213726539689739\n",
      "episode :  25\n",
      "current step :  4\n",
      "reward :  -0.37576767012548623\n",
      "episode :  25\n",
      "current step :  5\n",
      "reward :  -0.3636280664618903\n",
      "episode :  25\n",
      "current step :  6\n",
      "reward :  -0.3624131801459311\n",
      "episode :  25\n",
      "current step :  7\n",
      "reward :  -0.36018713626341975\n",
      "episode :  25\n",
      "current step :  8\n",
      "reward :  -0.3914323512592505\n",
      "episode :  25\n",
      "current step :  9\n",
      "reward :  -0.3581243932319619\n",
      "episode :  25\n",
      "current step :  10\n",
      "reward :  -0.41373807231522486\n",
      "episode :  25\n",
      "current step :  11\n",
      "reward :  -0.3698224905458198\n",
      "episode :  25\n",
      "current step :  12\n",
      "reward :  -0.37548060988939747\n",
      "episode :  25\n",
      "current step :  13\n",
      "reward :  -0.39492889758422683\n",
      "episode :  25\n",
      "current step :  14\n",
      "reward :  -0.37428817446630347\n",
      "episode :  25\n",
      "current step :  15\n",
      "reward :  -0.3733854479721725\n",
      "episode :  25\n",
      "current step :  16\n",
      "reward :  -0.3681360074389484\n",
      "episode :  25\n",
      "current step :  17\n",
      "reward :  -0.3843829375503135\n",
      "episode :  25\n",
      "current step :  18\n",
      "reward :  -0.3862476570985403\n",
      "episode :  25\n",
      "current step :  19\n",
      "reward :  -0.37329939863504474\n",
      "episode :  25\n",
      "current step :  20\n",
      "reward :  -0.37428075141974326\n",
      "episode :  25\n",
      "current step :  21\n",
      "reward :  -0.38957817131675954\n",
      "episode :  25\n",
      "current step :  22\n",
      "reward :  -0.3738186467796814\n",
      "episode :  25\n",
      "current step :  23\n",
      "reward :  -0.4026555718878288\n",
      "episode :  25\n",
      "current step :  24\n",
      "reward :  -0.3956714157909506\n",
      "episode :  25\n",
      "current step :  25\n",
      "reward :  -0.47019919856995795\n",
      "episode :  25\n",
      "current step :  26\n",
      "reward :  -0.5036097910652115\n",
      "episode :  25\n",
      "current step :  27\n",
      "reward :  -0.469541404254827\n",
      "episode :  25\n",
      "current step :  28\n",
      "reward :  -0.5309024021876537\n",
      "episode :  25\n",
      "current step :  29\n",
      "reward :  -0.4839520827568248\n",
      "episode :  25\n",
      "current step :  30\n",
      "reward :  -0.4569705107501954\n",
      "episode :  25\n",
      "current step :  31\n",
      "reward :  -0.44018199608379727\n",
      "episode :  25\n",
      "current step :  32\n",
      "reward :  -0.5743400680781232\n",
      "episode :  25\n",
      "current step :  33\n",
      "reward :  -0.6331675073375643\n",
      "episode :  25\n",
      "current step :  34\n",
      "reward :  -0.6155278579167605\n",
      "episode :  25\n",
      "current step :  35\n",
      "reward :  -0.5754581361041774\n",
      "episode :  25\n",
      "current step :  36\n",
      "reward :  -0.6764518060573756\n",
      "episode :  25\n",
      "current step :  37\n",
      "reward :  -0.5642309187986881\n",
      "episode :  25\n",
      "current step :  38\n",
      "reward :  -0.4787075544899704\n",
      "episode :  25\n",
      "current step :  39\n",
      "reward :  -0.6545744099893389\n",
      "episode :  25\n",
      "current step :  40\n",
      "reward :  -0.6633011296314654\n",
      "episode :  25\n",
      "current step :  41\n",
      "reward :  -0.6409774879667175\n",
      "episode :  25\n",
      "current step :  42\n",
      "reward :  -0.5087896706976681\n",
      "episode :  25\n",
      "current step :  43\n",
      "reward :  -0.5007287178413905\n",
      "episode :  25\n",
      "current step :  44\n",
      "reward :  -0.509651589540269\n",
      "episode :  25\n",
      "current step :  45\n",
      "reward :  -0.6699356884136372\n",
      "episode :  25\n",
      "current step :  46\n",
      "reward :  -0.6291376945404836\n",
      "episode :  25\n",
      "current step :  47\n",
      "reward :  -0.6497887516033175\n",
      "episode :  25\n",
      "current step :  48\n",
      "reward :  -0.6431508561770133\n",
      "episode :  25\n",
      "current step :  49\n",
      "reward :  -0.5357842112992062\n",
      "episode :  25\n",
      "current step :  50\n",
      "reward :  -0.5174733811640514\n",
      "episode :  25\n",
      "current step :  51\n",
      "reward :  -0.5850010465480718\n",
      "episode :  25\n",
      "current step :  52\n",
      "reward :  -0.6118843390678022\n",
      "episode :  25\n",
      "current step :  53\n",
      "reward :  -0.5883893705985777\n",
      "episode :  25\n",
      "current step :  54\n",
      "reward :  -0.5344369744690403\n",
      "episode :  25\n",
      "current step :  55\n",
      "reward :  -0.6519722469099768\n",
      "episode :  25\n",
      "current step :  56\n",
      "reward :  -0.6182472069202279\n",
      "episode :  25\n",
      "current step :  57\n",
      "reward :  -0.6241112227720879\n",
      "episode :  25\n",
      "current step :  58\n",
      "reward :  -0.7399587639245\n",
      "episode :  25\n",
      "current step :  59\n",
      "reward :  -0.7095492648112501\n",
      "episode :  25\n",
      "current step :  60\n",
      "reward :  -0.5964832443946836\n",
      "episode :  25\n",
      "current step :  61\n",
      "reward :  -0.6052228550347085\n",
      "episode :  25\n",
      "current step :  62\n",
      "reward :  -0.49636219665303355\n",
      "episode :  25\n",
      "current step :  63\n",
      "reward :  -0.45701401078372816\n",
      "episode :  25\n",
      "current step :  64\n",
      "reward :  -0.5592771848529445\n",
      "episode :  25\n",
      "current step :  65\n",
      "reward :  -0.6523754999775385\n",
      "episode :  25\n",
      "current step :  66\n",
      "reward :  -0.581927868306822\n",
      "episode :  25\n",
      "current step :  67\n",
      "reward :  -0.6159856317728136\n",
      "episode :  25\n",
      "current step :  68\n",
      "reward :  -0.6666823503072561\n",
      "episode :  25\n",
      "current step :  69\n",
      "reward :  -0.6363865292742836\n",
      "episode :  25\n",
      "current step :  70\n",
      "reward :  -0.4826627113451855\n",
      "episode :  25\n",
      "current step :  71\n",
      "reward :  -0.5604135022758313\n",
      "episode :  25\n",
      "current step :  72\n",
      "reward :  -0.544427387442635\n",
      "episode :  25\n",
      "current step :  73\n",
      "reward :  -0.550005202610475\n",
      "episode :  25\n",
      "current step :  74\n",
      "reward :  -0.49090764697636025\n",
      "episode :  25\n",
      "current step :  75\n",
      "reward :  -0.48303072145675613\n",
      "episode :  25\n",
      "current step :  76\n",
      "reward :  -0.47279168706510794\n",
      "episode :  25\n",
      "current step :  77\n",
      "reward :  -0.5978241524631221\n",
      "episode :  25\n",
      "current step :  78\n",
      "reward :  -0.5491698942144149\n",
      "episode :  25\n",
      "current step :  79\n",
      "reward :  -0.5435213617838542\n",
      "episode :  25\n",
      "current step :  80\n",
      "reward :  -0.6114028579347535\n",
      "episode :  25\n",
      "current step :  81\n",
      "reward :  -0.61752525560104\n",
      "episode :  25\n",
      "current step :  82\n",
      "reward :  -0.5199918964948199\n",
      "episode :  25\n",
      "current step :  83\n",
      "reward :  -0.5374274499500115\n",
      "episode :  25\n",
      "current step :  84\n",
      "reward :  -0.4769375945430001\n",
      "episode :  25\n",
      "current step :  85\n",
      "reward :  -0.4955184108455193\n",
      "episode :  25\n",
      "current step :  86\n",
      "reward :  -0.5417388102172005\n",
      "episode :  25\n",
      "current step :  87\n",
      "reward :  -0.44114484130572823\n",
      "episode :  25\n",
      "current step :  88\n",
      "reward :  -0.44974911360338254\n",
      "episode :  25\n",
      "current step :  89\n",
      "reward :  -0.44195089905703566\n",
      "episode :  25\n",
      "current step :  90\n",
      "reward :  -0.429387258296428\n",
      "episode :  25\n",
      "current step :  91\n",
      "reward :  -0.5211156187040662\n",
      "episode :  25\n",
      "current step :  92\n",
      "reward :  -0.44924795801756656\n",
      "episode :  25\n",
      "current step :  93\n",
      "reward :  -0.4722532549272784\n",
      "episode :  25\n",
      "current step :  94\n",
      "reward :  -0.3643177945733932\n",
      "episode :  25\n",
      "current step :  95\n",
      "reward :  -0.3839749221130829\n",
      "episode :  25\n",
      "current step :  96\n",
      "reward :  -0.3741050281163776\n",
      "episode :  25\n",
      "current step :  97\n",
      "reward :  -0.4145420736319294\n",
      "episode :  25\n",
      "current step :  98\n",
      "reward :  -0.4815505332387187\n",
      "episode :  25\n",
      "current step :  99\n",
      "reward :  -0.3824345791570875\n",
      "episode :  25\n",
      "current step :  100\n",
      "reward :  -0.3569290259064765\n",
      "episode :  25\n",
      "current step :  101\n",
      "reward :  -0.3659216267650718\n",
      "episode :  25\n",
      "current step :  102\n",
      "reward :  -0.3964144269803218\n",
      "episode :  25\n",
      "current step :  103\n",
      "reward :  -0.36136303824218813\n",
      "episode :  25\n",
      "current step :  104\n",
      "reward :  -0.4136741681376158\n",
      "episode :  25\n",
      "current step :  105\n",
      "reward :  -0.4200526307977481\n",
      "episode :  25\n",
      "current step :  106\n",
      "reward :  -0.3852820927124139\n",
      "episode :  25\n",
      "current step :  107\n",
      "reward :  -0.35125250840102146\n",
      "episode :  25\n",
      "current step :  108\n",
      "reward :  -0.37580755304430424\n",
      "episode :  25\n",
      "current step :  109\n",
      "reward :  -0.3559139302571597\n",
      "episode :  25\n",
      "current step :  110\n",
      "reward :  -0.3628785493496272\n",
      "episode :  25\n",
      "current step :  111\n",
      "reward :  -0.38287921754897625\n",
      "episode :  25\n",
      "current step :  112\n",
      "reward :  -0.3940542084201358\n",
      "episode :  25\n",
      "current step :  113\n",
      "reward :  -0.3397419627941774\n",
      "episode :  25\n",
      "current step :  114\n",
      "reward :  -0.35368534154834097\n",
      "episode :  25\n",
      "current step :  115\n",
      "reward :  -0.3773552249506939\n",
      "episode :  25\n",
      "current step :  116\n",
      "reward :  -0.36862050227597887\n",
      "episode :  25\n",
      "current step :  117\n",
      "reward :  -0.3799670536233446\n",
      "episode :  25\n",
      "current step :  118\n",
      "reward :  -0.45280832593729436\n",
      "episode :  25\n",
      "current step :  119\n",
      "reward :  -0.40690308991480834\n",
      "episode :  25\n",
      "current step :  120\n",
      "reward :  -0.33992296675224043\n",
      "episode :  25\n",
      "current step :  121\n",
      "reward :  -0.34070587565529487\n",
      "episode :  25\n",
      "current step :  122\n",
      "reward :  -0.3589952795540376\n",
      "episode :  25\n",
      "current step :  123\n",
      "reward :  -0.3974967731584738\n",
      "episode :  25\n",
      "current step :  124\n",
      "reward :  -0.35143716260246816\n",
      "episode :  25\n",
      "current step :  125\n",
      "reward :  -0.3491258359846636\n",
      "episode :  25\n",
      "current step :  126\n",
      "reward :  -0.3780175671718498\n",
      "episode :  25\n",
      "current step :  127\n",
      "reward :  -0.36221614680718883\n",
      "episode :  25\n",
      "current step :  128\n",
      "reward :  -0.33105103667778435\n",
      "episode :  25\n",
      "current step :  129\n",
      "reward :  -0.3667769433946847\n",
      "episode :  25\n",
      "current step :  130\n",
      "reward :  -0.39404548561562314\n",
      "episode :  25\n",
      "current step :  131\n",
      "reward :  -0.399431030136142\n",
      "episode :  25\n",
      "current step :  132\n",
      "reward :  -0.3313033869209648\n",
      "episode :  25\n",
      "current step :  133\n",
      "reward :  -0.3542996139084449\n",
      "episode :  25\n",
      "current step :  134\n",
      "reward :  -0.37240537500330556\n",
      "episode :  25\n",
      "current step :  135\n",
      "reward :  -0.36310154533510947\n",
      "episode :  25\n",
      "current step :  136\n",
      "reward :  -0.3353437304727098\n",
      "episode :  25\n",
      "current step :  137\n",
      "reward :  -0.3635661818045771\n",
      "episode :  25\n",
      "current step :  138\n",
      "reward :  -0.47288028640333085\n",
      "episode :  25\n",
      "current step :  139\n",
      "reward :  -0.35169023198843957\n",
      "episode :  25\n",
      "current step :  140\n",
      "reward :  -0.42046728596578103\n",
      "episode :  25\n",
      "current step :  141\n",
      "reward :  -0.3232476559307836\n",
      "episode :  25\n",
      "current step :  142\n",
      "reward :  -0.3780603267466769\n",
      "episode :  25\n",
      "current step :  143\n",
      "reward :  -0.3506799086375809\n",
      "episode :  25\n",
      "current step :  144\n",
      "reward :  -0.36177795017657205\n",
      "episode :  25\n",
      "current step :  145\n",
      "reward :  -0.36424653752828784\n",
      "episode :  25\n",
      "current step :  146\n",
      "reward :  -0.3242688260834876\n",
      "episode :  25\n",
      "current step :  147\n",
      "reward :  -0.3321963787634269\n",
      "episode :  25\n",
      "current step :  148\n",
      "reward :  -0.34014526851646915\n",
      "episode :  25\n",
      "current step :  149\n",
      "reward :  -0.41587735749151655\n",
      "episode :  25\n",
      "current step :  150\n",
      "reward :  -0.43648827942738005\n",
      "episode :  25\n",
      "current step :  151\n",
      "reward :  -0.44179232494308057\n",
      "episode :  25\n",
      "current step :  152\n",
      "reward :  -0.4583539412911851\n",
      "episode :  25\n",
      "current step :  153\n",
      "reward :  -0.42918760839140907\n",
      "episode :  25\n",
      "current step :  154\n",
      "reward :  -0.4260701993726235\n",
      "episode :  25\n",
      "current step :  155\n",
      "reward :  -0.38657950133532903\n",
      "episode :  25\n",
      "current step :  156\n",
      "reward :  -0.41948569878817155\n",
      "episode :  25\n",
      "current step :  157\n",
      "reward :  -0.34562169517305885\n",
      "episode :  25\n",
      "current step :  158\n",
      "reward :  -0.3755631788902032\n",
      "episode :  25\n",
      "current step :  159\n",
      "reward :  -0.4819562226496095\n",
      "episode :  25\n",
      "current step :  160\n",
      "reward :  -0.371413303255615\n",
      "episode :  25\n",
      "current step :  161\n",
      "reward :  -0.44905401945610274\n",
      "episode :  25\n",
      "current step :  162\n",
      "reward :  -0.39282224613697864\n",
      "episode :  25\n",
      "current step :  163\n",
      "reward :  -0.3632436088142705\n",
      "episode :  25\n",
      "current step :  164\n",
      "reward :  -0.36412023363702706\n",
      "episode :  25\n",
      "current step :  165\n",
      "reward :  -0.3480029753039755\n",
      "episode :  25\n",
      "current step :  166\n",
      "reward :  -0.38700521536862925\n",
      "episode :  25\n",
      "current step :  167\n",
      "reward :  -0.38024767866604203\n",
      "episode :  25\n",
      "current step :  168\n",
      "reward :  -0.3827524346649726\n",
      "episode :  25\n",
      "current step :  169\n",
      "reward :  -0.34293138651671284\n",
      "episode :  25\n",
      "current step :  170\n",
      "reward :  -0.33799067876708383\n",
      "episode :  25\n",
      "current step :  171\n",
      "reward :  -0.4592761191182256\n",
      "episode :  25\n",
      "current step :  172\n",
      "reward :  -0.3820071911773011\n",
      "episode :  25\n",
      "current step :  173\n",
      "reward :  -0.43419355794147413\n",
      "episode :  25\n",
      "current step :  174\n",
      "reward :  -0.3641631540654866\n",
      "episode :  25\n",
      "current step :  175\n",
      "reward :  -0.39055691101498136\n",
      "episode :  25\n",
      "current step :  176\n",
      "reward :  -0.35052439755532455\n",
      "episode :  25\n",
      "current step :  177\n",
      "reward :  -0.34883715412672106\n",
      "episode :  25\n",
      "current step :  178\n",
      "reward :  -0.40864974639933593\n",
      "episode :  25\n",
      "current step :  179\n",
      "reward :  -0.36628561864084086\n",
      "episode :  25\n",
      "current step :  180\n",
      "reward :  -0.3692747690156469\n",
      "episode :  25\n",
      "current step :  181\n",
      "reward :  -0.34261296895781124\n",
      "episode :  25\n",
      "current step :  182\n",
      "reward :  -0.33722437436519437\n",
      "episode :  25\n",
      "current step :  183\n",
      "reward :  -0.34114179587755356\n",
      "episode :  25\n",
      "current step :  184\n",
      "reward :  -0.3449644798484478\n",
      "episode :  25\n",
      "current step :  185\n",
      "reward :  -0.4603868458400791\n",
      "episode :  25\n",
      "current step :  186\n",
      "reward :  -0.32493934616093184\n",
      "episode :  25\n",
      "current step :  187\n",
      "reward :  -0.35670219243215323\n",
      "episode :  25\n",
      "current step :  188\n",
      "reward :  -0.4378663702271633\n",
      "episode :  25\n",
      "current step :  189\n",
      "reward :  -0.36020297750408303\n",
      "episode :  25\n",
      "current step :  190\n",
      "reward :  -0.35421510595707517\n",
      "episode :  25\n",
      "current step :  191\n",
      "reward :  -0.34649209036415496\n",
      "episode :  25\n",
      "current step :  192\n",
      "reward :  -0.3346593455223715\n",
      "episode :  25\n",
      "current step :  193\n",
      "reward :  -0.3493256088431331\n",
      "episode :  25\n",
      "current step :  194\n",
      "reward :  -0.3791476774552441\n",
      "episode :  25\n",
      "current step :  195\n",
      "reward :  -0.3596795611645048\n",
      "episode :  25\n",
      "current step :  196\n",
      "reward :  -0.45640976362182034\n",
      "episode :  25\n",
      "current step :  197\n",
      "reward :  -0.34150987203088035\n",
      "episode :  25\n",
      "current step :  198\n",
      "reward :  -0.3250620692125027\n",
      "episode :  25\n",
      "current step :  199\n",
      "reward :  -0.3815127695380864\n",
      "episode :  25\n",
      "current step :  200\n",
      "reward :  -0.5223426904960917\n",
      "episode :  25\n",
      "current step :  201\n",
      "reward :  -0.4271268378894869\n",
      "episode :  25\n",
      "current step :  202\n",
      "reward :  -0.3816635723127102\n",
      "episode :  25\n",
      "current step :  203\n",
      "reward :  -0.35984936916738086\n",
      "episode :  25\n",
      "current step :  204\n",
      "reward :  -0.36689328021970263\n",
      "episode :  25\n",
      "current step :  205\n",
      "reward :  -0.34623308207142467\n",
      "episode :  25\n",
      "current step :  206\n",
      "reward :  -0.476088326490325\n",
      "episode :  25\n",
      "current step :  207\n",
      "reward :  -0.33731031125515776\n",
      "episode :  25\n",
      "current step :  208\n",
      "reward :  -0.33637697220489754\n",
      "episode :  25\n",
      "current step :  209\n",
      "reward :  -0.41388000703942207\n",
      "episode :  25\n",
      "current step :  210\n",
      "reward :  -0.4093482922144233\n",
      "episode :  25\n",
      "current step :  211\n",
      "reward :  -0.41868491147837855\n",
      "episode :  25\n",
      "current step :  212\n",
      "reward :  -0.520213743865215\n",
      "episode :  25\n",
      "current step :  213\n",
      "reward :  -0.5268094022616666\n",
      "episode :  25\n",
      "current step :  214\n",
      "reward :  -0.5122540394205591\n",
      "episode :  25\n",
      "current step :  215\n",
      "reward :  -0.3550698413402106\n",
      "episode :  25\n",
      "current step :  216\n",
      "reward :  -0.40381846943891986\n",
      "episode :  25\n",
      "current step :  217\n",
      "reward :  -0.4445311807889032\n",
      "episode :  25\n",
      "current step :  218\n",
      "reward :  -0.3487918315558431\n",
      "episode :  25\n",
      "current step :  219\n",
      "reward :  -0.3183031209068139\n",
      "episode :  25\n",
      "current step :  220\n",
      "reward :  -0.3463836879188393\n",
      "episode :  25\n",
      "current step :  221\n",
      "reward :  -0.34285434638283513\n",
      "episode :  25\n",
      "current step :  222\n",
      "reward :  -0.33833488046654087\n",
      "episode :  25\n",
      "current step :  223\n",
      "reward :  -0.4327814599369427\n",
      "episode :  25\n",
      "current step :  224\n",
      "reward :  -0.4256673714118307\n",
      "episode :  25\n",
      "current step :  225\n",
      "reward :  -0.4271454966311532\n",
      "episode :  25\n",
      "current step :  226\n",
      "reward :  -0.41768979062378575\n",
      "episode :  25\n",
      "current step :  227\n",
      "reward :  -0.4134557097489188\n",
      "episode :  25\n",
      "current step :  228\n",
      "reward :  -0.33715334371082273\n",
      "episode :  25\n",
      "current step :  229\n",
      "reward :  -0.34921954472980826\n",
      "episode :  25\n",
      "current step :  230\n",
      "reward :  -0.3496269124044875\n",
      "episode :  25\n",
      "current step :  231\n",
      "reward :  -0.378958355680429\n",
      "episode :  25\n",
      "current step :  232\n",
      "reward :  -0.4776220210200616\n",
      "episode :  25\n",
      "current step :  233\n",
      "reward :  -0.49982837888404147\n",
      "episode :  25\n",
      "current step :  234\n",
      "reward :  -0.534241581530202\n",
      "episode :  25\n",
      "current step :  235\n",
      "reward :  -0.508149113283761\n",
      "episode :  25\n",
      "current step :  236\n",
      "reward :  -0.5085226382553961\n",
      "episode :  25\n",
      "current step :  237\n",
      "reward :  -0.3304206803877822\n",
      "episode :  25\n",
      "current step :  238\n",
      "reward :  -0.4016759252380432\n",
      "episode :  25\n",
      "current step :  239\n",
      "reward :  -0.3306041064012174\n",
      "episode :  25\n",
      "current step :  240\n",
      "reward :  -0.42217913080227343\n",
      "episode :  25\n",
      "current step :  241\n",
      "reward :  -0.4840347617970052\n",
      "episode :  25\n",
      "current step :  242\n",
      "reward :  -0.3389063744143519\n",
      "episode :  25\n",
      "current step :  243\n",
      "reward :  -0.34856708491064015\n",
      "episode :  25\n",
      "current step :  244\n",
      "reward :  -0.4295622759853376\n",
      "episode :  25\n",
      "current step :  245\n",
      "reward :  -0.3304592902907963\n",
      "episode :  25\n",
      "current step :  246\n",
      "reward :  -0.32706009513311474\n",
      "episode :  25\n",
      "current step :  247\n",
      "reward :  -0.33674668410689906\n",
      "episode :  25\n",
      "current step :  248\n",
      "reward :  -0.3960820119099634\n",
      "episode :  25\n",
      "current step :  249\n",
      "reward :  -0.45173710324651006\n",
      "episode :  25\n",
      "current step :  250\n",
      "reward :  -0.410071467603403\n",
      "episode :  25\n",
      "current step :  251\n",
      "reward :  -0.42785047991547315\n",
      "episode :  25\n",
      "current step :  252\n",
      "reward :  -0.409213120314464\n",
      "episode :  25\n",
      "current step :  253\n",
      "reward :  -0.36578433292596957\n",
      "episode :  25\n",
      "current step :  254\n",
      "reward :  -0.34664683983587735\n",
      "episode :  25\n",
      "current step :  255\n",
      "reward :  -0.4028182869911283\n",
      "episode :  25\n",
      "current step :  256\n",
      "reward :  -0.35871938664868075\n",
      "episode :  25\n",
      "current step :  257\n",
      "reward :  -0.405904419224154\n",
      "episode :  25\n",
      "current step :  258\n",
      "reward :  -0.4554240423469084\n",
      "episode :  25\n",
      "current step :  259\n",
      "reward :  -0.3437608936248882\n",
      "episode :  25\n",
      "current step :  260\n",
      "reward :  -0.3787197405182387\n",
      "episode :  25\n",
      "current step :  261\n",
      "reward :  -0.4541751728680984\n",
      "episode :  25\n",
      "current step :  262\n",
      "reward :  -0.3478302157809575\n",
      "episode :  25\n",
      "current step :  263\n",
      "reward :  -0.37841178588190627\n",
      "episode :  25\n",
      "current step :  264\n",
      "reward :  -0.37505301233034716\n",
      "episode :  25\n",
      "current step :  265\n",
      "reward :  -0.3741841515859105\n",
      "episode :  25\n",
      "current step :  266\n",
      "reward :  -0.3601803245844333\n",
      "episode :  25\n",
      "current step :  267\n",
      "reward :  -0.36255240068256583\n",
      "episode :  25\n",
      "current step :  268\n",
      "reward :  -0.34704216677150884\n",
      "episode :  25\n",
      "current step :  269\n",
      "reward :  -0.36966737750835543\n",
      "episode :  25\n",
      "current step :  270\n",
      "reward :  -0.35484810716669185\n",
      "episode :  25\n",
      "current step :  271\n",
      "reward :  -0.3924898793022457\n",
      "episode :  25\n",
      "current step :  272\n",
      "reward :  -0.33877539023944525\n",
      "episode :  25\n",
      "current step :  273\n",
      "reward :  -0.3830622557213178\n",
      "episode :  25\n",
      "current step :  274\n",
      "reward :  -0.40167712127997185\n",
      "episode :  25\n",
      "current step :  275\n",
      "reward :  -0.338309883796101\n",
      "episode :  25\n",
      "current step :  276\n",
      "reward :  -0.4260418906015924\n",
      "episode :  25\n",
      "current step :  277\n",
      "reward :  -0.34222306601270697\n",
      "episode :  25\n",
      "current step :  278\n",
      "reward :  -0.4178091746179459\n",
      "episode :  25\n",
      "current step :  279\n",
      "reward :  -0.40876492428126315\n",
      "episode :  25\n",
      "current step :  280\n",
      "reward :  -0.38825109475992525\n",
      "episode :  25\n",
      "current step :  281\n",
      "reward :  -0.37124032513958044\n",
      "episode :  25\n",
      "current step :  282\n",
      "reward :  -0.3712315686799831\n",
      "episode :  25\n",
      "current step :  283\n",
      "reward :  -0.4303458516616047\n",
      "episode :  25\n",
      "current step :  284\n",
      "reward :  -0.3648594280544757\n",
      "episode :  25\n",
      "current step :  285\n",
      "reward :  -0.39218788429873075\n",
      "episode :  26\n",
      "current step :  0\n",
      "reward :  -0.3531251571084061\n",
      "episode :  26\n",
      "current step :  1\n",
      "reward :  -0.3520994752532288\n",
      "episode :  26\n",
      "current step :  2\n",
      "reward :  -0.3519677687475322\n",
      "episode :  26\n",
      "current step :  3\n",
      "reward :  -0.3654135700390676\n",
      "episode :  26\n",
      "current step :  4\n",
      "reward :  -0.3725782506355808\n",
      "episode :  26\n",
      "current step :  5\n",
      "reward :  -0.3947991352892535\n",
      "episode :  26\n",
      "current step :  6\n",
      "reward :  -0.3861548205974057\n",
      "episode :  26\n",
      "current step :  7\n",
      "reward :  -0.3524000745251204\n",
      "episode :  26\n",
      "current step :  8\n",
      "reward :  -0.36065314756399086\n",
      "episode :  26\n",
      "current step :  9\n",
      "reward :  -0.36453468468995187\n",
      "episode :  26\n",
      "current step :  10\n",
      "reward :  -0.3902983602372576\n",
      "episode :  26\n",
      "current step :  11\n",
      "reward :  -0.3911149246078936\n",
      "episode :  26\n",
      "current step :  12\n",
      "reward :  -0.3974161954226276\n",
      "episode :  26\n",
      "current step :  13\n",
      "reward :  -0.3614457236963335\n",
      "episode :  26\n",
      "current step :  14\n",
      "reward :  -0.38313467503543513\n",
      "episode :  26\n",
      "current step :  15\n",
      "reward :  -0.3733768153887633\n",
      "episode :  26\n",
      "current step :  16\n",
      "reward :  -0.3811312223421222\n",
      "episode :  26\n",
      "current step :  17\n",
      "reward :  -0.37447025838680315\n",
      "episode :  26\n",
      "current step :  18\n",
      "reward :  -0.4186848075296579\n",
      "episode :  26\n",
      "current step :  19\n",
      "reward :  -0.42740190875877665\n",
      "episode :  26\n",
      "current step :  20\n",
      "reward :  -0.3697754239080522\n",
      "episode :  26\n",
      "current step :  21\n",
      "reward :  -0.5059192604091929\n",
      "episode :  26\n",
      "current step :  22\n",
      "reward :  -0.518283144619066\n",
      "episode :  26\n",
      "current step :  23\n",
      "reward :  -0.5239263455970896\n",
      "episode :  26\n",
      "current step :  24\n",
      "reward :  -0.5511205075242934\n",
      "episode :  26\n",
      "current step :  25\n",
      "reward :  -0.5649461184120007\n",
      "episode :  26\n",
      "current step :  26\n",
      "reward :  -0.536237147523351\n",
      "episode :  26\n",
      "current step :  27\n",
      "reward :  -0.49272911076865067\n",
      "episode :  26\n",
      "current step :  28\n",
      "reward :  -0.5307048166956257\n",
      "episode :  26\n",
      "current step :  29\n",
      "reward :  -0.4606621124159137\n",
      "episode :  26\n",
      "current step :  30\n",
      "reward :  -0.5266829523425515\n",
      "episode :  26\n",
      "current step :  31\n",
      "reward :  -0.5550080613051\n",
      "episode :  26\n",
      "current step :  32\n",
      "reward :  -0.4557017574708269\n",
      "episode :  26\n",
      "current step :  33\n",
      "reward :  -0.6217319277368254\n",
      "episode :  26\n",
      "current step :  34\n",
      "reward :  -0.6779674053458563\n",
      "episode :  26\n",
      "current step :  35\n",
      "reward :  -0.6422006441661586\n",
      "episode :  26\n",
      "current step :  36\n",
      "reward :  -0.46393260819789\n",
      "episode :  26\n",
      "current step :  37\n",
      "reward :  -0.4548612422562956\n",
      "episode :  26\n",
      "current step :  38\n",
      "reward :  -0.42483323851987653\n",
      "episode :  26\n",
      "current step :  39\n",
      "reward :  -0.5922670213069484\n",
      "episode :  26\n",
      "current step :  40\n",
      "reward :  -0.6483449391569782\n",
      "episode :  26\n",
      "current step :  41\n",
      "reward :  -0.6142024935526941\n",
      "episode :  26\n",
      "current step :  42\n",
      "reward :  -0.5828853154825032\n",
      "episode :  26\n",
      "current step :  43\n",
      "reward :  -0.5064066026344448\n",
      "episode :  26\n",
      "current step :  44\n",
      "reward :  -0.44553144171151293\n",
      "episode :  26\n",
      "current step :  45\n",
      "reward :  -0.4838761046673491\n",
      "episode :  26\n",
      "current step :  46\n",
      "reward :  -0.42041144445968587\n",
      "episode :  26\n",
      "current step :  47\n",
      "reward :  -0.4693014718203182\n",
      "episode :  26\n",
      "current step :  48\n",
      "reward :  -0.4523741020486246\n",
      "episode :  26\n",
      "current step :  49\n",
      "reward :  -0.4091178162594558\n",
      "episode :  26\n",
      "current step :  50\n",
      "reward :  -0.4304221429093682\n",
      "episode :  26\n",
      "current step :  51\n",
      "reward :  -0.41864187157948923\n",
      "episode :  26\n",
      "current step :  52\n",
      "reward :  -0.4993691890197521\n",
      "episode :  26\n",
      "current step :  53\n",
      "reward :  -0.5494932483543381\n",
      "episode :  26\n",
      "current step :  54\n",
      "reward :  -0.565018735232038\n",
      "episode :  26\n",
      "current step :  55\n",
      "reward :  -0.5145137152267435\n",
      "episode :  26\n",
      "current step :  56\n",
      "reward :  -0.4874137964002452\n",
      "episode :  26\n",
      "current step :  57\n",
      "reward :  -0.6123535466755442\n",
      "episode :  26\n",
      "current step :  58\n",
      "reward :  -0.4838032239467761\n",
      "episode :  26\n",
      "current step :  59\n",
      "reward :  -0.49246377298716054\n",
      "episode :  26\n",
      "current step :  60\n",
      "reward :  -0.4400843335030633\n",
      "episode :  26\n",
      "current step :  61\n",
      "reward :  -0.5660498321586784\n",
      "episode :  26\n",
      "current step :  62\n",
      "reward :  -0.5615595988774454\n",
      "episode :  26\n",
      "current step :  63\n",
      "reward :  -0.5065188012150905\n",
      "episode :  26\n",
      "current step :  64\n",
      "reward :  -0.4566168190644336\n",
      "episode :  26\n",
      "current step :  65\n",
      "reward :  -0.5312313116357408\n",
      "episode :  26\n",
      "current step :  66\n",
      "reward :  -0.4662438970365518\n",
      "episode :  26\n",
      "current step :  67\n",
      "reward :  -0.5574439069231518\n",
      "episode :  26\n",
      "current step :  68\n",
      "reward :  -0.5130715354319719\n",
      "episode :  26\n",
      "current step :  69\n",
      "reward :  -0.44001829283883875\n",
      "episode :  26\n",
      "current step :  70\n",
      "reward :  -0.4596058596466789\n",
      "episode :  26\n",
      "current step :  71\n",
      "reward :  -0.5089122501582293\n",
      "episode :  26\n",
      "current step :  72\n",
      "reward :  -0.5064114638979751\n",
      "episode :  26\n",
      "current step :  73\n",
      "reward :  -0.45384299211129353\n",
      "episode :  26\n",
      "current step :  74\n",
      "reward :  -0.4962386579421773\n",
      "episode :  26\n",
      "current step :  75\n",
      "reward :  -0.5060872580619161\n",
      "episode :  26\n",
      "current step :  76\n",
      "reward :  -0.5017536266243355\n",
      "episode :  26\n",
      "current step :  77\n",
      "reward :  -0.5180202998844909\n",
      "episode :  26\n",
      "current step :  78\n",
      "reward :  -0.5192072033550058\n",
      "episode :  26\n",
      "current step :  79\n",
      "reward :  -0.5133901399890562\n",
      "episode :  26\n",
      "current step :  80\n",
      "reward :  -0.535267591399815\n",
      "episode :  26\n",
      "current step :  81\n",
      "reward :  -0.5325973700018428\n",
      "episode :  26\n",
      "current step :  82\n",
      "reward :  -0.5303651486490952\n",
      "episode :  26\n",
      "current step :  83\n",
      "reward :  -0.5010439623137679\n",
      "episode :  26\n",
      "current step :  84\n",
      "reward :  -0.5116078776932061\n",
      "episode :  26\n",
      "current step :  85\n",
      "reward :  -0.5051316663178518\n",
      "episode :  26\n",
      "current step :  86\n",
      "reward :  -0.5098230233894123\n",
      "episode :  26\n",
      "current step :  87\n",
      "reward :  -0.5302376978145528\n",
      "episode :  26\n",
      "current step :  88\n",
      "reward :  -0.4853446704388895\n",
      "episode :  26\n",
      "current step :  89\n",
      "reward :  -0.518126234004238\n",
      "episode :  26\n",
      "current step :  90\n",
      "reward :  -0.5413883351786816\n",
      "episode :  26\n",
      "current step :  91\n",
      "reward :  -0.5451826755040243\n",
      "episode :  26\n",
      "current step :  92\n",
      "reward :  -0.553829574952015\n",
      "episode :  26\n",
      "current step :  93\n",
      "reward :  -0.5590162322896011\n",
      "episode :  26\n",
      "current step :  94\n",
      "reward :  -0.5634661121798223\n",
      "episode :  26\n",
      "current step :  95\n",
      "reward :  -0.5552649604050259\n",
      "episode :  26\n",
      "current step :  96\n",
      "reward :  -0.5158252140253383\n",
      "episode :  26\n",
      "current step :  97\n",
      "reward :  -0.5325790634845955\n",
      "episode :  26\n",
      "current step :  98\n",
      "reward :  -0.5259235775710817\n",
      "episode :  26\n",
      "current step :  99\n",
      "reward :  -0.5073884850500922\n",
      "episode :  26\n",
      "current step :  100\n",
      "reward :  -0.5545959217775223\n",
      "episode :  26\n",
      "current step :  101\n",
      "reward :  -0.544723416322578\n",
      "episode :  26\n",
      "current step :  102\n",
      "reward :  -0.49821475191456727\n",
      "episode :  26\n",
      "current step :  103\n",
      "reward :  -0.5147761213395031\n",
      "episode :  26\n",
      "current step :  104\n",
      "reward :  -0.514660672489823\n",
      "episode :  26\n",
      "current step :  105\n",
      "reward :  -0.5517534746983757\n",
      "episode :  26\n",
      "current step :  106\n",
      "reward :  -0.5567177881255095\n",
      "episode :  26\n",
      "current step :  107\n",
      "reward :  -0.5688097918344007\n",
      "episode :  26\n",
      "current step :  108\n",
      "reward :  -0.5268879482312213\n",
      "episode :  26\n",
      "current step :  109\n",
      "reward :  -0.500306875490292\n",
      "episode :  26\n",
      "current step :  110\n",
      "reward :  -0.5332911937536401\n",
      "episode :  26\n",
      "current step :  111\n",
      "reward :  -0.5180111878365987\n",
      "episode :  26\n",
      "current step :  112\n",
      "reward :  -0.5112308685701838\n",
      "episode :  26\n",
      "current step :  113\n",
      "reward :  -0.5461122591085809\n",
      "episode :  26\n",
      "current step :  114\n",
      "reward :  -0.5328368420331543\n",
      "episode :  26\n",
      "current step :  115\n",
      "reward :  -0.5445076315895218\n",
      "episode :  26\n",
      "current step :  116\n",
      "reward :  -0.42553159834928245\n",
      "episode :  26\n",
      "current step :  117\n",
      "reward :  -0.4426618749840565\n",
      "episode :  26\n",
      "current step :  118\n",
      "reward :  -0.5676824498269081\n",
      "episode :  26\n",
      "current step :  119\n",
      "reward :  -0.5581842185289083\n",
      "episode :  26\n",
      "current step :  120\n",
      "reward :  -0.5592976370733487\n",
      "episode :  26\n",
      "current step :  121\n",
      "reward :  -0.5135965551666254\n",
      "episode :  26\n",
      "current step :  122\n",
      "reward :  -0.5165727053017581\n",
      "episode :  26\n",
      "current step :  123\n",
      "reward :  -0.5152617028111214\n",
      "episode :  26\n",
      "current step :  124\n",
      "reward :  -0.521163597235631\n",
      "episode :  26\n",
      "current step :  125\n",
      "reward :  -0.5633053034920523\n",
      "episode :  26\n",
      "current step :  126\n",
      "reward :  -0.5318471961712316\n",
      "episode :  26\n",
      "current step :  127\n",
      "reward :  -0.5576507800722614\n",
      "episode :  26\n",
      "current step :  128\n",
      "reward :  -0.562867419521717\n",
      "episode :  26\n",
      "current step :  129\n",
      "reward :  -0.5296824791498482\n",
      "episode :  26\n",
      "current step :  130\n",
      "reward :  -0.5090021524964488\n",
      "episode :  26\n",
      "current step :  131\n",
      "reward :  -0.5602315965133595\n",
      "episode :  26\n",
      "current step :  132\n",
      "reward :  -0.5710403075768722\n",
      "episode :  26\n",
      "current step :  133\n",
      "reward :  -0.5263897033324014\n",
      "episode :  26\n",
      "current step :  134\n",
      "reward :  -0.399232441117814\n",
      "episode :  26\n",
      "current step :  135\n",
      "reward :  -0.530486610589818\n",
      "episode :  26\n",
      "current step :  136\n",
      "reward :  -0.5547411452148368\n",
      "episode :  26\n",
      "current step :  137\n",
      "reward :  -0.564802291380177\n",
      "episode :  26\n",
      "current step :  138\n",
      "reward :  -0.5576318433787675\n",
      "episode :  26\n",
      "current step :  139\n",
      "reward :  -0.5534490010084432\n",
      "episode :  26\n",
      "current step :  140\n",
      "reward :  -0.5313706103139334\n",
      "episode :  26\n",
      "current step :  141\n",
      "reward :  -0.5456855552952982\n",
      "episode :  26\n",
      "current step :  142\n",
      "reward :  -0.47647942537323806\n",
      "episode :  26\n",
      "current step :  143\n",
      "reward :  -0.45977927926220913\n",
      "episode :  26\n",
      "current step :  144\n",
      "reward :  -0.4986414388354324\n",
      "episode :  26\n",
      "current step :  145\n",
      "reward :  -0.5336888434549688\n",
      "episode :  26\n",
      "current step :  146\n",
      "reward :  -0.4800150421023624\n",
      "episode :  26\n",
      "current step :  147\n",
      "reward :  -0.5776653997082747\n",
      "episode :  26\n",
      "current step :  148\n",
      "reward :  -0.5498780278708573\n",
      "episode :  26\n",
      "current step :  149\n",
      "reward :  -0.5736835948554927\n",
      "episode :  26\n",
      "current step :  150\n",
      "reward :  -0.49257824960465507\n",
      "episode :  26\n",
      "current step :  151\n",
      "reward :  -0.4191602143719793\n",
      "episode :  26\n",
      "current step :  152\n",
      "reward :  -0.4788968253435478\n",
      "episode :  26\n",
      "current step :  153\n",
      "reward :  -0.602820913955827\n",
      "episode :  26\n",
      "current step :  154\n",
      "reward :  -0.6185060108759403\n",
      "episode :  26\n",
      "current step :  155\n",
      "reward :  -0.6000190916247381\n",
      "episode :  26\n",
      "current step :  156\n",
      "reward :  -0.5821846107761901\n",
      "episode :  26\n",
      "current step :  157\n",
      "reward :  -0.40089439773863006\n",
      "episode :  26\n",
      "current step :  158\n",
      "reward :  -0.5146084025833505\n",
      "episode :  26\n",
      "current step :  159\n",
      "reward :  -0.5358299930885387\n",
      "episode :  26\n",
      "current step :  160\n",
      "reward :  -0.45159298379398355\n",
      "episode :  26\n",
      "current step :  161\n",
      "reward :  -0.5896139423012368\n",
      "episode :  26\n",
      "current step :  162\n",
      "reward :  -0.5875847836958884\n",
      "episode :  26\n",
      "current step :  163\n",
      "reward :  -0.6363715200365877\n",
      "episode :  26\n",
      "current step :  164\n",
      "reward :  -0.6387946021232745\n",
      "episode :  26\n",
      "current step :  165\n",
      "reward :  -0.6360678668230518\n",
      "episode :  26\n",
      "current step :  166\n",
      "reward :  -0.5968632108686966\n",
      "episode :  26\n",
      "current step :  167\n",
      "reward :  -0.49833214652914826\n",
      "episode :  26\n",
      "current step :  168\n",
      "reward :  -0.6201566295821506\n",
      "episode :  26\n",
      "current step :  169\n",
      "reward :  -0.5428038867787128\n",
      "episode :  26\n",
      "current step :  170\n",
      "reward :  -0.5493855194753001\n",
      "episode :  26\n",
      "current step :  171\n",
      "reward :  -0.5480449946563789\n",
      "episode :  26\n",
      "current step :  172\n",
      "reward :  -0.5586487170167082\n",
      "episode :  26\n",
      "current step :  173\n",
      "reward :  -0.5671939946616804\n",
      "episode :  26\n",
      "current step :  174\n",
      "reward :  -0.4670319135061434\n",
      "episode :  26\n",
      "current step :  175\n",
      "reward :  -0.3829117050144337\n",
      "episode :  26\n",
      "current step :  176\n",
      "reward :  -0.4366151395187971\n",
      "episode :  26\n",
      "current step :  177\n",
      "reward :  -0.5123180187973492\n",
      "episode :  26\n",
      "current step :  178\n",
      "reward :  -0.464513084621074\n",
      "episode :  26\n",
      "current step :  179\n",
      "reward :  -0.49191146136063124\n",
      "episode :  26\n",
      "current step :  180\n",
      "reward :  -0.35852461201931074\n",
      "episode :  26\n",
      "current step :  181\n",
      "reward :  -0.39677431791130996\n",
      "episode :  26\n",
      "current step :  182\n",
      "reward :  -0.5059090580461563\n",
      "episode :  26\n",
      "current step :  183\n",
      "reward :  -0.5226519204735537\n",
      "episode :  26\n",
      "current step :  184\n",
      "reward :  -0.5870287559314478\n",
      "episode :  26\n",
      "current step :  185\n",
      "reward :  -0.6505306594260559\n",
      "episode :  26\n",
      "current step :  186\n",
      "reward :  -0.5571182787600145\n",
      "episode :  26\n",
      "current step :  187\n",
      "reward :  -0.6037978059316123\n",
      "episode :  26\n",
      "current step :  188\n",
      "reward :  -0.5197226862875841\n",
      "episode :  26\n",
      "current step :  189\n",
      "reward :  -0.5045620299260289\n",
      "episode :  26\n",
      "current step :  190\n",
      "reward :  -0.38538899697981616\n",
      "episode :  26\n",
      "current step :  191\n",
      "reward :  -0.4027486844532743\n",
      "episode :  26\n",
      "current step :  192\n",
      "reward :  -0.5604626350481089\n",
      "episode :  26\n",
      "current step :  193\n",
      "reward :  -0.6189094960660225\n",
      "episode :  26\n",
      "current step :  194\n",
      "reward :  -0.47778757143240136\n",
      "episode :  26\n",
      "current step :  195\n",
      "reward :  -0.500453776866053\n",
      "episode :  26\n",
      "current step :  196\n",
      "reward :  -0.5228797353306662\n",
      "episode :  26\n",
      "current step :  197\n",
      "reward :  -0.6050748997453029\n",
      "episode :  26\n",
      "current step :  198\n",
      "reward :  -0.6251795465418535\n",
      "episode :  26\n",
      "current step :  199\n",
      "reward :  -0.506185526109691\n",
      "episode :  26\n",
      "current step :  200\n",
      "reward :  -0.5506312300404289\n",
      "episode :  26\n",
      "current step :  201\n",
      "reward :  -0.6078146751955612\n",
      "episode :  26\n",
      "current step :  202\n",
      "reward :  -0.5996678323107454\n",
      "episode :  26\n",
      "current step :  203\n",
      "reward :  -0.6163102521066589\n",
      "episode :  26\n",
      "current step :  204\n",
      "reward :  -0.6484793353315966\n",
      "episode :  26\n",
      "current step :  205\n",
      "reward :  -0.6354122311444242\n",
      "episode :  26\n",
      "current step :  206\n",
      "reward :  -0.6116073309640545\n",
      "episode :  26\n",
      "current step :  207\n",
      "reward :  -0.5968766841912934\n",
      "episode :  26\n",
      "current step :  208\n",
      "reward :  -0.6065594932846168\n",
      "episode :  26\n",
      "current step :  209\n",
      "reward :  -0.559395288748451\n",
      "episode :  26\n",
      "current step :  210\n",
      "reward :  -0.6357488359897182\n",
      "episode :  26\n",
      "current step :  211\n",
      "reward :  -0.58574766422962\n",
      "episode :  26\n",
      "current step :  212\n",
      "reward :  -0.6476176677781659\n",
      "episode :  26\n",
      "current step :  213\n",
      "reward :  -0.6416700491406584\n",
      "episode :  26\n",
      "current step :  214\n",
      "reward :  -0.597135205768225\n",
      "episode :  26\n",
      "current step :  215\n",
      "reward :  -0.6534541861384275\n",
      "episode :  26\n",
      "current step :  216\n",
      "reward :  -0.6504582998743785\n",
      "episode :  26\n",
      "current step :  217\n",
      "reward :  -0.6485185795436679\n",
      "episode :  26\n",
      "current step :  218\n",
      "reward :  -0.6524798844608103\n",
      "episode :  26\n",
      "current step :  219\n",
      "reward :  -0.6433070856159078\n",
      "episode :  26\n",
      "current step :  220\n",
      "reward :  -0.5458634117248313\n",
      "episode :  26\n",
      "current step :  221\n",
      "reward :  -0.6324900500686587\n",
      "episode :  26\n",
      "current step :  222\n",
      "reward :  -0.6396892885148526\n",
      "episode :  26\n",
      "current step :  223\n",
      "reward :  -0.6405640627274798\n",
      "episode :  26\n",
      "current step :  224\n",
      "reward :  -0.6418184914496657\n",
      "episode :  26\n",
      "current step :  225\n",
      "reward :  -0.6587122500172501\n",
      "episode :  26\n",
      "current step :  226\n",
      "reward :  -0.6347632310134427\n",
      "episode :  26\n",
      "current step :  227\n",
      "reward :  -0.6596364411635429\n",
      "episode :  26\n",
      "current step :  228\n",
      "reward :  -0.5494770058941084\n",
      "episode :  26\n",
      "current step :  229\n",
      "reward :  -0.6271270995653084\n",
      "episode :  26\n",
      "current step :  230\n",
      "reward :  -0.6411219386296381\n",
      "episode :  26\n",
      "current step :  231\n",
      "reward :  -0.6213374290012399\n",
      "episode :  26\n",
      "current step :  232\n",
      "reward :  -0.618320701243932\n",
      "episode :  26\n",
      "current step :  233\n",
      "reward :  -0.6514183370616484\n",
      "episode :  26\n",
      "current step :  234\n",
      "reward :  -0.6603066109012526\n",
      "episode :  26\n",
      "current step :  235\n",
      "reward :  -0.6074791733725798\n",
      "episode :  26\n",
      "current step :  236\n",
      "reward :  -0.5572890889792385\n",
      "episode :  26\n",
      "current step :  237\n",
      "reward :  -0.522359001968773\n",
      "episode :  26\n",
      "current step :  238\n",
      "reward :  -0.5780555607305747\n",
      "episode :  26\n",
      "current step :  239\n",
      "reward :  -0.5775950393455518\n",
      "episode :  26\n",
      "current step :  240\n",
      "reward :  -0.500692588498135\n",
      "episode :  26\n",
      "current step :  241\n",
      "reward :  -0.5264244367863218\n",
      "episode :  26\n",
      "current step :  242\n",
      "reward :  -0.5828072588896169\n",
      "episode :  26\n",
      "current step :  243\n",
      "reward :  -0.5893176754150992\n",
      "episode :  26\n",
      "current step :  244\n",
      "reward :  -0.5828528896849917\n",
      "episode :  26\n",
      "current step :  245\n",
      "reward :  -0.5757417156907799\n",
      "episode :  26\n",
      "current step :  246\n",
      "reward :  -0.5748852944625121\n",
      "episode :  26\n",
      "current step :  247\n",
      "reward :  -0.5889154524203164\n",
      "episode :  26\n",
      "current step :  248\n",
      "reward :  -0.5854089873366035\n",
      "episode :  26\n",
      "current step :  249\n",
      "reward :  -0.5460318235069219\n",
      "episode :  26\n",
      "current step :  250\n",
      "reward :  -0.5740382156418442\n",
      "episode :  26\n",
      "current step :  251\n",
      "reward :  -0.5170735345248525\n",
      "episode :  26\n",
      "current step :  252\n",
      "reward :  -0.5282307938629512\n",
      "episode :  26\n",
      "current step :  253\n",
      "reward :  -0.5264513305761429\n",
      "episode :  26\n",
      "current step :  254\n",
      "reward :  -0.510511811474347\n",
      "episode :  26\n",
      "current step :  255\n",
      "reward :  -0.5535550339048951\n",
      "episode :  26\n",
      "current step :  256\n",
      "reward :  -0.5270701315720842\n",
      "episode :  26\n",
      "current step :  257\n",
      "reward :  -0.5349685777792395\n",
      "episode :  26\n",
      "current step :  258\n",
      "reward :  -0.5610306644243979\n",
      "episode :  26\n",
      "current step :  259\n",
      "reward :  -0.5466803376588758\n",
      "episode :  26\n",
      "current step :  260\n",
      "reward :  -0.5479113223196661\n",
      "episode :  26\n",
      "current step :  261\n",
      "reward :  -0.5246820428171021\n",
      "episode :  26\n",
      "current step :  262\n",
      "reward :  -0.5055697308841515\n",
      "episode :  26\n",
      "current step :  263\n",
      "reward :  -0.538557014475031\n",
      "episode :  26\n",
      "current step :  264\n",
      "reward :  -0.48980663049253004\n",
      "episode :  26\n",
      "current step :  265\n",
      "reward :  -0.5529612804562767\n",
      "episode :  26\n",
      "current step :  266\n",
      "reward :  -0.5412337672352432\n",
      "episode :  26\n",
      "current step :  267\n",
      "reward :  -0.5558643473708682\n",
      "episode :  26\n",
      "current step :  268\n",
      "reward :  -0.5600933147018738\n",
      "episode :  26\n",
      "current step :  269\n",
      "reward :  -0.5258037893402988\n",
      "episode :  26\n",
      "current step :  270\n",
      "reward :  -0.5353380995233423\n",
      "episode :  26\n",
      "current step :  271\n",
      "reward :  -0.49405130803677194\n",
      "episode :  26\n",
      "current step :  272\n",
      "reward :  -0.5204191117944668\n",
      "episode :  26\n",
      "current step :  273\n",
      "reward :  -0.5295811842201896\n",
      "episode :  26\n",
      "current step :  274\n",
      "reward :  -0.5482716763973597\n",
      "episode :  26\n",
      "current step :  275\n",
      "reward :  -0.5282878901224456\n",
      "episode :  26\n",
      "current step :  276\n",
      "reward :  -0.4710329669544656\n",
      "episode :  26\n",
      "current step :  277\n",
      "reward :  -0.503280899503524\n",
      "episode :  26\n",
      "current step :  278\n",
      "reward :  -0.5211351500212741\n",
      "episode :  26\n",
      "current step :  279\n",
      "reward :  -0.5066148206773236\n",
      "episode :  26\n",
      "current step :  280\n",
      "reward :  -0.4216985292057962\n",
      "episode :  26\n",
      "current step :  281\n",
      "reward :  -0.5060537534646844\n",
      "episode :  26\n",
      "current step :  282\n",
      "reward :  -0.5263770038802907\n",
      "episode :  26\n",
      "current step :  283\n",
      "reward :  -0.4781234766977653\n",
      "episode :  26\n",
      "current step :  284\n",
      "reward :  -0.5474847925656237\n",
      "episode :  26\n",
      "current step :  285\n",
      "reward :  -0.5230645117980423\n",
      "episode :  27\n",
      "current step :  0\n",
      "reward :  -0.3796344431223343\n",
      "episode :  27\n",
      "current step :  1\n",
      "reward :  -0.38372907793958694\n",
      "episode :  27\n",
      "current step :  2\n",
      "reward :  -0.3627561251458888\n",
      "episode :  27\n",
      "current step :  3\n",
      "reward :  -0.37456427689489313\n",
      "episode :  27\n",
      "current step :  4\n",
      "reward :  -0.5330253280535008\n",
      "episode :  27\n",
      "current step :  5\n",
      "reward :  -0.5553495412445641\n",
      "episode :  27\n",
      "current step :  6\n",
      "reward :  -0.5492518098467233\n",
      "episode :  27\n",
      "current step :  7\n",
      "reward :  -0.5361383498429535\n",
      "episode :  27\n",
      "current step :  8\n",
      "reward :  -0.534395514330856\n",
      "episode :  27\n",
      "current step :  9\n",
      "reward :  -0.5113634026332914\n",
      "episode :  27\n",
      "current step :  10\n",
      "reward :  -0.5039339455138931\n",
      "episode :  27\n",
      "current step :  11\n",
      "reward :  -0.5043376067480921\n",
      "episode :  27\n",
      "current step :  12\n",
      "reward :  -0.5344682828418832\n",
      "episode :  27\n",
      "current step :  13\n",
      "reward :  -0.5368294437671574\n",
      "episode :  27\n",
      "current step :  14\n",
      "reward :  -0.5347147835213134\n",
      "episode :  27\n",
      "current step :  15\n",
      "reward :  -0.5263611023102531\n",
      "episode :  27\n",
      "current step :  16\n",
      "reward :  -0.49531765951912177\n",
      "episode :  27\n",
      "current step :  17\n",
      "reward :  -0.5393213762951494\n",
      "episode :  27\n",
      "current step :  18\n",
      "reward :  -0.5279222400820287\n",
      "episode :  27\n",
      "current step :  19\n",
      "reward :  -0.5447232433587225\n",
      "episode :  27\n",
      "current step :  20\n",
      "reward :  -0.5448572590845778\n",
      "episode :  27\n",
      "current step :  21\n",
      "reward :  -0.5368965192185745\n",
      "episode :  27\n",
      "current step :  22\n",
      "reward :  -0.5327756413536479\n",
      "episode :  27\n",
      "current step :  23\n",
      "reward :  -0.5185604617100386\n",
      "episode :  27\n",
      "current step :  24\n",
      "reward :  -0.5177878812972272\n",
      "episode :  27\n",
      "current step :  25\n",
      "reward :  -0.525678074072625\n",
      "episode :  27\n",
      "current step :  26\n",
      "reward :  -0.5162852025572782\n",
      "episode :  27\n",
      "current step :  27\n",
      "reward :  -0.5288789345515283\n",
      "episode :  27\n",
      "current step :  28\n",
      "reward :  -0.5136332802487327\n",
      "episode :  27\n",
      "current step :  29\n",
      "reward :  -0.5017540499121548\n",
      "episode :  27\n",
      "current step :  30\n",
      "reward :  -0.48967345067430923\n",
      "episode :  27\n",
      "current step :  31\n",
      "reward :  -0.48690373023028466\n",
      "episode :  27\n",
      "current step :  32\n",
      "reward :  -0.4944294406793206\n",
      "episode :  27\n",
      "current step :  33\n",
      "reward :  -0.4904250285213639\n",
      "episode :  27\n",
      "current step :  34\n",
      "reward :  -0.4834623378412106\n",
      "episode :  27\n",
      "current step :  35\n",
      "reward :  -0.4825084726973251\n",
      "episode :  27\n",
      "current step :  36\n",
      "reward :  -0.4736106036013214\n",
      "episode :  27\n",
      "current step :  37\n",
      "reward :  -0.44550198711955874\n",
      "episode :  27\n",
      "current step :  38\n",
      "reward :  -0.43116867123518615\n",
      "episode :  27\n",
      "current step :  39\n",
      "reward :  -0.42539529877861726\n",
      "episode :  27\n",
      "current step :  40\n",
      "reward :  -0.4093552065008992\n",
      "episode :  27\n",
      "current step :  41\n",
      "reward :  -0.39122476455571803\n",
      "episode :  27\n",
      "current step :  42\n",
      "reward :  -0.3746664419148741\n",
      "episode :  27\n",
      "current step :  43\n",
      "reward :  -0.35225450760722404\n",
      "episode :  27\n",
      "current step :  44\n",
      "reward :  -0.3576921242017856\n",
      "episode :  27\n",
      "current step :  45\n",
      "reward :  -0.37893711115839523\n",
      "episode :  27\n",
      "current step :  46\n",
      "reward :  -0.32543484468638056\n",
      "episode :  27\n",
      "current step :  47\n",
      "reward :  -0.31346061083017795\n",
      "episode :  27\n",
      "current step :  48\n",
      "reward :  -0.3084008114432937\n",
      "episode :  27\n",
      "current step :  49\n",
      "reward :  -0.32199354554854676\n",
      "episode :  27\n",
      "current step :  50\n",
      "reward :  -0.2940668166302223\n",
      "episode :  27\n",
      "current step :  51\n",
      "reward :  -0.36073163151948\n",
      "episode :  27\n",
      "current step :  52\n",
      "reward :  -0.3160394408664668\n",
      "episode :  27\n",
      "current step :  53\n",
      "reward :  -0.369225218552304\n",
      "episode :  27\n",
      "current step :  54\n",
      "reward :  -0.3989888069466902\n",
      "episode :  27\n",
      "current step :  55\n",
      "reward :  -0.32173454737973767\n",
      "episode :  27\n",
      "current step :  56\n",
      "reward :  -0.31200202212056827\n",
      "episode :  27\n",
      "current step :  57\n",
      "reward :  -0.3328266643100763\n",
      "episode :  27\n",
      "current step :  58\n",
      "reward :  -0.31854218428430753\n",
      "episode :  27\n",
      "current step :  59\n",
      "reward :  -0.3079290561450586\n",
      "episode :  27\n",
      "current step :  60\n",
      "reward :  -0.28713321125303554\n",
      "episode :  27\n",
      "current step :  61\n",
      "reward :  -0.3114932804568078\n",
      "episode :  27\n",
      "current step :  62\n",
      "reward :  -0.3031605840873567\n",
      "episode :  27\n",
      "current step :  63\n",
      "reward :  -0.3006362364775028\n",
      "episode :  27\n",
      "current step :  64\n",
      "reward :  -0.287927156489241\n",
      "episode :  27\n",
      "current step :  65\n",
      "reward :  -0.3031961061181164\n",
      "episode :  27\n",
      "current step :  66\n",
      "reward :  -0.290489438899723\n",
      "episode :  27\n",
      "current step :  67\n",
      "reward :  -0.28401091763501685\n",
      "episode :  27\n",
      "current step :  68\n",
      "reward :  -0.35168811794554244\n",
      "episode :  27\n",
      "current step :  69\n",
      "reward :  -0.3100582678816382\n",
      "episode :  27\n",
      "current step :  70\n",
      "reward :  -0.28574522511422457\n",
      "episode :  27\n",
      "current step :  71\n",
      "reward :  -0.28193249124310105\n",
      "episode :  27\n",
      "current step :  72\n",
      "reward :  -0.3015766286846535\n",
      "episode :  27\n",
      "current step :  73\n",
      "reward :  -0.2887276498242779\n",
      "episode :  27\n",
      "current step :  74\n",
      "reward :  -0.31339459365082084\n",
      "episode :  27\n",
      "current step :  75\n",
      "reward :  -0.3691526633532634\n",
      "episode :  27\n",
      "current step :  76\n",
      "reward :  -0.306444981796112\n",
      "episode :  27\n",
      "current step :  77\n",
      "reward :  -0.300392474034186\n",
      "episode :  27\n",
      "current step :  78\n",
      "reward :  -0.29542684803930297\n",
      "episode :  27\n",
      "current step :  79\n",
      "reward :  -0.29833180695063344\n",
      "episode :  27\n",
      "current step :  80\n",
      "reward :  -0.3032279910383616\n",
      "episode :  27\n",
      "current step :  81\n",
      "reward :  -0.31014193913221005\n",
      "episode :  27\n",
      "current step :  82\n",
      "reward :  -0.323222009592343\n",
      "episode :  27\n",
      "current step :  83\n",
      "reward :  -0.3488077061858056\n",
      "episode :  27\n",
      "current step :  84\n",
      "reward :  -0.35750713287797714\n",
      "episode :  27\n",
      "current step :  85\n",
      "reward :  -0.35914472004201986\n",
      "episode :  27\n",
      "current step :  86\n",
      "reward :  -0.39438455839222275\n",
      "episode :  27\n",
      "current step :  87\n",
      "reward :  -0.42154444505431615\n",
      "episode :  27\n",
      "current step :  88\n",
      "reward :  -0.3940307590992425\n",
      "episode :  27\n",
      "current step :  89\n",
      "reward :  -0.4094956083242949\n",
      "episode :  27\n",
      "current step :  90\n",
      "reward :  -0.4340863534308673\n",
      "episode :  27\n",
      "current step :  91\n",
      "reward :  -0.45010867795041437\n",
      "episode :  27\n",
      "current step :  92\n",
      "reward :  -0.4521320818556659\n",
      "episode :  27\n",
      "current step :  93\n",
      "reward :  -0.47012697325001873\n",
      "episode :  27\n",
      "current step :  94\n",
      "reward :  -0.4870312772714135\n",
      "episode :  27\n",
      "current step :  95\n",
      "reward :  -0.49225704072262877\n",
      "episode :  27\n",
      "current step :  96\n",
      "reward :  -0.49336404964276487\n",
      "episode :  27\n",
      "current step :  97\n",
      "reward :  -0.503216030731588\n",
      "episode :  27\n",
      "current step :  98\n",
      "reward :  -0.48533389132923366\n",
      "episode :  27\n",
      "current step :  99\n",
      "reward :  -0.44832327102578867\n",
      "episode :  27\n",
      "current step :  100\n",
      "reward :  -0.43186744285914247\n",
      "episode :  27\n",
      "current step :  101\n",
      "reward :  -0.4870055269551192\n",
      "episode :  27\n",
      "current step :  102\n",
      "reward :  -0.5272667682361996\n",
      "episode :  27\n",
      "current step :  103\n",
      "reward :  -0.5311908833710169\n",
      "episode :  27\n",
      "current step :  104\n",
      "reward :  -0.45950851432541584\n",
      "episode :  27\n",
      "current step :  105\n",
      "reward :  -0.3682911273689033\n",
      "episode :  27\n",
      "current step :  106\n",
      "reward :  -0.39894043746623337\n",
      "episode :  27\n",
      "current step :  107\n",
      "reward :  -0.5251047114929348\n",
      "episode :  27\n",
      "current step :  108\n",
      "reward :  -0.5258644676019762\n",
      "episode :  27\n",
      "current step :  109\n",
      "reward :  -0.48904958732227444\n",
      "episode :  27\n",
      "current step :  110\n",
      "reward :  -0.4963672239159257\n",
      "episode :  27\n",
      "current step :  111\n",
      "reward :  -0.5375698556899476\n",
      "episode :  27\n",
      "current step :  112\n",
      "reward :  -0.4918769804282575\n",
      "episode :  27\n",
      "current step :  113\n",
      "reward :  -0.43363368877414404\n",
      "episode :  27\n",
      "current step :  114\n",
      "reward :  -0.3946997825666105\n",
      "episode :  27\n",
      "current step :  115\n",
      "reward :  -0.481779221279357\n",
      "episode :  27\n",
      "current step :  116\n",
      "reward :  -0.4763158633312063\n",
      "episode :  27\n",
      "current step :  117\n",
      "reward :  -0.5431202868697543\n",
      "episode :  27\n",
      "current step :  118\n",
      "reward :  -0.4796648077145036\n",
      "episode :  27\n",
      "current step :  119\n",
      "reward :  -0.47640442048772624\n",
      "episode :  27\n",
      "current step :  120\n",
      "reward :  -0.5026628511686718\n",
      "episode :  27\n",
      "current step :  121\n",
      "reward :  -0.4943711431549214\n",
      "episode :  27\n",
      "current step :  122\n",
      "reward :  -0.46744480962798346\n",
      "episode :  27\n",
      "current step :  123\n",
      "reward :  -0.490360820384306\n",
      "episode :  27\n",
      "current step :  124\n",
      "reward :  -0.4123709267855158\n",
      "episode :  27\n",
      "current step :  125\n",
      "reward :  -0.42310779075139077\n",
      "episode :  27\n",
      "current step :  126\n",
      "reward :  -0.4921540507973555\n",
      "episode :  27\n",
      "current step :  127\n",
      "reward :  -0.5028232776178705\n",
      "episode :  27\n",
      "current step :  128\n",
      "reward :  -0.5231201507832182\n",
      "episode :  27\n",
      "current step :  129\n",
      "reward :  -0.4723855785085759\n",
      "episode :  27\n",
      "current step :  130\n",
      "reward :  -0.35597934845293594\n",
      "episode :  27\n",
      "current step :  131\n",
      "reward :  -0.3395605596700778\n",
      "episode :  27\n",
      "current step :  132\n",
      "reward :  -0.4514868456950102\n",
      "episode :  27\n",
      "current step :  133\n",
      "reward :  -0.5247233282123304\n",
      "episode :  27\n",
      "current step :  134\n",
      "reward :  -0.46856896306640494\n",
      "episode :  27\n",
      "current step :  135\n",
      "reward :  -0.3268188659313986\n",
      "episode :  27\n",
      "current step :  136\n",
      "reward :  -0.3029387287098329\n",
      "episode :  27\n",
      "current step :  137\n",
      "reward :  -0.3994242249281374\n",
      "episode :  27\n",
      "current step :  138\n",
      "reward :  -0.4721889846603686\n",
      "episode :  27\n",
      "current step :  139\n",
      "reward :  -0.532423638829451\n",
      "episode :  27\n",
      "current step :  140\n",
      "reward :  -0.4327800060388889\n",
      "episode :  27\n",
      "current step :  141\n",
      "reward :  -0.29163364994917873\n",
      "episode :  27\n",
      "current step :  142\n",
      "reward :  -0.39798212093296464\n",
      "episode :  27\n",
      "current step :  143\n",
      "reward :  -0.35201871244592414\n",
      "episode :  27\n",
      "current step :  144\n",
      "reward :  -0.5195973614552134\n",
      "episode :  27\n",
      "current step :  145\n",
      "reward :  -0.5740524005513823\n",
      "episode :  27\n",
      "current step :  146\n",
      "reward :  -0.5791011114817177\n",
      "episode :  27\n",
      "current step :  147\n",
      "reward :  -0.433276571636947\n",
      "episode :  27\n",
      "current step :  148\n",
      "reward :  -0.29871482171754854\n",
      "episode :  27\n",
      "current step :  149\n",
      "reward :  -0.3503717160379299\n",
      "episode :  27\n",
      "current step :  150\n",
      "reward :  -0.45401059698159957\n",
      "episode :  27\n",
      "current step :  151\n",
      "reward :  -0.4810317784835268\n",
      "episode :  27\n",
      "current step :  152\n",
      "reward :  -0.5606378907781538\n",
      "episode :  27\n",
      "current step :  153\n",
      "reward :  -0.5560209560429625\n",
      "episode :  27\n",
      "current step :  154\n",
      "reward :  -0.38826808248737343\n",
      "episode :  27\n",
      "current step :  155\n",
      "reward :  -0.48691414799285204\n",
      "episode :  27\n",
      "current step :  156\n",
      "reward :  -0.45249625385123576\n",
      "episode :  27\n",
      "current step :  157\n",
      "reward :  -0.4387271602034414\n",
      "episode :  27\n",
      "current step :  158\n",
      "reward :  -0.37322236973875667\n",
      "episode :  27\n",
      "current step :  159\n",
      "reward :  -0.4280203461805261\n",
      "episode :  27\n",
      "current step :  160\n",
      "reward :  -0.38701603295449516\n",
      "episode :  27\n",
      "current step :  161\n",
      "reward :  -0.5009678011439581\n",
      "episode :  27\n",
      "current step :  162\n",
      "reward :  -0.37467635118478154\n",
      "episode :  27\n",
      "current step :  163\n",
      "reward :  -0.3683650386187426\n",
      "episode :  27\n",
      "current step :  164\n",
      "reward :  -0.3782872305917436\n",
      "episode :  27\n",
      "current step :  165\n",
      "reward :  -0.40907191801662807\n",
      "episode :  27\n",
      "current step :  166\n",
      "reward :  -0.4178864227314099\n",
      "episode :  27\n",
      "current step :  167\n",
      "reward :  -0.38791950458741664\n",
      "episode :  27\n",
      "current step :  168\n",
      "reward :  -0.39215540453235187\n",
      "episode :  27\n",
      "current step :  169\n",
      "reward :  -0.4791869901497477\n",
      "episode :  27\n",
      "current step :  170\n",
      "reward :  -0.5359778356577833\n",
      "episode :  27\n",
      "current step :  171\n",
      "reward :  -0.5754271348357919\n",
      "episode :  27\n",
      "current step :  172\n",
      "reward :  -0.4535862494051385\n",
      "episode :  27\n",
      "current step :  173\n",
      "reward :  -0.4096002756619439\n",
      "episode :  27\n",
      "current step :  174\n",
      "reward :  -0.4350617127653065\n",
      "episode :  27\n",
      "current step :  175\n",
      "reward :  -0.4100330970038645\n",
      "episode :  27\n",
      "current step :  176\n",
      "reward :  -0.41318092658527006\n",
      "episode :  27\n",
      "current step :  177\n",
      "reward :  -0.3919847499289582\n",
      "episode :  27\n",
      "current step :  178\n",
      "reward :  -0.40521644051524514\n",
      "episode :  27\n",
      "current step :  179\n",
      "reward :  -0.40131574338408926\n",
      "episode :  27\n",
      "current step :  180\n",
      "reward :  -0.41388318852792055\n",
      "episode :  27\n",
      "current step :  181\n",
      "reward :  -0.413850149129102\n",
      "episode :  27\n",
      "current step :  182\n",
      "reward :  -0.4327905800396728\n",
      "episode :  27\n",
      "current step :  183\n",
      "reward :  -0.403416259841309\n",
      "episode :  27\n",
      "current step :  184\n",
      "reward :  -0.3976279494725309\n",
      "episode :  27\n",
      "current step :  185\n",
      "reward :  -0.3977171322451903\n",
      "episode :  27\n",
      "current step :  186\n",
      "reward :  -0.3986252271186945\n",
      "episode :  27\n",
      "current step :  187\n",
      "reward :  -0.5337769850533379\n",
      "episode :  27\n",
      "current step :  188\n",
      "reward :  -0.577722300208991\n",
      "episode :  27\n",
      "current step :  189\n",
      "reward :  -0.5772954889857385\n",
      "episode :  27\n",
      "current step :  190\n",
      "reward :  -0.5780964741187123\n",
      "episode :  27\n",
      "current step :  191\n",
      "reward :  -0.5801447774436601\n",
      "episode :  27\n",
      "current step :  192\n",
      "reward :  -0.5788364776407429\n",
      "episode :  27\n",
      "current step :  193\n",
      "reward :  -0.5795025029008729\n",
      "episode :  27\n",
      "current step :  194\n",
      "reward :  -0.5795897855198646\n",
      "episode :  27\n",
      "current step :  195\n",
      "reward :  -0.5788526547996042\n",
      "episode :  27\n",
      "current step :  196\n",
      "reward :  -0.5780329325172445\n",
      "episode :  27\n",
      "current step :  197\n",
      "reward :  -0.5759041739377002\n",
      "episode :  27\n",
      "current step :  198\n",
      "reward :  -0.5751641463659037\n",
      "episode :  27\n",
      "current step :  199\n",
      "reward :  -0.5738103036557907\n",
      "episode :  27\n",
      "current step :  200\n",
      "reward :  -0.5740499696522776\n",
      "episode :  27\n",
      "current step :  201\n",
      "reward :  -0.5750566918025668\n",
      "episode :  27\n",
      "current step :  202\n",
      "reward :  -0.5735896508616571\n",
      "episode :  27\n",
      "current step :  203\n",
      "reward :  -0.572522500180111\n",
      "episode :  27\n",
      "current step :  204\n",
      "reward :  -0.5748654155420764\n",
      "episode :  27\n",
      "current step :  205\n",
      "reward :  -0.5748348163933543\n",
      "episode :  27\n",
      "current step :  206\n",
      "reward :  -0.573305134692134\n",
      "episode :  27\n",
      "current step :  207\n",
      "reward :  -0.5699966029023823\n",
      "episode :  27\n",
      "current step :  208\n",
      "reward :  -0.5702366294695066\n",
      "episode :  27\n",
      "current step :  209\n",
      "reward :  -0.5692557573355403\n",
      "episode :  27\n",
      "current step :  210\n",
      "reward :  -0.5674505285953324\n",
      "episode :  27\n",
      "current step :  211\n",
      "reward :  -0.5541890440324905\n",
      "episode :  27\n",
      "current step :  212\n",
      "reward :  -0.5452136498846786\n",
      "episode :  27\n",
      "current step :  213\n",
      "reward :  -0.5352799721583237\n",
      "episode :  27\n",
      "current step :  214\n",
      "reward :  -0.508780935980698\n",
      "episode :  27\n",
      "current step :  215\n",
      "reward :  -0.5034955515551068\n",
      "episode :  27\n",
      "current step :  216\n",
      "reward :  -0.5039495367659861\n",
      "episode :  27\n",
      "current step :  217\n",
      "reward :  -0.5030342975125475\n",
      "episode :  27\n",
      "current step :  218\n",
      "reward :  -0.500529165839675\n",
      "episode :  27\n",
      "current step :  219\n",
      "reward :  -0.4986790281251292\n",
      "episode :  27\n",
      "current step :  220\n",
      "reward :  -0.49663507692489806\n",
      "episode :  27\n",
      "current step :  221\n",
      "reward :  -0.49443451945414135\n",
      "episode :  27\n",
      "current step :  222\n",
      "reward :  -0.49547497467276336\n",
      "episode :  27\n",
      "current step :  223\n",
      "reward :  -0.4943380515242971\n",
      "episode :  27\n",
      "current step :  224\n",
      "reward :  -0.49365643648613744\n",
      "episode :  27\n",
      "current step :  225\n",
      "reward :  -0.4950760568258748\n",
      "episode :  27\n",
      "current step :  226\n",
      "reward :  -0.49654800322540515\n",
      "episode :  27\n",
      "current step :  227\n",
      "reward :  -0.4985956173876351\n",
      "episode :  27\n",
      "current step :  228\n",
      "reward :  -0.50106354050705\n",
      "episode :  27\n",
      "current step :  229\n",
      "reward :  -0.501281687429407\n",
      "episode :  27\n",
      "current step :  230\n",
      "reward :  -0.5006002574926693\n",
      "episode :  27\n",
      "current step :  231\n",
      "reward :  -0.49926114993336546\n",
      "episode :  27\n",
      "current step :  232\n",
      "reward :  -0.499356601856445\n",
      "episode :  27\n",
      "current step :  233\n",
      "reward :  -0.49893183510863864\n",
      "episode :  27\n",
      "current step :  234\n",
      "reward :  -0.499260966139616\n",
      "episode :  27\n",
      "current step :  235\n",
      "reward :  -0.4992699921503183\n",
      "episode :  27\n",
      "current step :  236\n",
      "reward :  -0.499893050198639\n",
      "episode :  27\n",
      "current step :  237\n",
      "reward :  -0.5034225260504299\n",
      "episode :  27\n",
      "current step :  238\n",
      "reward :  -0.5077125945020481\n",
      "episode :  27\n",
      "current step :  239\n",
      "reward :  -0.5114274524801946\n",
      "episode :  27\n",
      "current step :  240\n",
      "reward :  -0.514678607001715\n",
      "episode :  27\n",
      "current step :  241\n",
      "reward :  -0.5189226825388641\n",
      "episode :  27\n",
      "current step :  242\n",
      "reward :  -0.5199708547731631\n",
      "episode :  27\n",
      "current step :  243\n",
      "reward :  -0.5266012175892596\n",
      "episode :  27\n",
      "current step :  244\n",
      "reward :  -0.5196607560037595\n",
      "episode :  27\n",
      "current step :  245\n",
      "reward :  -0.4853645339011203\n",
      "episode :  27\n",
      "current step :  246\n",
      "reward :  -0.49421428809268214\n",
      "episode :  27\n",
      "current step :  247\n",
      "reward :  -0.49354207561954583\n",
      "episode :  27\n",
      "current step :  248\n",
      "reward :  -0.49827894355666424\n",
      "episode :  27\n",
      "current step :  249\n",
      "reward :  -0.5031538149431488\n",
      "episode :  27\n",
      "current step :  250\n",
      "reward :  -0.5070720330901366\n",
      "episode :  27\n",
      "current step :  251\n",
      "reward :  -0.5084789840171825\n",
      "episode :  27\n",
      "current step :  252\n",
      "reward :  -0.5096780317959635\n",
      "episode :  27\n",
      "current step :  253\n",
      "reward :  -0.5112282205530673\n",
      "episode :  27\n",
      "current step :  254\n",
      "reward :  -0.5146568684632757\n",
      "episode :  27\n",
      "current step :  255\n",
      "reward :  -0.5175082089141326\n",
      "episode :  27\n",
      "current step :  256\n",
      "reward :  -0.5191422582542696\n",
      "episode :  27\n",
      "current step :  257\n",
      "reward :  -0.5203155226254247\n",
      "episode :  27\n",
      "current step :  258\n",
      "reward :  -0.5216503244503718\n",
      "episode :  27\n",
      "current step :  259\n",
      "reward :  -0.52259774704405\n",
      "episode :  27\n",
      "current step :  260\n",
      "reward :  -0.5273168099323264\n",
      "episode :  27\n",
      "current step :  261\n",
      "reward :  -0.5317907222687993\n",
      "episode :  27\n",
      "current step :  262\n",
      "reward :  -0.5239405996891934\n",
      "episode :  27\n",
      "current step :  263\n",
      "reward :  -0.5291460421887365\n",
      "episode :  27\n",
      "current step :  264\n",
      "reward :  -0.5236076223837437\n",
      "episode :  27\n",
      "current step :  265\n",
      "reward :  -0.5263427988647027\n",
      "episode :  27\n",
      "current step :  266\n",
      "reward :  -0.5262511989074555\n",
      "episode :  27\n",
      "current step :  267\n",
      "reward :  -0.5281360002688533\n",
      "episode :  27\n",
      "current step :  268\n",
      "reward :  -0.524217162289027\n",
      "episode :  27\n",
      "current step :  269\n",
      "reward :  -0.5230422571842462\n",
      "episode :  27\n",
      "current step :  270\n",
      "reward :  -0.527916226018984\n",
      "episode :  27\n",
      "current step :  271\n",
      "reward :  -0.530240103247694\n",
      "episode :  27\n",
      "current step :  272\n",
      "reward :  -0.5302874626708243\n",
      "episode :  27\n",
      "current step :  273\n",
      "reward :  -0.5263373218917482\n",
      "episode :  27\n",
      "current step :  274\n",
      "reward :  -0.5244984447789421\n",
      "episode :  27\n",
      "current step :  275\n",
      "reward :  -0.5239341710969407\n",
      "episode :  27\n",
      "current step :  276\n",
      "reward :  -0.5278205547650512\n",
      "episode :  27\n",
      "current step :  277\n",
      "reward :  -0.5269475993946785\n",
      "episode :  27\n",
      "current step :  278\n",
      "reward :  -0.5264976836849876\n",
      "episode :  27\n",
      "current step :  279\n",
      "reward :  -0.523392575171405\n",
      "episode :  27\n",
      "current step :  280\n",
      "reward :  -0.5250659227339957\n",
      "episode :  27\n",
      "current step :  281\n",
      "reward :  -0.5187716372530593\n",
      "episode :  27\n",
      "current step :  282\n",
      "reward :  -0.5210293697883374\n",
      "episode :  27\n",
      "current step :  283\n",
      "reward :  -0.5192811232829594\n",
      "episode :  27\n",
      "current step :  284\n",
      "reward :  -0.5191895008568523\n",
      "episode :  27\n",
      "current step :  285\n",
      "reward :  -0.5246819224851076\n",
      "episode :  28\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 286      |\n",
      "|    ep_rew_mean     | -130     |\n",
      "| time/              |          |\n",
      "|    episodes        | 28       |\n",
      "|    fps             | 14       |\n",
      "|    time_elapsed    | 552      |\n",
      "|    total_timesteps | 8008     |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -86.2    |\n",
      "|    critic_loss     | 3.17     |\n",
      "|    ent_coef        | 0.138    |\n",
      "|    ent_coef_loss   | -4.69    |\n",
      "|    learning_rate   | 0.0003   |\n",
      "|    n_updates       | 7907     |\n",
      "---------------------------------\n",
      "current step :  0\n",
      "reward :  -0.5254690408111584\n",
      "episode :  28\n",
      "current step :  1\n",
      "reward :  -0.5397596893598148\n",
      "episode :  28\n",
      "current step :  2\n",
      "reward :  -0.5234697601604115\n",
      "episode :  28\n",
      "current step :  3\n",
      "reward :  -0.528406345181343\n",
      "episode :  28\n",
      "current step :  4\n",
      "reward :  -0.5329158549854194\n",
      "episode :  28\n",
      "current step :  5\n",
      "reward :  -0.5307188159623837\n",
      "episode :  28\n",
      "current step :  6\n",
      "reward :  -0.5330834135388997\n",
      "episode :  28\n",
      "current step :  7\n",
      "reward :  -0.5289657773784893\n",
      "episode :  28\n",
      "current step :  8\n",
      "reward :  -0.532414803821703\n",
      "episode :  28\n",
      "current step :  9\n",
      "reward :  -0.5324519700071177\n",
      "episode :  28\n",
      "current step :  10\n",
      "reward :  -0.5307939393607826\n",
      "episode :  28\n",
      "current step :  11\n",
      "reward :  -0.5249445690445229\n",
      "episode :  28\n",
      "current step :  12\n",
      "reward :  -0.5265959574321363\n",
      "episode :  28\n",
      "current step :  13\n",
      "reward :  -0.5242368162735984\n",
      "episode :  28\n",
      "current step :  14\n",
      "reward :  -0.5261937452391522\n",
      "episode :  28\n",
      "current step :  15\n",
      "reward :  -0.522729839016528\n",
      "episode :  28\n",
      "current step :  16\n",
      "reward :  -0.5253002859143318\n",
      "episode :  28\n",
      "current step :  17\n",
      "reward :  -0.5250582137926522\n",
      "episode :  28\n",
      "current step :  18\n",
      "reward :  -0.5226611552858111\n",
      "episode :  28\n",
      "current step :  19\n",
      "reward :  -0.5239082518001884\n",
      "episode :  28\n",
      "current step :  20\n",
      "reward :  -0.5239174345647553\n",
      "episode :  28\n",
      "current step :  21\n",
      "reward :  -0.5241940512088047\n",
      "episode :  28\n",
      "current step :  22\n",
      "reward :  -0.5266322079548246\n",
      "episode :  28\n",
      "current step :  23\n",
      "reward :  -0.527189877773067\n",
      "episode :  28\n",
      "current step :  24\n",
      "reward :  -0.5246700248484395\n",
      "episode :  28\n",
      "current step :  25\n",
      "reward :  -0.5280698398829171\n",
      "episode :  28\n",
      "current step :  26\n",
      "reward :  -0.5315830771179758\n",
      "episode :  28\n",
      "current step :  27\n",
      "reward :  -0.5375949523330745\n",
      "episode :  28\n",
      "current step :  28\n",
      "reward :  -0.5403445897232606\n",
      "episode :  28\n",
      "current step :  29\n",
      "reward :  -0.5391313317267415\n",
      "episode :  28\n",
      "current step :  30\n",
      "reward :  -0.5505583984960648\n",
      "episode :  28\n",
      "current step :  31\n",
      "reward :  -0.5567758103242076\n",
      "episode :  28\n",
      "current step :  32\n",
      "reward :  -0.5600083003942564\n",
      "episode :  28\n",
      "current step :  33\n",
      "reward :  -0.562812074099635\n",
      "episode :  28\n",
      "current step :  34\n",
      "reward :  -0.5598881380949641\n",
      "episode :  28\n",
      "current step :  35\n",
      "reward :  -0.56105214530405\n",
      "episode :  28\n",
      "current step :  36\n",
      "reward :  -0.5714564151951175\n",
      "episode :  28\n",
      "current step :  37\n",
      "reward :  -0.5593728062194285\n",
      "episode :  28\n",
      "current step :  38\n",
      "reward :  -0.565235743621717\n",
      "episode :  28\n",
      "current step :  39\n",
      "reward :  -0.5773045381211855\n",
      "episode :  28\n",
      "current step :  40\n",
      "reward :  -0.5838561196202976\n",
      "episode :  28\n",
      "current step :  41\n",
      "reward :  -0.5947861454353482\n",
      "episode :  28\n",
      "current step :  42\n",
      "reward :  -0.5949598734807056\n",
      "episode :  28\n",
      "current step :  43\n",
      "reward :  -0.6187115982176351\n",
      "episode :  28\n",
      "current step :  44\n",
      "reward :  -0.6117638884273572\n",
      "episode :  28\n",
      "current step :  45\n",
      "reward :  -0.6311838186178256\n",
      "episode :  28\n",
      "current step :  46\n",
      "reward :  -0.6434193164162754\n",
      "episode :  28\n",
      "current step :  47\n",
      "reward :  -0.6520049466129905\n",
      "episode :  28\n",
      "current step :  48\n",
      "reward :  -0.651006817112319\n",
      "episode :  28\n",
      "current step :  49\n",
      "reward :  -0.6514994180412556\n",
      "episode :  28\n",
      "current step :  50\n",
      "reward :  -0.6723023082579039\n",
      "episode :  28\n",
      "current step :  51\n",
      "reward :  -0.6672595595140162\n",
      "episode :  28\n",
      "current step :  52\n",
      "reward :  -0.67389786379251\n",
      "episode :  28\n",
      "current step :  53\n",
      "reward :  -0.6847085699653848\n",
      "episode :  28\n",
      "current step :  54\n",
      "reward :  -0.6884955735180639\n",
      "episode :  28\n",
      "current step :  55\n",
      "reward :  -0.6878862620432075\n",
      "episode :  28\n",
      "current step :  56\n",
      "reward :  -0.6903216038704112\n",
      "episode :  28\n",
      "current step :  57\n",
      "reward :  -0.690696187548039\n",
      "episode :  28\n",
      "current step :  58\n",
      "reward :  -0.681202043311794\n",
      "episode :  28\n",
      "current step :  59\n",
      "reward :  -0.6869072191841412\n",
      "episode :  28\n",
      "current step :  60\n",
      "reward :  -0.6798009037492103\n",
      "episode :  28\n",
      "current step :  61\n",
      "reward :  -0.6686217732182489\n",
      "episode :  28\n",
      "current step :  62\n",
      "reward :  -0.6799534263073801\n",
      "episode :  28\n",
      "current step :  63\n",
      "reward :  -0.6918155951697235\n",
      "episode :  28\n",
      "current step :  64\n",
      "reward :  -0.6941189249527946\n",
      "episode :  28\n",
      "current step :  65\n",
      "reward :  -0.6679685380411141\n",
      "episode :  28\n",
      "current step :  66\n",
      "reward :  -0.6739456190050629\n",
      "episode :  28\n",
      "current step :  67\n",
      "reward :  -0.6811540769943708\n",
      "episode :  28\n",
      "current step :  68\n",
      "reward :  -0.6898873891927076\n",
      "episode :  28\n",
      "current step :  69\n",
      "reward :  -0.6892571769603322\n",
      "episode :  28\n",
      "current step :  70\n",
      "reward :  -0.6846508493144802\n",
      "episode :  28\n",
      "current step :  71\n",
      "reward :  -0.6855287328033879\n",
      "episode :  28\n",
      "current step :  72\n",
      "reward :  -0.6780147194029433\n",
      "episode :  28\n",
      "current step :  73\n",
      "reward :  -0.6827858324181263\n",
      "episode :  28\n",
      "current step :  74\n",
      "reward :  -0.6906231722747458\n",
      "episode :  28\n",
      "current step :  75\n",
      "reward :  -0.6815596453880469\n",
      "episode :  28\n",
      "current step :  76\n",
      "reward :  -0.6668639738800692\n",
      "episode :  28\n",
      "current step :  77\n",
      "reward :  -0.6644573049551582\n",
      "episode :  28\n",
      "current step :  78\n",
      "reward :  -0.6725078216172347\n",
      "episode :  28\n",
      "current step :  79\n",
      "reward :  -0.6668796508323949\n",
      "episode :  28\n",
      "current step :  80\n",
      "reward :  -0.6578131386840623\n",
      "episode :  28\n",
      "current step :  81\n",
      "reward :  -0.6418967375786978\n",
      "episode :  28\n",
      "current step :  82\n",
      "reward :  -0.6310703115599882\n",
      "episode :  28\n",
      "current step :  83\n",
      "reward :  -0.6280238456873161\n",
      "episode :  28\n",
      "current step :  84\n",
      "reward :  -0.6116613567803291\n",
      "episode :  28\n",
      "current step :  85\n",
      "reward :  -0.6126943760252571\n",
      "episode :  28\n",
      "current step :  86\n",
      "reward :  -0.5928686829129891\n",
      "episode :  28\n",
      "current step :  87\n",
      "reward :  -0.5839390425015114\n",
      "episode :  28\n",
      "current step :  88\n",
      "reward :  -0.571165007659591\n",
      "episode :  28\n",
      "current step :  89\n",
      "reward :  -0.5586323272854182\n",
      "episode :  28\n",
      "current step :  90\n",
      "reward :  -0.5534275741980267\n",
      "episode :  28\n",
      "current step :  91\n",
      "reward :  -0.5532560093187467\n",
      "episode :  28\n",
      "current step :  92\n",
      "reward :  -0.53927599627332\n",
      "episode :  28\n",
      "current step :  93\n",
      "reward :  -0.5196196460797434\n",
      "episode :  28\n",
      "current step :  94\n",
      "reward :  -0.5243348601140787\n",
      "episode :  28\n",
      "current step :  95\n",
      "reward :  -0.5087974715799448\n",
      "episode :  28\n",
      "current step :  96\n",
      "reward :  -0.5058295681429399\n",
      "episode :  28\n",
      "current step :  97\n",
      "reward :  -0.5044042621412096\n",
      "episode :  28\n",
      "current step :  98\n",
      "reward :  -0.5112029429408147\n",
      "episode :  28\n",
      "current step :  99\n",
      "reward :  -0.5103900313208323\n",
      "episode :  28\n",
      "current step :  100\n",
      "reward :  -0.5091961359567059\n",
      "episode :  28\n",
      "current step :  101\n",
      "reward :  -0.5055941843227889\n",
      "episode :  28\n",
      "current step :  102\n",
      "reward :  -0.5090888395303987\n",
      "episode :  28\n",
      "current step :  103\n",
      "reward :  -0.5106875271519602\n",
      "episode :  28\n",
      "current step :  104\n",
      "reward :  -0.503171541581467\n",
      "episode :  28\n",
      "current step :  105\n",
      "reward :  -0.5089357335298358\n",
      "episode :  28\n",
      "current step :  106\n",
      "reward :  -0.5114533284946\n",
      "episode :  28\n",
      "current step :  107\n",
      "reward :  -0.5113154509203875\n",
      "episode :  28\n",
      "current step :  108\n",
      "reward :  -0.5115980728382333\n",
      "episode :  28\n",
      "current step :  109\n",
      "reward :  -0.5057420074177276\n",
      "episode :  28\n",
      "current step :  110\n",
      "reward :  -0.4618777703396553\n",
      "episode :  28\n",
      "current step :  111\n",
      "reward :  -0.5134331282100687\n",
      "episode :  28\n",
      "current step :  112\n",
      "reward :  -0.5100415698366273\n",
      "episode :  28\n",
      "current step :  113\n",
      "reward :  -0.5096245534393625\n",
      "episode :  28\n",
      "current step :  114\n",
      "reward :  -0.509277608324418\n",
      "episode :  28\n",
      "current step :  115\n",
      "reward :  -0.502905166238364\n",
      "episode :  28\n",
      "current step :  116\n",
      "reward :  -0.4978663490167385\n",
      "episode :  28\n",
      "current step :  117\n",
      "reward :  -0.4706266748296194\n",
      "episode :  28\n",
      "current step :  118\n",
      "reward :  -0.5085071332298036\n",
      "episode :  28\n",
      "current step :  119\n",
      "reward :  -0.5063819171118268\n",
      "episode :  28\n",
      "current step :  120\n",
      "reward :  -0.5076618133240206\n",
      "episode :  28\n",
      "current step :  121\n",
      "reward :  -0.3789059118898534\n",
      "episode :  28\n",
      "current step :  122\n",
      "reward :  -0.38363875819909915\n",
      "episode :  28\n",
      "current step :  123\n",
      "reward :  -0.409524945744678\n",
      "episode :  28\n",
      "current step :  124\n",
      "reward :  -0.4478286734602747\n",
      "episode :  28\n",
      "current step :  125\n",
      "reward :  -0.49658600681677095\n",
      "episode :  28\n",
      "current step :  126\n",
      "reward :  -0.42359367713677076\n",
      "episode :  28\n",
      "current step :  127\n",
      "reward :  -0.41231560828563935\n",
      "episode :  28\n",
      "current step :  128\n",
      "reward :  -0.406874185578473\n",
      "episode :  28\n",
      "current step :  129\n",
      "reward :  -0.40015906476415225\n",
      "episode :  28\n",
      "current step :  130\n",
      "reward :  -0.47107007461827133\n",
      "episode :  28\n",
      "current step :  131\n",
      "reward :  -0.45471609405170077\n",
      "episode :  28\n",
      "current step :  132\n",
      "reward :  -0.44135129186546934\n",
      "episode :  28\n",
      "current step :  133\n",
      "reward :  -0.4277364761678104\n",
      "episode :  28\n",
      "current step :  134\n",
      "reward :  -0.448886354712052\n",
      "episode :  28\n",
      "current step :  135\n",
      "reward :  -0.4644147549357746\n",
      "episode :  28\n",
      "current step :  136\n",
      "reward :  -0.47331110133237686\n",
      "episode :  28\n",
      "current step :  137\n",
      "reward :  -0.4587727674713607\n",
      "episode :  28\n",
      "current step :  138\n",
      "reward :  -0.4480650308758992\n",
      "episode :  28\n",
      "current step :  139\n",
      "reward :  -0.41347686431578584\n",
      "episode :  28\n",
      "current step :  140\n",
      "reward :  -0.4119859409149342\n",
      "episode :  28\n",
      "current step :  141\n",
      "reward :  -0.41655302078308654\n",
      "episode :  28\n",
      "current step :  142\n",
      "reward :  -0.41491186006591096\n",
      "episode :  28\n",
      "current step :  143\n",
      "reward :  -0.4272014912764244\n",
      "episode :  28\n",
      "current step :  144\n",
      "reward :  -0.4355524435120701\n",
      "episode :  28\n",
      "current step :  145\n",
      "reward :  -0.4229046555431196\n",
      "episode :  28\n",
      "current step :  146\n",
      "reward :  -0.4189554898587198\n",
      "episode :  28\n",
      "current step :  147\n",
      "reward :  -0.41553325879489605\n",
      "episode :  28\n",
      "current step :  148\n",
      "reward :  -0.398125100832674\n",
      "episode :  28\n",
      "current step :  149\n",
      "reward :  -0.4198287760361484\n",
      "episode :  28\n",
      "current step :  150\n",
      "reward :  -0.4231904046813542\n",
      "episode :  28\n",
      "current step :  151\n",
      "reward :  -0.40787141711562996\n",
      "episode :  28\n",
      "current step :  152\n",
      "reward :  -0.42414830836411566\n",
      "episode :  28\n",
      "current step :  153\n",
      "reward :  -0.4098282818687988\n",
      "episode :  28\n",
      "current step :  154\n",
      "reward :  -0.4132010350221451\n",
      "episode :  28\n",
      "current step :  155\n",
      "reward :  -0.4211774945384166\n",
      "episode :  28\n",
      "current step :  156\n",
      "reward :  -0.4229681616765693\n",
      "episode :  28\n",
      "current step :  157\n",
      "reward :  -0.4335344783503775\n",
      "episode :  28\n",
      "current step :  158\n",
      "reward :  -0.4313912257977767\n",
      "episode :  28\n",
      "current step :  159\n",
      "reward :  -0.4435468824915215\n",
      "episode :  28\n",
      "current step :  160\n",
      "reward :  -0.4460375898164485\n",
      "episode :  28\n",
      "current step :  161\n",
      "reward :  -0.4344836676530235\n",
      "episode :  28\n",
      "current step :  162\n",
      "reward :  -0.4563740208471836\n",
      "episode :  28\n",
      "current step :  163\n",
      "reward :  -0.46279468304027643\n",
      "episode :  28\n",
      "current step :  164\n",
      "reward :  -0.45520529834291\n",
      "episode :  28\n",
      "current step :  165\n",
      "reward :  -0.43817101244017725\n",
      "episode :  28\n",
      "current step :  166\n",
      "reward :  -0.4603675881692133\n",
      "episode :  28\n",
      "current step :  167\n",
      "reward :  -0.44015106041633467\n",
      "episode :  28\n",
      "current step :  168\n",
      "reward :  -0.44725054953667637\n",
      "episode :  28\n",
      "current step :  169\n",
      "reward :  -0.44900507713761745\n",
      "episode :  28\n",
      "current step :  170\n",
      "reward :  -0.44300519439261543\n",
      "episode :  28\n",
      "current step :  171\n",
      "reward :  -0.4548551479008804\n",
      "episode :  28\n",
      "current step :  172\n",
      "reward :  -0.4662931933195621\n",
      "episode :  28\n",
      "current step :  173\n",
      "reward :  -0.4722398276594273\n",
      "episode :  28\n",
      "current step :  174\n",
      "reward :  -0.4910911535004011\n",
      "episode :  28\n",
      "current step :  175\n",
      "reward :  -0.4618391859998658\n",
      "episode :  28\n",
      "current step :  176\n",
      "reward :  -0.4674226823050858\n",
      "episode :  28\n",
      "current step :  177\n",
      "reward :  -0.4608105970623488\n",
      "episode :  28\n",
      "current step :  178\n",
      "reward :  -0.4538553837757495\n",
      "episode :  28\n",
      "current step :  179\n",
      "reward :  -0.4618875640272116\n",
      "episode :  28\n",
      "current step :  180\n",
      "reward :  -0.48107737778202503\n",
      "episode :  28\n",
      "current step :  181\n",
      "reward :  -0.4660157641053149\n",
      "episode :  28\n",
      "current step :  182\n",
      "reward :  -0.46483259036898583\n",
      "episode :  28\n",
      "current step :  183\n",
      "reward :  -0.4474748520596837\n",
      "episode :  28\n",
      "current step :  184\n",
      "reward :  -0.433772268053994\n",
      "episode :  28\n",
      "current step :  185\n",
      "reward :  -0.4476931546262455\n",
      "episode :  28\n",
      "current step :  186\n",
      "reward :  -0.46135801765302575\n",
      "episode :  28\n",
      "current step :  187\n",
      "reward :  -0.4408558985513973\n",
      "episode :  28\n",
      "current step :  188\n",
      "reward :  -0.4493668649582973\n",
      "episode :  28\n",
      "current step :  189\n",
      "reward :  -0.4408828847771645\n",
      "episode :  28\n",
      "current step :  190\n",
      "reward :  -0.4399904482281949\n",
      "episode :  28\n",
      "current step :  191\n",
      "reward :  -0.4330356331670576\n",
      "episode :  28\n",
      "current step :  192\n",
      "reward :  -0.4355732938856411\n",
      "episode :  28\n",
      "current step :  193\n",
      "reward :  -0.46095579831283545\n",
      "episode :  28\n",
      "current step :  194\n",
      "reward :  -0.45301364052089593\n",
      "episode :  28\n",
      "current step :  195\n",
      "reward :  -0.4380916719227135\n",
      "episode :  28\n",
      "current step :  196\n",
      "reward :  -0.4330195527302739\n",
      "episode :  28\n",
      "current step :  197\n",
      "reward :  -0.433256337781543\n",
      "episode :  28\n",
      "current step :  198\n",
      "reward :  -0.4397061190947407\n",
      "episode :  28\n",
      "current step :  199\n",
      "reward :  -0.4402511156541268\n",
      "episode :  28\n",
      "current step :  200\n",
      "reward :  -0.47388160211452396\n",
      "episode :  28\n",
      "current step :  201\n",
      "reward :  -0.47591078260260583\n",
      "episode :  28\n",
      "current step :  202\n",
      "reward :  -0.4578692006357496\n",
      "episode :  28\n",
      "current step :  203\n",
      "reward :  -0.4365652270592269\n",
      "episode :  28\n",
      "current step :  204\n",
      "reward :  -0.47847040251516376\n",
      "episode :  28\n",
      "current step :  205\n",
      "reward :  -0.4420672062172575\n",
      "episode :  28\n",
      "current step :  206\n",
      "reward :  -0.4453161883639142\n",
      "episode :  28\n",
      "current step :  207\n",
      "reward :  -0.4605720275883946\n",
      "episode :  28\n",
      "current step :  208\n",
      "reward :  -0.4562660888159405\n",
      "episode :  28\n",
      "current step :  209\n",
      "reward :  -0.45685415944964874\n",
      "episode :  28\n",
      "current step :  210\n",
      "reward :  -0.458188340537443\n",
      "episode :  28\n",
      "current step :  211\n",
      "reward :  -0.43233412404237304\n",
      "episode :  28\n",
      "current step :  212\n",
      "reward :  -0.4204272726165975\n",
      "episode :  28\n",
      "current step :  213\n",
      "reward :  -0.40926189403778723\n",
      "episode :  28\n",
      "current step :  214\n",
      "reward :  -0.41025182647268954\n",
      "episode :  28\n",
      "current step :  215\n",
      "reward :  -0.4105792501889757\n",
      "episode :  28\n",
      "current step :  216\n",
      "reward :  -0.4269742634774828\n",
      "episode :  28\n",
      "current step :  217\n",
      "reward :  -0.44777696248345017\n",
      "episode :  28\n",
      "current step :  218\n",
      "reward :  -0.45711296529163925\n",
      "episode :  28\n",
      "current step :  219\n",
      "reward :  -0.4193284116201906\n",
      "episode :  28\n",
      "current step :  220\n",
      "reward :  -0.41823082197925565\n",
      "episode :  28\n",
      "current step :  221\n",
      "reward :  -0.439147861772839\n",
      "episode :  28\n",
      "current step :  222\n",
      "reward :  -0.4535696622611194\n",
      "episode :  28\n",
      "current step :  223\n",
      "reward :  -0.4763590300773983\n",
      "episode :  28\n",
      "current step :  224\n",
      "reward :  -0.4796811424198983\n",
      "episode :  28\n",
      "current step :  225\n",
      "reward :  -0.43133350877484744\n",
      "episode :  28\n",
      "current step :  226\n",
      "reward :  -0.45348478911555207\n",
      "episode :  28\n",
      "current step :  227\n",
      "reward :  -0.42089569604525695\n",
      "episode :  28\n",
      "current step :  228\n",
      "reward :  -0.41823889062738095\n",
      "episode :  28\n",
      "current step :  229\n",
      "reward :  -0.4318798876000944\n",
      "episode :  28\n",
      "current step :  230\n",
      "reward :  -0.43970732318656536\n",
      "episode :  28\n",
      "current step :  231\n",
      "reward :  -0.41774878566427803\n",
      "episode :  28\n",
      "current step :  232\n",
      "reward :  -0.40153465243041125\n",
      "episode :  28\n",
      "current step :  233\n",
      "reward :  -0.41572114326417065\n",
      "episode :  28\n",
      "current step :  234\n",
      "reward :  -0.39345298575514753\n",
      "episode :  28\n",
      "current step :  235\n",
      "reward :  -0.4094839872514262\n",
      "episode :  28\n",
      "current step :  236\n",
      "reward :  -0.3794066162341767\n",
      "episode :  28\n",
      "current step :  237\n",
      "reward :  -0.39626006891649623\n",
      "episode :  28\n",
      "current step :  238\n",
      "reward :  -0.3964451692865719\n",
      "episode :  28\n",
      "current step :  239\n",
      "reward :  -0.41837313684978844\n",
      "episode :  28\n",
      "current step :  240\n",
      "reward :  -0.42595731591878\n",
      "episode :  28\n",
      "current step :  241\n",
      "reward :  -0.41810433656060186\n",
      "episode :  28\n",
      "current step :  242\n",
      "reward :  -0.41374010627040064\n",
      "episode :  28\n",
      "current step :  243\n",
      "reward :  -0.4197311814720576\n",
      "episode :  28\n",
      "current step :  244\n",
      "reward :  -0.41767888511550966\n",
      "episode :  28\n",
      "current step :  245\n",
      "reward :  -0.413357359037467\n",
      "episode :  28\n",
      "current step :  246\n",
      "reward :  -0.40757151773658506\n",
      "episode :  28\n",
      "current step :  247\n",
      "reward :  -0.40096880178221145\n",
      "episode :  28\n",
      "current step :  248\n",
      "reward :  -0.39806680912303904\n",
      "episode :  28\n",
      "current step :  249\n",
      "reward :  -0.39398317103200714\n",
      "episode :  28\n",
      "current step :  250\n",
      "reward :  -0.39218847413746516\n",
      "episode :  28\n",
      "current step :  251\n",
      "reward :  -0.39435764829187087\n",
      "episode :  28\n",
      "current step :  252\n",
      "reward :  -0.39313685850269026\n",
      "episode :  28\n",
      "current step :  253\n",
      "reward :  -0.3925320435802358\n",
      "episode :  28\n",
      "current step :  254\n",
      "reward :  -0.39259700215654963\n",
      "episode :  28\n",
      "current step :  255\n",
      "reward :  -0.4032487172059853\n",
      "episode :  28\n",
      "current step :  256\n",
      "reward :  -0.3989494825797441\n",
      "episode :  28\n",
      "current step :  257\n",
      "reward :  -0.3960651650619076\n",
      "episode :  28\n",
      "current step :  258\n",
      "reward :  -0.4020233962061568\n",
      "episode :  28\n",
      "current step :  259\n",
      "reward :  -0.40926194302624613\n",
      "episode :  28\n",
      "current step :  260\n",
      "reward :  -0.41020432891894737\n",
      "episode :  28\n",
      "current step :  261\n",
      "reward :  -0.40522252688093774\n",
      "episode :  28\n",
      "current step :  262\n",
      "reward :  -0.4072186107366566\n",
      "episode :  28\n",
      "current step :  263\n",
      "reward :  -0.40981370811074025\n",
      "episode :  28\n",
      "current step :  264\n",
      "reward :  -0.40597978748294383\n",
      "episode :  28\n",
      "current step :  265\n",
      "reward :  -0.40996362581538215\n",
      "episode :  28\n",
      "current step :  266\n",
      "reward :  -0.4095980012488079\n",
      "episode :  28\n",
      "current step :  267\n",
      "reward :  -0.40088476154608793\n",
      "episode :  28\n",
      "current step :  268\n",
      "reward :  -0.40336759531190874\n",
      "episode :  28\n",
      "current step :  269\n",
      "reward :  -0.4024444823000985\n",
      "episode :  28\n",
      "current step :  270\n",
      "reward :  -0.4068112136665003\n",
      "episode :  28\n",
      "current step :  271\n",
      "reward :  -0.41165031117861556\n",
      "episode :  28\n",
      "current step :  272\n",
      "reward :  -0.41322018775054453\n",
      "episode :  28\n",
      "current step :  273\n",
      "reward :  -0.41156755064935685\n",
      "episode :  28\n",
      "current step :  274\n",
      "reward :  -0.4089380932081745\n",
      "episode :  28\n",
      "current step :  275\n",
      "reward :  -0.4185615571204294\n",
      "episode :  28\n",
      "current step :  276\n",
      "reward :  -0.41959744933148874\n",
      "episode :  28\n",
      "current step :  277\n",
      "reward :  -0.4145559141866349\n",
      "episode :  28\n",
      "current step :  278\n",
      "reward :  -0.41818372680371574\n",
      "episode :  28\n",
      "current step :  279\n",
      "reward :  -0.41794639573184567\n",
      "episode :  28\n",
      "current step :  280\n",
      "reward :  -0.41514877791368976\n",
      "episode :  28\n",
      "current step :  281\n",
      "reward :  -0.41690617535319363\n",
      "episode :  28\n",
      "current step :  282\n",
      "reward :  -0.41097879973305435\n",
      "episode :  28\n",
      "current step :  283\n",
      "reward :  -0.4185831718391807\n",
      "episode :  28\n",
      "current step :  284\n",
      "reward :  -0.42084919233749957\n",
      "episode :  28\n",
      "current step :  285\n",
      "reward :  -0.40643813547696894\n",
      "episode :  29\n",
      "current step :  0\n",
      "reward :  -0.4174795473505487\n",
      "episode :  29\n",
      "current step :  1\n",
      "reward :  -0.4087152799044654\n",
      "episode :  29\n",
      "current step :  2\n",
      "reward :  -0.4075448011608266\n",
      "episode :  29\n",
      "current step :  3\n",
      "reward :  -0.4246478477934755\n",
      "episode :  29\n",
      "current step :  4\n",
      "reward :  -0.42803695617680754\n",
      "episode :  29\n",
      "current step :  5\n",
      "reward :  -0.4290663606474091\n",
      "episode :  29\n",
      "current step :  6\n",
      "reward :  -0.41938234143988196\n",
      "episode :  29\n",
      "current step :  7\n",
      "reward :  -0.41699888084734116\n",
      "episode :  29\n",
      "current step :  8\n",
      "reward :  -0.4246785690243761\n",
      "episode :  29\n",
      "current step :  9\n",
      "reward :  -0.428592723170492\n",
      "episode :  29\n",
      "current step :  10\n",
      "reward :  -0.4246431437486747\n",
      "episode :  29\n",
      "current step :  11\n",
      "reward :  -0.42440913945686276\n",
      "episode :  29\n",
      "current step :  12\n",
      "reward :  -0.42613294879383307\n",
      "episode :  29\n",
      "current step :  13\n",
      "reward :  -0.42571757429266854\n",
      "episode :  29\n",
      "current step :  14\n",
      "reward :  -0.42005865207136334\n",
      "episode :  29\n",
      "current step :  15\n",
      "reward :  -0.429886683877053\n",
      "episode :  29\n",
      "current step :  16\n",
      "reward :  -0.4267232289098068\n",
      "episode :  29\n",
      "current step :  17\n",
      "reward :  -0.43336112499968027\n",
      "episode :  29\n",
      "current step :  18\n",
      "reward :  -0.4254375122447028\n",
      "episode :  29\n",
      "current step :  19\n",
      "reward :  -0.4219963032577886\n",
      "episode :  29\n",
      "current step :  20\n",
      "reward :  -0.4286492821255438\n",
      "episode :  29\n",
      "current step :  21\n",
      "reward :  -0.43406694096162796\n",
      "episode :  29\n",
      "current step :  22\n",
      "reward :  -0.4312277072726601\n",
      "episode :  29\n",
      "current step :  23\n",
      "reward :  -0.421042290704905\n",
      "episode :  29\n",
      "current step :  24\n",
      "reward :  -0.41875829044739143\n",
      "episode :  29\n",
      "current step :  25\n",
      "reward :  -0.43300434501115664\n",
      "episode :  29\n",
      "current step :  26\n",
      "reward :  -0.43208293203619647\n",
      "episode :  29\n",
      "current step :  27\n",
      "reward :  -0.4341567465256483\n",
      "episode :  29\n",
      "current step :  28\n",
      "reward :  -0.43740701812508814\n",
      "episode :  29\n",
      "current step :  29\n",
      "reward :  -0.43039845912035707\n",
      "episode :  29\n",
      "current step :  30\n",
      "reward :  -0.4321893764863924\n",
      "episode :  29\n",
      "current step :  31\n",
      "reward :  -0.42657889517066266\n",
      "episode :  29\n",
      "current step :  32\n",
      "reward :  -0.4235522874324945\n",
      "episode :  29\n",
      "current step :  33\n",
      "reward :  -0.4296184614409398\n",
      "episode :  29\n",
      "current step :  34\n",
      "reward :  -0.4155135100220439\n",
      "episode :  29\n",
      "current step :  35\n",
      "reward :  -0.4272423868874214\n",
      "episode :  29\n",
      "current step :  36\n",
      "reward :  -0.4105755266798832\n",
      "episode :  29\n",
      "current step :  37\n",
      "reward :  -0.4047649626741252\n",
      "episode :  29\n",
      "current step :  38\n",
      "reward :  -0.4210960206004237\n",
      "episode :  29\n",
      "current step :  39\n",
      "reward :  -0.4182353625623631\n",
      "episode :  29\n",
      "current step :  40\n",
      "reward :  -0.40259919586300513\n",
      "episode :  29\n",
      "current step :  41\n",
      "reward :  -0.3976468846708239\n",
      "episode :  29\n",
      "current step :  42\n",
      "reward :  -0.4052582420598853\n",
      "episode :  29\n",
      "current step :  43\n",
      "reward :  -0.38895142474062916\n",
      "episode :  29\n",
      "current step :  44\n",
      "reward :  -0.37982775573879485\n",
      "episode :  29\n",
      "current step :  45\n",
      "reward :  -0.39557893197988164\n",
      "episode :  29\n",
      "current step :  46\n",
      "reward :  -0.3909243155823175\n",
      "episode :  29\n",
      "current step :  47\n",
      "reward :  -0.392597000015218\n",
      "episode :  29\n",
      "current step :  48\n",
      "reward :  -0.4113820304656772\n",
      "episode :  29\n",
      "current step :  49\n",
      "reward :  -0.41232067741523426\n",
      "episode :  29\n",
      "current step :  50\n",
      "reward :  -0.42339932926550444\n",
      "episode :  29\n",
      "current step :  51\n",
      "reward :  -0.43150592125394205\n",
      "episode :  29\n",
      "current step :  52\n",
      "reward :  -0.422582692088976\n",
      "episode :  29\n",
      "current step :  53\n",
      "reward :  -0.41850473256848864\n",
      "episode :  29\n",
      "current step :  54\n",
      "reward :  -0.4033313490969336\n",
      "episode :  29\n",
      "current step :  55\n",
      "reward :  -0.43265811088777295\n",
      "episode :  29\n",
      "current step :  56\n",
      "reward :  -0.4333507616516745\n",
      "episode :  29\n",
      "current step :  57\n",
      "reward :  -0.41575662964147075\n",
      "episode :  29\n",
      "current step :  58\n",
      "reward :  -0.42170988316246794\n",
      "episode :  29\n",
      "current step :  59\n",
      "reward :  -0.4314487276313825\n",
      "episode :  29\n",
      "current step :  60\n",
      "reward :  -0.40572289106247167\n",
      "episode :  29\n",
      "current step :  61\n",
      "reward :  -0.4165505599424337\n",
      "episode :  29\n",
      "current step :  62\n",
      "reward :  -0.4171286183501323\n",
      "episode :  29\n",
      "current step :  63\n",
      "reward :  -0.4280153157751077\n",
      "episode :  29\n",
      "current step :  64\n",
      "reward :  -0.4284376272247184\n",
      "episode :  29\n",
      "current step :  65\n",
      "reward :  -0.43113807249315855\n",
      "episode :  29\n",
      "current step :  66\n",
      "reward :  -0.4089776238838732\n",
      "episode :  29\n",
      "current step :  67\n",
      "reward :  -0.4052545727668782\n",
      "episode :  29\n",
      "current step :  68\n",
      "reward :  -0.4162251549211428\n",
      "episode :  29\n",
      "current step :  69\n",
      "reward :  -0.4077993544965996\n",
      "episode :  29\n",
      "current step :  70\n",
      "reward :  -0.4222326088068919\n",
      "episode :  29\n",
      "current step :  71\n",
      "reward :  -0.4161861047605907\n",
      "episode :  29\n",
      "current step :  72\n",
      "reward :  -0.4184485894811086\n",
      "episode :  29\n",
      "current step :  73\n",
      "reward :  -0.4168606154373601\n",
      "episode :  29\n",
      "current step :  74\n",
      "reward :  -0.41726439148814815\n",
      "episode :  29\n",
      "current step :  75\n",
      "reward :  -0.41295365343725804\n",
      "episode :  29\n",
      "current step :  76\n",
      "reward :  -0.40422832982620105\n",
      "episode :  29\n",
      "current step :  77\n",
      "reward :  -0.4044693015571765\n",
      "episode :  29\n",
      "current step :  78\n",
      "reward :  -0.41089087217885356\n",
      "episode :  29\n",
      "current step :  79\n",
      "reward :  -0.4219452320649969\n",
      "episode :  29\n",
      "current step :  80\n",
      "reward :  -0.41453678667096316\n",
      "episode :  29\n",
      "current step :  81\n",
      "reward :  -0.39508518605169857\n",
      "episode :  29\n",
      "current step :  82\n",
      "reward :  -0.3961476849639641\n",
      "episode :  29\n",
      "current step :  83\n",
      "reward :  -0.4008142276853622\n",
      "episode :  29\n",
      "current step :  84\n",
      "reward :  -0.3881294721766733\n",
      "episode :  29\n",
      "current step :  85\n",
      "reward :  -0.39710684219161957\n",
      "episode :  29\n",
      "current step :  86\n",
      "reward :  -0.3856337173509061\n",
      "episode :  29\n",
      "current step :  87\n",
      "reward :  -0.38994514816921033\n",
      "episode :  29\n",
      "current step :  88\n",
      "reward :  -0.388861447558443\n",
      "episode :  29\n",
      "current step :  89\n",
      "reward :  -0.4027770958436201\n",
      "episode :  29\n",
      "current step :  90\n",
      "reward :  -0.391955827261992\n",
      "episode :  29\n",
      "current step :  91\n",
      "reward :  -0.3943604915037934\n",
      "episode :  29\n",
      "current step :  92\n",
      "reward :  -0.3945411578896228\n",
      "episode :  29\n",
      "current step :  93\n",
      "reward :  -0.39775608018068664\n",
      "episode :  29\n",
      "current step :  94\n",
      "reward :  -0.4059132461185061\n",
      "episode :  29\n",
      "current step :  95\n",
      "reward :  -0.41609868764292257\n",
      "episode :  29\n",
      "current step :  96\n",
      "reward :  -0.4110872967952968\n",
      "episode :  29\n",
      "current step :  97\n",
      "reward :  -0.4189242835822168\n",
      "episode :  29\n",
      "current step :  98\n",
      "reward :  -0.40839525185638836\n",
      "episode :  29\n",
      "current step :  99\n",
      "reward :  -0.4046760444575952\n",
      "episode :  29\n",
      "current step :  100\n",
      "reward :  -0.4065972921138212\n",
      "episode :  29\n",
      "current step :  101\n",
      "reward :  -0.4052763756147558\n",
      "episode :  29\n",
      "current step :  102\n",
      "reward :  -0.40755506805250985\n",
      "episode :  29\n",
      "current step :  103\n",
      "reward :  -0.40939819314641623\n",
      "episode :  29\n",
      "current step :  104\n",
      "reward :  -0.4177108655342194\n",
      "episode :  29\n",
      "current step :  105\n",
      "reward :  -0.4119566906678656\n",
      "episode :  29\n",
      "current step :  106\n",
      "reward :  -0.4135513211942554\n",
      "episode :  29\n",
      "current step :  107\n",
      "reward :  -0.41650226312984195\n",
      "episode :  29\n",
      "current step :  108\n",
      "reward :  -0.41624285182292475\n",
      "episode :  29\n",
      "current step :  109\n",
      "reward :  -0.41697565695866884\n",
      "episode :  29\n",
      "current step :  110\n",
      "reward :  -0.42170191423178305\n",
      "episode :  29\n",
      "current step :  111\n",
      "reward :  -0.41281136554833253\n",
      "episode :  29\n",
      "current step :  112\n",
      "reward :  -0.4131867259065332\n",
      "episode :  29\n",
      "current step :  113\n",
      "reward :  -0.41163522536193176\n",
      "episode :  29\n",
      "current step :  114\n",
      "reward :  -0.41346641629747205\n",
      "episode :  29\n",
      "current step :  115\n",
      "reward :  -0.42754397638005426\n",
      "episode :  29\n",
      "current step :  116\n",
      "reward :  -0.41597704447117323\n",
      "episode :  29\n",
      "current step :  117\n",
      "reward :  -0.41919049059078417\n",
      "episode :  29\n",
      "current step :  118\n",
      "reward :  -0.44735454558215054\n",
      "episode :  29\n",
      "current step :  119\n",
      "reward :  -0.4464172307973321\n",
      "episode :  29\n",
      "current step :  120\n",
      "reward :  -0.44520108490086213\n",
      "episode :  29\n",
      "current step :  121\n",
      "reward :  -0.4440317278168049\n",
      "episode :  29\n",
      "current step :  122\n",
      "reward :  -0.4033402771521888\n",
      "episode :  29\n",
      "current step :  123\n",
      "reward :  -0.4388253040040764\n",
      "episode :  29\n",
      "current step :  124\n",
      "reward :  -0.4110882646791913\n",
      "episode :  29\n",
      "current step :  125\n",
      "reward :  -0.4087740901920422\n",
      "episode :  29\n",
      "current step :  126\n",
      "reward :  -0.41532749623985665\n",
      "episode :  29\n",
      "current step :  127\n",
      "reward :  -0.43783626829925903\n",
      "episode :  29\n",
      "current step :  128\n",
      "reward :  -0.44602803834954946\n",
      "episode :  29\n",
      "current step :  129\n",
      "reward :  -0.42096351431769546\n",
      "episode :  29\n",
      "current step :  130\n",
      "reward :  -0.40379556265582717\n",
      "episode :  29\n",
      "current step :  131\n",
      "reward :  -0.40577885766696076\n",
      "episode :  29\n",
      "current step :  132\n",
      "reward :  -0.4156430421509043\n",
      "episode :  29\n",
      "current step :  133\n",
      "reward :  -0.42942992833266236\n",
      "episode :  29\n",
      "current step :  134\n",
      "reward :  -0.41710192683969605\n",
      "episode :  29\n",
      "current step :  135\n",
      "reward :  -0.42062627800363134\n",
      "episode :  29\n",
      "current step :  136\n",
      "reward :  -0.4192524138781584\n",
      "episode :  29\n",
      "current step :  137\n",
      "reward :  -0.42851364203893466\n",
      "episode :  29\n",
      "current step :  138\n",
      "reward :  -0.4244393478907694\n",
      "episode :  29\n",
      "current step :  139\n",
      "reward :  -0.4063299451960814\n",
      "episode :  29\n",
      "current step :  140\n",
      "reward :  -0.41668482591621453\n",
      "episode :  29\n",
      "current step :  141\n",
      "reward :  -0.4151069108971113\n",
      "episode :  29\n",
      "current step :  142\n",
      "reward :  -0.41293669313628195\n",
      "episode :  29\n",
      "current step :  143\n",
      "reward :  -0.41055988736201393\n",
      "episode :  29\n",
      "current step :  144\n",
      "reward :  -0.4089989137315238\n",
      "episode :  29\n",
      "current step :  145\n",
      "reward :  -0.40819110607053416\n",
      "episode :  29\n",
      "current step :  146\n",
      "reward :  -0.4067225847986113\n",
      "episode :  29\n",
      "current step :  147\n",
      "reward :  -0.40676853631918986\n",
      "episode :  29\n",
      "current step :  148\n",
      "reward :  -0.40878532931697026\n",
      "episode :  29\n",
      "current step :  149\n",
      "reward :  -0.4098830414953229\n",
      "episode :  29\n",
      "current step :  150\n",
      "reward :  -0.41406710262916735\n",
      "episode :  29\n",
      "current step :  151\n",
      "reward :  -0.41803741726264737\n",
      "episode :  29\n",
      "current step :  152\n",
      "reward :  -0.42281784575870984\n",
      "episode :  29\n",
      "current step :  153\n",
      "reward :  -0.42502348321399785\n",
      "episode :  29\n",
      "current step :  154\n",
      "reward :  -0.43077562343454573\n",
      "episode :  29\n",
      "current step :  155\n",
      "reward :  -0.43637431653069303\n",
      "episode :  29\n",
      "current step :  156\n",
      "reward :  -0.4393975964690348\n",
      "episode :  29\n",
      "current step :  157\n",
      "reward :  -0.4465815240184622\n",
      "episode :  29\n",
      "current step :  158\n",
      "reward :  -0.4514024579595058\n",
      "episode :  29\n",
      "current step :  159\n",
      "reward :  -0.4548774773862002\n",
      "episode :  29\n",
      "current step :  160\n",
      "reward :  -0.4568883323547617\n",
      "episode :  29\n",
      "current step :  161\n",
      "reward :  -0.45807799613673833\n",
      "episode :  29\n",
      "current step :  162\n",
      "reward :  -0.46038469673337734\n",
      "episode :  29\n",
      "current step :  163\n",
      "reward :  -0.46373164172330095\n",
      "episode :  29\n",
      "current step :  164\n",
      "reward :  -0.47576676090717845\n",
      "episode :  29\n",
      "current step :  165\n",
      "reward :  -0.47163158238713004\n",
      "episode :  29\n",
      "current step :  166\n",
      "reward :  -0.4849523017448745\n",
      "episode :  29\n",
      "current step :  167\n",
      "reward :  -0.5120135422072752\n",
      "episode :  29\n",
      "current step :  168\n",
      "reward :  -0.47707594653402374\n",
      "episode :  29\n",
      "current step :  169\n",
      "reward :  -0.47945682268979734\n",
      "episode :  29\n",
      "current step :  170\n",
      "reward :  -0.48953210997404034\n",
      "episode :  29\n",
      "current step :  171\n",
      "reward :  -0.48423606789098955\n",
      "episode :  29\n",
      "current step :  172\n",
      "reward :  -0.4863892808982764\n",
      "episode :  29\n",
      "current step :  173\n",
      "reward :  -0.4887201663682308\n",
      "episode :  29\n",
      "current step :  174\n",
      "reward :  -0.4908295785399282\n",
      "episode :  29\n",
      "current step :  175\n",
      "reward :  -0.4937362483303317\n",
      "episode :  29\n",
      "current step :  176\n",
      "reward :  -0.49111240348929147\n",
      "episode :  29\n",
      "current step :  177\n",
      "reward :  -0.49450116397669286\n",
      "episode :  29\n",
      "current step :  178\n",
      "reward :  -0.495515973685397\n",
      "episode :  29\n",
      "current step :  179\n",
      "reward :  -0.5257702935135689\n",
      "episode :  29\n",
      "current step :  180\n",
      "reward :  -0.516158583823105\n",
      "episode :  29\n",
      "current step :  181\n",
      "reward :  -0.49836456188166767\n",
      "episode :  29\n",
      "current step :  182\n",
      "reward :  -0.49887177826483997\n",
      "episode :  29\n",
      "current step :  183\n",
      "reward :  -0.5006341689017304\n",
      "episode :  29\n",
      "current step :  184\n",
      "reward :  -0.5013256146468543\n",
      "episode :  29\n",
      "current step :  185\n",
      "reward :  -0.5023807600022626\n",
      "episode :  29\n",
      "current step :  186\n",
      "reward :  -0.5032582952203826\n",
      "episode :  29\n",
      "current step :  187\n",
      "reward :  -0.5029430403658969\n",
      "episode :  29\n",
      "current step :  188\n",
      "reward :  -0.503137717974697\n",
      "episode :  29\n",
      "current step :  189\n",
      "reward :  -0.5046388817397895\n",
      "episode :  29\n",
      "current step :  190\n",
      "reward :  -0.5048852832355403\n",
      "episode :  29\n",
      "current step :  191\n",
      "reward :  -0.5044140094050916\n",
      "episode :  29\n",
      "current step :  192\n",
      "reward :  -0.5055033009046314\n",
      "episode :  29\n",
      "current step :  193\n",
      "reward :  -0.505179920414748\n",
      "episode :  29\n",
      "current step :  194\n",
      "reward :  -0.5054376390472277\n",
      "episode :  29\n",
      "current step :  195\n",
      "reward :  -0.5052432154729964\n",
      "episode :  29\n",
      "current step :  196\n",
      "reward :  -0.5054105408380107\n",
      "episode :  29\n",
      "current step :  197\n",
      "reward :  -0.5092199981155324\n",
      "episode :  29\n",
      "current step :  198\n",
      "reward :  -0.531711423600207\n",
      "episode :  29\n",
      "current step :  199\n",
      "reward :  -0.5042276761560859\n",
      "episode :  29\n",
      "current step :  200\n",
      "reward :  -0.5035334457693933\n",
      "episode :  29\n",
      "current step :  201\n",
      "reward :  -0.5074519102310208\n",
      "episode :  29\n",
      "current step :  202\n",
      "reward :  -0.5028657098160727\n",
      "episode :  29\n",
      "current step :  203\n",
      "reward :  -0.503075200259264\n",
      "episode :  29\n",
      "current step :  204\n",
      "reward :  -0.500749384779717\n",
      "episode :  29\n",
      "current step :  205\n",
      "reward :  -0.5007694013558504\n",
      "episode :  29\n",
      "current step :  206\n",
      "reward :  -0.49942157405808346\n",
      "episode :  29\n",
      "current step :  207\n",
      "reward :  -0.49871167107805037\n",
      "episode :  29\n",
      "current step :  208\n",
      "reward :  -0.4978474542159319\n",
      "episode :  29\n",
      "current step :  209\n",
      "reward :  -0.4964108680980349\n",
      "episode :  29\n",
      "current step :  210\n",
      "reward :  -0.4961243052929474\n",
      "episode :  29\n",
      "current step :  211\n",
      "reward :  -0.4914713561449586\n",
      "episode :  29\n",
      "current step :  212\n",
      "reward :  -0.4900956202416105\n",
      "episode :  29\n",
      "current step :  213\n",
      "reward :  -0.48811022402366794\n",
      "episode :  29\n",
      "current step :  214\n",
      "reward :  -0.48481770254009754\n",
      "episode :  29\n",
      "current step :  215\n",
      "reward :  -0.48166014285108455\n",
      "episode :  29\n",
      "current step :  216\n",
      "reward :  -0.4783841006532519\n",
      "episode :  29\n",
      "current step :  217\n",
      "reward :  -0.4738855010647788\n",
      "episode :  29\n",
      "current step :  218\n",
      "reward :  -0.4716083033563286\n",
      "episode :  29\n",
      "current step :  219\n",
      "reward :  -0.46725807762311466\n",
      "episode :  29\n",
      "current step :  220\n",
      "reward :  -0.4651758506867671\n",
      "episode :  29\n",
      "current step :  221\n",
      "reward :  -0.4623486186735143\n",
      "episode :  29\n",
      "current step :  222\n",
      "reward :  -0.4597074051164777\n",
      "episode :  29\n",
      "current step :  223\n",
      "reward :  -0.458200339335391\n",
      "episode :  29\n",
      "current step :  224\n",
      "reward :  -0.45776051496714854\n",
      "episode :  29\n",
      "current step :  225\n",
      "reward :  -0.4521602850951575\n",
      "episode :  29\n",
      "current step :  226\n",
      "reward :  -0.4533122820209723\n",
      "episode :  29\n",
      "current step :  227\n",
      "reward :  -0.45230818690134217\n",
      "episode :  29\n",
      "current step :  228\n",
      "reward :  -0.4524937113751506\n",
      "episode :  29\n",
      "current step :  229\n",
      "reward :  -0.45054959187739296\n",
      "episode :  29\n",
      "current step :  230\n",
      "reward :  -0.4454264559720693\n",
      "episode :  29\n",
      "current step :  231\n",
      "reward :  -0.44757647756783986\n",
      "episode :  29\n",
      "current step :  232\n",
      "reward :  -0.4412612763830541\n",
      "episode :  29\n",
      "current step :  233\n",
      "reward :  -0.4373601264016538\n",
      "episode :  29\n",
      "current step :  234\n",
      "reward :  -0.4309528041230936\n",
      "episode :  29\n",
      "current step :  235\n",
      "reward :  -0.42729190066767164\n",
      "episode :  29\n",
      "current step :  236\n",
      "reward :  -0.42114152316987985\n",
      "episode :  29\n",
      "current step :  237\n",
      "reward :  -0.41666619436930885\n",
      "episode :  29\n",
      "current step :  238\n",
      "reward :  -0.41288710026573133\n",
      "episode :  29\n",
      "current step :  239\n",
      "reward :  -0.4094323617276226\n",
      "episode :  29\n",
      "current step :  240\n",
      "reward :  -0.40655677545874674\n",
      "episode :  29\n",
      "current step :  241\n",
      "reward :  -0.4036976008148338\n",
      "episode :  29\n",
      "current step :  242\n",
      "reward :  -0.39992118162842694\n",
      "episode :  29\n",
      "current step :  243\n",
      "reward :  -0.393979796983998\n",
      "episode :  29\n",
      "current step :  244\n",
      "reward :  -0.39934680827510083\n",
      "episode :  29\n",
      "current step :  245\n",
      "reward :  -0.3922737990646249\n",
      "episode :  29\n",
      "current step :  246\n",
      "reward :  -0.40026464678612855\n",
      "episode :  29\n",
      "current step :  247\n",
      "reward :  -0.4024214890084078\n",
      "episode :  29\n",
      "current step :  248\n",
      "reward :  -0.4041048291030802\n",
      "episode :  29\n",
      "current step :  249\n",
      "reward :  -0.40522554073512707\n",
      "episode :  29\n",
      "current step :  250\n",
      "reward :  -0.40808186274867486\n",
      "episode :  29\n",
      "current step :  251\n",
      "reward :  -0.4102452744812189\n",
      "episode :  29\n",
      "current step :  252\n",
      "reward :  -0.4129484309870608\n",
      "episode :  29\n",
      "current step :  253\n",
      "reward :  -0.416129425091431\n",
      "episode :  29\n",
      "current step :  254\n",
      "reward :  -0.4194200957304998\n",
      "episode :  29\n",
      "current step :  255\n",
      "reward :  -0.42219014952953304\n",
      "episode :  29\n",
      "current step :  256\n",
      "reward :  -0.42522710152992166\n",
      "episode :  29\n",
      "current step :  257\n",
      "reward :  -0.42807763127953385\n",
      "episode :  29\n",
      "current step :  258\n",
      "reward :  -0.4312163041752216\n",
      "episode :  29\n",
      "current step :  259\n",
      "reward :  -0.43398281629370783\n",
      "episode :  29\n",
      "current step :  260\n",
      "reward :  -0.43762482255858604\n",
      "episode :  29\n",
      "current step :  261\n",
      "reward :  -0.44101442389377776\n",
      "episode :  29\n",
      "current step :  262\n",
      "reward :  -0.44344285972383113\n",
      "episode :  29\n",
      "current step :  263\n",
      "reward :  -0.4465895669388725\n",
      "episode :  29\n",
      "current step :  264\n",
      "reward :  -0.44840055428874714\n",
      "episode :  29\n",
      "current step :  265\n",
      "reward :  -0.44992078302851524\n",
      "episode :  29\n",
      "current step :  266\n",
      "reward :  -0.4513246950753925\n",
      "episode :  29\n",
      "current step :  267\n",
      "reward :  -0.45235580084057475\n",
      "episode :  29\n",
      "current step :  268\n",
      "reward :  -0.45339136581867784\n",
      "episode :  29\n",
      "current step :  269\n",
      "reward :  -0.45362395407393746\n",
      "episode :  29\n",
      "current step :  270\n",
      "reward :  -0.45497841793988303\n",
      "episode :  29\n",
      "current step :  271\n",
      "reward :  -0.45547150682279786\n",
      "episode :  29\n",
      "current step :  272\n",
      "reward :  -0.45485543512669574\n",
      "episode :  29\n",
      "current step :  273\n",
      "reward :  -0.45426372211759475\n",
      "episode :  29\n",
      "current step :  274\n",
      "reward :  -0.45659682860897466\n",
      "episode :  29\n",
      "current step :  275\n",
      "reward :  -0.4489119510280752\n",
      "episode :  29\n",
      "current step :  276\n",
      "reward :  -0.4576733760873863\n",
      "episode :  29\n",
      "current step :  277\n",
      "reward :  -0.45773446551162533\n",
      "episode :  29\n",
      "current step :  278\n",
      "reward :  -0.45801305220056504\n",
      "episode :  29\n",
      "current step :  279\n",
      "reward :  -0.4576498734076795\n",
      "episode :  29\n",
      "current step :  280\n",
      "reward :  -0.4581727587274828\n",
      "episode :  29\n",
      "current step :  281\n",
      "reward :  -0.4474588561944648\n",
      "episode :  29\n",
      "current step :  282\n",
      "reward :  -0.4565464443912788\n",
      "episode :  29\n",
      "current step :  283\n",
      "reward :  -0.4573230696130397\n",
      "episode :  29\n",
      "current step :  284\n",
      "reward :  -0.4569439580404275\n",
      "episode :  29\n",
      "current step :  285\n",
      "reward :  -0.4569465120873628\n",
      "episode :  30\n",
      "current step :  0\n",
      "reward :  -0.4606553567802318\n",
      "episode :  30\n",
      "current step :  1\n",
      "reward :  -0.4591456533694959\n",
      "episode :  30\n",
      "current step :  2\n",
      "reward :  -0.46890259969312503\n",
      "episode :  30\n",
      "current step :  3\n",
      "reward :  -0.46541298908861173\n",
      "episode :  30\n",
      "current step :  4\n",
      "reward :  -0.4705924016839086\n",
      "episode :  30\n",
      "current step :  5\n",
      "reward :  -0.4714666898852212\n",
      "episode :  30\n",
      "current step :  6\n",
      "reward :  -0.47150334502582586\n",
      "episode :  30\n",
      "current step :  7\n",
      "reward :  -0.47204626095158675\n",
      "episode :  30\n",
      "current step :  8\n",
      "reward :  -0.4709083360845248\n",
      "episode :  30\n",
      "current step :  9\n",
      "reward :  -0.47140794543698816\n",
      "episode :  30\n",
      "current step :  10\n",
      "reward :  -0.46603490896488037\n",
      "episode :  30\n",
      "current step :  11\n",
      "reward :  -0.473001378046205\n",
      "episode :  30\n",
      "current step :  12\n",
      "reward :  -0.4739157048800522\n",
      "episode :  30\n",
      "current step :  13\n",
      "reward :  -0.47472161484112485\n",
      "episode :  30\n",
      "current step :  14\n",
      "reward :  -0.47543237474627303\n",
      "episode :  30\n",
      "current step :  15\n",
      "reward :  -0.4727489699225954\n",
      "episode :  30\n",
      "current step :  16\n",
      "reward :  -0.4580097810542328\n",
      "episode :  30\n",
      "current step :  17\n",
      "reward :  -0.47015678006039463\n",
      "episode :  30\n",
      "current step :  18\n",
      "reward :  -0.47487602059425404\n",
      "episode :  30\n",
      "current step :  19\n",
      "reward :  -0.47938178177195506\n",
      "episode :  30\n",
      "current step :  20\n",
      "reward :  -0.480010623666156\n",
      "episode :  30\n",
      "current step :  21\n",
      "reward :  -0.47946462648259214\n",
      "episode :  30\n",
      "current step :  22\n",
      "reward :  -0.4795859283440153\n",
      "episode :  30\n",
      "current step :  23\n",
      "reward :  -0.484089932651383\n",
      "episode :  30\n",
      "current step :  24\n",
      "reward :  -0.48615203971467286\n",
      "episode :  30\n",
      "current step :  25\n",
      "reward :  -0.48616012432866584\n",
      "episode :  30\n",
      "current step :  26\n",
      "reward :  -0.4827054822529003\n",
      "episode :  30\n",
      "current step :  27\n",
      "reward :  -0.4868601128427713\n",
      "episode :  30\n",
      "current step :  28\n",
      "reward :  -0.4908232841350954\n",
      "episode :  30\n",
      "current step :  29\n",
      "reward :  -0.4861356948642499\n",
      "episode :  30\n",
      "current step :  30\n",
      "reward :  -0.4819738376586221\n",
      "episode :  30\n",
      "current step :  31\n",
      "reward :  -0.49043994958937387\n",
      "episode :  30\n",
      "current step :  32\n",
      "reward :  -0.49228148515938125\n",
      "episode :  30\n",
      "current step :  33\n",
      "reward :  -0.48945013381151786\n",
      "episode :  30\n",
      "current step :  34\n",
      "reward :  -0.4755871912093819\n",
      "episode :  30\n",
      "current step :  35\n",
      "reward :  -0.4862131264858086\n",
      "episode :  30\n",
      "current step :  36\n",
      "reward :  -0.4730507082951895\n",
      "episode :  30\n",
      "current step :  37\n",
      "reward :  -0.4675091597603775\n",
      "episode :  30\n",
      "current step :  38\n",
      "reward :  -0.4756404727056151\n",
      "episode :  30\n",
      "current step :  39\n",
      "reward :  -0.4719553429525191\n",
      "episode :  30\n",
      "current step :  40\n",
      "reward :  -0.4556471394064155\n",
      "episode :  30\n",
      "current step :  41\n",
      "reward :  -0.4515106515926679\n",
      "episode :  30\n",
      "current step :  42\n",
      "reward :  -0.4485138035100539\n",
      "episode :  30\n",
      "current step :  43\n",
      "reward :  -0.4811446114081378\n",
      "episode :  30\n",
      "current step :  44\n",
      "reward :  -0.46253465094639545\n",
      "episode :  30\n",
      "current step :  45\n",
      "reward :  -0.44765715872570605\n",
      "episode :  30\n",
      "current step :  46\n",
      "reward :  -0.45936655212511207\n",
      "episode :  30\n",
      "current step :  47\n",
      "reward :  -0.46079363452674704\n",
      "episode :  30\n",
      "current step :  48\n",
      "reward :  -0.4447533464473979\n",
      "episode :  30\n",
      "current step :  49\n",
      "reward :  -0.46477561249101945\n",
      "episode :  30\n",
      "current step :  50\n",
      "reward :  -0.46698711509010277\n",
      "episode :  30\n",
      "current step :  51\n",
      "reward :  -0.4418672969065248\n",
      "episode :  30\n",
      "current step :  52\n",
      "reward :  -0.4529749823871578\n",
      "episode :  30\n",
      "current step :  53\n",
      "reward :  -0.47156234553928467\n",
      "episode :  30\n",
      "current step :  54\n",
      "reward :  -0.4701088600443798\n",
      "episode :  30\n",
      "current step :  55\n",
      "reward :  -0.47006760036498446\n",
      "episode :  30\n",
      "current step :  56\n",
      "reward :  -0.47184942014173026\n",
      "episode :  30\n",
      "current step :  57\n",
      "reward :  -0.4714513826684444\n",
      "episode :  30\n",
      "current step :  58\n",
      "reward :  -0.47239006799698585\n",
      "episode :  30\n",
      "current step :  59\n",
      "reward :  -0.4743410696722048\n",
      "episode :  30\n",
      "current step :  60\n",
      "reward :  -0.476747529561282\n",
      "episode :  30\n",
      "current step :  61\n",
      "reward :  -0.47728235894662846\n",
      "episode :  30\n",
      "current step :  62\n",
      "reward :  -0.4805378966152621\n",
      "episode :  30\n",
      "current step :  63\n",
      "reward :  -0.47196637464654545\n",
      "episode :  30\n",
      "current step :  64\n",
      "reward :  -0.472964542404076\n",
      "episode :  30\n",
      "current step :  65\n",
      "reward :  -0.4739649651595925\n",
      "episode :  30\n",
      "current step :  66\n",
      "reward :  -0.4734310970975883\n",
      "episode :  30\n",
      "current step :  67\n",
      "reward :  -0.47363965843160355\n",
      "episode :  30\n",
      "current step :  68\n",
      "reward :  -0.47271736678557635\n",
      "episode :  30\n",
      "current step :  69\n",
      "reward :  -0.474782259640208\n",
      "episode :  30\n",
      "current step :  70\n",
      "reward :  -0.4769870516013\n",
      "episode :  30\n",
      "current step :  71\n",
      "reward :  -0.4762931076794545\n",
      "episode :  30\n",
      "current step :  72\n",
      "reward :  -0.4714649458484339\n",
      "episode :  30\n",
      "current step :  73\n",
      "reward :  -0.4734366896899128\n",
      "episode :  30\n",
      "current step :  74\n",
      "reward :  -0.4740843814642863\n",
      "episode :  30\n",
      "current step :  75\n",
      "reward :  -0.47367715947519645\n",
      "episode :  30\n",
      "current step :  76\n",
      "reward :  -0.47315686536304846\n",
      "episode :  30\n",
      "current step :  77\n",
      "reward :  -0.47537223915508925\n",
      "episode :  30\n",
      "current step :  78\n",
      "reward :  -0.4770670786958916\n",
      "episode :  30\n",
      "current step :  79\n",
      "reward :  -0.4730854262484306\n",
      "episode :  30\n",
      "current step :  80\n",
      "reward :  -0.4702680103451219\n",
      "episode :  30\n",
      "current step :  81\n",
      "reward :  -0.4662651432029163\n",
      "episode :  30\n",
      "current step :  82\n",
      "reward :  -0.46466269349107664\n",
      "episode :  30\n",
      "current step :  83\n",
      "reward :  -0.4617559378635551\n",
      "episode :  30\n",
      "current step :  84\n",
      "reward :  -0.46250863427920474\n",
      "episode :  30\n",
      "current step :  85\n",
      "reward :  -0.46407367716882264\n",
      "episode :  30\n",
      "current step :  86\n",
      "reward :  -0.4627111293092853\n",
      "episode :  30\n",
      "current step :  87\n",
      "reward :  -0.46241679923887385\n",
      "episode :  30\n",
      "current step :  88\n",
      "reward :  -0.43491433700530197\n",
      "episode :  30\n",
      "current step :  89\n",
      "reward :  -0.44449913858769685\n",
      "episode :  30\n",
      "current step :  90\n",
      "reward :  -0.460113879200022\n",
      "episode :  30\n",
      "current step :  91\n",
      "reward :  -0.469951863236439\n",
      "episode :  30\n",
      "current step :  92\n",
      "reward :  -0.4690172374260761\n",
      "episode :  30\n",
      "current step :  93\n",
      "reward :  -0.46745961125214897\n",
      "episode :  30\n",
      "current step :  94\n",
      "reward :  -0.46789322665989735\n",
      "episode :  30\n",
      "current step :  95\n",
      "reward :  -0.4678247798731508\n",
      "episode :  30\n",
      "current step :  96\n",
      "reward :  -0.46775324367651727\n",
      "episode :  30\n",
      "current step :  97\n",
      "reward :  -0.4691133390645355\n",
      "episode :  30\n",
      "current step :  98\n",
      "reward :  -0.4672407245820042\n",
      "episode :  30\n",
      "current step :  99\n",
      "reward :  -0.4690492627398896\n",
      "episode :  30\n",
      "current step :  100\n",
      "reward :  -0.4667990275777005\n",
      "episode :  30\n",
      "current step :  101\n",
      "reward :  -0.4632147068473873\n",
      "episode :  30\n",
      "current step :  102\n",
      "reward :  -0.46494222042147454\n",
      "episode :  30\n",
      "current step :  103\n",
      "reward :  -0.46120998362813326\n",
      "episode :  30\n",
      "current step :  104\n",
      "reward :  -0.4657698591040671\n",
      "episode :  30\n",
      "current step :  105\n",
      "reward :  -0.46310198637736616\n",
      "episode :  30\n",
      "current step :  106\n",
      "reward :  -0.46277514035671974\n",
      "episode :  30\n",
      "current step :  107\n",
      "reward :  -0.4570707663808649\n",
      "episode :  30\n",
      "current step :  108\n",
      "reward :  -0.46154982140927164\n",
      "episode :  30\n",
      "current step :  109\n",
      "reward :  -0.46082152077406235\n",
      "episode :  30\n",
      "current step :  110\n",
      "reward :  -0.4609981774176275\n",
      "episode :  30\n",
      "current step :  111\n",
      "reward :  -0.4595691354973951\n",
      "episode :  30\n",
      "current step :  112\n",
      "reward :  -0.45899878354183044\n",
      "episode :  30\n",
      "current step :  113\n",
      "reward :  -0.4589246775454387\n",
      "episode :  30\n",
      "current step :  114\n",
      "reward :  -0.45633151944875816\n",
      "episode :  30\n",
      "current step :  115\n",
      "reward :  -0.4557673071355196\n",
      "episode :  30\n",
      "current step :  116\n",
      "reward :  -0.45569407191819794\n",
      "episode :  30\n",
      "current step :  117\n",
      "reward :  -0.4555666536879927\n",
      "episode :  30\n",
      "current step :  118\n",
      "reward :  -0.4532271386151743\n",
      "episode :  30\n",
      "current step :  119\n",
      "reward :  -0.4548580389595413\n",
      "episode :  30\n",
      "current step :  120\n",
      "reward :  -0.4537269204652255\n",
      "episode :  30\n",
      "current step :  121\n",
      "reward :  -0.4527711815269973\n",
      "episode :  30\n",
      "current step :  122\n",
      "reward :  -0.45095800161416016\n",
      "episode :  30\n",
      "current step :  123\n",
      "reward :  -0.45273528636813964\n",
      "episode :  30\n",
      "current step :  124\n",
      "reward :  -0.45058693777072384\n",
      "episode :  30\n",
      "current step :  125\n",
      "reward :  -0.44776543273952196\n",
      "episode :  30\n",
      "current step :  126\n",
      "reward :  -0.4466612379595162\n",
      "episode :  30\n",
      "current step :  127\n",
      "reward :  -0.44651262993039825\n",
      "episode :  30\n",
      "current step :  128\n",
      "reward :  -0.44657708829095\n",
      "episode :  30\n",
      "current step :  129\n",
      "reward :  -0.44345877927273764\n",
      "episode :  30\n",
      "current step :  130\n",
      "reward :  -0.440297265812762\n",
      "episode :  30\n",
      "current step :  131\n",
      "reward :  -0.4368684166171326\n",
      "episode :  30\n",
      "current step :  132\n",
      "reward :  -0.43450961293372925\n",
      "episode :  30\n",
      "current step :  133\n",
      "reward :  -0.43053163411945256\n",
      "episode :  30\n",
      "current step :  134\n",
      "reward :  -0.4277377478854567\n",
      "episode :  30\n",
      "current step :  135\n",
      "reward :  -0.424002848279532\n",
      "episode :  30\n",
      "current step :  136\n",
      "reward :  -0.42143469258758115\n",
      "episode :  30\n",
      "current step :  137\n",
      "reward :  -0.4157014204295471\n",
      "episode :  30\n",
      "current step :  138\n",
      "reward :  -0.41396090329930396\n",
      "episode :  30\n",
      "current step :  139\n",
      "reward :  -0.41039342486956404\n",
      "episode :  30\n",
      "current step :  140\n",
      "reward :  -0.4064923690613374\n",
      "episode :  30\n",
      "current step :  141\n",
      "reward :  -0.4026636611627083\n",
      "episode :  30\n",
      "current step :  142\n",
      "reward :  -0.40082120025167606\n",
      "episode :  30\n",
      "current step :  143\n",
      "reward :  -0.39655381534039863\n",
      "episode :  30\n",
      "current step :  144\n",
      "reward :  -0.39173246946534646\n",
      "episode :  30\n",
      "current step :  145\n",
      "reward :  -0.39240030811362797\n",
      "episode :  30\n",
      "current step :  146\n",
      "reward :  -0.39282365247403583\n",
      "episode :  30\n",
      "current step :  147\n",
      "reward :  -0.3951194208621299\n",
      "episode :  30\n",
      "current step :  148\n",
      "reward :  -0.395272534788627\n",
      "episode :  30\n",
      "current step :  149\n",
      "reward :  -0.3963174678323256\n",
      "episode :  30\n",
      "current step :  150\n",
      "reward :  -0.4003382120904479\n",
      "episode :  30\n",
      "current step :  151\n",
      "reward :  -0.40431736056301365\n",
      "episode :  30\n",
      "current step :  152\n",
      "reward :  -0.40972848424597774\n",
      "episode :  30\n",
      "current step :  153\n",
      "reward :  -0.4077322060423718\n",
      "episode :  30\n",
      "current step :  154\n",
      "reward :  -0.41403496640344567\n",
      "episode :  30\n",
      "current step :  155\n",
      "reward :  -0.4224885586224895\n",
      "episode :  30\n",
      "current step :  156\n",
      "reward :  -0.4287079797201484\n",
      "episode :  30\n",
      "current step :  157\n",
      "reward :  -0.434615308178515\n",
      "episode :  30\n",
      "current step :  158\n",
      "reward :  -0.4371293157990333\n",
      "episode :  30\n",
      "current step :  159\n",
      "reward :  -0.44435250762661965\n",
      "episode :  30\n",
      "current step :  160\n",
      "reward :  -0.44238185245480083\n",
      "episode :  30\n",
      "current step :  161\n",
      "reward :  -0.44623027766225865\n",
      "episode :  30\n",
      "current step :  162\n",
      "reward :  -0.4473223088596466\n",
      "episode :  30\n",
      "current step :  163\n",
      "reward :  -0.4498770045169491\n",
      "episode :  30\n",
      "current step :  164\n",
      "reward :  -0.45423601029695904\n",
      "episode :  30\n",
      "current step :  165\n",
      "reward :  -0.45772275527658307\n",
      "episode :  30\n",
      "current step :  166\n",
      "reward :  -0.4603740916013566\n",
      "episode :  30\n",
      "current step :  167\n",
      "reward :  -0.46299778570781946\n",
      "episode :  30\n",
      "current step :  168\n",
      "reward :  -0.46530632083487394\n",
      "episode :  30\n",
      "current step :  169\n",
      "reward :  -0.46675594082354777\n",
      "episode :  30\n",
      "current step :  170\n",
      "reward :  -0.46813146929096383\n",
      "episode :  30\n",
      "current step :  171\n",
      "reward :  -0.4736241886368598\n",
      "episode :  30\n",
      "current step :  172\n",
      "reward :  -0.47313465479763617\n",
      "episode :  30\n",
      "current step :  173\n",
      "reward :  -0.47675300117324293\n",
      "episode :  30\n",
      "current step :  174\n",
      "reward :  -0.47940278262693553\n",
      "episode :  30\n",
      "current step :  175\n",
      "reward :  -0.47621798352663136\n",
      "episode :  30\n",
      "current step :  176\n",
      "reward :  -0.480593416873124\n",
      "episode :  30\n",
      "current step :  177\n",
      "reward :  -0.4806900346885717\n",
      "episode :  30\n",
      "current step :  178\n",
      "reward :  -0.48098342617655127\n",
      "episode :  30\n",
      "current step :  179\n",
      "reward :  -0.48602329871556127\n",
      "episode :  30\n",
      "current step :  180\n",
      "reward :  -0.4856981514274847\n",
      "episode :  30\n",
      "current step :  181\n",
      "reward :  -0.486935958546554\n",
      "episode :  30\n",
      "current step :  182\n",
      "reward :  -0.4885409738289918\n",
      "episode :  30\n",
      "current step :  183\n",
      "reward :  -0.49058017121980513\n",
      "episode :  30\n",
      "current step :  184\n",
      "reward :  -0.49120876820311266\n",
      "episode :  30\n",
      "current step :  185\n",
      "reward :  -0.4909168617767082\n",
      "episode :  30\n",
      "current step :  186\n",
      "reward :  -0.4909744193309282\n",
      "episode :  30\n",
      "current step :  187\n",
      "reward :  -0.48934315878883416\n",
      "episode :  30\n",
      "current step :  188\n",
      "reward :  -0.4927131176679008\n",
      "episode :  30\n",
      "current step :  189\n",
      "reward :  -0.4878359846246443\n",
      "episode :  30\n",
      "current step :  190\n",
      "reward :  -0.49093538942057285\n",
      "episode :  30\n",
      "current step :  191\n",
      "reward :  -0.4919558465368773\n",
      "episode :  30\n",
      "current step :  192\n",
      "reward :  -0.49216325292483765\n",
      "episode :  30\n",
      "current step :  193\n",
      "reward :  -0.4929010782600819\n",
      "episode :  30\n",
      "current step :  194\n",
      "reward :  -0.4904827086299521\n",
      "episode :  30\n",
      "current step :  195\n",
      "reward :  -0.4936228969509652\n",
      "episode :  30\n",
      "current step :  196\n",
      "reward :  -0.49223017880254394\n",
      "episode :  30\n",
      "current step :  197\n",
      "reward :  -0.4921386497507284\n",
      "episode :  30\n",
      "current step :  198\n",
      "reward :  -0.49238222456587105\n",
      "episode :  30\n",
      "current step :  199\n",
      "reward :  -0.49172831317867965\n",
      "episode :  30\n",
      "current step :  200\n",
      "reward :  -0.4915844202455456\n",
      "episode :  30\n",
      "current step :  201\n",
      "reward :  -0.4883976766996623\n",
      "episode :  30\n",
      "current step :  202\n",
      "reward :  -0.4911854162396372\n",
      "episode :  30\n",
      "current step :  203\n",
      "reward :  -0.490307477966524\n",
      "episode :  30\n",
      "current step :  204\n",
      "reward :  -0.48805868090960514\n",
      "episode :  30\n",
      "current step :  205\n",
      "reward :  -0.4880515506576833\n",
      "episode :  30\n",
      "current step :  206\n",
      "reward :  -0.48624361906908925\n",
      "episode :  30\n",
      "current step :  207\n",
      "reward :  -0.4819373662915547\n",
      "episode :  30\n",
      "current step :  208\n",
      "reward :  -0.4864096307718724\n",
      "episode :  30\n",
      "current step :  209\n",
      "reward :  -0.48327635165073646\n",
      "episode :  30\n",
      "current step :  210\n",
      "reward :  -0.4783402353212636\n",
      "episode :  30\n",
      "current step :  211\n",
      "reward :  -0.4785968633711615\n",
      "episode :  30\n",
      "current step :  212\n",
      "reward :  -0.4777534472817422\n",
      "episode :  30\n",
      "current step :  213\n",
      "reward :  -0.4736828732380905\n",
      "episode :  30\n",
      "current step :  214\n",
      "reward :  -0.47254290268595733\n",
      "episode :  30\n",
      "current step :  215\n",
      "reward :  -0.4688985506210064\n",
      "episode :  30\n",
      "current step :  216\n",
      "reward :  -0.46065548111407767\n",
      "episode :  30\n",
      "current step :  217\n",
      "reward :  -0.4625975126306049\n",
      "episode :  30\n",
      "current step :  218\n",
      "reward :  -0.46025538351007633\n",
      "episode :  30\n",
      "current step :  219\n",
      "reward :  -0.4547289810386819\n",
      "episode :  30\n",
      "current step :  220\n",
      "reward :  -0.4464971791472095\n",
      "episode :  30\n",
      "current step :  221\n",
      "reward :  -0.4491000414325512\n",
      "episode :  30\n",
      "current step :  222\n",
      "reward :  -0.44476090660131923\n",
      "episode :  30\n",
      "current step :  223\n",
      "reward :  -0.4435470334060641\n",
      "episode :  30\n",
      "current step :  224\n",
      "reward :  -0.44250215303499235\n",
      "episode :  30\n",
      "current step :  225\n",
      "reward :  -0.44007269883970584\n",
      "episode :  30\n",
      "current step :  226\n",
      "reward :  -0.44033490035222117\n",
      "episode :  30\n",
      "current step :  227\n",
      "reward :  -0.4403763585911005\n",
      "episode :  30\n",
      "current step :  228\n",
      "reward :  -0.43705898840596014\n",
      "episode :  30\n",
      "current step :  229\n",
      "reward :  -0.4372883733957801\n",
      "episode :  30\n",
      "current step :  230\n",
      "reward :  -0.4328300378001973\n",
      "episode :  30\n",
      "current step :  231\n",
      "reward :  -0.43239346989946703\n",
      "episode :  30\n",
      "current step :  232\n",
      "reward :  -0.4290210976766291\n",
      "episode :  30\n",
      "current step :  233\n",
      "reward :  -0.42451181381986314\n",
      "episode :  30\n",
      "current step :  234\n",
      "reward :  -0.4172221358531647\n",
      "episode :  30\n",
      "current step :  235\n",
      "reward :  -0.41427566557771245\n",
      "episode :  30\n",
      "current step :  236\n",
      "reward :  -0.4085519936223919\n",
      "episode :  30\n",
      "current step :  237\n",
      "reward :  -0.40092726347362345\n",
      "episode :  30\n",
      "current step :  238\n",
      "reward :  -0.39961022149548614\n",
      "episode :  30\n",
      "current step :  239\n",
      "reward :  -0.3948069213198627\n",
      "episode :  30\n",
      "current step :  240\n",
      "reward :  -0.39094553934043513\n",
      "episode :  30\n",
      "current step :  241\n",
      "reward :  -0.3885640697561776\n",
      "episode :  30\n",
      "current step :  242\n",
      "reward :  -0.3876688908403622\n",
      "episode :  30\n",
      "current step :  243\n",
      "reward :  -0.38833143812687315\n",
      "episode :  30\n",
      "current step :  244\n",
      "reward :  -0.3864324205674815\n",
      "episode :  30\n",
      "current step :  245\n",
      "reward :  -0.3865213977564474\n",
      "episode :  30\n",
      "current step :  246\n",
      "reward :  -0.38874357056406067\n",
      "episode :  30\n",
      "current step :  247\n",
      "reward :  -0.3888525844008001\n",
      "episode :  30\n",
      "current step :  248\n",
      "reward :  -0.3899464771282023\n",
      "episode :  30\n",
      "current step :  249\n",
      "reward :  -0.39300474509446587\n",
      "episode :  30\n",
      "current step :  250\n",
      "reward :  -0.39642764982702217\n",
      "episode :  30\n",
      "current step :  251\n",
      "reward :  -0.3994100421684527\n",
      "episode :  30\n",
      "current step :  252\n",
      "reward :  -0.4014273226882567\n",
      "episode :  30\n",
      "current step :  253\n",
      "reward :  -0.40426330597855725\n",
      "episode :  30\n",
      "current step :  254\n",
      "reward :  -0.40574497020920036\n",
      "episode :  30\n",
      "current step :  255\n",
      "reward :  -0.4105608691825511\n",
      "episode :  30\n",
      "current step :  256\n",
      "reward :  -0.4153214779136821\n",
      "episode :  30\n",
      "current step :  257\n",
      "reward :  -0.4205831033420458\n",
      "episode :  30\n",
      "current step :  258\n",
      "reward :  -0.42207002678241795\n",
      "episode :  30\n",
      "current step :  259\n",
      "reward :  -0.4212336991938106\n",
      "episode :  30\n",
      "current step :  260\n",
      "reward :  -0.4265544179753257\n",
      "episode :  30\n",
      "current step :  261\n",
      "reward :  -0.4248175922301284\n",
      "episode :  30\n",
      "current step :  262\n",
      "reward :  -0.4325822165794908\n",
      "episode :  30\n",
      "current step :  263\n",
      "reward :  -0.4355123995752709\n",
      "episode :  30\n",
      "current step :  264\n",
      "reward :  -0.4378203311538907\n",
      "episode :  30\n",
      "current step :  265\n",
      "reward :  -0.4402745561743891\n",
      "episode :  30\n",
      "current step :  266\n",
      "reward :  -0.45981568480951507\n",
      "episode :  30\n",
      "current step :  267\n",
      "reward :  -0.44246620696645694\n",
      "episode :  30\n",
      "current step :  268\n",
      "reward :  -0.4489174606722935\n",
      "episode :  30\n",
      "current step :  269\n",
      "reward :  -0.44507727024056604\n",
      "episode :  30\n",
      "current step :  270\n",
      "reward :  -0.46607740607813647\n",
      "episode :  30\n",
      "current step :  271\n",
      "reward :  -0.4706186189679591\n",
      "episode :  30\n",
      "current step :  272\n",
      "reward :  -0.4461095422078934\n",
      "episode :  30\n",
      "current step :  273\n",
      "reward :  -0.44616066733976767\n",
      "episode :  30\n",
      "current step :  274\n",
      "reward :  -0.44794528928632094\n",
      "episode :  30\n",
      "current step :  275\n",
      "reward :  -0.44808008931509213\n",
      "episode :  30\n",
      "current step :  276\n",
      "reward :  -0.4479592399427343\n",
      "episode :  30\n",
      "current step :  277\n",
      "reward :  -0.44791753420699126\n",
      "episode :  30\n",
      "current step :  278\n",
      "reward :  -0.44841260950261597\n",
      "episode :  30\n",
      "current step :  279\n",
      "reward :  -0.44880027746118195\n",
      "episode :  30\n",
      "current step :  280\n",
      "reward :  -0.4464715777167443\n",
      "episode :  30\n",
      "current step :  281\n",
      "reward :  -0.4474390170727483\n",
      "episode :  30\n",
      "current step :  282\n",
      "reward :  -0.4463924985519209\n",
      "episode :  30\n",
      "current step :  283\n",
      "reward :  -0.46584770597355\n",
      "episode :  30\n",
      "current step :  284\n",
      "reward :  -0.4895963792904646\n",
      "episode :  30\n",
      "current step :  285\n",
      "reward :  -0.4693518769656332\n",
      "episode :  31\n",
      "current step :  0\n",
      "reward :  -0.46180485013937855\n",
      "episode :  31\n",
      "current step :  1\n",
      "reward :  -0.46183311193583604\n",
      "episode :  31\n",
      "current step :  2\n",
      "reward :  -0.4820746535606844\n",
      "episode :  31\n",
      "current step :  3\n",
      "reward :  -0.4720769470176127\n",
      "episode :  31\n",
      "current step :  4\n",
      "reward :  -0.461739553054825\n",
      "episode :  31\n",
      "current step :  5\n",
      "reward :  -0.4564041418417983\n",
      "episode :  31\n",
      "current step :  6\n",
      "reward :  -0.4625586005956634\n",
      "episode :  31\n",
      "current step :  7\n",
      "reward :  -0.46451490039214155\n",
      "episode :  31\n",
      "current step :  8\n",
      "reward :  -0.46520188495662756\n",
      "episode :  31\n",
      "current step :  9\n",
      "reward :  -0.465022759335917\n",
      "episode :  31\n",
      "current step :  10\n",
      "reward :  -0.4653173846499477\n",
      "episode :  31\n",
      "current step :  11\n",
      "reward :  -0.4663988854194396\n",
      "episode :  31\n",
      "current step :  12\n",
      "reward :  -0.46798691944551096\n",
      "episode :  31\n",
      "current step :  13\n",
      "reward :  -0.4698847203799988\n",
      "episode :  31\n",
      "current step :  14\n",
      "reward :  -0.4712055984965419\n",
      "episode :  31\n",
      "current step :  15\n",
      "reward :  -0.47472064425283195\n",
      "episode :  31\n",
      "current step :  16\n",
      "reward :  -0.4766663891211578\n",
      "episode :  31\n",
      "current step :  17\n",
      "reward :  -0.4765236399334682\n",
      "episode :  31\n",
      "current step :  18\n",
      "reward :  -0.47813975907171097\n",
      "episode :  31\n",
      "current step :  19\n",
      "reward :  -0.4799698680837198\n",
      "episode :  31\n",
      "current step :  20\n",
      "reward :  -0.4831482445105606\n",
      "episode :  31\n",
      "current step :  21\n",
      "reward :  -0.48428246022694227\n",
      "episode :  31\n",
      "current step :  22\n",
      "reward :  -0.4836337483757484\n",
      "episode :  31\n",
      "current step :  23\n",
      "reward :  -0.4868151566415955\n",
      "episode :  31\n",
      "current step :  24\n",
      "reward :  -0.4904785587230311\n",
      "episode :  31\n",
      "current step :  25\n",
      "reward :  -0.48933496342755134\n",
      "episode :  31\n",
      "current step :  26\n",
      "reward :  -0.4942091529893764\n",
      "episode :  31\n",
      "current step :  27\n",
      "reward :  -0.49516916252623855\n",
      "episode :  31\n",
      "current step :  28\n",
      "reward :  -0.4978920977892106\n",
      "episode :  31\n",
      "current step :  29\n",
      "reward :  -0.4938647147855997\n",
      "episode :  31\n",
      "current step :  30\n",
      "reward :  -0.4948072162999613\n",
      "episode :  31\n",
      "current step :  31\n",
      "reward :  -0.4981022189108375\n",
      "episode :  31\n",
      "current step :  32\n",
      "reward :  -0.49756397096119803\n",
      "episode :  31\n",
      "current step :  33\n",
      "reward :  -0.49672689336177456\n",
      "episode :  31\n",
      "current step :  34\n",
      "reward :  -0.49277731497271127\n",
      "episode :  31\n",
      "current step :  35\n",
      "reward :  -0.49393151508358063\n",
      "episode :  31\n",
      "current step :  36\n",
      "reward :  -0.4891391634029326\n",
      "episode :  31\n",
      "current step :  37\n",
      "reward :  -0.4842864396882934\n",
      "episode :  31\n",
      "current step :  38\n",
      "reward :  -0.4811205178382847\n",
      "episode :  31\n",
      "current step :  39\n",
      "reward :  -0.4754162462520558\n",
      "episode :  31\n",
      "current step :  40\n",
      "reward :  -0.4753133647929347\n",
      "episode :  31\n",
      "current step :  41\n",
      "reward :  -0.4671633545442856\n",
      "episode :  31\n",
      "current step :  42\n",
      "reward :  -0.4647816082160963\n",
      "episode :  31\n",
      "current step :  43\n",
      "reward :  -0.4594782695703547\n",
      "episode :  31\n",
      "current step :  44\n",
      "reward :  -0.46107291053732247\n",
      "episode :  31\n",
      "current step :  45\n",
      "reward :  -0.46093936501347177\n",
      "episode :  31\n",
      "current step :  46\n",
      "reward :  -0.46085279810227947\n",
      "episode :  31\n",
      "current step :  47\n",
      "reward :  -0.46196576896137415\n",
      "episode :  31\n",
      "current step :  48\n",
      "reward :  -0.4641250518554911\n",
      "episode :  31\n",
      "current step :  49\n",
      "reward :  -0.4697923185665306\n",
      "episode :  31\n",
      "current step :  50\n",
      "reward :  -0.47302744932885266\n",
      "episode :  31\n",
      "current step :  51\n",
      "reward :  -0.472352593852585\n",
      "episode :  31\n",
      "current step :  52\n",
      "reward :  -0.47200725939051436\n",
      "episode :  31\n",
      "current step :  53\n",
      "reward :  -0.4783040161512898\n",
      "episode :  31\n",
      "current step :  54\n",
      "reward :  -0.4783416306460103\n",
      "episode :  31\n",
      "current step :  55\n",
      "reward :  -0.48131306238737315\n",
      "episode :  31\n",
      "current step :  56\n",
      "reward :  -0.4743508059741583\n",
      "episode :  31\n",
      "current step :  57\n",
      "reward :  -0.48802669154267836\n",
      "episode :  31\n",
      "current step :  58\n",
      "reward :  -0.4754255139997218\n",
      "episode :  31\n",
      "current step :  59\n",
      "reward :  -0.4731758662599158\n",
      "episode :  31\n",
      "current step :  60\n",
      "reward :  -0.4749361257923932\n",
      "episode :  31\n",
      "current step :  61\n",
      "reward :  -0.47897483995503315\n",
      "episode :  31\n",
      "current step :  62\n",
      "reward :  -0.48890689062064185\n",
      "episode :  31\n",
      "current step :  63\n",
      "reward :  -0.4876604685778983\n",
      "episode :  31\n",
      "current step :  64\n",
      "reward :  -0.48787319713791516\n",
      "episode :  31\n",
      "current step :  65\n",
      "reward :  -0.49470521075510804\n",
      "episode :  31\n",
      "current step :  66\n",
      "reward :  -0.5054944424179962\n",
      "episode :  31\n",
      "current step :  67\n",
      "reward :  -0.5034166554632087\n",
      "episode :  31\n",
      "current step :  68\n",
      "reward :  -0.5115942962401118\n",
      "episode :  31\n",
      "current step :  69\n",
      "reward :  -0.5196618694275222\n",
      "episode :  31\n",
      "current step :  70\n",
      "reward :  -0.5637064631057268\n",
      "episode :  31\n",
      "current step :  71\n",
      "reward :  -0.5893370286996319\n",
      "episode :  31\n",
      "current step :  72\n",
      "reward :  -0.5983053076887827\n",
      "episode :  31\n",
      "current step :  73\n",
      "reward :  -0.5339260642482981\n",
      "episode :  31\n",
      "current step :  74\n",
      "reward :  -0.4914844688289693\n",
      "episode :  31\n",
      "current step :  75\n",
      "reward :  -0.48288559702048567\n",
      "episode :  31\n",
      "current step :  76\n",
      "reward :  -0.49610058223209924\n",
      "episode :  31\n",
      "current step :  77\n",
      "reward :  -0.5021032445631342\n",
      "episode :  31\n",
      "current step :  78\n",
      "reward :  -0.49243096409286885\n",
      "episode :  31\n",
      "current step :  79\n",
      "reward :  -0.49794684292833735\n",
      "episode :  31\n",
      "current step :  80\n",
      "reward :  -0.5293179808044248\n",
      "episode :  31\n",
      "current step :  81\n",
      "reward :  -0.4438930460445274\n",
      "episode :  31\n",
      "current step :  82\n",
      "reward :  -0.4321539546842893\n",
      "episode :  31\n",
      "current step :  83\n",
      "reward :  -0.44077646021309885\n",
      "episode :  31\n",
      "current step :  84\n",
      "reward :  -0.4549639653927647\n",
      "episode :  31\n",
      "current step :  85\n",
      "reward :  -0.4649782342925993\n",
      "episode :  31\n",
      "current step :  86\n",
      "reward :  -0.46009392376048397\n",
      "episode :  31\n",
      "current step :  87\n",
      "reward :  -0.42538809060598287\n",
      "episode :  31\n",
      "current step :  88\n",
      "reward :  -0.41158766500781924\n",
      "episode :  31\n",
      "current step :  89\n",
      "reward :  -0.3626530195355044\n",
      "episode :  31\n",
      "current step :  90\n",
      "reward :  -0.3528036663486732\n",
      "episode :  31\n",
      "current step :  91\n",
      "reward :  -0.37796409423114385\n",
      "episode :  31\n",
      "current step :  92\n",
      "reward :  -0.3841358318618542\n",
      "episode :  31\n",
      "current step :  93\n",
      "reward :  -0.4190490230354857\n",
      "episode :  31\n",
      "current step :  94\n",
      "reward :  -0.36616394703608857\n",
      "episode :  31\n",
      "current step :  95\n",
      "reward :  -0.3414482610587923\n",
      "episode :  31\n",
      "current step :  96\n",
      "reward :  -0.3482123393644839\n",
      "episode :  31\n",
      "current step :  97\n",
      "reward :  -0.42213239901103444\n",
      "episode :  31\n",
      "current step :  98\n",
      "reward :  -0.48389614060701003\n",
      "episode :  31\n",
      "current step :  99\n",
      "reward :  -0.48210928898416866\n",
      "episode :  31\n",
      "current step :  100\n",
      "reward :  -0.4335707069643754\n",
      "episode :  31\n",
      "current step :  101\n",
      "reward :  -0.3984149702917112\n",
      "episode :  31\n",
      "current step :  102\n",
      "reward :  -0.3815111433082358\n",
      "episode :  31\n",
      "current step :  103\n",
      "reward :  -0.43860930368889295\n",
      "episode :  31\n",
      "current step :  104\n",
      "reward :  -0.4718315313023871\n",
      "episode :  31\n",
      "current step :  105\n",
      "reward :  -0.3978964952007211\n",
      "episode :  31\n",
      "current step :  106\n",
      "reward :  -0.4029210297470504\n",
      "episode :  31\n",
      "current step :  107\n",
      "reward :  -0.42938667582855067\n",
      "episode :  31\n",
      "current step :  108\n",
      "reward :  -0.4991584816011713\n",
      "episode :  31\n",
      "current step :  109\n",
      "reward :  -0.5228774473499662\n",
      "episode :  31\n",
      "current step :  110\n",
      "reward :  -0.4676143743188578\n",
      "episode :  31\n",
      "current step :  111\n",
      "reward :  -0.42526145056420017\n",
      "episode :  31\n",
      "current step :  112\n",
      "reward :  -0.421727953663611\n",
      "episode :  31\n",
      "current step :  113\n",
      "reward :  -0.4311604913149592\n",
      "episode :  31\n",
      "current step :  114\n",
      "reward :  -0.46651816075267655\n",
      "episode :  31\n",
      "current step :  115\n",
      "reward :  -0.5184587572368018\n",
      "episode :  31\n",
      "current step :  116\n",
      "reward :  -0.5178023590188935\n",
      "episode :  31\n",
      "current step :  117\n",
      "reward :  -0.45369148237002677\n",
      "episode :  31\n",
      "current step :  118\n",
      "reward :  -0.42859084651460455\n",
      "episode :  31\n",
      "current step :  119\n",
      "reward :  -0.43728118578081565\n",
      "episode :  31\n",
      "current step :  120\n",
      "reward :  -0.4947668178888701\n",
      "episode :  31\n",
      "current step :  121\n",
      "reward :  -0.5226350259759153\n",
      "episode :  31\n",
      "current step :  122\n",
      "reward :  -0.5037906925205148\n",
      "episode :  31\n",
      "current step :  123\n",
      "reward :  -0.43886112326909194\n",
      "episode :  31\n",
      "current step :  124\n",
      "reward :  -0.4409589808331003\n",
      "episode :  31\n",
      "current step :  125\n",
      "reward :  -0.43296477776807873\n",
      "episode :  31\n",
      "current step :  126\n",
      "reward :  -0.42846196053535174\n",
      "episode :  31\n",
      "current step :  127\n",
      "reward :  -0.4517179016577403\n",
      "episode :  31\n",
      "current step :  128\n",
      "reward :  -0.42800944951799735\n",
      "episode :  31\n",
      "current step :  129\n",
      "reward :  -0.45523679957558716\n",
      "episode :  31\n",
      "current step :  130\n",
      "reward :  -0.4482618013700339\n",
      "episode :  31\n",
      "current step :  131\n",
      "reward :  -0.477143988337714\n",
      "episode :  31\n",
      "current step :  132\n",
      "reward :  -0.4428973359383069\n",
      "episode :  31\n",
      "current step :  133\n",
      "reward :  -0.42609688508371485\n",
      "episode :  31\n",
      "current step :  134\n",
      "reward :  -0.414541609652481\n",
      "episode :  31\n",
      "current step :  135\n",
      "reward :  -0.4347587545279676\n",
      "episode :  31\n",
      "current step :  136\n",
      "reward :  -0.4710317999881664\n",
      "episode :  31\n",
      "current step :  137\n",
      "reward :  -0.4661457000632698\n",
      "episode :  31\n",
      "current step :  138\n",
      "reward :  -0.42524499660060155\n",
      "episode :  31\n",
      "current step :  139\n",
      "reward :  -0.4103486111421471\n",
      "episode :  31\n",
      "current step :  140\n",
      "reward :  -0.3840426472606121\n",
      "episode :  31\n",
      "current step :  141\n",
      "reward :  -0.39110983898640483\n",
      "episode :  31\n",
      "current step :  142\n",
      "reward :  -0.3931209614565394\n",
      "episode :  31\n",
      "current step :  143\n",
      "reward :  -0.3790767184737064\n",
      "episode :  31\n",
      "current step :  144\n",
      "reward :  -0.3628986804193846\n",
      "episode :  31\n",
      "current step :  145\n",
      "reward :  -0.3854585569760781\n",
      "episode :  31\n",
      "current step :  146\n",
      "reward :  -0.35721208393201176\n",
      "episode :  31\n",
      "current step :  147\n",
      "reward :  -0.4235952557563128\n",
      "episode :  31\n",
      "current step :  148\n",
      "reward :  -0.370853352295894\n",
      "episode :  31\n",
      "current step :  149\n",
      "reward :  -0.3567543959643307\n",
      "episode :  31\n",
      "current step :  150\n",
      "reward :  -0.3925280953292554\n",
      "episode :  31\n",
      "current step :  151\n",
      "reward :  -0.3524049432085429\n",
      "episode :  31\n",
      "current step :  152\n",
      "reward :  -0.3808351469478814\n",
      "episode :  31\n",
      "current step :  153\n",
      "reward :  -0.37141314864041813\n",
      "episode :  31\n",
      "current step :  154\n",
      "reward :  -0.36613643883377955\n",
      "episode :  31\n",
      "current step :  155\n",
      "reward :  -0.3729222999503257\n",
      "episode :  31\n",
      "current step :  156\n",
      "reward :  -0.47238932172645476\n",
      "episode :  31\n",
      "current step :  157\n",
      "reward :  -0.47739041569716806\n",
      "episode :  31\n",
      "current step :  158\n",
      "reward :  -0.5037156088592318\n",
      "episode :  31\n",
      "current step :  159\n",
      "reward :  -0.4897966224243521\n",
      "episode :  31\n",
      "current step :  160\n",
      "reward :  -0.41554374467477406\n",
      "episode :  31\n",
      "current step :  161\n",
      "reward :  -0.4240582748737041\n",
      "episode :  31\n",
      "current step :  162\n",
      "reward :  -0.4385866108859739\n",
      "episode :  31\n",
      "current step :  163\n",
      "reward :  -0.5223102875630641\n",
      "episode :  31\n",
      "current step :  164\n",
      "reward :  -0.5274139173696367\n",
      "episode :  31\n",
      "current step :  165\n",
      "reward :  -0.5550486582897093\n",
      "episode :  31\n",
      "current step :  166\n",
      "reward :  -0.4607668961125421\n",
      "episode :  31\n",
      "current step :  167\n",
      "reward :  -0.4316407790524937\n",
      "episode :  31\n",
      "current step :  168\n",
      "reward :  -0.4335829939560745\n",
      "episode :  31\n",
      "current step :  169\n",
      "reward :  -0.4702033134639697\n",
      "episode :  31\n",
      "current step :  170\n",
      "reward :  -0.572017888250521\n",
      "episode :  31\n",
      "current step :  171\n",
      "reward :  -0.6037699986236479\n",
      "episode :  31\n",
      "current step :  172\n",
      "reward :  -0.6067030549362411\n",
      "episode :  31\n",
      "current step :  173\n",
      "reward :  -0.568298464211037\n",
      "episode :  31\n",
      "current step :  174\n",
      "reward :  -0.488746360475878\n",
      "episode :  31\n",
      "current step :  175\n",
      "reward :  -0.47523765290433795\n",
      "episode :  31\n",
      "current step :  176\n",
      "reward :  -0.5844329931481623\n",
      "episode :  31\n",
      "current step :  177\n",
      "reward :  -0.5860109316731285\n",
      "episode :  31\n",
      "current step :  178\n",
      "reward :  -0.5323034660896303\n",
      "episode :  31\n",
      "current step :  179\n",
      "reward :  -0.4503783432779472\n",
      "episode :  31\n",
      "current step :  180\n",
      "reward :  -0.4794146472345989\n",
      "episode :  31\n",
      "current step :  181\n",
      "reward :  -0.45925347712482134\n",
      "episode :  31\n",
      "current step :  182\n",
      "reward :  -0.5020272039742495\n",
      "episode :  31\n",
      "current step :  183\n",
      "reward :  -0.5664372447860898\n",
      "episode :  31\n",
      "current step :  184\n",
      "reward :  -0.6323765811897903\n",
      "episode :  31\n",
      "current step :  185\n",
      "reward :  -0.6188454119089662\n",
      "episode :  31\n",
      "current step :  186\n",
      "reward :  -0.6166834787905471\n",
      "episode :  31\n",
      "current step :  187\n",
      "reward :  -0.4942990755026083\n",
      "episode :  31\n",
      "current step :  188\n",
      "reward :  -0.4934595048691517\n",
      "episode :  31\n",
      "current step :  189\n",
      "reward :  -0.4609836027492534\n",
      "episode :  31\n",
      "current step :  190\n",
      "reward :  -0.4784542108438698\n",
      "episode :  31\n",
      "current step :  191\n",
      "reward :  -0.4618388541236902\n",
      "episode :  31\n",
      "current step :  192\n",
      "reward :  -0.5861479397807424\n",
      "episode :  31\n",
      "current step :  193\n",
      "reward :  -0.6161442513694781\n",
      "episode :  31\n",
      "current step :  194\n",
      "reward :  -0.6323618791781566\n",
      "episode :  31\n",
      "current step :  195\n",
      "reward :  -0.6051517754085255\n",
      "episode :  31\n",
      "current step :  196\n",
      "reward :  -0.5449689999047412\n",
      "episode :  31\n",
      "current step :  197\n",
      "reward :  -0.48143138252390894\n",
      "episode :  31\n",
      "current step :  198\n",
      "reward :  -0.483388924815471\n",
      "episode :  31\n",
      "current step :  199\n",
      "reward :  -0.5192163930927526\n",
      "episode :  31\n",
      "current step :  200\n",
      "reward :  -0.5682211991149746\n",
      "episode :  31\n",
      "current step :  201\n",
      "reward :  -0.6025736885551067\n",
      "episode :  31\n",
      "current step :  202\n",
      "reward :  -0.5462143964804969\n",
      "episode :  31\n",
      "current step :  203\n",
      "reward :  -0.4864417292483374\n",
      "episode :  31\n",
      "current step :  204\n",
      "reward :  -0.45666971805980555\n",
      "episode :  31\n",
      "current step :  205\n",
      "reward :  -0.47398983490056085\n",
      "episode :  31\n",
      "current step :  206\n",
      "reward :  -0.5593378094308491\n",
      "episode :  31\n",
      "current step :  207\n",
      "reward :  -0.6155250482537216\n",
      "episode :  31\n",
      "current step :  208\n",
      "reward :  -0.577167467585103\n",
      "episode :  31\n",
      "current step :  209\n",
      "reward :  -0.489882582644705\n",
      "episode :  31\n",
      "current step :  210\n",
      "reward :  -0.4649724949307471\n",
      "episode :  31\n",
      "current step :  211\n",
      "reward :  -0.4691211070064178\n",
      "episode :  31\n",
      "current step :  212\n",
      "reward :  -0.5528605834029894\n",
      "episode :  31\n",
      "current step :  213\n",
      "reward :  -0.5979857973870153\n",
      "episode :  31\n",
      "current step :  214\n",
      "reward :  -0.5861104695947921\n",
      "episode :  31\n",
      "current step :  215\n",
      "reward :  -0.5008439856465574\n",
      "episode :  31\n",
      "current step :  216\n",
      "reward :  -0.4687263065736418\n",
      "episode :  31\n",
      "current step :  217\n",
      "reward :  -0.4482015075762949\n",
      "episode :  31\n",
      "current step :  218\n",
      "reward :  -0.4545931080162151\n",
      "episode :  31\n",
      "current step :  219\n",
      "reward :  -0.4775029186668539\n",
      "episode :  31\n",
      "current step :  220\n",
      "reward :  -0.4377956854577668\n",
      "episode :  31\n",
      "current step :  221\n",
      "reward :  -0.4508706304030134\n",
      "episode :  31\n",
      "current step :  222\n",
      "reward :  -0.48474027286915955\n",
      "episode :  31\n",
      "current step :  223\n",
      "reward :  -0.5185221536370228\n",
      "episode :  31\n",
      "current step :  224\n",
      "reward :  -0.4370199005601229\n",
      "episode :  31\n",
      "current step :  225\n",
      "reward :  -0.41363841374800586\n",
      "episode :  31\n",
      "current step :  226\n",
      "reward :  -0.42251377686150604\n",
      "episode :  31\n",
      "current step :  227\n",
      "reward :  -0.3997862552808628\n",
      "episode :  31\n",
      "current step :  228\n",
      "reward :  -0.38915770222826923\n",
      "episode :  31\n",
      "current step :  229\n",
      "reward :  -0.3846868161843401\n",
      "episode :  31\n",
      "current step :  230\n",
      "reward :  -0.39841984600143854\n",
      "episode :  31\n",
      "current step :  231\n",
      "reward :  -0.44669451974556784\n",
      "episode :  31\n",
      "current step :  232\n",
      "reward :  -0.46921403258438726\n",
      "episode :  31\n",
      "current step :  233\n",
      "reward :  -0.4684858819487701\n",
      "episode :  31\n",
      "current step :  234\n",
      "reward :  -0.386212521211368\n",
      "episode :  31\n",
      "current step :  235\n",
      "reward :  -0.4225517016919218\n",
      "episode :  31\n",
      "current step :  236\n",
      "reward :  -0.4088444487158149\n",
      "episode :  31\n",
      "current step :  237\n",
      "reward :  -0.3919334035056324\n",
      "episode :  31\n",
      "current step :  238\n",
      "reward :  -0.41038223536463825\n",
      "episode :  31\n",
      "current step :  239\n",
      "reward :  -0.34373269714405735\n",
      "episode :  31\n",
      "current step :  240\n",
      "reward :  -0.3585063034470268\n",
      "episode :  31\n",
      "current step :  241\n",
      "reward :  -0.411711877645489\n",
      "episode :  31\n",
      "current step :  242\n",
      "reward :  -0.4212036060950155\n",
      "episode :  31\n",
      "current step :  243\n",
      "reward :  -0.3812523211422668\n",
      "episode :  31\n",
      "current step :  244\n",
      "reward :  -0.40616855782004924\n",
      "episode :  31\n",
      "current step :  245\n",
      "reward :  -0.42561043986587554\n",
      "episode :  31\n",
      "current step :  246\n",
      "reward :  -0.37024250033729467\n",
      "episode :  31\n",
      "current step :  247\n",
      "reward :  -0.4484802551263631\n",
      "episode :  31\n",
      "current step :  248\n",
      "reward :  -0.4779823273134048\n",
      "episode :  31\n",
      "current step :  249\n",
      "reward :  -0.4169281788509543\n",
      "episode :  31\n",
      "current step :  250\n",
      "reward :  -0.4762644098159449\n",
      "episode :  31\n",
      "current step :  251\n",
      "reward :  -0.5012634992347819\n",
      "episode :  31\n",
      "current step :  252\n",
      "reward :  -0.4604411036950065\n",
      "episode :  31\n",
      "current step :  253\n",
      "reward :  -0.4525463017450986\n",
      "episode :  31\n",
      "current step :  254\n",
      "reward :  -0.5003638109770034\n",
      "episode :  31\n",
      "current step :  255\n",
      "reward :  -0.47412464976403906\n",
      "episode :  31\n",
      "current step :  256\n",
      "reward :  -0.5621983123005554\n",
      "episode :  31\n",
      "current step :  257\n",
      "reward :  -0.550806552236994\n",
      "episode :  31\n",
      "current step :  258\n",
      "reward :  -0.5162640023793083\n",
      "episode :  31\n",
      "current step :  259\n",
      "reward :  -0.5485674688492371\n",
      "episode :  31\n",
      "current step :  260\n",
      "reward :  -0.5546492300923378\n",
      "episode :  31\n",
      "current step :  261\n",
      "reward :  -0.5577872253616056\n",
      "episode :  31\n",
      "current step :  262\n",
      "reward :  -0.5602197189512755\n",
      "episode :  31\n",
      "current step :  263\n",
      "reward :  -0.557743107498517\n",
      "episode :  31\n",
      "current step :  264\n",
      "reward :  -0.5634375016103944\n",
      "episode :  31\n",
      "current step :  265\n",
      "reward :  -0.5652254540686521\n",
      "episode :  31\n",
      "current step :  266\n",
      "reward :  -0.5578027607564692\n",
      "episode :  31\n",
      "current step :  267\n",
      "reward :  -0.5666279263048934\n",
      "episode :  31\n",
      "current step :  268\n",
      "reward :  -0.5659495118714647\n",
      "episode :  31\n",
      "current step :  269\n",
      "reward :  -0.5653442174480974\n",
      "episode :  31\n",
      "current step :  270\n",
      "reward :  -0.5645129358635134\n",
      "episode :  31\n",
      "current step :  271\n",
      "reward :  -0.5650991494670459\n",
      "episode :  31\n",
      "current step :  272\n",
      "reward :  -0.5636679237685568\n",
      "episode :  31\n",
      "current step :  273\n",
      "reward :  -0.5620876987411791\n",
      "episode :  31\n",
      "current step :  274\n",
      "reward :  -0.5621037951261056\n",
      "episode :  31\n",
      "current step :  275\n",
      "reward :  -0.5599345293876047\n",
      "episode :  31\n",
      "current step :  276\n",
      "reward :  -0.5596993293829191\n",
      "episode :  31\n",
      "current step :  277\n",
      "reward :  -0.5594849688938898\n",
      "episode :  31\n",
      "current step :  278\n",
      "reward :  -0.5589569838137115\n",
      "episode :  31\n",
      "current step :  279\n",
      "reward :  -0.558352115361836\n",
      "episode :  31\n",
      "current step :  280\n",
      "reward :  -0.5562904877694298\n",
      "episode :  31\n",
      "current step :  281\n",
      "reward :  -0.5562431007380269\n",
      "episode :  31\n",
      "current step :  282\n",
      "reward :  -0.5560351208262027\n",
      "episode :  31\n",
      "current step :  283\n",
      "reward :  -0.5571675667918191\n",
      "episode :  31\n",
      "current step :  284\n",
      "reward :  -0.5604388848393901\n",
      "episode :  31\n",
      "current step :  285\n",
      "reward :  -0.5554350686778828\n",
      "episode :  32\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 286      |\n",
      "|    ep_rew_mean     | -130     |\n",
      "| time/              |          |\n",
      "|    episodes        | 32       |\n",
      "|    fps             | 14       |\n",
      "|    time_elapsed    | 625      |\n",
      "|    total_timesteps | 9152     |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -94.2    |\n",
      "|    critic_loss     | 4.31     |\n",
      "|    ent_coef        | 0.124    |\n",
      "|    ent_coef_loss   | -7.95    |\n",
      "|    learning_rate   | 0.0003   |\n",
      "|    n_updates       | 9051     |\n",
      "---------------------------------\n",
      "current step :  0\n",
      "reward :  -0.4624187569037545\n",
      "episode :  32\n",
      "current step :  1\n",
      "reward :  -0.4464092751483684\n",
      "episode :  32\n",
      "current step :  2\n",
      "reward :  -0.46430771045129304\n",
      "episode :  32\n",
      "current step :  3\n",
      "reward :  -0.545887355799201\n",
      "episode :  32\n",
      "current step :  4\n",
      "reward :  -0.5521979500162456\n",
      "episode :  32\n",
      "current step :  5\n",
      "reward :  -0.5349119543438461\n",
      "episode :  32\n",
      "current step :  6\n",
      "reward :  -0.5350246559390942\n",
      "episode :  32\n",
      "current step :  7\n",
      "reward :  -0.5479611323436008\n",
      "episode :  32\n",
      "current step :  8\n",
      "reward :  -0.559360746038742\n",
      "episode :  32\n",
      "current step :  9\n",
      "reward :  -0.5327183116473589\n",
      "episode :  32\n",
      "current step :  10\n",
      "reward :  -0.5637793372517692\n",
      "episode :  32\n",
      "current step :  11\n",
      "reward :  -0.5616154143147543\n",
      "episode :  32\n",
      "current step :  12\n",
      "reward :  -0.5568338087084724\n",
      "episode :  32\n",
      "current step :  13\n",
      "reward :  -0.5588331507649309\n",
      "episode :  32\n",
      "current step :  14\n",
      "reward :  -0.5570604197740254\n",
      "episode :  32\n",
      "current step :  15\n",
      "reward :  -0.5568784843339787\n",
      "episode :  32\n",
      "current step :  16\n",
      "reward :  -0.5573481341986816\n",
      "episode :  32\n",
      "current step :  17\n",
      "reward :  -0.5591100945744046\n",
      "episode :  32\n",
      "current step :  18\n",
      "reward :  -0.5542373576507033\n",
      "episode :  32\n",
      "current step :  19\n",
      "reward :  -0.5578285479498261\n",
      "episode :  32\n",
      "current step :  20\n",
      "reward :  -0.558049483338179\n",
      "episode :  32\n",
      "current step :  21\n",
      "reward :  -0.5584549907358035\n",
      "episode :  32\n",
      "current step :  22\n",
      "reward :  -0.5590946710273661\n",
      "episode :  32\n",
      "current step :  23\n",
      "reward :  -0.5395476525487397\n",
      "episode :  32\n",
      "current step :  24\n",
      "reward :  -0.5605754829620831\n",
      "episode :  32\n",
      "current step :  25\n",
      "reward :  -0.5640558390271126\n",
      "episode :  32\n",
      "current step :  26\n",
      "reward :  -0.5706053579446986\n",
      "episode :  32\n",
      "current step :  27\n",
      "reward :  -0.5747008174423018\n",
      "episode :  32\n",
      "current step :  28\n",
      "reward :  -0.5754455217406209\n",
      "episode :  32\n",
      "current step :  29\n",
      "reward :  -0.5098677009532183\n",
      "episode :  32\n",
      "current step :  30\n",
      "reward :  -0.5434259011374785\n",
      "episode :  32\n",
      "current step :  31\n",
      "reward :  -0.546159868346562\n",
      "episode :  32\n",
      "current step :  32\n",
      "reward :  -0.56789869595263\n",
      "episode :  32\n",
      "current step :  33\n",
      "reward :  -0.5751471029900576\n",
      "episode :  32\n",
      "current step :  34\n",
      "reward :  -0.5506685974497031\n",
      "episode :  32\n",
      "current step :  35\n",
      "reward :  -0.5570796785452314\n",
      "episode :  32\n",
      "current step :  36\n",
      "reward :  -0.6166133727592178\n",
      "episode :  32\n",
      "current step :  37\n",
      "reward :  -0.6153133484518577\n",
      "episode :  32\n",
      "current step :  38\n",
      "reward :  -0.5954320616151334\n",
      "episode :  32\n",
      "current step :  39\n",
      "reward :  -0.6078196247737997\n",
      "episode :  32\n",
      "current step :  40\n",
      "reward :  -0.6441648120262794\n",
      "episode :  32\n",
      "current step :  41\n",
      "reward :  -0.6520543543873237\n",
      "episode :  32\n",
      "current step :  42\n",
      "reward :  -0.5931152109830781\n",
      "episode :  32\n",
      "current step :  43\n",
      "reward :  -0.5629812396787053\n",
      "episode :  32\n",
      "current step :  44\n",
      "reward :  -0.6086155717673837\n",
      "episode :  32\n",
      "current step :  45\n",
      "reward :  -0.4977715840014187\n",
      "episode :  32\n",
      "current step :  46\n",
      "reward :  -0.4846804331245524\n",
      "episode :  32\n",
      "current step :  47\n",
      "reward :  -0.4862024637441373\n",
      "episode :  32\n",
      "current step :  48\n",
      "reward :  -0.4896377770870308\n",
      "episode :  32\n",
      "current step :  49\n",
      "reward :  -0.5015541021952424\n",
      "episode :  32\n",
      "current step :  50\n",
      "reward :  -0.5273328736353832\n",
      "episode :  32\n",
      "current step :  51\n",
      "reward :  -0.5157380361911631\n",
      "episode :  32\n",
      "current step :  52\n",
      "reward :  -0.5159143195790926\n",
      "episode :  32\n",
      "current step :  53\n",
      "reward :  -0.5182813356269956\n",
      "episode :  32\n",
      "current step :  54\n",
      "reward :  -0.5666853288657934\n",
      "episode :  32\n",
      "current step :  55\n",
      "reward :  -0.5270994983854144\n",
      "episode :  32\n",
      "current step :  56\n",
      "reward :  -0.523806314719665\n",
      "episode :  32\n",
      "current step :  57\n",
      "reward :  -0.5721038953816935\n",
      "episode :  32\n",
      "current step :  58\n",
      "reward :  -0.5531172431438559\n",
      "episode :  32\n",
      "current step :  59\n",
      "reward :  -0.5705802778771585\n",
      "episode :  32\n",
      "current step :  60\n",
      "reward :  -0.586800460467356\n",
      "episode :  32\n",
      "current step :  61\n",
      "reward :  -0.5675481556695939\n",
      "episode :  32\n",
      "current step :  62\n",
      "reward :  -0.5614728805514931\n",
      "episode :  32\n",
      "current step :  63\n",
      "reward :  -0.5744867477886425\n",
      "episode :  32\n",
      "current step :  64\n",
      "reward :  -0.5813970901821729\n",
      "episode :  32\n",
      "current step :  65\n",
      "reward :  -0.5779197273305496\n",
      "episode :  32\n",
      "current step :  66\n",
      "reward :  -0.5450576924055018\n",
      "episode :  32\n",
      "current step :  67\n",
      "reward :  -0.5431265489984753\n",
      "episode :  32\n",
      "current step :  68\n",
      "reward :  -0.513225033745946\n",
      "episode :  32\n",
      "current step :  69\n",
      "reward :  -0.5091915522766911\n",
      "episode :  32\n",
      "current step :  70\n",
      "reward :  -0.5220689366999008\n",
      "episode :  32\n",
      "current step :  71\n",
      "reward :  -0.5574491608147912\n",
      "episode :  32\n",
      "current step :  72\n",
      "reward :  -0.5479649406728817\n",
      "episode :  32\n",
      "current step :  73\n",
      "reward :  -0.5047951687667565\n",
      "episode :  32\n",
      "current step :  74\n",
      "reward :  -0.5041224002913489\n",
      "episode :  32\n",
      "current step :  75\n",
      "reward :  -0.5182467327715804\n",
      "episode :  32\n",
      "current step :  76\n",
      "reward :  -0.5546126194368843\n",
      "episode :  32\n",
      "current step :  77\n",
      "reward :  -0.5377500990067027\n",
      "episode :  32\n",
      "current step :  78\n",
      "reward :  -0.5316731616857443\n",
      "episode :  32\n",
      "current step :  79\n",
      "reward :  -0.4850747966660876\n",
      "episode :  32\n",
      "current step :  80\n",
      "reward :  -0.48570387969774903\n",
      "episode :  32\n",
      "current step :  81\n",
      "reward :  -0.4851335049417453\n",
      "episode :  32\n",
      "current step :  82\n",
      "reward :  -0.4310840015544473\n",
      "episode :  32\n",
      "current step :  83\n",
      "reward :  -0.470351475682462\n",
      "episode :  32\n",
      "current step :  84\n",
      "reward :  -0.4115462951630842\n",
      "episode :  32\n",
      "current step :  85\n",
      "reward :  -0.4690353784396792\n",
      "episode :  32\n",
      "current step :  86\n",
      "reward :  -0.4311261481388814\n",
      "episode :  32\n",
      "current step :  87\n",
      "reward :  -0.3993257556837761\n",
      "episode :  32\n",
      "current step :  88\n",
      "reward :  -0.41657616983867785\n",
      "episode :  32\n",
      "current step :  89\n",
      "reward :  -0.4076604163946758\n",
      "episode :  32\n",
      "current step :  90\n",
      "reward :  -0.4117004820317846\n",
      "episode :  32\n",
      "current step :  91\n",
      "reward :  -0.4131823750096075\n",
      "episode :  32\n",
      "current step :  92\n",
      "reward :  -0.42031116457530143\n",
      "episode :  32\n",
      "current step :  93\n",
      "reward :  -0.4187943608184598\n",
      "episode :  32\n",
      "current step :  94\n",
      "reward :  -0.4427646915047818\n",
      "episode :  32\n",
      "current step :  95\n",
      "reward :  -0.43688748957387263\n",
      "episode :  32\n",
      "current step :  96\n",
      "reward :  -0.42859010568478373\n",
      "episode :  32\n",
      "current step :  97\n",
      "reward :  -0.39387806846802015\n",
      "episode :  32\n",
      "current step :  98\n",
      "reward :  -0.38450007475319725\n",
      "episode :  32\n",
      "current step :  99\n",
      "reward :  -0.4337307410114653\n",
      "episode :  32\n",
      "current step :  100\n",
      "reward :  -0.43603239832655577\n",
      "episode :  32\n",
      "current step :  101\n",
      "reward :  -0.44331853048770054\n",
      "episode :  32\n",
      "current step :  102\n",
      "reward :  -0.43237212996681257\n",
      "episode :  32\n",
      "current step :  103\n",
      "reward :  -0.3661826342696223\n",
      "episode :  32\n",
      "current step :  104\n",
      "reward :  -0.32246453152841414\n",
      "episode :  32\n",
      "current step :  105\n",
      "reward :  -0.35157748511472914\n",
      "episode :  32\n",
      "current step :  106\n",
      "reward :  -0.3375130651022509\n",
      "episode :  32\n",
      "current step :  107\n",
      "reward :  -0.47702966923654505\n",
      "episode :  32\n",
      "current step :  108\n",
      "reward :  -0.46981418621655646\n",
      "episode :  32\n",
      "current step :  109\n",
      "reward :  -0.4621347661244958\n",
      "episode :  32\n",
      "current step :  110\n",
      "reward :  -0.44841166094675766\n",
      "episode :  32\n",
      "current step :  111\n",
      "reward :  -0.35020141525164905\n",
      "episode :  32\n",
      "current step :  112\n",
      "reward :  -0.4703102703450704\n",
      "episode :  32\n",
      "current step :  113\n",
      "reward :  -0.44611535622654774\n",
      "episode :  32\n",
      "current step :  114\n",
      "reward :  -0.4402458919734329\n",
      "episode :  32\n",
      "current step :  115\n",
      "reward :  -0.435745148256123\n",
      "episode :  32\n",
      "current step :  116\n",
      "reward :  -0.48799507169770723\n",
      "episode :  32\n",
      "current step :  117\n",
      "reward :  -0.5018041186462164\n",
      "episode :  32\n",
      "current step :  118\n",
      "reward :  -0.4677117652861419\n",
      "episode :  32\n",
      "current step :  119\n",
      "reward :  -0.5053652092976187\n",
      "episode :  32\n",
      "current step :  120\n",
      "reward :  -0.3921420198191466\n",
      "episode :  32\n",
      "current step :  121\n",
      "reward :  -0.420131150251854\n",
      "episode :  32\n",
      "current step :  122\n",
      "reward :  -0.4369925365063973\n",
      "episode :  32\n",
      "current step :  123\n",
      "reward :  -0.4352897128064824\n",
      "episode :  32\n",
      "current step :  124\n",
      "reward :  -0.4225903994141313\n",
      "episode :  32\n",
      "current step :  125\n",
      "reward :  -0.40520610902434706\n",
      "episode :  32\n",
      "current step :  126\n",
      "reward :  -0.4135345434553896\n",
      "episode :  32\n",
      "current step :  127\n",
      "reward :  -0.343206923246483\n",
      "episode :  32\n",
      "current step :  128\n",
      "reward :  -0.3475249260762949\n",
      "episode :  32\n",
      "current step :  129\n",
      "reward :  -0.3741321186845886\n",
      "episode :  32\n",
      "current step :  130\n",
      "reward :  -0.34179446026445837\n",
      "episode :  32\n",
      "current step :  131\n",
      "reward :  -0.3486462145216378\n",
      "episode :  32\n",
      "current step :  132\n",
      "reward :  -0.37054037831359626\n",
      "episode :  32\n",
      "current step :  133\n",
      "reward :  -0.3695084009462509\n",
      "episode :  32\n",
      "current step :  134\n",
      "reward :  -0.4250862606905166\n",
      "episode :  32\n",
      "current step :  135\n",
      "reward :  -0.4138967302731763\n",
      "episode :  32\n",
      "current step :  136\n",
      "reward :  -0.3848296715185007\n",
      "episode :  32\n",
      "current step :  137\n",
      "reward :  -0.3611481763144607\n",
      "episode :  32\n",
      "current step :  138\n",
      "reward :  -0.3766446027191041\n",
      "episode :  32\n",
      "current step :  139\n",
      "reward :  -0.3657534831539405\n",
      "episode :  32\n",
      "current step :  140\n",
      "reward :  -0.36941683144052845\n",
      "episode :  32\n",
      "current step :  141\n",
      "reward :  -0.3674556002279137\n",
      "episode :  32\n",
      "current step :  142\n",
      "reward :  -0.35925195063836884\n",
      "episode :  32\n",
      "current step :  143\n",
      "reward :  -0.3873905494055135\n",
      "episode :  32\n",
      "current step :  144\n",
      "reward :  -0.39354411410276163\n",
      "episode :  32\n",
      "current step :  145\n",
      "reward :  -0.3793194979172624\n",
      "episode :  32\n",
      "current step :  146\n",
      "reward :  -0.38845425983428405\n",
      "episode :  32\n",
      "current step :  147\n",
      "reward :  -0.42131608491321654\n",
      "episode :  32\n",
      "current step :  148\n",
      "reward :  -0.43098188035792145\n",
      "episode :  32\n",
      "current step :  149\n",
      "reward :  -0.4471093152365555\n",
      "episode :  32\n",
      "current step :  150\n",
      "reward :  -0.3887878286926199\n",
      "episode :  32\n",
      "current step :  151\n",
      "reward :  -0.4501056891789237\n",
      "episode :  32\n",
      "current step :  152\n",
      "reward :  -0.41612181860591446\n",
      "episode :  32\n",
      "current step :  153\n",
      "reward :  -0.36989947700312503\n",
      "episode :  32\n",
      "current step :  154\n",
      "reward :  -0.3768943732881538\n",
      "episode :  32\n",
      "current step :  155\n",
      "reward :  -0.4527567024454496\n",
      "episode :  32\n",
      "current step :  156\n",
      "reward :  -0.41010179902592964\n",
      "episode :  32\n",
      "current step :  157\n",
      "reward :  -0.40250038704244256\n",
      "episode :  32\n",
      "current step :  158\n",
      "reward :  -0.5477036222290579\n",
      "episode :  32\n",
      "current step :  159\n",
      "reward :  -0.5518432800138185\n",
      "episode :  32\n",
      "current step :  160\n",
      "reward :  -0.4606336669063167\n",
      "episode :  32\n",
      "current step :  161\n",
      "reward :  -0.4600345202701404\n",
      "episode :  32\n",
      "current step :  162\n",
      "reward :  -0.4136473886776924\n",
      "episode :  32\n",
      "current step :  163\n",
      "reward :  -0.5197059816118041\n",
      "episode :  32\n",
      "current step :  164\n",
      "reward :  -0.4222863278225346\n",
      "episode :  32\n",
      "current step :  165\n",
      "reward :  -0.5252887736509243\n",
      "episode :  32\n",
      "current step :  166\n",
      "reward :  -0.5313715833121958\n",
      "episode :  32\n",
      "current step :  167\n",
      "reward :  -0.4557105879558878\n",
      "episode :  32\n",
      "current step :  168\n",
      "reward :  -0.4598225131322423\n",
      "episode :  32\n",
      "current step :  169\n",
      "reward :  -0.4496697483411896\n",
      "episode :  32\n",
      "current step :  170\n",
      "reward :  -0.4361929853329593\n",
      "episode :  32\n",
      "current step :  171\n",
      "reward :  -0.599253618544689\n",
      "episode :  32\n",
      "current step :  172\n",
      "reward :  -0.43723317323609556\n",
      "episode :  32\n",
      "current step :  173\n",
      "reward :  -0.4679096777416587\n",
      "episode :  32\n",
      "current step :  174\n",
      "reward :  -0.46902557471940687\n",
      "episode :  32\n",
      "current step :  175\n",
      "reward :  -0.460669592776643\n",
      "episode :  32\n",
      "current step :  176\n",
      "reward :  -0.460204676350526\n",
      "episode :  32\n",
      "current step :  177\n",
      "reward :  -0.49166455588595415\n",
      "episode :  32\n",
      "current step :  178\n",
      "reward :  -0.459798248270712\n",
      "episode :  32\n",
      "current step :  179\n",
      "reward :  -0.4928380432561505\n",
      "episode :  32\n",
      "current step :  180\n",
      "reward :  -0.4801366333926205\n",
      "episode :  32\n",
      "current step :  181\n",
      "reward :  -0.4964892876508665\n",
      "episode :  32\n",
      "current step :  182\n",
      "reward :  -0.5031717656184216\n",
      "episode :  32\n",
      "current step :  183\n",
      "reward :  -0.508495813725461\n",
      "episode :  32\n",
      "current step :  184\n",
      "reward :  -0.5066846434841638\n",
      "episode :  32\n",
      "current step :  185\n",
      "reward :  -0.492655195099211\n",
      "episode :  32\n",
      "current step :  186\n",
      "reward :  -0.45784403392492495\n",
      "episode :  32\n",
      "current step :  187\n",
      "reward :  -0.45893615652705283\n",
      "episode :  32\n",
      "current step :  188\n",
      "reward :  -0.4658511743013624\n",
      "episode :  32\n",
      "current step :  189\n",
      "reward :  -0.46082661368103284\n",
      "episode :  32\n",
      "current step :  190\n",
      "reward :  -0.4532770037214436\n",
      "episode :  32\n",
      "current step :  191\n",
      "reward :  -0.4452384172758353\n",
      "episode :  32\n",
      "current step :  192\n",
      "reward :  -0.4606370512364692\n",
      "episode :  32\n",
      "current step :  193\n",
      "reward :  -0.4579471524234223\n",
      "episode :  32\n",
      "current step :  194\n",
      "reward :  -0.42655633811928473\n",
      "episode :  32\n",
      "current step :  195\n",
      "reward :  -0.4483632792531145\n",
      "episode :  32\n",
      "current step :  196\n",
      "reward :  -0.4392703032503903\n",
      "episode :  32\n",
      "current step :  197\n",
      "reward :  -0.43714395844045106\n",
      "episode :  32\n",
      "current step :  198\n",
      "reward :  -0.4357610690716892\n",
      "episode :  32\n",
      "current step :  199\n",
      "reward :  -0.4350516903519516\n",
      "episode :  32\n",
      "current step :  200\n",
      "reward :  -0.4473569843822205\n",
      "episode :  32\n",
      "current step :  201\n",
      "reward :  -0.4313697128428788\n",
      "episode :  32\n",
      "current step :  202\n",
      "reward :  -0.4237730747013634\n",
      "episode :  32\n",
      "current step :  203\n",
      "reward :  -0.40395457703410137\n",
      "episode :  32\n",
      "current step :  204\n",
      "reward :  -0.41723480541537455\n",
      "episode :  32\n",
      "current step :  205\n",
      "reward :  -0.40510338923857164\n",
      "episode :  32\n",
      "current step :  206\n",
      "reward :  -0.3915072865158021\n",
      "episode :  32\n",
      "current step :  207\n",
      "reward :  -0.3958910679383079\n",
      "episode :  32\n",
      "current step :  208\n",
      "reward :  -0.39477490211020083\n",
      "episode :  32\n",
      "current step :  209\n",
      "reward :  -0.39466605329579363\n",
      "episode :  32\n",
      "current step :  210\n",
      "reward :  -0.39097187988592924\n",
      "episode :  32\n",
      "current step :  211\n",
      "reward :  -0.3926813571410293\n",
      "episode :  32\n",
      "current step :  212\n",
      "reward :  -0.3872420559065819\n",
      "episode :  32\n",
      "current step :  213\n",
      "reward :  -0.3847482775710253\n",
      "episode :  32\n",
      "current step :  214\n",
      "reward :  -0.40470209392515805\n",
      "episode :  32\n",
      "current step :  215\n",
      "reward :  -0.39106796768072954\n",
      "episode :  32\n",
      "current step :  216\n",
      "reward :  -0.38855913389986463\n",
      "episode :  32\n",
      "current step :  217\n",
      "reward :  -0.3805642788162521\n",
      "episode :  32\n",
      "current step :  218\n",
      "reward :  -0.4004761103936661\n",
      "episode :  32\n",
      "current step :  219\n",
      "reward :  -0.3987529218021142\n",
      "episode :  32\n",
      "current step :  220\n",
      "reward :  -0.3827793189436138\n",
      "episode :  32\n",
      "current step :  221\n",
      "reward :  -0.3597739895924606\n",
      "episode :  32\n",
      "current step :  222\n",
      "reward :  -0.39133148743931795\n",
      "episode :  32\n",
      "current step :  223\n",
      "reward :  -0.40359641198139995\n",
      "episode :  32\n",
      "current step :  224\n",
      "reward :  -0.42115758955777166\n",
      "episode :  32\n",
      "current step :  225\n",
      "reward :  -0.4219066497412585\n",
      "episode :  32\n",
      "current step :  226\n",
      "reward :  -0.42347851944325965\n",
      "episode :  32\n",
      "current step :  227\n",
      "reward :  -0.41184764071593544\n",
      "episode :  32\n",
      "current step :  228\n",
      "reward :  -0.4167738141605732\n",
      "episode :  32\n",
      "current step :  229\n",
      "reward :  -0.4179868971032903\n",
      "episode :  32\n",
      "current step :  230\n",
      "reward :  -0.39726934193444713\n",
      "episode :  32\n",
      "current step :  231\n",
      "reward :  -0.3962336633268838\n",
      "episode :  32\n",
      "current step :  232\n",
      "reward :  -0.41570461529080516\n",
      "episode :  32\n",
      "current step :  233\n",
      "reward :  -0.4098226754869372\n",
      "episode :  32\n",
      "current step :  234\n",
      "reward :  -0.3770987140277916\n",
      "episode :  32\n",
      "current step :  235\n",
      "reward :  -0.3697846299542922\n",
      "episode :  32\n",
      "current step :  236\n",
      "reward :  -0.38073087489269236\n",
      "episode :  32\n",
      "current step :  237\n",
      "reward :  -0.3932313381020038\n",
      "episode :  32\n",
      "current step :  238\n",
      "reward :  -0.3891426785112783\n",
      "episode :  32\n",
      "current step :  239\n",
      "reward :  -0.3844051842887526\n",
      "episode :  32\n",
      "current step :  240\n",
      "reward :  -0.38171849058270263\n",
      "episode :  32\n",
      "current step :  241\n",
      "reward :  -0.3609488107110408\n",
      "episode :  32\n",
      "current step :  242\n",
      "reward :  -0.36680412144943486\n",
      "episode :  32\n",
      "current step :  243\n",
      "reward :  -0.3697818932681306\n",
      "episode :  32\n",
      "current step :  244\n",
      "reward :  -0.36886376351391753\n",
      "episode :  32\n",
      "current step :  245\n",
      "reward :  -0.36013358013976443\n",
      "episode :  32\n",
      "current step :  246\n",
      "reward :  -0.3747199952342831\n",
      "episode :  32\n",
      "current step :  247\n",
      "reward :  -0.380180010388221\n",
      "episode :  32\n",
      "current step :  248\n",
      "reward :  -0.3791175852227544\n",
      "episode :  32\n",
      "current step :  249\n",
      "reward :  -0.3533021170053163\n",
      "episode :  32\n",
      "current step :  250\n",
      "reward :  -0.3539008857686625\n",
      "episode :  32\n",
      "current step :  251\n",
      "reward :  -0.3821829482787615\n",
      "episode :  32\n",
      "current step :  252\n",
      "reward :  -0.3899481995378563\n",
      "episode :  32\n",
      "current step :  253\n",
      "reward :  -0.39365759835818237\n",
      "episode :  32\n",
      "current step :  254\n",
      "reward :  -0.39548448440271816\n",
      "episode :  32\n",
      "current step :  255\n",
      "reward :  -0.3891092655042269\n",
      "episode :  32\n",
      "current step :  256\n",
      "reward :  -0.39492997765342647\n",
      "episode :  32\n",
      "current step :  257\n",
      "reward :  -0.4110414867613222\n",
      "episode :  32\n",
      "current step :  258\n",
      "reward :  -0.38276745406806767\n",
      "episode :  32\n",
      "current step :  259\n",
      "reward :  -0.3863494023330954\n",
      "episode :  32\n",
      "current step :  260\n",
      "reward :  -0.4118117235407231\n",
      "episode :  32\n",
      "current step :  261\n",
      "reward :  -0.413359836569118\n",
      "episode :  32\n",
      "current step :  262\n",
      "reward :  -0.4259105130676985\n",
      "episode :  32\n",
      "current step :  263\n",
      "reward :  -0.43015708001030445\n",
      "episode :  32\n",
      "current step :  264\n",
      "reward :  -0.4315925077206418\n",
      "episode :  32\n",
      "current step :  265\n",
      "reward :  -0.4344929953520378\n",
      "episode :  32\n",
      "current step :  266\n",
      "reward :  -0.43762754809577764\n",
      "episode :  32\n",
      "current step :  267\n",
      "reward :  -0.43812176717278956\n",
      "episode :  32\n",
      "current step :  268\n",
      "reward :  -0.43659535953521234\n",
      "episode :  32\n",
      "current step :  269\n",
      "reward :  -0.4401229293022062\n",
      "episode :  32\n",
      "current step :  270\n",
      "reward :  -0.4321250501910886\n",
      "episode :  32\n",
      "current step :  271\n",
      "reward :  -0.44014421810352966\n",
      "episode :  32\n",
      "current step :  272\n",
      "reward :  -0.4196782642984118\n",
      "episode :  32\n",
      "current step :  273\n",
      "reward :  -0.42063793486296397\n",
      "episode :  32\n",
      "current step :  274\n",
      "reward :  -0.416559048969261\n",
      "episode :  32\n",
      "current step :  275\n",
      "reward :  -0.4215342672923386\n",
      "episode :  32\n",
      "current step :  276\n",
      "reward :  -0.4282111693888664\n",
      "episode :  32\n",
      "current step :  277\n",
      "reward :  -0.4412250570208775\n",
      "episode :  32\n",
      "current step :  278\n",
      "reward :  -0.43321492801976885\n",
      "episode :  32\n",
      "current step :  279\n",
      "reward :  -0.43560160880457466\n",
      "episode :  32\n",
      "current step :  280\n",
      "reward :  -0.42801503681276587\n",
      "episode :  32\n",
      "current step :  281\n",
      "reward :  -0.4338431221082024\n",
      "episode :  32\n",
      "current step :  282\n",
      "reward :  -0.44073057705468544\n",
      "episode :  32\n",
      "current step :  283\n",
      "reward :  -0.443917271308059\n",
      "episode :  32\n",
      "current step :  284\n",
      "reward :  -0.4418307944680629\n",
      "episode :  32\n",
      "current step :  285\n",
      "reward :  -0.44599821315341925\n",
      "episode :  33\n",
      "current step :  0\n",
      "reward :  -0.36134391288819767\n",
      "episode :  33\n",
      "current step :  1\n",
      "reward :  -0.3598170587683004\n",
      "episode :  33\n",
      "current step :  2\n",
      "reward :  -0.4217955648417457\n",
      "episode :  33\n",
      "current step :  3\n",
      "reward :  -0.43891566676091137\n",
      "episode :  33\n",
      "current step :  4\n",
      "reward :  -0.4423374324996639\n",
      "episode :  33\n",
      "current step :  5\n",
      "reward :  -0.44801694768657246\n",
      "episode :  33\n",
      "current step :  6\n",
      "reward :  -0.44892084571046775\n",
      "episode :  33\n",
      "current step :  7\n",
      "reward :  -0.4488975724601159\n",
      "episode :  33\n",
      "current step :  8\n",
      "reward :  -0.44868448818983675\n",
      "episode :  33\n",
      "current step :  9\n",
      "reward :  -0.4479620832022531\n",
      "episode :  33\n",
      "current step :  10\n",
      "reward :  -0.4361235797520665\n",
      "episode :  33\n",
      "current step :  11\n",
      "reward :  -0.43946376992765196\n",
      "episode :  33\n",
      "current step :  12\n",
      "reward :  -0.4407659200044535\n",
      "episode :  33\n",
      "current step :  13\n",
      "reward :  -0.43909043295885686\n",
      "episode :  33\n",
      "current step :  14\n",
      "reward :  -0.4373833794414709\n",
      "episode :  33\n",
      "current step :  15\n",
      "reward :  -0.43893483166893993\n",
      "episode :  33\n",
      "current step :  16\n",
      "reward :  -0.4272914802550129\n",
      "episode :  33\n",
      "current step :  17\n",
      "reward :  -0.4064264957286111\n",
      "episode :  33\n",
      "current step :  18\n",
      "reward :  -0.40638550534490375\n",
      "episode :  33\n",
      "current step :  19\n",
      "reward :  -0.42265889531903417\n",
      "episode :  33\n",
      "current step :  20\n",
      "reward :  -0.4242557300222629\n",
      "episode :  33\n",
      "current step :  21\n",
      "reward :  -0.3981447532457135\n",
      "episode :  33\n",
      "current step :  22\n",
      "reward :  -0.4176290014956302\n",
      "episode :  33\n",
      "current step :  23\n",
      "reward :  -0.40874998785783034\n",
      "episode :  33\n",
      "current step :  24\n",
      "reward :  -0.41891622360509845\n",
      "episode :  33\n",
      "current step :  25\n",
      "reward :  -0.4175840029510317\n",
      "episode :  33\n",
      "current step :  26\n",
      "reward :  -0.41769764351351535\n",
      "episode :  33\n",
      "current step :  27\n",
      "reward :  -0.4199657249968925\n",
      "episode :  33\n",
      "current step :  28\n",
      "reward :  -0.4170967638812574\n",
      "episode :  33\n",
      "current step :  29\n",
      "reward :  -0.4160479369359671\n",
      "episode :  33\n",
      "current step :  30\n",
      "reward :  -0.41687363127987104\n",
      "episode :  33\n",
      "current step :  31\n",
      "reward :  -0.3873285394614216\n",
      "episode :  33\n",
      "current step :  32\n",
      "reward :  -0.40120686379360165\n",
      "episode :  33\n",
      "current step :  33\n",
      "reward :  -0.4149655633660292\n",
      "episode :  33\n",
      "current step :  34\n",
      "reward :  -0.432276362712411\n",
      "episode :  33\n",
      "current step :  35\n",
      "reward :  -0.41557979162126407\n",
      "episode :  33\n",
      "current step :  36\n",
      "reward :  -0.41366026017390994\n",
      "episode :  33\n",
      "current step :  37\n",
      "reward :  -0.3997607640295365\n",
      "episode :  33\n",
      "current step :  38\n",
      "reward :  -0.4157282111442929\n",
      "episode :  33\n",
      "current step :  39\n",
      "reward :  -0.4151005471621121\n",
      "episode :  33\n",
      "current step :  40\n",
      "reward :  -0.4082793187870795\n",
      "episode :  33\n",
      "current step :  41\n",
      "reward :  -0.41650961411416126\n",
      "episode :  33\n",
      "current step :  42\n",
      "reward :  -0.41243004710922565\n",
      "episode :  33\n",
      "current step :  43\n",
      "reward :  -0.41157855692208756\n",
      "episode :  33\n",
      "current step :  44\n",
      "reward :  -0.37987412338821214\n",
      "episode :  33\n",
      "current step :  45\n",
      "reward :  -0.3647722485286204\n",
      "episode :  33\n",
      "current step :  46\n",
      "reward :  -0.40496742903224264\n",
      "episode :  33\n",
      "current step :  47\n",
      "reward :  -0.4148888563501731\n",
      "episode :  33\n",
      "current step :  48\n",
      "reward :  -0.4318709665905777\n",
      "episode :  33\n",
      "current step :  49\n",
      "reward :  -0.43384170675903083\n",
      "episode :  33\n",
      "current step :  50\n",
      "reward :  -0.4012965906149782\n",
      "episode :  33\n",
      "current step :  51\n",
      "reward :  -0.41505017919855186\n",
      "episode :  33\n",
      "current step :  52\n",
      "reward :  -0.4405216907837081\n",
      "episode :  33\n",
      "current step :  53\n",
      "reward :  -0.43982208352318075\n",
      "episode :  33\n",
      "current step :  54\n",
      "reward :  -0.4307166462721154\n",
      "episode :  33\n",
      "current step :  55\n",
      "reward :  -0.4294077486889286\n",
      "episode :  33\n",
      "current step :  56\n",
      "reward :  -0.4385266287825943\n",
      "episode :  33\n",
      "current step :  57\n",
      "reward :  -0.44047098039476756\n",
      "episode :  33\n",
      "current step :  58\n",
      "reward :  -0.46091248879340124\n",
      "episode :  33\n",
      "current step :  59\n",
      "reward :  -0.46926358046448713\n",
      "episode :  33\n",
      "current step :  60\n",
      "reward :  -0.4562702486171617\n",
      "episode :  33\n",
      "current step :  61\n",
      "reward :  -0.4582337565601153\n",
      "episode :  33\n",
      "current step :  62\n",
      "reward :  -0.47531504846816797\n",
      "episode :  33\n",
      "current step :  63\n",
      "reward :  -0.4606252373750544\n",
      "episode :  33\n",
      "current step :  64\n",
      "reward :  -0.456511786206869\n",
      "episode :  33\n",
      "current step :  65\n",
      "reward :  -0.4700062965284526\n",
      "episode :  33\n",
      "current step :  66\n",
      "reward :  -0.47776155745900495\n",
      "episode :  33\n",
      "current step :  67\n",
      "reward :  -0.4855040230148869\n",
      "episode :  33\n",
      "current step :  68\n",
      "reward :  -0.47876801347323034\n",
      "episode :  33\n",
      "current step :  69\n",
      "reward :  -0.4829867141881384\n",
      "episode :  33\n",
      "current step :  70\n",
      "reward :  -0.48172794919672174\n",
      "episode :  33\n",
      "current step :  71\n",
      "reward :  -0.48531846361679476\n",
      "episode :  33\n",
      "current step :  72\n",
      "reward :  -0.48115870706176095\n",
      "episode :  33\n",
      "current step :  73\n",
      "reward :  -0.4681251949635555\n",
      "episode :  33\n",
      "current step :  74\n",
      "reward :  -0.47079888982080825\n",
      "episode :  33\n",
      "current step :  75\n",
      "reward :  -0.47672625249523964\n",
      "episode :  33\n",
      "current step :  76\n",
      "reward :  -0.4754104189179287\n",
      "episode :  33\n",
      "current step :  77\n",
      "reward :  -0.4771947895304068\n",
      "episode :  33\n",
      "current step :  78\n",
      "reward :  -0.4767025206130098\n",
      "episode :  33\n",
      "current step :  79\n",
      "reward :  -0.45440419056187753\n",
      "episode :  33\n",
      "current step :  80\n",
      "reward :  -0.4658142610706609\n",
      "episode :  33\n",
      "current step :  81\n",
      "reward :  -0.45488797832999833\n",
      "episode :  33\n",
      "current step :  82\n",
      "reward :  -0.4210941805591713\n",
      "episode :  33\n",
      "current step :  83\n",
      "reward :  -0.44145116779040666\n",
      "episode :  33\n",
      "current step :  84\n",
      "reward :  -0.4363286548342043\n",
      "episode :  33\n",
      "current step :  85\n",
      "reward :  -0.43024770349798946\n",
      "episode :  33\n",
      "current step :  86\n",
      "reward :  -0.4272122382806806\n",
      "episode :  33\n",
      "current step :  87\n",
      "reward :  -0.42351795975729184\n",
      "episode :  33\n",
      "current step :  88\n",
      "reward :  -0.41600124723097454\n",
      "episode :  33\n",
      "current step :  89\n",
      "reward :  -0.412364448106606\n",
      "episode :  33\n",
      "current step :  90\n",
      "reward :  -0.4016624083993179\n",
      "episode :  33\n",
      "current step :  91\n",
      "reward :  -0.40876586604476606\n",
      "episode :  33\n",
      "current step :  92\n",
      "reward :  -0.4068590865280613\n",
      "episode :  33\n",
      "current step :  93\n",
      "reward :  -0.4070964217538685\n",
      "episode :  33\n",
      "current step :  94\n",
      "reward :  -0.4064630039121822\n",
      "episode :  33\n",
      "current step :  95\n",
      "reward :  -0.4086506956278447\n",
      "episode :  33\n",
      "current step :  96\n",
      "reward :  -0.4110860035122873\n",
      "episode :  33\n",
      "current step :  97\n",
      "reward :  -0.4139900932297788\n",
      "episode :  33\n",
      "current step :  98\n",
      "reward :  -0.41651032611518446\n",
      "episode :  33\n",
      "current step :  99\n",
      "reward :  -0.4191878623901274\n",
      "episode :  33\n",
      "current step :  100\n",
      "reward :  -0.4233488748867497\n",
      "episode :  33\n",
      "current step :  101\n",
      "reward :  -0.4258372217065854\n",
      "episode :  33\n",
      "current step :  102\n",
      "reward :  -0.42932748606082743\n",
      "episode :  33\n",
      "current step :  103\n",
      "reward :  -0.431599196047815\n",
      "episode :  33\n",
      "current step :  104\n",
      "reward :  -0.4351395680590471\n",
      "episode :  33\n",
      "current step :  105\n",
      "reward :  -0.4377356237707443\n",
      "episode :  33\n",
      "current step :  106\n",
      "reward :  -0.43891000698508703\n",
      "episode :  33\n",
      "current step :  107\n",
      "reward :  -0.4413827855951666\n",
      "episode :  33\n",
      "current step :  108\n",
      "reward :  -0.4430384277440208\n",
      "episode :  33\n",
      "current step :  109\n",
      "reward :  -0.44355403145404565\n",
      "episode :  33\n",
      "current step :  110\n",
      "reward :  -0.4442757874584407\n",
      "episode :  33\n",
      "current step :  111\n",
      "reward :  -0.44503279210512836\n",
      "episode :  33\n",
      "current step :  112\n",
      "reward :  -0.445715565447801\n",
      "episode :  33\n",
      "current step :  113\n",
      "reward :  -0.4443065030527915\n",
      "episode :  33\n",
      "current step :  114\n",
      "reward :  -0.44350190367186293\n",
      "episode :  33\n",
      "current step :  115\n",
      "reward :  -0.4460777615315707\n",
      "episode :  33\n",
      "current step :  116\n",
      "reward :  -0.44626189854597254\n",
      "episode :  33\n",
      "current step :  117\n",
      "reward :  -0.4465505709087982\n",
      "episode :  33\n",
      "current step :  118\n",
      "reward :  -0.44609672935147865\n",
      "episode :  33\n",
      "current step :  119\n",
      "reward :  -0.4445266322290379\n",
      "episode :  33\n",
      "current step :  120\n",
      "reward :  -0.448085403454977\n",
      "episode :  33\n",
      "current step :  121\n",
      "reward :  -0.4483647978101709\n",
      "episode :  33\n",
      "current step :  122\n",
      "reward :  -0.4463179932175241\n",
      "episode :  33\n",
      "current step :  123\n",
      "reward :  -0.44764202078213605\n",
      "episode :  33\n",
      "current step :  124\n",
      "reward :  -0.44680265074535014\n",
      "episode :  33\n",
      "current step :  125\n",
      "reward :  -0.44366097152680506\n",
      "episode :  33\n",
      "current step :  126\n",
      "reward :  -0.44210303326499467\n",
      "episode :  33\n",
      "current step :  127\n",
      "reward :  -0.4418118904661436\n",
      "episode :  33\n",
      "current step :  128\n",
      "reward :  -0.44022883950242236\n",
      "episode :  33\n",
      "current step :  129\n",
      "reward :  -0.4383461537435049\n",
      "episode :  33\n",
      "current step :  130\n",
      "reward :  -0.4364438316891924\n",
      "episode :  33\n",
      "current step :  131\n",
      "reward :  -0.43389478435866663\n",
      "episode :  33\n",
      "current step :  132\n",
      "reward :  -0.43023599391499884\n",
      "episode :  33\n",
      "current step :  133\n",
      "reward :  -0.42805518636238915\n",
      "episode :  33\n",
      "current step :  134\n",
      "reward :  -0.42399677185167206\n",
      "episode :  33\n",
      "current step :  135\n",
      "reward :  -0.4234034600629031\n",
      "episode :  33\n",
      "current step :  136\n",
      "reward :  -0.41730907570435544\n",
      "episode :  33\n",
      "current step :  137\n",
      "reward :  -0.4141067958883367\n",
      "episode :  33\n",
      "current step :  138\n",
      "reward :  -0.4076365752297872\n",
      "episode :  33\n",
      "current step :  139\n",
      "reward :  -0.40366581183850603\n",
      "episode :  33\n",
      "current step :  140\n",
      "reward :  -0.40155688439101644\n",
      "episode :  33\n",
      "current step :  141\n",
      "reward :  -0.3954972661673157\n",
      "episode :  33\n",
      "current step :  142\n",
      "reward :  -0.39078380857157574\n",
      "episode :  33\n",
      "current step :  143\n",
      "reward :  -0.38846910302296556\n",
      "episode :  33\n",
      "current step :  144\n",
      "reward :  -0.3876996706655025\n",
      "episode :  33\n",
      "current step :  145\n",
      "reward :  -0.3852379032807959\n",
      "episode :  33\n",
      "current step :  146\n",
      "reward :  -0.38328369870667667\n",
      "episode :  33\n",
      "current step :  147\n",
      "reward :  -0.38088317261656207\n",
      "episode :  33\n",
      "current step :  148\n",
      "reward :  -0.37845900385577247\n",
      "episode :  33\n",
      "current step :  149\n",
      "reward :  -0.3791347101502783\n",
      "episode :  33\n",
      "current step :  150\n",
      "reward :  -0.38826418786735034\n",
      "episode :  33\n",
      "current step :  151\n",
      "reward :  -0.39436544668988655\n",
      "episode :  33\n",
      "current step :  152\n",
      "reward :  -0.3969071341329552\n",
      "episode :  33\n",
      "current step :  153\n",
      "reward :  -0.395164988261552\n",
      "episode :  33\n",
      "current step :  154\n",
      "reward :  -0.4017758813481898\n",
      "episode :  33\n",
      "current step :  155\n",
      "reward :  -0.40226309616370154\n",
      "episode :  33\n",
      "current step :  156\n",
      "reward :  -0.40645962878222025\n",
      "episode :  33\n",
      "current step :  157\n",
      "reward :  -0.41097907120140403\n",
      "episode :  33\n",
      "current step :  158\n",
      "reward :  -0.4146192998963682\n",
      "episode :  33\n",
      "current step :  159\n",
      "reward :  -0.4197849800324034\n",
      "episode :  33\n",
      "current step :  160\n",
      "reward :  -0.4202884560915959\n",
      "episode :  33\n",
      "current step :  161\n",
      "reward :  -0.42352943471702387\n",
      "episode :  33\n",
      "current step :  162\n",
      "reward :  -0.4259452424775661\n",
      "episode :  33\n",
      "current step :  163\n",
      "reward :  -0.4282655252090569\n",
      "episode :  33\n",
      "current step :  164\n",
      "reward :  -0.4298326876185212\n",
      "episode :  33\n",
      "current step :  165\n",
      "reward :  -0.433314971353454\n",
      "episode :  33\n",
      "current step :  166\n",
      "reward :  -0.43792970218098154\n",
      "episode :  33\n",
      "current step :  167\n",
      "reward :  -0.4396042204655388\n",
      "episode :  33\n",
      "current step :  168\n",
      "reward :  -0.4414012444435336\n",
      "episode :  33\n",
      "current step :  169\n",
      "reward :  -0.4437375653952341\n",
      "episode :  33\n",
      "current step :  170\n",
      "reward :  -0.4460906879344475\n",
      "episode :  33\n",
      "current step :  171\n",
      "reward :  -0.45101251656786484\n",
      "episode :  33\n",
      "current step :  172\n",
      "reward :  -0.4544327358025963\n",
      "episode :  33\n",
      "current step :  173\n",
      "reward :  -0.45397636497907373\n",
      "episode :  33\n",
      "current step :  174\n",
      "reward :  -0.45658474825720446\n",
      "episode :  33\n",
      "current step :  175\n",
      "reward :  -0.45687876289878\n",
      "episode :  33\n",
      "current step :  176\n",
      "reward :  -0.46083882442436697\n",
      "episode :  33\n",
      "current step :  177\n",
      "reward :  -0.46232665466565576\n",
      "episode :  33\n",
      "current step :  178\n",
      "reward :  -0.46656542388851996\n",
      "episode :  33\n",
      "current step :  179\n",
      "reward :  -0.46893885760511883\n",
      "episode :  33\n",
      "current step :  180\n",
      "reward :  -0.46978322001188566\n",
      "episode :  33\n",
      "current step :  181\n",
      "reward :  -0.47139567332677895\n",
      "episode :  33\n",
      "current step :  182\n",
      "reward :  -0.4705750505488305\n",
      "episode :  33\n",
      "current step :  183\n",
      "reward :  -0.46960360910267424\n",
      "episode :  33\n",
      "current step :  184\n",
      "reward :  -0.4700207099085359\n",
      "episode :  33\n",
      "current step :  185\n",
      "reward :  -0.47270848559327516\n",
      "episode :  33\n",
      "current step :  186\n",
      "reward :  -0.47115711607122496\n",
      "episode :  33\n",
      "current step :  187\n",
      "reward :  -0.4747450224537952\n",
      "episode :  33\n",
      "current step :  188\n",
      "reward :  -0.47156070851631976\n",
      "episode :  33\n",
      "current step :  189\n",
      "reward :  -0.4720131175124255\n",
      "episode :  33\n",
      "current step :  190\n",
      "reward :  -0.47119291997068297\n",
      "episode :  33\n",
      "current step :  191\n",
      "reward :  -0.48062629082090724\n",
      "episode :  33\n",
      "current step :  192\n",
      "reward :  -0.480720554432781\n",
      "episode :  33\n",
      "current step :  193\n",
      "reward :  -0.4759895455578935\n",
      "episode :  33\n",
      "current step :  194\n",
      "reward :  -0.47498943491855444\n",
      "episode :  33\n",
      "current step :  195\n",
      "reward :  -0.47261431197261405\n",
      "episode :  33\n",
      "current step :  196\n",
      "reward :  -0.47370714016768073\n",
      "episode :  33\n",
      "current step :  197\n",
      "reward :  -0.47451337982442504\n",
      "episode :  33\n",
      "current step :  198\n",
      "reward :  -0.472879504296767\n",
      "episode :  33\n",
      "current step :  199\n",
      "reward :  -0.4710145872255156\n",
      "episode :  33\n",
      "current step :  200\n",
      "reward :  -0.4698881374513318\n",
      "episode :  33\n",
      "current step :  201\n",
      "reward :  -0.4700975950082199\n",
      "episode :  33\n",
      "current step :  202\n",
      "reward :  -0.46978466618135284\n",
      "episode :  33\n",
      "current step :  203\n",
      "reward :  -0.46877364015515144\n",
      "episode :  33\n",
      "current step :  204\n",
      "reward :  -0.4697804312308927\n",
      "episode :  33\n",
      "current step :  205\n",
      "reward :  -0.46798762145209394\n",
      "episode :  33\n",
      "current step :  206\n",
      "reward :  -0.47106358867406894\n",
      "episode :  33\n",
      "current step :  207\n",
      "reward :  -0.46812133378026616\n",
      "episode :  33\n",
      "current step :  208\n",
      "reward :  -0.46725190902653774\n",
      "episode :  33\n",
      "current step :  209\n",
      "reward :  -0.4664942779130967\n",
      "episode :  33\n",
      "current step :  210\n",
      "reward :  -0.4643555030773306\n",
      "episode :  33\n",
      "current step :  211\n",
      "reward :  -0.45911153136469074\n",
      "episode :  33\n",
      "current step :  212\n",
      "reward :  -0.45502715936419696\n",
      "episode :  33\n",
      "current step :  213\n",
      "reward :  -0.45305797992243957\n",
      "episode :  33\n",
      "current step :  214\n",
      "reward :  -0.44868933497362995\n",
      "episode :  33\n",
      "current step :  215\n",
      "reward :  -0.4500392189131465\n",
      "episode :  33\n",
      "current step :  216\n",
      "reward :  -0.44087558739764315\n",
      "episode :  33\n",
      "current step :  217\n",
      "reward :  -0.4383533826125654\n",
      "episode :  33\n",
      "current step :  218\n",
      "reward :  -0.44169797528773946\n",
      "episode :  33\n",
      "current step :  219\n",
      "reward :  -0.4316335003021032\n",
      "episode :  33\n",
      "current step :  220\n",
      "reward :  -0.42772941089794914\n",
      "episode :  33\n",
      "current step :  221\n",
      "reward :  -0.42410501422142943\n",
      "episode :  33\n",
      "current step :  222\n",
      "reward :  -0.419556805270467\n",
      "episode :  33\n",
      "current step :  223\n",
      "reward :  -0.4146672069845393\n",
      "episode :  33\n",
      "current step :  224\n",
      "reward :  -0.41157687877135035\n",
      "episode :  33\n",
      "current step :  225\n",
      "reward :  -0.40806408283463175\n",
      "episode :  33\n",
      "current step :  226\n",
      "reward :  -0.40498867100630115\n",
      "episode :  33\n",
      "current step :  227\n",
      "reward :  -0.402025505178911\n",
      "episode :  33\n",
      "current step :  228\n",
      "reward :  -0.3994542265521665\n",
      "episode :  33\n",
      "current step :  229\n",
      "reward :  -0.39530156521913434\n",
      "episode :  33\n",
      "current step :  230\n",
      "reward :  -0.3908142596571891\n",
      "episode :  33\n",
      "current step :  231\n",
      "reward :  -0.38655346205568464\n",
      "episode :  33\n",
      "current step :  232\n",
      "reward :  -0.3814224803238321\n",
      "episode :  33\n",
      "current step :  233\n",
      "reward :  -0.378320391417112\n",
      "episode :  33\n",
      "current step :  234\n",
      "reward :  -0.3685725411864236\n",
      "episode :  33\n",
      "current step :  235\n",
      "reward :  -0.37138843773230784\n",
      "episode :  33\n",
      "current step :  236\n",
      "reward :  -0.37288419106709103\n",
      "episode :  33\n",
      "current step :  237\n",
      "reward :  -0.36786795964927416\n",
      "episode :  33\n",
      "current step :  238\n",
      "reward :  -0.3673037155103677\n",
      "episode :  33\n",
      "current step :  239\n",
      "reward :  -0.3510713113453298\n",
      "episode :  33\n",
      "current step :  240\n",
      "reward :  -0.3598928152151984\n",
      "episode :  33\n",
      "current step :  241\n",
      "reward :  -0.3541800204721217\n",
      "episode :  33\n",
      "current step :  242\n",
      "reward :  -0.3567144925856779\n",
      "episode :  33\n",
      "current step :  243\n",
      "reward :  -0.3704717420061218\n",
      "episode :  33\n",
      "current step :  244\n",
      "reward :  -0.37288718935644327\n",
      "episode :  33\n",
      "current step :  245\n",
      "reward :  -0.369055488984662\n",
      "episode :  33\n",
      "current step :  246\n",
      "reward :  -0.37020507630088123\n",
      "episode :  33\n",
      "current step :  247\n",
      "reward :  -0.37439890206993715\n",
      "episode :  33\n",
      "current step :  248\n",
      "reward :  -0.38873103896718975\n",
      "episode :  33\n",
      "current step :  249\n",
      "reward :  -0.4072007384775493\n",
      "episode :  33\n",
      "current step :  250\n",
      "reward :  -0.4042023179586309\n",
      "episode :  33\n",
      "current step :  251\n",
      "reward :  -0.4191928096845115\n",
      "episode :  33\n",
      "current step :  252\n",
      "reward :  -0.42736698201105755\n",
      "episode :  33\n",
      "current step :  253\n",
      "reward :  -0.44253344674005\n",
      "episode :  33\n",
      "current step :  254\n",
      "reward :  -0.44868265737663526\n",
      "episode :  33\n",
      "current step :  255\n",
      "reward :  -0.45578761727658806\n",
      "episode :  33\n",
      "current step :  256\n",
      "reward :  -0.4699095655431367\n",
      "episode :  33\n",
      "current step :  257\n",
      "reward :  -0.47621301597197924\n",
      "episode :  33\n",
      "current step :  258\n",
      "reward :  -0.475950241041111\n",
      "episode :  33\n",
      "current step :  259\n",
      "reward :  -0.48058839223380645\n",
      "episode :  33\n",
      "current step :  260\n",
      "reward :  -0.48731642821351256\n",
      "episode :  33\n",
      "current step :  261\n",
      "reward :  -0.4973231225810715\n",
      "episode :  33\n",
      "current step :  262\n",
      "reward :  -0.5057196691269865\n",
      "episode :  33\n",
      "current step :  263\n",
      "reward :  -0.5083765153701767\n",
      "episode :  33\n",
      "current step :  264\n",
      "reward :  -0.5093090946094795\n",
      "episode :  33\n",
      "current step :  265\n",
      "reward :  -0.5178759729747906\n",
      "episode :  33\n",
      "current step :  266\n",
      "reward :  -0.51746774271403\n",
      "episode :  33\n",
      "current step :  267\n",
      "reward :  -0.5166911490379398\n",
      "episode :  33\n",
      "current step :  268\n",
      "reward :  -0.5282615360627028\n",
      "episode :  33\n",
      "current step :  269\n",
      "reward :  -0.5295281888051272\n",
      "episode :  33\n",
      "current step :  270\n",
      "reward :  -0.5208304576301855\n",
      "episode :  33\n",
      "current step :  271\n",
      "reward :  -0.49611417039722266\n",
      "episode :  33\n",
      "current step :  272\n",
      "reward :  -0.5148729161144706\n",
      "episode :  33\n",
      "current step :  273\n",
      "reward :  -0.5244277301387763\n",
      "episode :  33\n",
      "current step :  274\n",
      "reward :  -0.5294657686746367\n",
      "episode :  33\n",
      "current step :  275\n",
      "reward :  -0.5356157830195925\n",
      "episode :  33\n",
      "current step :  276\n",
      "reward :  -0.5383370512491104\n",
      "episode :  33\n",
      "current step :  277\n",
      "reward :  -0.5369931561429445\n",
      "episode :  33\n",
      "current step :  278\n",
      "reward :  -0.5367085908533312\n",
      "episode :  33\n",
      "current step :  279\n",
      "reward :  -0.536676167129434\n",
      "episode :  33\n",
      "current step :  280\n",
      "reward :  -0.538370831810261\n",
      "episode :  33\n",
      "current step :  281\n",
      "reward :  -0.5385782158498658\n",
      "episode :  33\n",
      "current step :  282\n",
      "reward :  -0.540981830368003\n",
      "episode :  33\n",
      "current step :  283\n",
      "reward :  -0.5389221395882069\n",
      "episode :  33\n",
      "current step :  284\n",
      "reward :  -0.5358682218768537\n",
      "episode :  33\n",
      "current step :  285\n",
      "reward :  -0.5316249089018913\n",
      "episode :  34\n",
      "current step :  0\n",
      "reward :  -0.4385494122182364\n",
      "episode :  34\n",
      "current step :  1\n",
      "reward :  -0.4259679205850058\n",
      "episode :  34\n",
      "current step :  2\n",
      "reward :  -0.49566056399333497\n",
      "episode :  34\n",
      "current step :  3\n",
      "reward :  -0.5545833821875992\n",
      "episode :  34\n",
      "current step :  4\n",
      "reward :  -0.5646725825397003\n",
      "episode :  34\n",
      "current step :  5\n",
      "reward :  -0.5643872637543799\n",
      "episode :  34\n",
      "current step :  6\n",
      "reward :  -0.5643684867116718\n",
      "episode :  34\n",
      "current step :  7\n",
      "reward :  -0.5628208318584297\n",
      "episode :  34\n",
      "current step :  8\n",
      "reward :  -0.557255325813663\n",
      "episode :  34\n",
      "current step :  9\n",
      "reward :  -0.5585975838777686\n",
      "episode :  34\n",
      "current step :  10\n",
      "reward :  -0.5603383316958374\n",
      "episode :  34\n",
      "current step :  11\n",
      "reward :  -0.5606530240137421\n",
      "episode :  34\n",
      "current step :  12\n",
      "reward :  -0.5617156918571737\n",
      "episode :  34\n",
      "current step :  13\n",
      "reward :  -0.5620399139331302\n",
      "episode :  34\n",
      "current step :  14\n",
      "reward :  -0.5623842093685564\n",
      "episode :  34\n",
      "current step :  15\n",
      "reward :  -0.5612659537736558\n",
      "episode :  34\n",
      "current step :  16\n",
      "reward :  -0.5638218994815322\n",
      "episode :  34\n",
      "current step :  17\n",
      "reward :  -0.5587286641170802\n",
      "episode :  34\n",
      "current step :  18\n",
      "reward :  -0.5475759670381335\n",
      "episode :  34\n",
      "current step :  19\n",
      "reward :  -0.5561554395486525\n",
      "episode :  34\n",
      "current step :  20\n",
      "reward :  -0.5573437382159496\n",
      "episode :  34\n",
      "current step :  21\n",
      "reward :  -0.5518191127351768\n",
      "episode :  34\n",
      "current step :  22\n",
      "reward :  -0.5482479368266655\n",
      "episode :  34\n",
      "current step :  23\n",
      "reward :  -0.5458832387147406\n",
      "episode :  34\n",
      "current step :  24\n",
      "reward :  -0.5294630884017657\n",
      "episode :  34\n",
      "current step :  25\n",
      "reward :  -0.5374582261458831\n",
      "episode :  34\n",
      "current step :  26\n",
      "reward :  -0.5330262288619998\n",
      "episode :  34\n",
      "current step :  27\n",
      "reward :  -0.5323949298932327\n",
      "episode :  34\n",
      "current step :  28\n",
      "reward :  -0.5286978716044701\n",
      "episode :  34\n",
      "current step :  29\n",
      "reward :  -0.5267820487263147\n",
      "episode :  34\n",
      "current step :  30\n",
      "reward :  -0.5283242417007439\n",
      "episode :  34\n",
      "current step :  31\n",
      "reward :  -0.525442394648673\n",
      "episode :  34\n",
      "current step :  32\n",
      "reward :  -0.5198769925541431\n",
      "episode :  34\n",
      "current step :  33\n",
      "reward :  -0.5180159032838951\n",
      "episode :  34\n",
      "current step :  34\n",
      "reward :  -0.5161508801956198\n",
      "episode :  34\n",
      "current step :  35\n",
      "reward :  -0.5154120543243849\n",
      "episode :  34\n",
      "current step :  36\n",
      "reward :  -0.510084606349395\n",
      "episode :  34\n",
      "current step :  37\n",
      "reward :  -0.5092420491076886\n",
      "episode :  34\n",
      "current step :  38\n",
      "reward :  -0.5043494866067268\n",
      "episode :  34\n",
      "current step :  39\n",
      "reward :  -0.4957818524945573\n",
      "episode :  34\n",
      "current step :  40\n",
      "reward :  -0.49308543508653824\n",
      "episode :  34\n",
      "current step :  41\n",
      "reward :  -0.4908310198162498\n",
      "episode :  34\n",
      "current step :  42\n",
      "reward :  -0.4881218825845457\n",
      "episode :  34\n",
      "current step :  43\n",
      "reward :  -0.48452870626180083\n",
      "episode :  34\n",
      "current step :  44\n",
      "reward :  -0.4871534559525336\n",
      "episode :  34\n",
      "current step :  45\n",
      "reward :  -0.48899614338739994\n",
      "episode :  34\n",
      "current step :  46\n",
      "reward :  -0.49127410717801967\n",
      "episode :  34\n",
      "current step :  47\n",
      "reward :  -0.49355456176971996\n",
      "episode :  34\n",
      "current step :  48\n",
      "reward :  -0.4950673023343252\n",
      "episode :  34\n",
      "current step :  49\n",
      "reward :  -0.499364492527349\n",
      "episode :  34\n",
      "current step :  50\n",
      "reward :  -0.5045829186675355\n",
      "episode :  34\n",
      "current step :  51\n",
      "reward :  -0.5067224463906893\n",
      "episode :  34\n",
      "current step :  52\n",
      "reward :  -0.5067844764715668\n",
      "episode :  34\n",
      "current step :  53\n",
      "reward :  -0.5075300378112066\n",
      "episode :  34\n",
      "current step :  54\n",
      "reward :  -0.49607272968080907\n",
      "episode :  34\n",
      "current step :  55\n",
      "reward :  -0.4833101490154596\n",
      "episode :  34\n",
      "current step :  56\n",
      "reward :  -0.4922781359619889\n",
      "episode :  34\n",
      "current step :  57\n",
      "reward :  -0.49858032274526715\n",
      "episode :  34\n",
      "current step :  58\n",
      "reward :  -0.5040058325416743\n",
      "episode :  34\n",
      "current step :  59\n",
      "reward :  -0.5034711268661831\n",
      "episode :  34\n",
      "current step :  60\n",
      "reward :  -0.5028169905870766\n",
      "episode :  34\n",
      "current step :  61\n",
      "reward :  -0.4990669596815278\n",
      "episode :  34\n",
      "current step :  62\n",
      "reward :  -0.5018047180300044\n",
      "episode :  34\n",
      "current step :  63\n",
      "reward :  -0.5005068258881304\n",
      "episode :  34\n",
      "current step :  64\n",
      "reward :  -0.5020416528528593\n",
      "episode :  34\n",
      "current step :  65\n",
      "reward :  -0.49212442038416476\n",
      "episode :  34\n",
      "current step :  66\n",
      "reward :  -0.49049960267880877\n",
      "episode :  34\n",
      "current step :  67\n",
      "reward :  -0.4920330629867225\n",
      "episode :  34\n",
      "current step :  68\n",
      "reward :  -0.497244047450522\n",
      "episode :  34\n",
      "current step :  69\n",
      "reward :  -0.4987329408728563\n",
      "episode :  34\n",
      "current step :  70\n",
      "reward :  -0.4996364150990251\n",
      "episode :  34\n",
      "current step :  71\n",
      "reward :  -0.4988110789557452\n",
      "episode :  34\n",
      "current step :  72\n",
      "reward :  -0.5034416448959261\n",
      "episode :  34\n",
      "current step :  73\n",
      "reward :  -0.5053235445942278\n",
      "episode :  34\n",
      "current step :  74\n",
      "reward :  -0.5032730247764624\n",
      "episode :  34\n",
      "current step :  75\n",
      "reward :  -0.5032316236118746\n",
      "episode :  34\n",
      "current step :  76\n",
      "reward :  -0.5063317682328682\n",
      "episode :  34\n",
      "current step :  77\n",
      "reward :  -0.5081143682741416\n",
      "episode :  34\n",
      "current step :  78\n",
      "reward :  -0.5077588869109396\n",
      "episode :  34\n",
      "current step :  79\n",
      "reward :  -0.5067807474097216\n",
      "episode :  34\n",
      "current step :  80\n",
      "reward :  -0.5068988067324497\n",
      "episode :  34\n",
      "current step :  81\n",
      "reward :  -0.5012775887880518\n",
      "episode :  34\n",
      "current step :  82\n",
      "reward :  -0.49967506292959135\n",
      "episode :  34\n",
      "current step :  83\n",
      "reward :  -0.49923951350718104\n",
      "episode :  34\n",
      "current step :  84\n",
      "reward :  -0.49916745814153135\n",
      "episode :  34\n",
      "current step :  85\n",
      "reward :  -0.4974251379490533\n",
      "episode :  34\n",
      "current step :  86\n",
      "reward :  -0.4987209139257659\n",
      "episode :  34\n",
      "current step :  87\n",
      "reward :  -0.5002474629895559\n",
      "episode :  34\n",
      "current step :  88\n",
      "reward :  -0.49987878760575943\n",
      "episode :  34\n",
      "current step :  89\n",
      "reward :  -0.5017123597294494\n",
      "episode :  34\n",
      "current step :  90\n",
      "reward :  -0.5039544164290216\n",
      "episode :  34\n",
      "current step :  91\n",
      "reward :  -0.5068688120164828\n",
      "episode :  34\n",
      "current step :  92\n",
      "reward :  -0.5092455712391121\n",
      "episode :  34\n",
      "current step :  93\n",
      "reward :  -0.5134234294300807\n",
      "episode :  34\n",
      "current step :  94\n",
      "reward :  -0.5168115814009507\n",
      "episode :  34\n",
      "current step :  95\n",
      "reward :  -0.5216758116502476\n",
      "episode :  34\n",
      "current step :  96\n",
      "reward :  -0.5273921467479109\n",
      "episode :  34\n",
      "current step :  97\n",
      "reward :  -0.5316413130591008\n",
      "episode :  34\n",
      "current step :  98\n",
      "reward :  -0.5355727667172999\n",
      "episode :  34\n",
      "current step :  99\n",
      "reward :  -0.536887436295381\n",
      "episode :  34\n",
      "current step :  100\n",
      "reward :  -0.5414567332557998\n",
      "episode :  34\n",
      "current step :  101\n",
      "reward :  -0.5447677892610274\n",
      "episode :  34\n",
      "current step :  102\n",
      "reward :  -0.5446785109402499\n",
      "episode :  34\n",
      "current step :  103\n",
      "reward :  -0.5457044613289707\n",
      "episode :  34\n",
      "current step :  104\n",
      "reward :  -0.5461817394441629\n",
      "episode :  34\n",
      "current step :  105\n",
      "reward :  -0.5453408186255966\n",
      "episode :  34\n",
      "current step :  106\n",
      "reward :  -0.5456783772748763\n",
      "episode :  34\n",
      "current step :  107\n",
      "reward :  -0.5460316994500902\n",
      "episode :  34\n",
      "current step :  108\n",
      "reward :  -0.543869232642457\n",
      "episode :  34\n",
      "current step :  109\n",
      "reward :  -0.5428612406015262\n",
      "episode :  34\n",
      "current step :  110\n",
      "reward :  -0.5421341532783258\n",
      "episode :  34\n",
      "current step :  111\n",
      "reward :  -0.53970762798975\n",
      "episode :  34\n",
      "current step :  112\n",
      "reward :  -0.5364140493049059\n",
      "episode :  34\n",
      "current step :  113\n",
      "reward :  -0.5325255377532627\n",
      "episode :  34\n",
      "current step :  114\n",
      "reward :  -0.5325553993093654\n",
      "episode :  34\n",
      "current step :  115\n",
      "reward :  -0.5315233661885108\n",
      "episode :  34\n",
      "current step :  116\n",
      "reward :  -0.5326206425171567\n",
      "episode :  34\n",
      "current step :  117\n",
      "reward :  -0.5312597200187444\n",
      "episode :  34\n",
      "current step :  118\n",
      "reward :  -0.5297768802968078\n",
      "episode :  34\n",
      "current step :  119\n",
      "reward :  -0.5310871069533529\n",
      "episode :  34\n",
      "current step :  120\n",
      "reward :  -0.5294098506130668\n",
      "episode :  34\n",
      "current step :  121\n",
      "reward :  -0.5289867435724668\n",
      "episode :  34\n",
      "current step :  122\n",
      "reward :  -0.5297862738941324\n",
      "episode :  34\n",
      "current step :  123\n",
      "reward :  -0.5334001636259134\n",
      "episode :  34\n",
      "current step :  124\n",
      "reward :  -0.5324547303222424\n",
      "episode :  34\n",
      "current step :  125\n",
      "reward :  -0.5302660401115273\n",
      "episode :  34\n",
      "current step :  126\n",
      "reward :  -0.5275156565712128\n",
      "episode :  34\n",
      "current step :  127\n",
      "reward :  -0.5294857728135357\n",
      "episode :  34\n",
      "current step :  128\n",
      "reward :  -0.5271592531773918\n",
      "episode :  34\n",
      "current step :  129\n",
      "reward :  -0.5216149773955625\n",
      "episode :  34\n",
      "current step :  130\n",
      "reward :  -0.5199474270162312\n",
      "episode :  34\n",
      "current step :  131\n",
      "reward :  -0.5167453902330742\n",
      "episode :  34\n",
      "current step :  132\n",
      "reward :  -0.5125997287077918\n",
      "episode :  34\n",
      "current step :  133\n",
      "reward :  -0.5093014662736203\n",
      "episode :  34\n",
      "current step :  134\n",
      "reward :  -0.5065663213300798\n",
      "episode :  34\n",
      "current step :  135\n",
      "reward :  -0.5038759250192582\n",
      "episode :  34\n",
      "current step :  136\n",
      "reward :  -0.5020344368708545\n",
      "episode :  34\n",
      "current step :  137\n",
      "reward :  -0.4985023256549415\n",
      "episode :  34\n",
      "current step :  138\n",
      "reward :  -0.49691042266052776\n",
      "episode :  34\n",
      "current step :  139\n",
      "reward :  -0.4942374356120122\n",
      "episode :  34\n",
      "current step :  140\n",
      "reward :  -0.4946137003482794\n",
      "episode :  34\n",
      "current step :  141\n",
      "reward :  -0.4941938350445808\n",
      "episode :  34\n",
      "current step :  142\n",
      "reward :  -0.4939455016695601\n",
      "episode :  34\n",
      "current step :  143\n",
      "reward :  -0.49480977441326357\n",
      "episode :  34\n",
      "current step :  144\n",
      "reward :  -0.4953573472509136\n",
      "episode :  34\n",
      "current step :  145\n",
      "reward :  -0.4861203094417178\n",
      "episode :  34\n",
      "current step :  146\n",
      "reward :  -0.48108630372080086\n",
      "episode :  34\n",
      "current step :  147\n",
      "reward :  -0.47866941957352993\n",
      "episode :  34\n",
      "current step :  148\n",
      "reward :  -0.48075087371097275\n",
      "episode :  34\n",
      "current step :  149\n",
      "reward :  -0.48390490910910466\n",
      "episode :  34\n",
      "current step :  150\n",
      "reward :  -0.4870471017408668\n",
      "episode :  34\n",
      "current step :  151\n",
      "reward :  -0.4959577813728251\n",
      "episode :  34\n",
      "current step :  152\n",
      "reward :  -0.4954812327214572\n",
      "episode :  34\n",
      "current step :  153\n",
      "reward :  -0.5004579108727025\n",
      "episode :  34\n",
      "current step :  154\n",
      "reward :  -0.5049295819549212\n",
      "episode :  34\n",
      "current step :  155\n",
      "reward :  -0.5086239372344998\n",
      "episode :  34\n",
      "current step :  156\n",
      "reward :  -0.5118350850586687\n",
      "episode :  34\n",
      "current step :  157\n",
      "reward :  -0.5212018783404275\n",
      "episode :  34\n",
      "current step :  158\n",
      "reward :  -0.532041741837605\n",
      "episode :  34\n",
      "current step :  159\n",
      "reward :  -0.5360257659616754\n",
      "episode :  34\n",
      "current step :  160\n",
      "reward :  -0.5438267302139641\n",
      "episode :  34\n",
      "current step :  161\n",
      "reward :  -0.5518026777714199\n",
      "episode :  34\n",
      "current step :  162\n",
      "reward :  -0.5627245473721433\n",
      "episode :  34\n",
      "current step :  163\n",
      "reward :  -0.5792828804796701\n",
      "episode :  34\n",
      "current step :  164\n",
      "reward :  -0.5868258502671234\n",
      "episode :  34\n",
      "current step :  165\n",
      "reward :  -0.5862744756355406\n",
      "episode :  34\n",
      "current step :  166\n",
      "reward :  -0.5895867990895545\n",
      "episode :  34\n",
      "current step :  167\n",
      "reward :  -0.5936003376279303\n",
      "episode :  34\n",
      "current step :  168\n",
      "reward :  -0.5997122035406565\n",
      "episode :  34\n",
      "current step :  169\n",
      "reward :  -0.6076010455766832\n",
      "episode :  34\n",
      "current step :  170\n",
      "reward :  -0.6195873630653342\n",
      "episode :  34\n",
      "current step :  171\n",
      "reward :  -0.6209259164306079\n",
      "episode :  34\n",
      "current step :  172\n",
      "reward :  -0.6260382186085669\n",
      "episode :  34\n",
      "current step :  173\n",
      "reward :  -0.6260636590263902\n",
      "episode :  34\n",
      "current step :  174\n",
      "reward :  -0.6309586441054248\n",
      "episode :  34\n",
      "current step :  175\n",
      "reward :  -0.6310875445146593\n",
      "episode :  34\n",
      "current step :  176\n",
      "reward :  -0.6303639472305022\n",
      "episode :  34\n",
      "current step :  177\n",
      "reward :  -0.6322776878941148\n",
      "episode :  34\n",
      "current step :  178\n",
      "reward :  -0.6322311181722011\n",
      "episode :  34\n",
      "current step :  179\n",
      "reward :  -0.6328683432215545\n",
      "episode :  34\n",
      "current step :  180\n",
      "reward :  -0.6358031951367594\n",
      "episode :  34\n",
      "current step :  181\n",
      "reward :  -0.6507416248339495\n",
      "episode :  34\n",
      "current step :  182\n",
      "reward :  -0.6528659039539886\n",
      "episode :  34\n",
      "current step :  183\n",
      "reward :  -0.6546345494881535\n",
      "episode :  34\n",
      "current step :  184\n",
      "reward :  -0.6508355386203082\n",
      "episode :  34\n",
      "current step :  185\n",
      "reward :  -0.6480387546867034\n",
      "episode :  34\n",
      "current step :  186\n",
      "reward :  -0.6439557768924503\n",
      "episode :  34\n",
      "current step :  187\n",
      "reward :  -0.6438644933552738\n",
      "episode :  34\n",
      "current step :  188\n",
      "reward :  -0.6440720226478839\n",
      "episode :  34\n",
      "current step :  189\n",
      "reward :  -0.6564276042455943\n",
      "episode :  34\n",
      "current step :  190\n",
      "reward :  -0.6568376659370674\n",
      "episode :  34\n",
      "current step :  191\n",
      "reward :  -0.6559870678002\n",
      "episode :  34\n",
      "current step :  192\n",
      "reward :  -0.6558723314178355\n",
      "episode :  34\n",
      "current step :  193\n",
      "reward :  -0.6561131262154969\n",
      "episode :  34\n",
      "current step :  194\n",
      "reward :  -0.6550753091852741\n",
      "episode :  34\n",
      "current step :  195\n",
      "reward :  -0.6503771533945137\n",
      "episode :  34\n",
      "current step :  196\n",
      "reward :  -0.6474192445765141\n",
      "episode :  34\n",
      "current step :  197\n",
      "reward :  -0.6487621074558497\n",
      "episode :  34\n",
      "current step :  198\n",
      "reward :  -0.6423342728108318\n",
      "episode :  34\n",
      "current step :  199\n",
      "reward :  -0.6444724614329479\n",
      "episode :  34\n",
      "current step :  200\n",
      "reward :  -0.6422613757704936\n",
      "episode :  34\n",
      "current step :  201\n",
      "reward :  -0.6386090378980187\n",
      "episode :  34\n",
      "current step :  202\n",
      "reward :  -0.6384084496261938\n",
      "episode :  34\n",
      "current step :  203\n",
      "reward :  -0.6386833083597908\n",
      "episode :  34\n",
      "current step :  204\n",
      "reward :  -0.6368007801075617\n",
      "episode :  34\n",
      "current step :  205\n",
      "reward :  -0.6358631750632966\n",
      "episode :  34\n",
      "current step :  206\n",
      "reward :  -0.6353101612086006\n",
      "episode :  34\n",
      "current step :  207\n",
      "reward :  -0.6381752550235593\n",
      "episode :  34\n",
      "current step :  208\n",
      "reward :  -0.636470295594238\n",
      "episode :  34\n",
      "current step :  209\n",
      "reward :  -0.638408921972144\n",
      "episode :  34\n",
      "current step :  210\n",
      "reward :  -0.6409633897302202\n",
      "episode :  34\n",
      "current step :  211\n",
      "reward :  -0.6372030314917608\n",
      "episode :  34\n",
      "current step :  212\n",
      "reward :  -0.637581009424767\n",
      "episode :  34\n",
      "current step :  213\n",
      "reward :  -0.6422688674189789\n",
      "episode :  34\n",
      "current step :  214\n",
      "reward :  -0.638384089251095\n",
      "episode :  34\n",
      "current step :  215\n",
      "reward :  -0.6354390596272439\n",
      "episode :  34\n",
      "current step :  216\n",
      "reward :  -0.6326242233096608\n",
      "episode :  34\n",
      "current step :  217\n",
      "reward :  -0.6247369609105085\n",
      "episode :  34\n",
      "current step :  218\n",
      "reward :  -0.6159169270061648\n",
      "episode :  34\n",
      "current step :  219\n",
      "reward :  -0.6054019881939823\n",
      "episode :  34\n",
      "current step :  220\n",
      "reward :  -0.598950192509622\n",
      "episode :  34\n",
      "current step :  221\n",
      "reward :  -0.5866127373777947\n",
      "episode :  34\n",
      "current step :  222\n",
      "reward :  -0.5822557813540312\n",
      "episode :  34\n",
      "current step :  223\n",
      "reward :  -0.5710397947840945\n",
      "episode :  34\n",
      "current step :  224\n",
      "reward :  -0.5685023705701813\n",
      "episode :  34\n",
      "current step :  225\n",
      "reward :  -0.5624706318154148\n",
      "episode :  34\n",
      "current step :  226\n",
      "reward :  -0.5448909508177456\n",
      "episode :  34\n",
      "current step :  227\n",
      "reward :  -0.5488370132991985\n",
      "episode :  34\n",
      "current step :  228\n",
      "reward :  -0.5370625616885917\n",
      "episode :  34\n",
      "current step :  229\n",
      "reward :  -0.5302121332443012\n",
      "episode :  34\n",
      "current step :  230\n",
      "reward :  -0.5255059804642855\n",
      "episode :  34\n",
      "current step :  231\n",
      "reward :  -0.5191294481257479\n",
      "episode :  34\n",
      "current step :  232\n",
      "reward :  -0.5119117560420547\n",
      "episode :  34\n",
      "current step :  233\n",
      "reward :  -0.5090876276090064\n",
      "episode :  34\n",
      "current step :  234\n",
      "reward :  -0.5028812147964712\n",
      "episode :  34\n",
      "current step :  235\n",
      "reward :  -0.5096360221888285\n",
      "episode :  34\n",
      "current step :  236\n",
      "reward :  -0.48805725540142497\n",
      "episode :  34\n",
      "current step :  237\n",
      "reward :  -0.49519740456494193\n",
      "episode :  34\n",
      "current step :  238\n",
      "reward :  -0.48773003089274003\n",
      "episode :  34\n",
      "current step :  239\n",
      "reward :  -0.4579082325628138\n",
      "episode :  34\n",
      "current step :  240\n",
      "reward :  -0.4404077838428149\n",
      "episode :  34\n",
      "current step :  241\n",
      "reward :  -0.4512838441463177\n",
      "episode :  34\n",
      "current step :  242\n",
      "reward :  -0.43413309864973754\n",
      "episode :  34\n",
      "current step :  243\n",
      "reward :  -0.4431376028447996\n",
      "episode :  34\n",
      "current step :  244\n",
      "reward :  -0.43325514050620045\n",
      "episode :  34\n",
      "current step :  245\n",
      "reward :  -0.42037422292249177\n",
      "episode :  34\n",
      "current step :  246\n",
      "reward :  -0.43160533351934705\n",
      "episode :  34\n",
      "current step :  247\n",
      "reward :  -0.442400025148544\n",
      "episode :  34\n",
      "current step :  248\n",
      "reward :  -0.4528915839456486\n",
      "episode :  34\n",
      "current step :  249\n",
      "reward :  -0.4485658429130472\n",
      "episode :  34\n",
      "current step :  250\n",
      "reward :  -0.4308695110099135\n",
      "episode :  34\n",
      "current step :  251\n",
      "reward :  -0.42949468186717243\n",
      "episode :  34\n",
      "current step :  252\n",
      "reward :  -0.43398702960288615\n",
      "episode :  34\n",
      "current step :  253\n",
      "reward :  -0.4372034872144253\n",
      "episode :  34\n",
      "current step :  254\n",
      "reward :  -0.44557249460794013\n",
      "episode :  34\n",
      "current step :  255\n",
      "reward :  -0.4475186564894558\n",
      "episode :  34\n",
      "current step :  256\n",
      "reward :  -0.4586246228980664\n",
      "episode :  34\n",
      "current step :  257\n",
      "reward :  -0.4673925605618105\n",
      "episode :  34\n",
      "current step :  258\n",
      "reward :  -0.4708216976651318\n",
      "episode :  34\n",
      "current step :  259\n",
      "reward :  -0.48611474945634503\n",
      "episode :  34\n",
      "current step :  260\n",
      "reward :  -0.4848040585792612\n",
      "episode :  34\n",
      "current step :  261\n",
      "reward :  -0.4901258207638297\n",
      "episode :  34\n",
      "current step :  262\n",
      "reward :  -0.4705007029180401\n",
      "episode :  34\n",
      "current step :  263\n",
      "reward :  -0.48008263747689156\n",
      "episode :  34\n",
      "current step :  264\n",
      "reward :  -0.48301541879586635\n",
      "episode :  34\n",
      "current step :  265\n",
      "reward :  -0.48356780266515126\n",
      "episode :  34\n",
      "current step :  266\n",
      "reward :  -0.4871607202539071\n",
      "episode :  34\n",
      "current step :  267\n",
      "reward :  -0.4975862908313688\n",
      "episode :  34\n",
      "current step :  268\n",
      "reward :  -0.4867108489290123\n",
      "episode :  34\n",
      "current step :  269\n",
      "reward :  -0.4862878785162266\n",
      "episode :  34\n",
      "current step :  270\n",
      "reward :  -0.4828160153890044\n",
      "episode :  34\n",
      "current step :  271\n",
      "reward :  -0.4868833437676742\n",
      "episode :  34\n",
      "current step :  272\n",
      "reward :  -0.49484487355459017\n",
      "episode :  34\n",
      "current step :  273\n",
      "reward :  -0.4945260388605172\n",
      "episode :  34\n",
      "current step :  274\n",
      "reward :  -0.4941385446414189\n",
      "episode :  34\n",
      "current step :  275\n",
      "reward :  -0.49691030234455824\n",
      "episode :  34\n"
     ]
    }
   ],
   "source": [
    "model = SAC('MlpPolicy', env, verbose=1)\n",
    "model.learn(total_timesteps=10000)\n",
    "model.save(\"sac_imitation\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "3812a3d7",
   "metadata": {},
   "source": [
    "The below is just some other tials, you can ignore it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c314bfa5",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
